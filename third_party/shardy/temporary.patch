diff --git a/third_party/llvm/generated.patch b/third_party/llvm/generated.patch
index 7f5123e..287d5b6 100644
--- a/third_party/llvm/generated.patch
+++ b/third_party/llvm/generated.patch
@@ -1,254 +1,326 @@
 Auto generated patch. Do not edit or delete it, even if empty.
-diff -ruN --strip-trailing-cr a/llvm/include/llvm/Analysis/LoopInfo.h b/llvm/include/llvm/Analysis/LoopInfo.h
---- a/llvm/include/llvm/Analysis/LoopInfo.h
-+++ b/llvm/include/llvm/Analysis/LoopInfo.h
-@@ -59,11 +59,12 @@
-   };
+diff -ruN --strip-trailing-cr a/clang/lib/AST/DeclarationName.cpp b/clang/lib/AST/DeclarationName.cpp
+--- a/clang/lib/AST/DeclarationName.cpp
++++ b/clang/lib/AST/DeclarationName.cpp
+@@ -113,6 +113,7 @@
+                                               PrintingPolicy Policy) {
+   // We know we're printing C++ here. Ensure we print types properly.
+   Policy.adjustForCPlusPlus();
++  Policy.SuppressScope = true;
  
-   /// Return true if the specified value is loop invariant.
--  bool isLoopInvariant(const Value *V) const;
-+  bool isLoopInvariant(const Value *V, bool HasCoroSuspendInst = false) const;
- 
-   /// Return true if all the operands of the specified instruction are loop
-   /// invariant.
--  bool hasLoopInvariantOperands(const Instruction *I) const;
-+  bool hasLoopInvariantOperands(const Instruction *I,
-+                                bool HasCoroSuspendInst = false) const;
- 
-   /// If the given value is an instruction inside of the loop and it can be
-   /// hoisted, do so to make it trivially loop-invariant.
-diff -ruN --strip-trailing-cr a/llvm/include/llvm/Transforms/Utils/LoopUtils.h b/llvm/include/llvm/Transforms/Utils/LoopUtils.h
---- a/llvm/include/llvm/Transforms/Utils/LoopUtils.h
-+++ b/llvm/include/llvm/Transforms/Utils/LoopUtils.h
-@@ -185,7 +185,8 @@
-                           TargetLibraryInfo *, Loop *, MemorySSAUpdater &,
-                           ScalarEvolution *, ICFLoopSafetyInfo *,
-                           SinkAndHoistLICMFlags &, OptimizationRemarkEmitter *,
--                          bool, bool AllowSpeculation);
-+                          bool, bool AllowSpeculation,
-+                          bool HasCoroSuspendInst = false);
- 
- /// Return true if the induction variable \p IV in a Loop whose latch is
- /// \p LatchBlock would become dead if the exit test \p Cond were removed.
-diff -ruN --strip-trailing-cr a/llvm/lib/Analysis/LoopInfo.cpp b/llvm/lib/Analysis/LoopInfo.cpp
---- a/llvm/lib/Analysis/LoopInfo.cpp
-+++ b/llvm/lib/Analysis/LoopInfo.cpp
-@@ -58,14 +58,26 @@
- // Loop implementation
- //
- 
--bool Loop::isLoopInvariant(const Value *V) const {
--  if (const Instruction *I = dyn_cast<Instruction>(V))
--    return !contains(I);
-+bool Loop::isLoopInvariant(const Value *V, bool HasCoroSuspendInst) const {
-+  if (const Instruction *I = dyn_cast<Instruction>(V)) {
-+    // FIXME: this is semantically inconsistent. We're tracking a proper fix in
-+    // issue #149604.
-+    // If V is a pointer to stack object and L contains a coro.suspend function
-+    // call, then V may not be loop invariant because the ramp function and
-+    // resume function have different stack frames.
-+    if (HasCoroSuspendInst && isa<AllocaInst>(I))
-+      return false;
-+    else
-+      return !contains(I);
-+  }
-   return true; // All non-instructions are loop invariant
+   if (const RecordType *ClassRec = ClassType->getAsCanonical<RecordType>()) {
+     ClassRec->getOriginalDecl()->printName(OS, Policy);
+diff -ruN --strip-trailing-cr a/clang/lib/AST/MicrosoftMangle.cpp b/clang/lib/AST/MicrosoftMangle.cpp
+--- a/clang/lib/AST/MicrosoftMangle.cpp
++++ b/clang/lib/AST/MicrosoftMangle.cpp
+@@ -3246,13 +3246,17 @@
  }
- 
--bool Loop::hasLoopInvariantOperands(const Instruction *I) const {
--  return all_of(I->operands(), [this](Value *V) { return isLoopInvariant(V); });
-+bool Loop::hasLoopInvariantOperands(const Instruction *I,
-+                                    bool HasCoroSuspendInst) const {
-+  return all_of(I->operands(), [&](Value *V) {
-+    return isLoopInvariant(V, HasCoroSuspendInst);
-+  });
+ void MicrosoftCXXNameMangler::mangleType(const EnumType *T, Qualifiers,
+                                          SourceRange) {
+-  mangleType(cast<TagType>(T)->getOriginalDecl()->getDefinitionOrSelf());
++  mangleType(cast<TagType>(T)->getOriginalDecl());
+ }
+ void MicrosoftCXXNameMangler::mangleType(const RecordType *T, Qualifiers,
+                                          SourceRange) {
+-  mangleType(cast<TagType>(T)->getOriginalDecl()->getDefinitionOrSelf());
++  mangleType(cast<TagType>(T)->getOriginalDecl());
+ }
+ void MicrosoftCXXNameMangler::mangleType(const TagDecl *TD) {
++  // MSVC chooses the tag kind of the definition if it exists, otherwise it
++  // always picks the first declaration.
++  const auto *Def = TD->getDefinition();
++  TD = Def ? Def : TD->getFirstDecl();
+   mangleTagTypeKind(TD->getTagKind());
+   mangleName(TD);
  }
+diff -ruN --strip-trailing-cr a/clang/lib/Sema/SemaDecl.cpp b/clang/lib/Sema/SemaDecl.cpp
+--- a/clang/lib/Sema/SemaDecl.cpp
++++ b/clang/lib/Sema/SemaDecl.cpp
+@@ -18544,8 +18544,14 @@
+   if (PrevDecl)
+     CheckRedeclarationInModule(New, PrevDecl);
  
- bool Loop::makeLoopInvariant(Value *V, bool &Changed, Instruction *InsertPt,
-diff -ruN --strip-trailing-cr a/llvm/lib/Target/NVPTX/NVPTXISelLowering.cpp b/llvm/lib/Target/NVPTX/NVPTXISelLowering.cpp
---- a/llvm/lib/Target/NVPTX/NVPTXISelLowering.cpp
-+++ b/llvm/lib/Target/NVPTX/NVPTXISelLowering.cpp
-@@ -680,6 +680,8 @@
-   // No support for these operations with v2f32.
-   setOperationAction(ISD::INSERT_VECTOR_ELT, MVT::v2f32, Expand);
-   setOperationAction(ISD::VECTOR_SHUFFLE, MVT::v2f32, Expand);
-+  // Need custom lowering in case the index is dynamic.
-+  setOperationAction(ISD::EXTRACT_VECTOR_ELT, MVT::v2f32, Custom);
- 
-   // Custom conversions to/from v2i8.
-   setOperationAction(ISD::BITCAST, MVT::v2i8, Custom);
-diff -ruN --strip-trailing-cr a/llvm/lib/Transforms/Scalar/LICM.cpp b/llvm/lib/Transforms/Scalar/LICM.cpp
---- a/llvm/lib/Transforms/Scalar/LICM.cpp
-+++ b/llvm/lib/Transforms/Scalar/LICM.cpp
-@@ -472,7 +472,7 @@
-   if (Preheader)
-     Changed |= hoistRegion(DT->getNode(L->getHeader()), AA, LI, DT, AC, TLI, L,
-                            MSSAU, SE, &SafetyInfo, Flags, ORE, LoopNestMode,
--                           LicmAllowSpeculation);
-+                           LicmAllowSpeculation, HasCoroSuspendInst);
- 
-   // Now that all loop invariants have been removed from the loop, promote any
-   // memory references to scalars that we can.
-@@ -881,7 +881,7 @@
-                        ICFLoopSafetyInfo *SafetyInfo,
-                        SinkAndHoistLICMFlags &Flags,
-                        OptimizationRemarkEmitter *ORE, bool LoopNestMode,
--                       bool AllowSpeculation) {
-+                       bool AllowSpeculation, bool HasCoroSuspendInst) {
-   // Verify inputs.
-   assert(N != nullptr && AA != nullptr && LI != nullptr && DT != nullptr &&
-          CurLoop != nullptr && SafetyInfo != nullptr &&
-@@ -914,11 +914,11 @@
-       // TODO: It may be safe to hoist if we are hoisting to a conditional block
-       // and we have accurately duplicated the control flow from the loop header
-       // to that block.
--      if (CurLoop->hasLoopInvariantOperands(&I) &&
-+      if (CurLoop->hasLoopInvariantOperands(&I, HasCoroSuspendInst) &&
-           canSinkOrHoistInst(I, AA, DT, CurLoop, MSSAU, true, Flags, ORE) &&
--          isSafeToExecuteUnconditionally(
--              I, DT, TLI, CurLoop, SafetyInfo, ORE,
--              Preheader->getTerminator(), AC, AllowSpeculation)) {
-+          isSafeToExecuteUnconditionally(I, DT, TLI, CurLoop, SafetyInfo, ORE,
-+                                         Preheader->getTerminator(), AC,
-+                                         AllowSpeculation)) {
-         hoist(I, DT, CurLoop, CFH.getOrCreateHoistedBlock(BB), SafetyInfo,
-               MSSAU, SE, ORE);
-         HoistedInstructions.push_back(&I);
-@@ -964,7 +964,7 @@
-                SafetyInfo->doesNotWriteMemoryBefore(I, CurLoop);
-       };
-       if ((IsInvariantStart(I) || isGuard(&I)) &&
--          CurLoop->hasLoopInvariantOperands(&I) &&
-+          CurLoop->hasLoopInvariantOperands(&I, HasCoroSuspendInst) &&
-           MustExecuteWithoutWritesBefore(I)) {
-         hoist(I, DT, CurLoop, CFH.getOrCreateHoistedBlock(BB), SafetyInfo,
-               MSSAU, SE, ORE);
-diff -ruN --strip-trailing-cr a/llvm/test/CodeGen/NVPTX/f32x2-instructions.ll b/llvm/test/CodeGen/NVPTX/f32x2-instructions.ll
---- a/llvm/test/CodeGen/NVPTX/f32x2-instructions.ll
-+++ b/llvm/test/CodeGen/NVPTX/f32x2-instructions.ll
-@@ -79,13 +79,24 @@
-   ret float %e
+-  if (TUK == TagUseKind::Definition && (!SkipBody || !SkipBody->ShouldSkip))
+-    New->startDefinition();
++  if (TUK == TagUseKind::Definition) {
++    if (!SkipBody || !SkipBody->ShouldSkip) {
++      New->startDefinition();
++    } else {
++      New->setCompleteDefinition();
++      New->demoteThisDefinitionToDeclaration();
++    }
++  }
+ 
+   ProcessDeclAttributeList(S, New, Attrs);
+   AddPragmaAttributes(S, New);
+diff -ruN --strip-trailing-cr a/clang/lib/Sema/SemaType.cpp b/clang/lib/Sema/SemaType.cpp
+--- a/clang/lib/Sema/SemaType.cpp
++++ b/clang/lib/Sema/SemaType.cpp
+@@ -9878,7 +9878,14 @@
+   S.DiagnoseUseOfDecl(ED, Loc);
+ 
+   QualType Underlying = ED->getIntegerType();
+-  assert(!Underlying.isNull());
++  if (Underlying.isNull()) {
++    // This is an enum without a fixed underlying type which we skipped parsing
++    // the body because we saw its definition previously in another module.
++    // Use the definition's integer type in that case.
++    assert(ED->isThisDeclarationADemotedDefinition());
++    Underlying = ED->getDefinition()->getIntegerType();
++    assert(!Underlying.isNull());
++  }
+ 
+   return Underlying;
  }
+diff -ruN --strip-trailing-cr a/clang/test/AST/ast-dump-decl.cpp b/clang/test/AST/ast-dump-decl.cpp
+--- a/clang/test/AST/ast-dump-decl.cpp
++++ b/clang/test/AST/ast-dump-decl.cpp
+@@ -330,8 +330,8 @@
+ // CHECK-NEXT:  | | `-Destructor irrelevant non_trivial user_declared{{$}}
+ // CHECK-NEXT:  | |-CXXRecordDecl 0x{{.+}} <col:24, col:30> col:30 implicit referenced class TestClassTemplate{{$}}
+ // CHECK-NEXT:  | |-AccessSpecDecl 0x{{.+}} <line:[[@LINE-50]]:3, col:9> col:3 public{{$}}
+-// CHECK-NEXT:  | |-CXXConstructorDecl 0x[[#%x,TEMPLATE_CONSTRUCTOR_DECL:]] <line:[[@LINE-50]]:5, col:23> col:5 testClassTemplateDecl::TestClassTemplate<T> 'void ()'{{$}}
+-// CHECK-NEXT:  | |-CXXDestructorDecl 0x[[#%x,TEMPLATE_DESTRUCTOR_DECL:]] <line:[[@LINE-50]]:5, col:24> col:5 ~testClassTemplateDecl::TestClassTemplate<T> 'void ()' not_selected{{$}}
++// CHECK-NEXT:  | |-CXXConstructorDecl 0x[[#%x,TEMPLATE_CONSTRUCTOR_DECL:]] <line:[[@LINE-50]]:5, col:23> col:5 TestClassTemplate<T> 'void ()'{{$}}
++// CHECK-NEXT:  | |-CXXDestructorDecl 0x[[#%x,TEMPLATE_DESTRUCTOR_DECL:]] <line:[[@LINE-50]]:5, col:24> col:5 ~TestClassTemplate<T> 'void ()' not_selected{{$}}
+ // CHECK-NEXT:  | |-CXXMethodDecl 0x[[#%x,TEMPLATE_METHOD_DECL:]] <line:[[@LINE-50]]:5, col:11> col:9 j 'int ()'{{$}}
+ // CHECK-NEXT:  | `-FieldDecl 0x{{.+}} <line:[[@LINE-50]]:5, col:9> col:9 i 'int'{{$}}
+ // CHECK-NEXT:  |-ClassTemplateSpecializationDecl 0x{{.+}} <line:[[@LINE-56]]:3, line:[[@LINE-50]]:3> line:[[@LINE-56]]:30 class TestClassTemplate definition implicit_instantiation{{$}}
+diff -ruN --strip-trailing-cr a/clang/test/AST/ast-dump-templates.cpp b/clang/test/AST/ast-dump-templates.cpp
+--- a/clang/test/AST/ast-dump-templates.cpp
++++ b/clang/test/AST/ast-dump-templates.cpp
+@@ -8170,7 +8170,7 @@
+ // JSON-NEXT:              "tokLen": 1
+ // JSON-NEXT:             }
+ // JSON-NEXT:            },
+-// JSON-NEXT:            "name": "GH153540::N::S<T>",
++// JSON-NEXT:            "name": "S<T>",
+ // JSON-NEXT:            "type": {
+ // JSON-NEXT:             "qualType": "void (T)"
+ // JSON-NEXT:            },
+diff -ruN --strip-trailing-cr a/clang/test/AST/HLSL/StructuredBuffers-AST.hlsl b/clang/test/AST/HLSL/StructuredBuffers-AST.hlsl
+--- a/clang/test/AST/HLSL/StructuredBuffers-AST.hlsl
++++ b/clang/test/AST/HLSL/StructuredBuffers-AST.hlsl
+@@ -91,7 +91,7 @@
  
--; NOTE: disabled as -O3 miscompiles this into pointer arithmetic on
--; test_extract_i_param_0 where the symbol's address is not taken first (that
--; is, moved to a temporary)
--; define float @test_extract_i(<2 x float> %a, i64 %idx) #0 {
--;   %e = extractelement <2 x float> %a, i64 %idx
--;   ret float %e
--; }
-+define float @test_extract_i(<2 x float> %a, i64 %idx) #0 {
-+; CHECK-LABEL: test_extract_i(
-+; CHECK:       {
-+; CHECK-NEXT:    .reg .pred %p<2>;
-+; CHECK-NEXT:    .reg .b32 %r<4>;
-+; CHECK-NEXT:    .reg .b64 %rd<3>;
-+; CHECK-EMPTY:
-+; CHECK-NEXT:  // %bb.0:
-+; CHECK-NEXT:    ld.param.b64 %rd2, [test_extract_i_param_1];
-+; CHECK-NEXT:    ld.param.b64 %rd1, [test_extract_i_param_0];
-+; CHECK-NEXT:    setp.eq.b64 %p1, %rd2, 0;
-+; CHECK-NEXT:    mov.b64 {%r1, %r2}, %rd1;
-+; CHECK-NEXT:    selp.f32 %r3, %r1, %r2, %p1;
-+; CHECK-NEXT:    st.param.b32 [func_retval0], %r3;
-+; CHECK-NEXT:    ret;
-+  %e = extractelement <2 x float> %a, i64 %idx
-+  ret float %e
-+}
+ // Default constructor
+ 
+-// CHECK: CXXConstructorDecl {{.*}} hlsl::[[RESOURCE]]<element_type> 'void ()' inline
++// CHECK: CXXConstructorDecl {{.*}} [[RESOURCE]]<element_type> 'void ()' inline
+ // CHECK-NEXT: CompoundStmt
+ // CHECK-NEXT: BinaryOperator {{.*}} '='
+ // CHECK-NEXT: MemberExpr {{.*}} lvalue .__handle
+@@ -105,7 +105,7 @@
+ 
+ // Constructor from binding
+ 
+-// CHECK: CXXConstructorDecl {{.*}} hlsl::[[RESOURCE]]<element_type> 'void (unsigned int, unsigned int, int, unsigned int, const char *)' inline
++// CHECK: CXXConstructorDecl {{.*}} [[RESOURCE]]<element_type> 'void (unsigned int, unsigned int, int, unsigned int, const char *)' inline
+ // CHECK-NEXT: ParmVarDecl {{.*}} registerNo 'unsigned int'
+ // CHECK-NEXT: ParmVarDecl {{.*}} spaceNo 'unsigned int'
+ // CHECK-NEXT: ParmVarDecl {{.*}} range 'int'
+@@ -129,7 +129,7 @@
+ 
+ // Constructor from implicit binding
+ 
+-// CHECK: CXXConstructorDecl {{.*}} hlsl::[[RESOURCE]]<element_type> 'void (unsigned int, int, unsigned int, unsigned int, const char *)' inline
++// CHECK: CXXConstructorDecl {{.*}} [[RESOURCE]]<element_type> 'void (unsigned int, int, unsigned int, unsigned int, const char *)' inline
+ // CHECK-NEXT: ParmVarDecl {{.*}} spaceNo 'unsigned int'
+ // CHECK-NEXT: ParmVarDecl {{.*}} range 'int'
+ // CHECK-NEXT: ParmVarDecl {{.*}} index 'unsigned int'
+diff -ruN --strip-trailing-cr a/clang/test/AST/HLSL/TypedBuffers-AST.hlsl b/clang/test/AST/HLSL/TypedBuffers-AST.hlsl
+--- a/clang/test/AST/HLSL/TypedBuffers-AST.hlsl
++++ b/clang/test/AST/HLSL/TypedBuffers-AST.hlsl
+@@ -66,7 +66,7 @@
+ 
+ // Default constructor
  
- define <2 x float> @test_fadd(<2 x float> %a, <2 x float> %b) #0 {
- ; CHECK-NOF32X2-LABEL: test_fadd(
-diff -ruN --strip-trailing-cr a/llvm/test/Transforms/LICM/licm-coroutine.ll b/llvm/test/Transforms/LICM/licm-coroutine.ll
---- a/llvm/test/Transforms/LICM/licm-coroutine.ll
-+++ b/llvm/test/Transforms/LICM/licm-coroutine.ll
-@@ -0,0 +1,78 @@
-+; NOTE: Assertions have been autogenerated by utils/update_test_checks.py UTC_ARGS: --version 5
-+; RUN: opt < %s -passes=licm -S | FileCheck %s
+-// CHECK: CXXConstructorDecl {{.*}} hlsl::[[RESOURCE]]<element_type> 'void ()' inline
++// CHECK: CXXConstructorDecl {{.*}} [[RESOURCE]]<element_type> 'void ()' inline
+ // CHECK-NEXT: CompoundStmt
+ // CHECK-NEXT: BinaryOperator {{.*}} '='
+ // CHECK-NEXT: MemberExpr {{.*}} lvalue .__handle
+@@ -80,7 +80,7 @@
+ 
+ // Constructor from binding
+ 
+-// CHECK: CXXConstructorDecl {{.*}} hlsl::[[RESOURCE]]<element_type> 'void (unsigned int, unsigned int, int, unsigned int, const char *)' inline
++// CHECK: CXXConstructorDecl {{.*}} [[RESOURCE]]<element_type> 'void (unsigned int, unsigned int, int, unsigned int, const char *)' inline
+ // CHECK-NEXT: ParmVarDecl {{.*}} registerNo 'unsigned int'
+ // CHECK-NEXT: ParmVarDecl {{.*}} spaceNo 'unsigned int'
+ // CHECK-NEXT: ParmVarDecl {{.*}} range 'int'
+@@ -104,7 +104,7 @@
+ 
+ // Constructor from implicit binding
+ 
+-// CHECK: CXXConstructorDecl {{.*}} hlsl::[[RESOURCE]]<element_type> 'void (unsigned int, int, unsigned int, unsigned int, const char *)' inline
++// CHECK: CXXConstructorDecl {{.*}} [[RESOURCE]]<element_type> 'void (unsigned int, int, unsigned int, unsigned int, const char *)' inline
+ // CHECK-NEXT: ParmVarDecl {{.*}} spaceNo 'unsigned int'
+ // CHECK-NEXT: ParmVarDecl {{.*}} range 'int'
+ // CHECK-NEXT: ParmVarDecl {{.*}} index 'unsigned int'
+diff -ruN --strip-trailing-cr a/clang/test/CodeGenCXX/mangle-ms-cxx11.cpp b/clang/test/CodeGenCXX/mangle-ms-cxx11.cpp
+--- a/clang/test/CodeGenCXX/mangle-ms-cxx11.cpp
++++ b/clang/test/CodeGenCXX/mangle-ms-cxx11.cpp
+@@ -358,3 +358,42 @@
+ // DBG-DAG: DW_TAG_enumeration_type{{.*}}identifier: ".?AW4<unnamed-type-$S3>@s@pr37723@@"
+ s x;
+ }
 +
-+; %fca.0 and %fca.1 should not be hoisted out of the loop because the ramp
-+; function and resume function have different stack frames, so %pointer1 and
-+; %pointer2 have different values before and after @llvm.coro.suspend.
++namespace InconsistentTagKinds {
++  namespace t1 {
++    class A;
++    struct A;
++    void f(A*) {}
++    // CHECK-DAG: @"?f@t1@InconsistentTagKinds@@YAXPAVA@12@@Z"
++  } // namespace t1
++  namespace t2 {
++    struct A;
++    class A;
++    void f(A*) {}
++    // CHECK-DAG: @"?f@t2@InconsistentTagKinds@@YAXPAUA@12@@Z"
++  } // namespace t2
++  namespace t3 {
++    class A {};
++    struct A;
++    void f(A*) {}
++    // CHECK-DAG: @"?f@t3@InconsistentTagKinds@@YAXPAVA@12@@Z"
++  } // namespace t3
++  namespace t4 {
++    struct A {};
++    class A;
++    void f(A*) {}
++    // CHECK-DAG: @"?f@t4@InconsistentTagKinds@@YAXPAUA@12@@Z"
++  } // namespace t4
++  namespace t5 {
++    class A;
++    struct A {};
++    void f(A*) {}
++    // CHECK-DAG: @"?f@t5@InconsistentTagKinds@@YAXPAUA@12@@Z"
++  } // namespace t5
++  namespace t6 {
++    struct A;
++    class A {};
++    void f(A*) {}
++    // CHECK-DAG: @"?f@t6@InconsistentTagKinds@@YAXPAVA@12@@Z"
++  } // namespace t6
++} // namespace InconsistentTagKinds
+diff -ruN --strip-trailing-cr a/clang/test/CXX/drs/cwg6xx.cpp b/clang/test/CXX/drs/cwg6xx.cpp
+--- a/clang/test/CXX/drs/cwg6xx.cpp
++++ b/clang/test/CXX/drs/cwg6xx.cpp
+@@ -383,7 +383,7 @@
+   template<typename T> template<typename U> D<T>::D() {}
+   template<typename T> D<T>::D<T>() {} // #cwg635-D-T
+   // expected-error@#cwg635-D-T {{out-of-line constructor for 'D' cannot have template arguments}}
+-  // expected-error@#cwg635-D-T {{redefinition of 'cwg635::D<T>'}}
++  // expected-error@#cwg635-D-T {{redefinition of 'D<T>'}}
+   //   expected-note@#cwg635-D {{previous definition is here}}
+ } // namespace cwg635
+ 
+diff -ruN --strip-trailing-cr a/clang/test/Index/recursive-cxx-member-calls.cpp b/clang/test/Index/recursive-cxx-member-calls.cpp
+--- a/clang/test/Index/recursive-cxx-member-calls.cpp
++++ b/clang/test/Index/recursive-cxx-member-calls.cpp
+@@ -823,18 +823,18 @@
+ // CHECK-tokens: Punctuation: ";" [85:18 - 85:19] ClassTemplate=StringSwitch:83:47 (Definition)
+ // CHECK-tokens: Keyword: "public" [86:1 - 86:7] CXXAccessSpecifier=:86:1 (Definition)
+ // CHECK-tokens: Punctuation: ":" [86:7 - 86:8] CXXAccessSpecifier=:86:1 (Definition)
+-// CHECK-tokens: Keyword: "explicit" [87:3 - 87:11] CXXConstructor=llvm::StringSwitch<T, R>:87:12 (Definition)
+-// CHECK-tokens: Identifier: "StringSwitch" [87:12 - 87:24] CXXConstructor=llvm::StringSwitch<T, R>:87:12 (Definition) (explicit)
+-// CHECK-tokens: Punctuation: "(" [87:24 - 87:25] CXXConstructor=llvm::StringSwitch<T, R>:87:12 (Definition)
++// CHECK-tokens: Keyword: "explicit" [87:3 - 87:11] CXXConstructor=StringSwitch<T, R>:87:12 (Definition)
++// CHECK-tokens: Identifier: "StringSwitch" [87:12 - 87:24] CXXConstructor=StringSwitch<T, R>:87:12 (Definition) (explicit)
++// CHECK-tokens: Punctuation: "(" [87:24 - 87:25] CXXConstructor=StringSwitch<T, R>:87:12 (Definition)
+ // CHECK-tokens: Identifier: "StringRef" [87:25 - 87:34] TypeRef=class llvm::StringRef:38:7
+ // CHECK-tokens: Identifier: "Str" [87:35 - 87:38] ParmDecl=Str:87:35 (Definition)
+-// CHECK-tokens: Punctuation: ")" [87:38 - 87:39] CXXConstructor=llvm::StringSwitch<T, R>:87:12 (Definition)
+-// CHECK-tokens: Punctuation: ":" [87:40 - 87:41] CXXConstructor=llvm::StringSwitch<T, R>:87:12 (Definition)
++// CHECK-tokens: Punctuation: ")" [87:38 - 87:39] CXXConstructor=StringSwitch<T, R>:87:12 (Definition)
++// CHECK-tokens: Punctuation: ":" [87:40 - 87:41] CXXConstructor=StringSwitch<T, R>:87:12 (Definition)
+ // CHECK-tokens: Identifier: "Str" [87:42 - 87:45] MemberRef=Str:84:13
+ // CHECK-tokens: Punctuation: "(" [87:45 - 87:46] CallExpr=StringRef:38:7
+ // CHECK-tokens: Identifier: "Str" [87:46 - 87:49] DeclRefExpr=Str:87:35
+ // CHECK-tokens: Punctuation: ")" [87:49 - 87:50] CallExpr=StringRef:38:7
+-// CHECK-tokens: Punctuation: "," [87:50 - 87:51] CXXConstructor=llvm::StringSwitch<T, R>:87:12 (Definition)
++// CHECK-tokens: Punctuation: "," [87:50 - 87:51] CXXConstructor=StringSwitch<T, R>:87:12 (Definition)
+ // CHECK-tokens: Identifier: "Result" [87:52 - 87:58] MemberRef=Result:85:12
+ // CHECK-tokens: Punctuation: "(" [87:58 - 87:59] UnexposedExpr=
+ // CHECK-tokens: Literal: "0" [87:59 - 87:60] IntegerLiteral=
+@@ -1839,7 +1839,7 @@
+ // CHECK: 84:3: TypeRef=class llvm::StringRef:38:7 Extent=[84:3 - 84:12]
+ // CHECK: 85:12: FieldDecl=Result:85:12 (Definition) Extent=[85:3 - 85:18]
+ // CHECK: 86:1: CXXAccessSpecifier=:86:1 (Definition) Extent=[86:1 - 86:8]
+-// CHECK: 87:12: CXXConstructor=llvm::StringSwitch<T, R>:87:12 (Definition) (explicit) Extent=[87:3 - 87:64]
++// CHECK: 87:12: CXXConstructor=StringSwitch<T, R>:87:12 (Definition) (explicit) Extent=[87:3 - 87:64]
+ // CHECK: 87:35: ParmDecl=Str:87:35 (Definition) Extent=[87:25 - 87:38]
+ // CHECK: 87:25: TypeRef=class llvm::StringRef:38:7 Extent=[87:25 - 87:34]
+ // CHECK: 87:42: MemberRef=Str:84:13 Extent=[87:42 - 87:45]
+diff -ruN --strip-trailing-cr a/clang/test/Modules/GH155028-1.cpp b/clang/test/Modules/GH155028-1.cpp
+--- a/clang/test/Modules/GH155028-1.cpp
++++ b/clang/test/Modules/GH155028-1.cpp
+@@ -0,0 +1,17 @@
++// RUN: %clang_cc1 -std=c++20 -verify %s
++// expected-no-diagnostics
 +
-+define ptr @f(i32 %n) presplitcoroutine {
-+; CHECK-LABEL: define ptr @f(
-+; CHECK-SAME: i32 [[N:%.*]]) #[[ATTR0:[0-9]+]] {
-+; CHECK-NEXT:  [[ENTRY:.*]]:
-+; CHECK-NEXT:    [[POINTER1:%.*]] = alloca ptr, align 8
-+; CHECK-NEXT:    [[POINTER2:%.*]] = alloca ptr, align 8
-+; CHECK-NEXT:    [[ID:%.*]] = call token @llvm.coro.id(i32 0, ptr null, ptr null, ptr null)
-+; CHECK-NEXT:    [[SIZE:%.*]] = call i32 @llvm.coro.size.i32()
-+; CHECK-NEXT:    [[ALLOC:%.*]] = call ptr @malloc(i32 [[SIZE]])
-+; CHECK-NEXT:    [[HDL:%.*]] = call noalias ptr @llvm.coro.begin(token [[ID]], ptr [[ALLOC]])
-+; CHECK-NEXT:    br label %[[LOOP:.*]]
-+; CHECK:       [[LOOP]]:
-+; CHECK-NEXT:    [[N_VAL:%.*]] = phi i32 [ [[N]], %[[ENTRY]] ], [ [[INC:%.*]], %[[RESUME:.*]] ]
-+; CHECK-NEXT:    [[INC]] = add nsw i32 [[N_VAL]], 1
-+; CHECK-NEXT:    call void @print(i32 [[N_VAL]])
-+; CHECK-NEXT:    [[TMP0:%.*]] = call i8 @llvm.coro.suspend(token none, i1 false)
-+; CHECK-NEXT:    switch i8 [[TMP0]], label %[[SUSPEND_LOOPEXIT:.*]] [
-+; CHECK-NEXT:      i8 0, label %[[RESUME]]
-+; CHECK-NEXT:      i8 1, label %[[CLEANUP:.*]]
-+; CHECK-NEXT:    ]
-+; CHECK:       [[RESUME]]:
-+; CHECK-NEXT:    [[FCA_0:%.*]] = insertvalue [2 x ptr] poison, ptr [[POINTER1]], 0
-+; CHECK-NEXT:    [[FCA_1:%.*]] = insertvalue [2 x ptr] [[FCA_0]], ptr [[POINTER2]], 1
-+; CHECK-NEXT:    call void @foo([2 x ptr] [[FCA_1]])
-+; CHECK-NEXT:    br label %[[LOOP]]
-+; CHECK:       [[CLEANUP]]:
-+; CHECK-NEXT:    [[MEM:%.*]] = call ptr @llvm.coro.free(token [[ID]], ptr [[HDL]])
-+; CHECK-NEXT:    call void @free(ptr [[MEM]])
-+; CHECK-NEXT:    br label %[[SUSPEND:.*]]
-+; CHECK:       [[SUSPEND_LOOPEXIT]]:
-+; CHECK-NEXT:    br label %[[SUSPEND]]
-+; CHECK:       [[SUSPEND]]:
-+; CHECK-NEXT:    [[UNUSED:%.*]] = call i1 @llvm.coro.end(ptr [[HDL]], i1 false, token none)
-+; CHECK-NEXT:    ret ptr [[HDL]]
-+;
-+entry:
-+  %pointer1 = alloca ptr
-+  %pointer2 = alloca ptr
-+  %id = call token @llvm.coro.id(i32 0, ptr null, ptr null, ptr null)
-+  %size = call i32 @llvm.coro.size.i32()
-+  %alloc = call ptr @malloc(i32 %size)
-+  %hdl = call noalias ptr @llvm.coro.begin(token %id, ptr %alloc)
-+  br label %loop
++#pragma clang module build M
++module "M" {
++  module "A" {}
++  module "B" {}
++}
++#pragma clang module contents
++#pragma clang module begin M.A
++enum E1 {};
++#pragma clang module end
++#pragma clang module begin M.B
++enum E1 {};
++using T = __underlying_type(E1);
++#pragma clang module end
++#pragma clang module endbuild
+diff -ruN --strip-trailing-cr a/clang/test/PCH/cxx-explicit-specifier.cpp b/clang/test/PCH/cxx-explicit-specifier.cpp
+--- a/clang/test/PCH/cxx-explicit-specifier.cpp
++++ b/clang/test/PCH/cxx-explicit-specifier.cpp
+@@ -85,7 +85,7 @@
+ //expected-note@-8+ {{explicit conversion function is not a candidate (explicit specifier}}
+ //expected-note@-11 {{explicit constructor is not a candidate (explicit specifier}}
+ 
+-//CHECK: explicit(b){{ +}}templ::A<b>(B<b>)
++//CHECK: explicit(b){{ +}}A
+ //CHECK: explicit(b{{ +}}^{{ +}}T::value){{ +}}operator
+ 
+ A a = { b_true }; //expected-error {{class template argument deduction}}
+diff -ruN --strip-trailing-cr a/clang/test/SemaCXX/return.cpp b/clang/test/SemaCXX/return.cpp
+--- a/clang/test/SemaCXX/return.cpp
++++ b/clang/test/SemaCXX/return.cpp
+@@ -115,9 +115,9 @@
+   };
+ 
+   template <typename T> struct ST {
+-    ST() { return f(); } // expected-error {{constructor 'ctor_returns_void::ST<T>' must not return void expression}}
++    ST() { return f(); } // expected-error {{constructor 'ST<T>' must not return void expression}}
+                          // expected-error@-1 {{constructor 'ST' must not return void expression}}
+-    ~ST() { return f(); } // expected-error {{destructor '~ctor_returns_void::ST<T>' must not return void expression}}
++    ~ST() { return f(); } // expected-error {{destructor '~ST<T>' must not return void expression}}
+                           // expected-error@-1 {{destructor '~ST' must not return void expression}}
+   };
+ 
+diff -ruN --strip-trailing-cr a/clang/unittests/AST/DeclTest.cpp b/clang/unittests/AST/DeclTest.cpp
+--- a/clang/unittests/AST/DeclTest.cpp
++++ b/clang/unittests/AST/DeclTest.cpp
+@@ -570,3 +570,19 @@
+   EXPECT_EQ(GetNameInfoRange(Matches[1]), "<input.cc:6:14, col:15>");
+   EXPECT_EQ(GetNameInfoRange(Matches[2]), "<input.cc:6:14, col:15>");
+ }
 +
-+loop:
-+  %n.val = phi i32 [ %n, %entry ], [ %inc, %resume ]
-+  %inc = add nsw i32 %n.val, 1
-+  call void @print(i32 %n.val)
-+  %0 = call i8 @llvm.coro.suspend(token none, i1 false)
-+  switch i8 %0, label %suspend [i8 0, label %resume
-+  i8 1, label %cleanup]
++TEST(Decl, getQualifiedNameAsString) {
++  llvm::Annotations Code(R"cpp(
++namespace x::y {
++  template <class T> class Foo { Foo() {} };
++}
++)cpp");
 +
-+resume:
-+  %fca.0 = insertvalue [2 x ptr] poison, ptr %pointer1, 0
-+  %fca.1 = insertvalue [2 x ptr] %fca.0, ptr %pointer2, 1
-+  call void @foo([2 x ptr] %fca.1)
-+  br label %loop
++  auto AST = tooling::buildASTFromCode(Code.code());
++  ASTContext &Ctx = AST->getASTContext();
 +
-+cleanup:
-+  %mem = call ptr @llvm.coro.free(token %id, ptr %hdl)
-+  call void @free(ptr %mem)
-+  br label %suspend
-+suspend:
-+  %unused = call i1 @llvm.coro.end(ptr %hdl, i1 false, token none)
-+  ret ptr %hdl
++  auto const *FD = selectFirst<CXXConstructorDecl>(
++      "ctor", match(cxxConstructorDecl().bind("ctor"), Ctx));
++  ASSERT_NE(FD, nullptr);
++  ASSERT_EQ(FD->getQualifiedNameAsString(), "x::y::Foo::Foo<T>");
 +}
-+
-+declare void @free(ptr)
-+declare ptr @malloc(i32)
-+declare void @print(i32)
-+declare void @foo([2 x ptr])
-diff -ruN --strip-trailing-cr a/mlir/test/Dialect/Linalg/linalg-morph-category-ops.mlir b/mlir/test/Dialect/Linalg/linalg-morph-category-ops.mlir
---- a/mlir/test/Dialect/Linalg/linalg-morph-category-ops.mlir
-+++ b/mlir/test/Dialect/Linalg/linalg-morph-category-ops.mlir
-@@ -2,7 +2,7 @@
- // RUN: mlir-opt %s -linalg-morph-ops=named-to-category | FileCheck %s  --check-prefix=NAMED_TO_CATEGORY
- 
- // RUN: mlir-opt %s -linalg-morph-ops=named-to-category |  \
--// RUN:   mlir-opt %s -linalg-morph-ops=category-to-generic | FileCheck %s  --check-prefix=CATEGORY_TO_GENERIC
-+// RUN:   mlir-opt -linalg-morph-ops=category-to-generic | FileCheck %s  --check-prefix=CATEGORY_TO_GENERIC
- 
- func.func @exp(%A : tensor<16x8xf32>, %B : tensor<16x8xf32>) ->  tensor<16x8xf32> {
-   %exp = linalg.exp ins(%A : tensor<16x8xf32>) outs(%B :  tensor<16x8xf32>) -> tensor<16x8xf32>
diff --git a/third_party/llvm/workspace.bzl b/third_party/llvm/workspace.bzl
index e54cc0d..704ed7a 100644
--- a/third_party/llvm/workspace.bzl
+++ b/third_party/llvm/workspace.bzl
@@ -4,8 +4,8 @@ load("//third_party:repo.bzl", "tf_http_archive")
 
 def repo(name):
     """Imports LLVM."""
-    LLVM_COMMIT = "fc44a4fcd3c54be927c15ddd9211aca1501633e7"
-    LLVM_SHA256 = "d228aebe5583c69c4e48fd7a8e149e3d22ee6dafaeae94009467143d32d9bfc4"
+    LLVM_COMMIT = "aa46657c127f478206bda91aa67db2cfb8f37335"
+    LLVM_SHA256 = "e13798bf4cd06ff3e1eeff4535daa34980633ce7fa52f220ab27fc5687c768ab"
 
     tf_http_archive(
         name = name,
diff --git a/third_party/stablehlo/temporary.patch b/third_party/stablehlo/temporary.patch
index 1fcd9fd..9a6635f 100755
--- a/third_party/stablehlo/temporary.patch
+++ b/third_party/stablehlo/temporary.patch
@@ -4706,1500 +4706,4 @@ diff --ruN a/stablehlo/stablehlo/integrations/cpp/builder/StablehloBuilderTest.c
 -
 -}  // namespace stablehlo
 -}  // namespace mlir
-diff --ruN a/stablehlo/stablehlo/tests/transforms/stablehlo_aggressive_folder.mlir b/stablehlo/stablehlo/tests/transforms/stablehlo_aggressive_folder.mlir
---- stablehlo/stablehlo/tests/transforms/stablehlo_aggressive_folder.mlir
-+++ stablehlo/stablehlo/tests/transforms/stablehlo_aggressive_folder.mlir
-@@ -150,8 +150,8 @@
- ////////
- // CompareOp
- 
--// CHECK-LABEL: func.func @compare_folds
--func.func @compare_folds()
-+// CHECK-LABEL: func.func @compare_fold_int
-+func.func @compare_fold_int()
-   -> (tensor<i1>, tensor<i1>, tensor<i1>, tensor<i1>, tensor<i1>, tensor<i1>, tensor<i1>, tensor<i1>) {
-   %cn1 = stablehlo.constant dense<-1> : tensor<i32>
-   %c0 = stablehlo.constant dense<0> : tensor<i32>
-@@ -176,6 +176,270 @@
-          tensor<i1>, tensor<i1>, tensor<i1>, tensor<i1>, tensor<i1>, tensor<i1>, tensor<i1>, tensor<i1>
- }
- 
-+// -----
-+
-+// CHECK-LABEL: func.func @compare_fold_float
-+func.func @compare_fold_float()
-+  -> (tensor<i1>, tensor<i1>, tensor<i1>, tensor<i1>, tensor<i1>, tensor<i1>, tensor<i1>, tensor<i1>, tensor<i1>, tensor<i1>, tensor<i1>, tensor<i1>) {
-+  %c0 = stablehlo.constant dense<0.0> : tensor<f32>
-+  %c1 = stablehlo.constant dense<0.01> : tensor<f32>
-+  %c2 = stablehlo.constant dense<-0.01> : tensor<f32>
-+  %c3 = stablehlo.constant dense<42.1> : tensor<f32>
-+  %c4 = stablehlo.constant dense<-50.0> : tensor<f32>
-+
-+  %0 = stablehlo.compare EQ, %c0, %c0, FLOAT : (tensor<f32>, tensor<f32>) -> tensor<i1>
-+  %1 = stablehlo.compare EQ, %c1, %c2, FLOAT : (tensor<f32>, tensor<f32>) -> tensor<i1>
-+  %2 = stablehlo.compare NE, %c0, %c0, FLOAT : (tensor<f32>, tensor<f32>) -> tensor<i1>
-+  %3 = stablehlo.compare NE, %c1, %c2, FLOAT : (tensor<f32>, tensor<f32>) -> tensor<i1>
-+  %4 = stablehlo.compare GT, %c3, %c3, FLOAT : (tensor<f32>, tensor<f32>) -> tensor<i1>
-+  %5 = stablehlo.compare GT, %c3, %c4, FLOAT : (tensor<f32>, tensor<f32>) -> tensor<i1>
-+  %6 = stablehlo.compare GE, %c3, %c3, FLOAT : (tensor<f32>, tensor<f32>) -> tensor<i1>
-+  %7 = stablehlo.compare GE, %c3, %c4, FLOAT : (tensor<f32>, tensor<f32>) -> tensor<i1>
-+  %8 = stablehlo.compare LT, %c2, %c2, FLOAT : (tensor<f32>, tensor<f32>) -> tensor<i1>
-+  %9 = stablehlo.compare LT, %c2, %c4, FLOAT : (tensor<f32>, tensor<f32>) -> tensor<i1>
-+  %10 = stablehlo.compare LE, %c2, %c2, FLOAT : (tensor<f32>, tensor<f32>) -> tensor<i1>
-+  %11 = stablehlo.compare LE, %c2, %c4, FLOAT : (tensor<f32>, tensor<f32>) -> tensor<i1>
-+
-+  // CHECK-DAG:  [[FALSE:%.+]] = stablehlo.constant dense<false> : tensor<i1>
-+  // CHECK-DAG:  [[TRUE:%.+]] = stablehlo.constant dense<true> : tensor<i1>
-+
-+  // CHECK-NEXT: return [[TRUE]], [[FALSE]], [[FALSE]], [[TRUE]], [[FALSE]], [[TRUE]], [[TRUE]], [[TRUE]], [[FALSE]], [[FALSE]], [[TRUE]], [[FALSE]]
-+  return %0, %1, %2, %3, %4, %5, %6, %7, %8, %9, %10, %11 :
-+         tensor<i1>, tensor<i1>, tensor<i1>, tensor<i1>, tensor<i1>, tensor<i1>, tensor<i1>, tensor<i1>, tensor<i1>, tensor<i1>, tensor<i1>, tensor<i1>
-+}
-+
-+// -----
-+
-+// CHECK-LABEL: func.func @compare_fold_float_edge_cases
-+func.func @compare_fold_float_edge_cases()
-+  -> (tensor<i1>, tensor<i1>, tensor<i1>, tensor<i1>,
-+      tensor<i1>, tensor<i1>, tensor<i1>, tensor<i1>,
-+      tensor<i1>, tensor<i1>, tensor<i1>, tensor<i1>,
-+      tensor<i1>, tensor<i1>, tensor<i1>, tensor<i1>,
-+
-+      tensor<i1>, tensor<i1>, tensor<i1>, tensor<i1>,
-+      tensor<i1>, tensor<i1>, tensor<i1>, tensor<i1>,
-+      tensor<i1>, tensor<i1>, tensor<i1>, tensor<i1>,
-+      tensor<i1>, tensor<i1>, tensor<i1>, tensor<i1>,
-+
-+      tensor<i1>, tensor<i1>, tensor<i1>, tensor<i1>,
-+      tensor<i1>, tensor<i1>, tensor<i1>, tensor<i1>,
-+      tensor<i1>, tensor<i1>, tensor<i1>, tensor<i1>,
-+      tensor<i1>, tensor<i1>, tensor<i1>, tensor<i1>,
-+
-+      tensor<i1>, tensor<i1>, tensor<i1>, tensor<i1>,
-+      tensor<i1>, tensor<i1>, tensor<i1>, tensor<i1>,
-+      tensor<i1>, tensor<i1>, tensor<i1>, tensor<i1>,
-+      tensor<i1>, tensor<i1>, tensor<i1>, tensor<i1>,
-+
-+      tensor<i1>, tensor<i1>, tensor<i1>, tensor<i1>,
-+      tensor<i1>, tensor<i1>, tensor<i1>, tensor<i1>,
-+      tensor<i1>, tensor<i1>, tensor<i1>, tensor<i1>,
-+      tensor<i1>, tensor<i1>, tensor<i1>, tensor<i1>,
-+
-+      tensor<i1>, tensor<i1>, tensor<i1>, tensor<i1>,
-+      tensor<i1>, tensor<i1>, tensor<i1>, tensor<i1>,
-+      tensor<i1>, tensor<i1>, tensor<i1>, tensor<i1>,
-+      tensor<i1>, tensor<i1>, tensor<i1>, tensor<i1>) {
-+  %zero = stablehlo.constant dense<0.0> : tensor<f32>
-+  %pos_inf = stablehlo.constant dense<0x7F800000> : tensor<f32>
-+  %neg_inf = stablehlo.constant dense<0xFF800000> : tensor<f32>
-+  %nan = stablehlo.constant dense<0x7FC00000> : tensor<f32>
-+
-+  // CHECK-DAG:  [[FALSE:%.+]] = stablehlo.constant dense<false> : tensor<i1>
-+  // CHECK-DAG:  [[TRUE:%.+]] = stablehlo.constant dense<true> : tensor<i1>
-+
-+  %0 = stablehlo.compare EQ, %zero, %zero, FLOAT : (tensor<f32>, tensor<f32>) -> tensor<i1>
-+  %1 = stablehlo.compare EQ, %zero, %pos_inf, FLOAT : (tensor<f32>, tensor<f32>) -> tensor<i1>
-+  %2 = stablehlo.compare EQ, %zero, %neg_inf, FLOAT : (tensor<f32>, tensor<f32>) -> tensor<i1>
-+  %3 = stablehlo.compare EQ, %zero, %nan, FLOAT : (tensor<f32>, tensor<f32>) -> tensor<i1>
-+  %4 = stablehlo.compare EQ, %pos_inf, %zero, FLOAT : (tensor<f32>, tensor<f32>) -> tensor<i1>
-+  %5 = stablehlo.compare EQ, %pos_inf, %pos_inf, FLOAT : (tensor<f32>, tensor<f32>) -> tensor<i1>
-+  %6 = stablehlo.compare EQ, %pos_inf, %neg_inf, FLOAT : (tensor<f32>, tensor<f32>) -> tensor<i1>
-+  %7 = stablehlo.compare EQ, %pos_inf, %nan, FLOAT : (tensor<f32>, tensor<f32>) -> tensor<i1>
-+  %8 = stablehlo.compare EQ, %neg_inf, %zero, FLOAT : (tensor<f32>, tensor<f32>) -> tensor<i1>
-+  %9 = stablehlo.compare EQ, %neg_inf, %pos_inf, FLOAT : (tensor<f32>, tensor<f32>) -> tensor<i1>
-+  %10 = stablehlo.compare EQ, %neg_inf, %neg_inf, FLOAT : (tensor<f32>, tensor<f32>) -> tensor<i1>
-+  %11 = stablehlo.compare EQ, %neg_inf, %nan, FLOAT : (tensor<f32>, tensor<f32>) -> tensor<i1>
-+  %12 = stablehlo.compare EQ, %nan, %zero, FLOAT : (tensor<f32>, tensor<f32>) -> tensor<i1>
-+  %13 = stablehlo.compare EQ, %nan, %pos_inf, FLOAT : (tensor<f32>, tensor<f32>) -> tensor<i1>
-+  %14 = stablehlo.compare EQ, %nan, %neg_inf, FLOAT : (tensor<f32>, tensor<f32>) -> tensor<i1>
-+  %15 = stablehlo.compare EQ, %nan, %nan, FLOAT : (tensor<f32>, tensor<f32>) -> tensor<i1>
-+
-+  %16 = stablehlo.compare NE, %zero, %zero, FLOAT : (tensor<f32>, tensor<f32>) -> tensor<i1>
-+  %17 = stablehlo.compare NE, %zero, %pos_inf, FLOAT : (tensor<f32>, tensor<f32>) -> tensor<i1>
-+  %18 = stablehlo.compare NE, %zero, %neg_inf, FLOAT : (tensor<f32>, tensor<f32>) -> tensor<i1>
-+  %19 = stablehlo.compare NE, %zero, %nan, FLOAT : (tensor<f32>, tensor<f32>) -> tensor<i1>
-+  %20 = stablehlo.compare NE, %pos_inf, %zero, FLOAT : (tensor<f32>, tensor<f32>) -> tensor<i1>
-+  %21 = stablehlo.compare NE, %pos_inf, %pos_inf, FLOAT : (tensor<f32>, tensor<f32>) -> tensor<i1>
-+  %22 = stablehlo.compare NE, %pos_inf, %neg_inf, FLOAT : (tensor<f32>, tensor<f32>) -> tensor<i1>
-+  %23 = stablehlo.compare NE, %pos_inf, %nan, FLOAT : (tensor<f32>, tensor<f32>) -> tensor<i1>
-+  %24 = stablehlo.compare NE, %neg_inf, %zero, FLOAT : (tensor<f32>, tensor<f32>) -> tensor<i1>
-+  %25 = stablehlo.compare NE, %neg_inf, %pos_inf, FLOAT : (tensor<f32>, tensor<f32>) -> tensor<i1>
-+  %26 = stablehlo.compare NE, %neg_inf, %neg_inf, FLOAT : (tensor<f32>, tensor<f32>) -> tensor<i1>
-+  %27 = stablehlo.compare NE, %neg_inf, %nan, FLOAT : (tensor<f32>, tensor<f32>) -> tensor<i1>
-+  %28 = stablehlo.compare NE, %nan, %zero, FLOAT : (tensor<f32>, tensor<f32>) -> tensor<i1>
-+  %29 = stablehlo.compare NE, %nan, %pos_inf, FLOAT : (tensor<f32>, tensor<f32>) -> tensor<i1>
-+  %30 = stablehlo.compare NE, %nan, %neg_inf, FLOAT : (tensor<f32>, tensor<f32>) -> tensor<i1>
-+  %31 = stablehlo.compare NE, %nan, %nan, FLOAT : (tensor<f32>, tensor<f32>) -> tensor<i1>
-+
-+  %32 = stablehlo.compare GT, %zero, %zero, FLOAT : (tensor<f32>, tensor<f32>) -> tensor<i1>
-+  %33 = stablehlo.compare GT, %zero, %pos_inf, FLOAT : (tensor<f32>, tensor<f32>) -> tensor<i1>
-+  %34 = stablehlo.compare GT, %zero, %neg_inf, FLOAT : (tensor<f32>, tensor<f32>) -> tensor<i1>
-+  %35 = stablehlo.compare GT, %zero, %nan, FLOAT : (tensor<f32>, tensor<f32>) -> tensor<i1>
-+  %36 = stablehlo.compare GT, %pos_inf, %zero, FLOAT : (tensor<f32>, tensor<f32>) -> tensor<i1>
-+  %37 = stablehlo.compare GT, %pos_inf, %pos_inf, FLOAT : (tensor<f32>, tensor<f32>) -> tensor<i1>
-+  %38 = stablehlo.compare GT, %pos_inf, %neg_inf, FLOAT : (tensor<f32>, tensor<f32>) -> tensor<i1>
-+  %39 = stablehlo.compare GT, %pos_inf, %nan, FLOAT : (tensor<f32>, tensor<f32>) -> tensor<i1>
-+  %40 = stablehlo.compare GT, %neg_inf, %zero, FLOAT : (tensor<f32>, tensor<f32>) -> tensor<i1>
-+  %41 = stablehlo.compare GT, %neg_inf, %pos_inf, FLOAT : (tensor<f32>, tensor<f32>) -> tensor<i1>
-+  %42 = stablehlo.compare GT, %neg_inf, %neg_inf, FLOAT : (tensor<f32>, tensor<f32>) -> tensor<i1>
-+  %43 = stablehlo.compare GT, %neg_inf, %nan, FLOAT : (tensor<f32>, tensor<f32>) -> tensor<i1>
-+  %44 = stablehlo.compare GT, %nan, %zero, FLOAT : (tensor<f32>, tensor<f32>) -> tensor<i1>
-+  %45 = stablehlo.compare GT, %nan, %pos_inf, FLOAT : (tensor<f32>, tensor<f32>) -> tensor<i1>
-+  %46 = stablehlo.compare GT, %nan, %neg_inf, FLOAT : (tensor<f32>, tensor<f32>) -> tensor<i1>
-+  %47 = stablehlo.compare GT, %nan, %nan, FLOAT : (tensor<f32>, tensor<f32>) -> tensor<i1>
-+
-+  %48 = stablehlo.compare GE, %zero, %zero, FLOAT : (tensor<f32>, tensor<f32>) -> tensor<i1>
-+  %49 = stablehlo.compare GE, %zero, %pos_inf, FLOAT : (tensor<f32>, tensor<f32>) -> tensor<i1>
-+  %50 = stablehlo.compare GE, %zero, %neg_inf, FLOAT : (tensor<f32>, tensor<f32>) -> tensor<i1>
-+  %51 = stablehlo.compare GE, %zero, %nan, FLOAT : (tensor<f32>, tensor<f32>) -> tensor<i1>
-+  %52 = stablehlo.compare GE, %pos_inf, %zero, FLOAT : (tensor<f32>, tensor<f32>) -> tensor<i1>
-+  %53 = stablehlo.compare GE, %pos_inf, %pos_inf, FLOAT : (tensor<f32>, tensor<f32>) -> tensor<i1>
-+  %54 = stablehlo.compare GE, %pos_inf, %neg_inf, FLOAT : (tensor<f32>, tensor<f32>) -> tensor<i1>
-+  %55 = stablehlo.compare GE, %pos_inf, %nan, FLOAT : (tensor<f32>, tensor<f32>) -> tensor<i1>
-+  %56 = stablehlo.compare GE, %neg_inf, %zero, FLOAT : (tensor<f32>, tensor<f32>) -> tensor<i1>
-+  %57 = stablehlo.compare GE, %neg_inf, %pos_inf, FLOAT : (tensor<f32>, tensor<f32>) -> tensor<i1>
-+  %58 = stablehlo.compare GE, %neg_inf, %neg_inf, FLOAT : (tensor<f32>, tensor<f32>) -> tensor<i1>
-+  %59 = stablehlo.compare GE, %neg_inf, %nan, FLOAT : (tensor<f32>, tensor<f32>) -> tensor<i1>
-+  %60 = stablehlo.compare GE, %nan, %zero, FLOAT : (tensor<f32>, tensor<f32>) -> tensor<i1>
-+  %61 = stablehlo.compare GE, %nan, %pos_inf, FLOAT : (tensor<f32>, tensor<f32>) -> tensor<i1>
-+  %62 = stablehlo.compare GE, %nan, %neg_inf, FLOAT : (tensor<f32>, tensor<f32>) -> tensor<i1>
-+  %63 = stablehlo.compare GE, %nan, %nan, FLOAT : (tensor<f32>, tensor<f32>) -> tensor<i1>
-+
-+  %64 = stablehlo.compare LT, %zero, %zero, FLOAT : (tensor<f32>, tensor<f32>) -> tensor<i1>
-+  %65 = stablehlo.compare LT, %zero, %pos_inf, FLOAT : (tensor<f32>, tensor<f32>) -> tensor<i1>
-+  %66 = stablehlo.compare LT, %zero, %neg_inf, FLOAT : (tensor<f32>, tensor<f32>) -> tensor<i1>
-+  %67 = stablehlo.compare LT, %zero, %nan, FLOAT : (tensor<f32>, tensor<f32>) -> tensor<i1>
-+  %68 = stablehlo.compare LT, %pos_inf, %zero, FLOAT : (tensor<f32>, tensor<f32>) -> tensor<i1>
-+  %69 = stablehlo.compare LT, %pos_inf, %pos_inf, FLOAT : (tensor<f32>, tensor<f32>) -> tensor<i1>
-+  %70 = stablehlo.compare LT, %pos_inf, %neg_inf, FLOAT : (tensor<f32>, tensor<f32>) -> tensor<i1>
-+  %71 = stablehlo.compare LT, %pos_inf, %nan, FLOAT : (tensor<f32>, tensor<f32>) -> tensor<i1>
-+  %72 = stablehlo.compare LT, %neg_inf, %zero, FLOAT : (tensor<f32>, tensor<f32>) -> tensor<i1>
-+  %73 = stablehlo.compare LT, %neg_inf, %pos_inf, FLOAT : (tensor<f32>, tensor<f32>) -> tensor<i1>
-+  %74 = stablehlo.compare LT, %neg_inf, %neg_inf, FLOAT : (tensor<f32>, tensor<f32>) -> tensor<i1>
-+  %75 = stablehlo.compare LT, %neg_inf, %nan, FLOAT : (tensor<f32>, tensor<f32>) -> tensor<i1>
-+  %76 = stablehlo.compare LT, %nan, %zero, FLOAT : (tensor<f32>, tensor<f32>) -> tensor<i1>
-+  %77 = stablehlo.compare LT, %nan, %pos_inf, FLOAT : (tensor<f32>, tensor<f32>) -> tensor<i1>
-+  %78 = stablehlo.compare LT, %nan, %neg_inf, FLOAT : (tensor<f32>, tensor<f32>) -> tensor<i1>
-+  %79 = stablehlo.compare LT, %nan, %nan, FLOAT : (tensor<f32>, tensor<f32>) -> tensor<i1>
-+
-+  %80 = stablehlo.compare LE, %zero, %zero, FLOAT : (tensor<f32>, tensor<f32>) -> tensor<i1>
-+  %81 = stablehlo.compare LE, %zero, %pos_inf, FLOAT : (tensor<f32>, tensor<f32>) -> tensor<i1>
-+  %82 = stablehlo.compare LE, %zero, %neg_inf, FLOAT : (tensor<f32>, tensor<f32>) -> tensor<i1>
-+  %83 = stablehlo.compare LE, %zero, %nan, FLOAT : (tensor<f32>, tensor<f32>) -> tensor<i1>
-+  %84 = stablehlo.compare LE, %pos_inf, %zero, FLOAT : (tensor<f32>, tensor<f32>) -> tensor<i1>
-+  %85 = stablehlo.compare LE, %pos_inf, %pos_inf, FLOAT : (tensor<f32>, tensor<f32>) -> tensor<i1>
-+  %86 = stablehlo.compare LE, %pos_inf, %neg_inf, FLOAT : (tensor<f32>, tensor<f32>) -> tensor<i1>
-+  %87 = stablehlo.compare LE, %pos_inf, %nan, FLOAT : (tensor<f32>, tensor<f32>) -> tensor<i1>
-+  %88 = stablehlo.compare LE, %neg_inf, %zero, FLOAT : (tensor<f32>, tensor<f32>) -> tensor<i1>
-+  %89 = stablehlo.compare LE, %neg_inf, %pos_inf, FLOAT : (tensor<f32>, tensor<f32>) -> tensor<i1>
-+  %90 = stablehlo.compare LE, %neg_inf, %neg_inf, FLOAT : (tensor<f32>, tensor<f32>) -> tensor<i1>
-+  %91 = stablehlo.compare LE, %neg_inf, %nan, FLOAT : (tensor<f32>, tensor<f32>) -> tensor<i1>
-+  %92 = stablehlo.compare LE, %nan, %zero, FLOAT : (tensor<f32>, tensor<f32>) -> tensor<i1>
-+  %93 = stablehlo.compare LE, %nan, %pos_inf, FLOAT : (tensor<f32>, tensor<f32>) -> tensor<i1>
-+  %94 = stablehlo.compare LE, %nan, %neg_inf, FLOAT : (tensor<f32>, tensor<f32>) -> tensor<i1>
-+  %95 = stablehlo.compare LE, %nan, %nan, FLOAT : (tensor<f32>, tensor<f32>) -> tensor<i1>
-+
-+  // CHECK: return [[TRUE]],  [[FALSE]], [[FALSE]], [[FALSE]],
-+  // CHECK-SAME:   [[FALSE]], [[TRUE]],  [[FALSE]], [[FALSE]],
-+  // CHECK-SAME:   [[FALSE]], [[FALSE]], [[TRUE]],  [[FALSE]],
-+  // CHECK-SAME:   [[FALSE]], [[FALSE]], [[FALSE]], [[FALSE]],
-+
-+  // CHECK-SAME:   [[FALSE]], [[TRUE]],  [[TRUE]],  [[TRUE]],
-+  // CHECK-SAME:   [[TRUE]],  [[FALSE]], [[TRUE]],  [[TRUE]],
-+  // CHECK-SAME:   [[TRUE]],  [[TRUE]],  [[FALSE]], [[TRUE]],
-+  // CHECK-SAME:   [[TRUE]],  [[TRUE]],  [[TRUE]],  [[TRUE]],
-+
-+  // CHECK-SAME:   [[FALSE]], [[FALSE]], [[TRUE]],  [[FALSE]],
-+  // CHECK-SAME:   [[TRUE]],  [[FALSE]], [[TRUE]],  [[FALSE]],
-+  // CHECK-SAME:   [[FALSE]], [[FALSE]], [[FALSE]], [[FALSE]],
-+  // CHECK-SAME:   [[FALSE]], [[FALSE]], [[FALSE]], [[FALSE]],
-+
-+  // CHECK-SAME:   [[TRUE]],  [[FALSE]], [[TRUE]],  [[FALSE]],
-+  // CHECK-SAME:   [[TRUE]],  [[TRUE]],  [[TRUE]],  [[FALSE]],
-+  // CHECK-SAME:   [[FALSE]], [[FALSE]], [[TRUE]],  [[FALSE]],
-+  // CHECK-SAME:   [[FALSE]], [[FALSE]], [[FALSE]], [[FALSE]],
-+
-+  // CHECK-SAME:   [[FALSE]], [[TRUE]],  [[FALSE]], [[FALSE]],
-+  // CHECK-SAME:   [[FALSE]], [[FALSE]], [[FALSE]], [[FALSE]],
-+  // CHECK-SAME:   [[TRUE]],  [[TRUE]],  [[FALSE]], [[FALSE]],
-+  // CHECK-SAME:   [[FALSE]], [[FALSE]], [[FALSE]], [[FALSE]],
-+
-+  // CHECK-SAME:   [[TRUE]],  [[TRUE]],  [[FALSE]], [[FALSE]],
-+  // CHECK-SAME:   [[FALSE]], [[TRUE]],  [[FALSE]], [[FALSE]],
-+  // CHECK-SAME:   [[TRUE]],  [[TRUE]],  [[TRUE]],  [[FALSE]],
-+  // CHECK-SAME:   [[FALSE]], [[FALSE]], [[FALSE]], [[FALSE]]
-+
-+  return  %0,  %1,  %2,  %3,
-+          %4,  %5,  %6,  %7,
-+          %8,  %9, %10, %11,
-+         %12, %13, %14, %15,
-+
-+         %16, %17, %18, %19,
-+         %20, %21, %22, %23,
-+         %24, %25, %26, %27,
-+         %28, %29, %30, %31,
-+
-+         %32, %33, %34, %35,
-+         %36, %37, %38, %39,
-+         %40, %41, %42, %43,
-+         %44, %45, %46, %47,
-+
-+         %48, %49, %50, %51,
-+         %52, %53, %54, %55,
-+         %56, %57, %58, %59,
-+         %60, %61, %62, %63,
-+
-+         %64, %65, %66, %67,
-+         %68, %69, %70, %71,
-+         %72, %73, %74, %75,
-+         %76, %77, %78, %79,
-+
-+         %80, %81, %82, %83,
-+         %84, %85, %86, %87,
-+         %88, %89, %90, %91,
-+         %92, %93, %94, %95 :
-+         tensor<i1>, tensor<i1>, tensor<i1>, tensor<i1>,
-+         tensor<i1>, tensor<i1>, tensor<i1>, tensor<i1>,
-+         tensor<i1>, tensor<i1>, tensor<i1>, tensor<i1>,
-+         tensor<i1>, tensor<i1>, tensor<i1>, tensor<i1>,
-+
-+         tensor<i1>, tensor<i1>, tensor<i1>, tensor<i1>,
-+         tensor<i1>, tensor<i1>, tensor<i1>, tensor<i1>,
-+         tensor<i1>, tensor<i1>, tensor<i1>, tensor<i1>,
-+         tensor<i1>, tensor<i1>, tensor<i1>, tensor<i1>,
-+
-+         tensor<i1>, tensor<i1>, tensor<i1>, tensor<i1>,
-+         tensor<i1>, tensor<i1>, tensor<i1>, tensor<i1>,
-+         tensor<i1>, tensor<i1>, tensor<i1>, tensor<i1>,
-+         tensor<i1>, tensor<i1>, tensor<i1>, tensor<i1>,
-+
-+         tensor<i1>, tensor<i1>, tensor<i1>, tensor<i1>,
-+         tensor<i1>, tensor<i1>, tensor<i1>, tensor<i1>,
-+         tensor<i1>, tensor<i1>, tensor<i1>, tensor<i1>,
-+         tensor<i1>, tensor<i1>, tensor<i1>, tensor<i1>,
-+
-+         tensor<i1>, tensor<i1>, tensor<i1>, tensor<i1>,
-+         tensor<i1>, tensor<i1>, tensor<i1>, tensor<i1>,
-+         tensor<i1>, tensor<i1>, tensor<i1>, tensor<i1>,
-+         tensor<i1>, tensor<i1>, tensor<i1>, tensor<i1>,
-+
-+         tensor<i1>, tensor<i1>, tensor<i1>, tensor<i1>,
-+         tensor<i1>, tensor<i1>, tensor<i1>, tensor<i1>,
-+         tensor<i1>, tensor<i1>, tensor<i1>, tensor<i1>,
-+         tensor<i1>, tensor<i1>, tensor<i1>, tensor<i1>
-+}
- 
- // -----
- 
-@@ -218,8 +482,7 @@
-   %cst_2 = stablehlo.constant dense<2.0> : tensor<f32>
-   // CHECK: stablehlo.constant dense<1> : tensor<i32>
-   // CHECK: stablehlo.constant dense<1> : tensor<ui32>
--  // CHECK: stablehlo.divide{{.*}} : tensor<f32>
--  // DISABLED-CHECK: stablehlo.constant dense<1.0{{.*}}> : tensor<f32>
-+  // CHECK: stablehlo.constant dense<1.0{{.*}}> : tensor<f32>
-   %0 = stablehlo.divide %cst, %cst : tensor<i32>
-   %1 = stablehlo.divide %cst_1, %cst_1 : tensor<ui32>
-   %2 = stablehlo.divide %cst_2, %cst_2 : tensor<f32>
-diff --ruN a/stablehlo/stablehlo/tests/transforms/stablehlo_aggressive_simplification.mlir b/stablehlo/stablehlo/tests/transforms/stablehlo_aggressive_simplification.mlir
---- stablehlo/stablehlo/tests/transforms/stablehlo_aggressive_simplification.mlir
-+++ stablehlo/stablehlo/tests/transforms/stablehlo_aggressive_simplification.mlir
-@@ -1633,17 +1633,17 @@
-   %s4 = stablehlo.select %4, %arg1, %arg2 : (tensor<2xi1>, tensor<2xi32>, tensor<2xi32>) -> tensor<2xi32>
-   %s5 = stablehlo.select %5, %arg1, %arg3 : (tensor<2xi1>, tensor<2xi32>, tensor<2xi32>) -> tensor<2xi32>
- 
--  // CHECK-DAG:  [[C0:%.+]] = stablehlo.compare EQ, [[ARG0]], [[ARG1]], SIGNED
--  // CHECK-DAG:  [[C1:%.+]] = stablehlo.compare NE, [[ARG0]], [[ARG1]], SIGNED
--
--  // CHECK-DAG:  [[S0:%.+]] = stablehlo.select [[C0]], [[ARG0]], [[ARG1]]
--  // CHECK-DAG:  [[S1:%.+]] = stablehlo.select [[C1]], [[ARG0]], [[ARG1]]
--  // CHECK-DAG:  [[S2:%.+]] = stablehlo.maximum [[ARG0]], [[ARG1]]
--  // CHECK-DAG:  [[S3:%.+]] = stablehlo.maximum [[ARG0]], [[ARG2]]
--  // CHECK-DAG:  [[S4:%.+]] = stablehlo.minimum [[ARG1]], [[ARG2]]
--  // CHECK-DAG:  [[S5:%.+]] = stablehlo.minimum [[ARG1]], [[ARG3]]
--
--  // CHECK-NEXT: return [[S0]], [[S1]], [[S2]], [[S3]], [[S4]], [[S5]]
-+  // DISABLED-CHECK-DAG:  [[C0:%.+]] = stablehlo.compare EQ, [[ARG0]], [[ARG1]], SIGNED
-+  // DISABLED-CHECK-DAG:  [[C1:%.+]] = stablehlo.compare NE, [[ARG0]], [[ARG1]], SIGNED
-+
-+  // DISABLED-CHECK-DAG:  [[S0:%.+]] = stablehlo.select [[C0]], [[ARG0]], [[ARG1]]
-+  // DISABLED-CHECK-DAG:  [[S1:%.+]] = stablehlo.select [[C1]], [[ARG0]], [[ARG1]]
-+  // DISABLED-CHECK-DAG:  [[S2:%.+]] = stablehlo.maximum [[ARG0]], [[ARG1]]
-+  // DISABLED-CHECK-DAG:  [[S3:%.+]] = stablehlo.maximum [[ARG0]], [[ARG2]]
-+  // DISABLED-CHECK-DAG:  [[S4:%.+]] = stablehlo.minimum [[ARG1]], [[ARG2]]
-+  // DISABLED-CHECK-DAG:  [[S5:%.+]] = stablehlo.minimum [[ARG1]], [[ARG3]]
-+
-+  // DISABLED-CHECK-NEXT: return [[S0]], [[S1]], [[S2]], [[S3]], [[S4]], [[S5]]
-   return %s0, %s1, %s2, %s3, %s4, %s5 :
-          tensor<2xi32>, tensor<2xi32>, tensor<2xi32>, tensor<2xi32>, tensor<2xi32>, tensor<2xi32>
- }
-@@ -1674,23 +1674,23 @@
-   %s6 = stablehlo.select %6, %arg3, %arg2 : (tensor<i1>, tensor<i32>, tensor<i32>) -> tensor<i32>
-   %s7 = stablehlo.select %7, %arg2, %arg3 : (tensor<i1>, tensor<i32>, tensor<i32>) -> tensor<i32>
- 
--  // CHECK-DAG:  [[C1:%.+]] = stablehlo.compare GT, [[ARG1]], [[ARG2]], SIGNED
--  // CHECK-DAG:  [[C3:%.+]] = stablehlo.compare GE, [[ARG1]], [[ARG2]], SIGNED
--
--  // CHECK-DAG:  [[S0:%.+]] = stablehlo.minimum [[ARG0]], [[ARG1]]
--  // CHECK-DAG:  [[S1:%.+]] = stablehlo.select [[C1]], [[ARG0]], [[ARG1]]
--  // CHECK-DAG:  [[S2:%.+]] = stablehlo.minimum [[ARG3]], [[ARG1]]
--  // CHECK-DAG:  [[S3:%.+]] = stablehlo.select [[C3]], [[ARG0]], [[ARG2]]
--
--  // CHECK-DAG:  [[C5:%.+]] = stablehlo.compare LT, [[ARG0]], [[ARG2]], SIGNED
--  // CHECK-DAG:  [[C7:%.+]] = stablehlo.compare LE, [[ARG0]], [[ARG2]], SIGNED
--
--  // CHECK-DAG:  [[S4:%.+]] = stablehlo.maximum [[ARG2]], [[ARG1]]
--  // CHECK-DAG:  [[S5:%.+]] = stablehlo.select [[C5]], [[ARG1]], [[ARG2]]
--  // CHECK-DAG:  [[S6:%.+]] = stablehlo.maximum [[ARG3]], [[ARG2]]
--  // CHECK-DAG:  [[S7:%.+]] = stablehlo.select [[C7]], [[ARG2]], [[ARG3]]
--
--  // CHECK-NEXT: return [[S0]], [[S1]], [[S2]], [[S3]], [[S4]], [[S5]], [[S6]], [[S7]]
-+  // DISABLED-CHECK-DAG:  [[C1:%.+]] = stablehlo.compare GT, [[ARG1]], [[ARG2]], SIGNED
-+  // DISABLED-CHECK-DAG:  [[C3:%.+]] = stablehlo.compare GE, [[ARG1]], [[ARG2]], SIGNED
-+
-+  // DISABLED-CHECK-DAG:  [[S0:%.+]] = stablehlo.minimum [[ARG0]], [[ARG1]]
-+  // DISABLED-CHECK-DAG:  [[S1:%.+]] = stablehlo.select [[C1]], [[ARG0]], [[ARG1]]
-+  // DISABLED-CHECK-DAG:  [[S2:%.+]] = stablehlo.minimum [[ARG3]], [[ARG1]]
-+  // DISABLED-CHECK-DAG:  [[S3:%.+]] = stablehlo.select [[C3]], [[ARG0]], [[ARG2]]
-+
-+  // DISABLED-CHECK-DAG:  [[C5:%.+]] = stablehlo.compare LT, [[ARG0]], [[ARG2]], SIGNED
-+  // DISABLED-CHECK-DAG:  [[C7:%.+]] = stablehlo.compare LE, [[ARG0]], [[ARG2]], SIGNED
-+
-+  // DISABLED-CHECK-DAG:  [[S4:%.+]] = stablehlo.maximum [[ARG2]], [[ARG1]]
-+  // DISABLED-CHECK-DAG:  [[S5:%.+]] = stablehlo.select [[C5]], [[ARG1]], [[ARG2]]
-+  // DISABLED-CHECK-DAG:  [[S6:%.+]] = stablehlo.maximum [[ARG3]], [[ARG2]]
-+  // DISABLED-CHECK-DAG:  [[S7:%.+]] = stablehlo.select [[C7]], [[ARG2]], [[ARG3]]
-+
-+  // DISABLED-CHECK-NEXT: return [[S0]], [[S1]], [[S2]], [[S3]], [[S4]], [[S5]], [[S6]], [[S7]]
-   return %s0, %s1, %s2, %s3, %s4, %s5, %s6, %s7 : tensor<i32>, tensor<i32>, tensor<i32>, tensor<i32>,
-                                                   tensor<i32>, tensor<i32>, tensor<i32>, tensor<i32>
- }
-@@ -2040,12 +2040,12 @@
- 
- // CHECK-LABEL: @push_shape_ops_to_end
- func.func @push_shape_ops_to_end(%arg0 : tensor<12xf32>) -> tensor<3x4x2x1xf32> {
--  // CHECK: %[[COS:.+]] = stablehlo.cosine %arg0 : tensor<12xf32>
--  // CHECK: %[[ABS:.+]] = stablehlo.abs %[[COS]] : tensor<12xf32>
--  // CHECK: %[[RESHAPE:.+]] = stablehlo.reshape %[[ABS]] : (tensor<12xf32>) -> tensor<3x4xf32>
--  // CHECK: %[[BROADCAST:.+]] = stablehlo.broadcast %[[RESHAPE]], sizes = [1, 2] : (tensor<3x4xf32>) -> tensor<1x2x3x4xf32>
--  // CHECK: %[[TRANSPOSE:.+]] = stablehlo.transpose %[[BROADCAST]], dims = [2, 3, 1, 0] : (tensor<1x2x3x4xf32>) -> tensor<3x4x2x1xf32>
--  // CHECK: return %[[TRANSPOSE]]
-+  // DISABLED-CHECK: %[[COS:.+]] = stablehlo.cosine %arg0 : tensor<12xf32>
-+  // DISABLED-CHECK: %[[ABS:.+]] = stablehlo.abs %[[COS]] : tensor<12xf32>
-+  // DISABLED-CHECK: %[[RESHAPE:.+]] = stablehlo.reshape %[[ABS]] : (tensor<12xf32>) -> tensor<3x4xf32>
-+  // DISABLED-CHECK: %[[BROADCAST:.+]] = stablehlo.broadcast %[[RESHAPE]], sizes = [1, 2] : (tensor<3x4xf32>) -> tensor<1x2x3x4xf32>
-+  // DISABLED-CHECK: %[[TRANSPOSE:.+]] = stablehlo.transpose %[[BROADCAST]], dims = [2, 3, 1, 0] : (tensor<1x2x3x4xf32>) -> tensor<3x4x2x1xf32>
-+  // DISABLED-CHECK: return %[[TRANSPOSE]]
-   %0 = stablehlo.reshape %arg0 : (tensor<12xf32>) -> tensor<3x4xf32>
-   %1 = stablehlo.broadcast %0, sizes = [1, 2] : (tensor<3x4xf32>) -> tensor<1x2x3x4xf32>
-   %2 = stablehlo.cosine %1 : (tensor<1x2x3x4xf32>) -> tensor<1x2x3x4xf32>
-@@ -2059,9 +2059,9 @@
- 
- // CHECK-LABEL: @reorder_with_type_change
- func.func @reorder_with_type_change(%arg0 : tensor<3x4xi32>) -> tensor<12xi64> {
--  // CHECK: %[[CONVERT:.+]] = stablehlo.convert %arg0 : (tensor<3x4xi32>) -> tensor<3x4xi64>
--  // CHECK: %[[RESHAPE:.+]] = stablehlo.reshape %[[CONVERT]] : (tensor<3x4xi64>) -> tensor<12xi64>
--  // CHECK: return %[[RESHAPE]]
-+  // DISABLED-CHECK: %[[CONVERT:.+]] = stablehlo.convert %arg0 : (tensor<3x4xi32>) -> tensor<3x4xi64>
-+  // DISABLED-CHECK: %[[RESHAPE:.+]] = stablehlo.reshape %[[CONVERT]] : (tensor<3x4xi64>) -> tensor<12xi64>
-+  // DISABLED-CHECK: return %[[RESHAPE]]
-   %0 = stablehlo.reshape %arg0 : (tensor<3x4xi32>) -> tensor<12xi32>
-   %1 = stablehlo.convert %0 : (tensor<12xi32>) -> tensor<12xi64>
-   return %1 : tensor<12xi64>
-diff --ruN a/stablehlo/stablehlo/tests/transforms/stablehlo_target_independent_optimization.mlir b/stablehlo/stablehlo/tests/transforms/stablehlo_target_independent_optimization.mlir
---- stablehlo/stablehlo/tests/transforms/stablehlo_target_independent_optimization.mlir
-+++ stablehlo/stablehlo/tests/transforms/stablehlo_target_independent_optimization.mlir
-@@ -59,3 +59,34 @@
-   }
-   return %0 : tensor<i64>
- }
-+
-+// -----
-+
-+// Check that we properly handle expressions involving NaN terms or variables
-+// that could potentially be NaN.
-+
-+// CHECK-LABEL: @fold_constant_nan_to_nan
-+func.func @fold_constant_nan_to_nan() -> tensor<f32> {
-+  // CHECK: [[NAN:%.*]] = stablehlo.constant dense<0x7FC00000> : tensor<f32>
-+  // CHECK: return [[NAN]] : tensor<f32>
-+  %zero = stablehlo.constant dense<0.0> : tensor<f32>
-+  %one = stablehlo.constant dense<1.0> : tensor<f32>
-+  %nan = stablehlo.constant dense<0x7FC00000> : tensor<f32>
-+  %nan_times_zero = stablehlo.multiply %nan, %zero : tensor<f32>
-+  %result = stablehlo.add %one, %nan_times_zero : tensor<f32>
-+  return %result : tensor<f32>
-+}
-+
-+// TODO: Consider adding an `--assume-non-nan` pass option to override this.
-+// CHECK-LABEL: @do_not_assume_non_nan
-+func.func @do_not_assume_non_nan(%arg0: tensor<f32>) -> tensor<f32> {
-+  // Note: These two checks are out of order on purpose: [[RESULT]] binds to the
-+  // `return` op first and then looks backward for the corresponding assignment.
-+  // CHECK-DAG: return [[RESULT:.*]] : tensor<f32>
-+  // CHECK-DAG: [[RESULT]] = stablehlo.{{(add|multiply).*}} : tensor<f32>
-+  %zero = stablehlo.constant dense<0.0> : tensor<f32>
-+  %one = stablehlo.constant dense<1.0> : tensor<f32>
-+  %arg_times_zero = stablehlo.multiply %arg0, %zero : tensor<f32>
-+  %result = stablehlo.add %one, %arg_times_zero : tensor<f32>
-+  return %result : tensor<f32>
-+}
-diff --ruN a/stablehlo/stablehlo/transforms/optimization/StablehloAggressiveFolder.cpp b/stablehlo/stablehlo/transforms/optimization/StablehloAggressiveFolder.cpp
---- stablehlo/stablehlo/transforms/optimization/StablehloAggressiveFolder.cpp
-+++ stablehlo/stablehlo/transforms/optimization/StablehloAggressiveFolder.cpp
-@@ -23,6 +23,7 @@
- #include <string>
- #include <utility>
- 
-+#include "llvm/ADT/APFloat.h"
- #include "llvm/ADT/APInt.h"
- #include "llvm/ADT/APSInt.h"
- #include "llvm/ADT/FloatingPointMode.h"
-@@ -86,6 +87,18 @@
-       /*isUnsigned=*/isUnsigned);
- }
- 
-+APFloat getAPFloat(
-+    Type type, double value,
-+    llvm::RoundingMode roundingMode = llvm::RoundingMode::NearestTiesToEven) {
-+  auto floatType = dyn_cast<FloatType>(type);
-+  if (!floatType) llvm::report_fatal_error("expected float type");
-+
-+  APFloat result(value);
-+  bool losesInfo = false;
-+  result.convert(floatType.getFloatSemantics(), roundingMode, &losesInfo);
-+  return result;
-+}
-+
- LogicalResult validateStaticShapeResult(PatternRewriter& rewriter,
-                                         Operation* op, ShapedType resultType) {
-   if (!resultType.hasStaticShape())
-@@ -94,26 +107,30 @@
-   return success();
- }
- 
--template <typename Fn>
--static TypedAttr foldUnaryOpIntOrFloat(Type resultType, TypedAttr operand,
--                                       Fn&& folder) {
-+/// Unary constant folder that uses a generic folder function to handle both
-+/// ints and floats.
-+template <typename Fn, typename IntResultType = IntegerAttr,
-+          typename FloatResultType = FloatAttr>
-+TypedAttr foldUnaryOpIntOrFloat(Type resultType, TypedAttr operand,
-+                                Fn&& folder) {
-   Type elemTy = getElementTypeOrSelf(operand);
- 
-   Attribute res;
-   if (isa<IntegerType>(elemTy))
--    res = constFoldUnaryOp<IntegerAttr, IntegerAttr::ValueType, void>(operand,
--                                                                      folder);
-+    res = constFoldUnaryOp<IntegerAttr, IntegerAttr::ValueType, void,
-+                           IntResultType>(operand, folder);
-   if (isa<FloatType>(elemTy))
--    res = constFoldUnaryOp<FloatAttr, FloatAttr::ValueType, void>(operand,
--                                                                  folder);
-+    res = constFoldUnaryOp<FloatAttr, FloatAttr::ValueType, void,
-+                           FloatResultType>(operand, folder);
-   if (res) return cast<TypedAttr>(res);
- 
-   return nullptr;
- }
- 
--/// Binary constant folder that used a generic folder function to handle both
-+/// Unary constant folder that uses a generic folder function to handle both
- /// ints and floats.
--template <typename Fn>
-+template <typename Fn, typename IntResultType = IntegerAttr,
-+          typename FloatResultType = FloatAttr>
- FailureOr<TypedAttr> foldUnaryOpIntOrFloat(PatternRewriter& rewriter,
-                                            Operation* op, Fn&& folder) {
-   if (op->getNumOperands() != 1 || op->getNumResults() != 1)
-@@ -124,35 +141,38 @@
- 
-   if (!attr) return rewriter.notifyMatchFailure(op, "operand not constants");
- 
--  TypedAttr res = foldUnaryOpIntOrFloat(op->getResultTypes()[0], attr, folder);
-+  TypedAttr res = foldUnaryOpIntOrFloat<Fn, IntResultType, FloatResultType>(
-+      op->getResultTypes()[0], attr, std::forward<Fn>(folder));
-   if (!res) return rewriter.notifyMatchFailure(op, "folding failed");
- 
-   return res;
- }
- 
--/// Binary constant folder that used a generic folder function to handle both
-+/// Binary constant folder that uses a generic folder function to handle both
- /// ints and floats.
--template <typename Fn>
--static TypedAttr foldBinaryOpIntOrFloat(Type resultType, TypedAttr lhs,
--                                        TypedAttr rhs, Fn&& folder) {
-+template <typename Fn, typename IntResultType = IntegerAttr,
-+          typename FloatResultType = FloatAttr>
-+TypedAttr foldBinaryOpIntOrFloat(Type resultType, TypedAttr lhs, TypedAttr rhs,
-+                                 Fn&& folder) {
-   Attribute operands[2] = {lhs, rhs};
-   Type elemTy = getElementTypeOrSelf(lhs);
- 
-   Attribute res;
-   if (isa<IntegerType>(elemTy))
--    res = constFoldBinaryOp<IntegerAttr, IntegerAttr::ValueType, void>(
--        operands, resultType, folder);
-+    res = constFoldBinaryOp<IntegerAttr, IntegerAttr::ValueType, void,
-+                            IntResultType>(operands, resultType, folder);
-   if (isa<FloatType>(elemTy))
--    res = constFoldBinaryOp<FloatAttr, FloatAttr::ValueType, void>(
--        operands, resultType, folder);
-+    res = constFoldBinaryOp<FloatAttr, FloatAttr::ValueType, void,
-+                            FloatResultType>(operands, resultType, folder);
-   if (res) return cast<TypedAttr>(res);
- 
-   return nullptr;
- }
- 
--/// Binary constant folder that used a generic folder function to handle both
-+/// Binary constant folder that uses a generic folder function to handle both
- /// ints and floats.
--template <typename Fn>
-+template <typename Fn, typename IntResultType = IntegerAttr,
-+          typename FloatResultType = FloatAttr>
- FailureOr<TypedAttr> foldBinaryOpIntOrFloat(PatternRewriter& rewriter,
-                                             Operation* op, Fn&& folder) {
-   if (op->getNumOperands() != 2 || op->getNumResults() != 1)
-@@ -165,8 +185,8 @@
-   if (!lhsAttr || !rhsAttr)
-     return rewriter.notifyMatchFailure(op, "lhs & rhs operands not constants");
- 
--  TypedAttr res =
--      foldBinaryOpIntOrFloat(op->getResultTypes()[0], lhsAttr, rhsAttr, folder);
-+  TypedAttr res = foldBinaryOpIntOrFloat<Fn, IntResultType, FloatResultType>(
-+      op->getResultTypes()[0], lhsAttr, rhsAttr, std::forward<Fn>(folder));
-   if (!res) return rewriter.notifyMatchFailure(op, "folding failed");
- 
-   return res;
-@@ -371,23 +391,38 @@
- struct FoldAndOpPattern : public ShapeOpRewritePattern<AndOp> {
-   using ShapeOpRewritePattern::ShapeOpRewritePattern;
- 
--  LogicalResult matchAndRewrite(mlir::stablehlo::AndOp op,
--                                PatternRewriter& rewriter) const override {
--    // TODO: Support more int types
-+  LogicalResult matchAndRewrite(AndOp op,
-+                                PatternRewriter& rewriter) const override {
-     auto resultType = op.getType();
--    if (!resultType.getElementType().isInteger(1))
--      return rewriter.notifyMatchFailure(op, "expected boolean element type");
--
--    auto res = foldBinaryOpIntOrFloat(rewriter, op, FoldAnd{});
--    if (failed(res)) return failure();
--    rewriter.replaceOpWithNewOp<mlir::stablehlo::ConstantOp>(op, res.value());
--    return success();
--  }
--
--  struct FoldAnd {
-+    auto resultElementType = resultType.getElementType();
-+    FailureOr<TypedAttr> result;
-+
-+    if (resultElementType.isInteger(/*width=*/1)) {
-+      result = foldBinaryOpIntOrFloat(rewriter, op, FoldLogicalAnd{});
-+    } else if (resultElementType.isInteger()) {
-+      result = foldBinaryOpIntOrFloat(rewriter, op, FoldBitwiseAnd{});
-+    } else {
-+      return rewriter.notifyMatchFailure(op, "Expected integral element type.");
-+    }
-+
-+    if (failed(result)) return failure();
-+    rewriter.replaceOpWithNewOp<mlir::stablehlo::ConstantOp>(op,
-+                                                             result.value());
-+    return success();
-+  }
-+
-+  struct FoldLogicalAnd {
-     APInt operator()(APInt lhs, APInt rhs) const {
-       return APInt(lhs.getBitWidth(), !lhs.isZero() && !rhs.isZero());
-     }
-+    std::optional<APFloat> operator()(APFloat lhs, APFloat rhs) const {
-+      return std::nullopt;
-+    }
-+  };
-+
-+  struct FoldBitwiseAnd {
-+    APInt operator()(APInt lhs, APInt rhs) const { return lhs & rhs; }
-+
-     std::optional<APFloat> operator()(APFloat lhs, APFloat rhs) const {
-       return std::nullopt;
-     }
-@@ -426,7 +461,7 @@
-     if (failed(validateShapeFoldDtype(rewriter, op, resultType)))
-       return failure();
- 
--    auto res = foldBinaryOpIntOrFloat(
-+    auto res = foldBinaryOpIntOrFloat<FoldCompare, IntegerAttr, IntegerAttr>(
-         rewriter, op,
-         FoldCompare(op.getComparisonDirection(), op.getCompareType()));
-     if (failed(res)) return failure();
-@@ -441,9 +476,29 @@
-     ComparisonDirection direction;
-     std::optional<ComparisonType> kind;
- 
--    // TODO: Enable float folding.
--    std::optional<APFloat> operator()(APFloat lhs, APFloat rhs) {
--      return std::nullopt;
-+    APInt operator()(APFloat lhs, APFloat rhs) {
-+      bool result = false;
-+      switch (direction) {
-+        case ComparisonDirection::EQ:
-+          result = lhs == rhs;
-+          break;
-+        case ComparisonDirection::NE:
-+          result = lhs != rhs;
-+          break;
-+        case ComparisonDirection::GE:
-+          result = lhs >= rhs;
-+          break;
-+        case ComparisonDirection::GT:
-+          result = lhs > rhs;
-+          break;
-+        case ComparisonDirection::LE:
-+          result = lhs <= rhs;
-+          break;
-+        case ComparisonDirection::LT:
-+          result = lhs < rhs;
-+          break;
-+      }
-+      return APInt(/*bitwidth=*/1, result);
-     }
-     APInt operator()(APInt lhs, APInt rhs) {
-       bool result = false;
-@@ -509,6 +564,20 @@
-     Operation* terminator = blockToInline->getTerminator();
-     ValueRange results = terminator->getOperands();
- 
-+    // TODO: Add support for complex, quantized, and token return types.
-+    // Currently, this pattern only supports int and float return types. We'll
-+    // need a more general equivalent of `getZeroAttr` to support other types.
-+    SmallVector<TypedAttr> placeholderAttrs;
-+    for (auto result : op.getResults()) {
-+      TypedAttr placeholderAttr = rewriter.getZeroAttr(result.getType());
-+      if (!placeholderAttr)
-+        return rewriter.notifyMatchFailure(
-+            op,
-+            "The case op's return type isn't currently supported by this "
-+            "optimization pattern.");
-+      placeholderAttrs.push_back(placeholderAttr);
-+    }
-+
-     // Inline the active branch of the `case` op.
-     rewriter.inlineBlockBefore(blockToInline, op, blockArgs);
-     rewriter.replaceAllOpUsesWith(op, results);
-@@ -521,9 +590,9 @@
-     Block& noopBlock = region.emplaceBlock();
-     SmallVector<Value> placeholderResults;
-     rewriter.setInsertionPointToEnd(&noopBlock);
--    for (auto result : op.getResults()) {
--      placeholderResults.push_back(rewriter.create<ConstantOp>(
--          region.getLoc(), rewriter.getZeroAttr(result.getType())));
-+    for (auto placeholderAttr : placeholderAttrs) {
-+      placeholderResults.push_back(
-+          rewriter.create<ConstantOp>(region.getLoc(), placeholderAttr));
-     }
-     rewriter.create<stablehlo::ReturnOp>(region.getLoc(), placeholderResults);
- 
-@@ -628,10 +697,7 @@
-         : foldIntFn(isUnsignedInt ? foldUint : foldSint) {}
-     std::function<APInt(APInt, APInt)> foldIntFn;
- 
--    // TODO: Enable float folding.
--    std::optional<APFloat> operator()(APFloat lhs, APFloat rhs) {
--      return std::nullopt;  // return lhs / rhs;
--    }
-+    APFloat operator()(APFloat lhs, APFloat rhs) { return lhs / rhs; }
-     APInt operator()(APInt lhs, APInt rhs) { return foldIntFn(lhs, rhs); }
-     static APInt foldUint(APInt lhs, APInt rhs) { return lhs.udiv(rhs); }
-     static APInt foldSint(APInt lhs, APInt rhs) { return lhs.sdiv(rhs); }
-@@ -669,9 +735,8 @@
-       : foldIntFn(isUnsignedInt ? foldUint : foldSint) {}
-   std::function<APInt(APInt, APInt)> foldIntFn;
- 
--  // TODO: Enable float folding.
--  std::optional<APFloat> operator()(APFloat lhs, APFloat rhs) {
--    return std::nullopt;  // return lhs >= rhs ? lhs : rhs;
-+  APFloat operator()(APFloat lhs, APFloat rhs) {
-+    return lhs >= rhs ? lhs : rhs;
-   }
-   APInt operator()(APInt lhs, APInt rhs) { return foldIntFn(lhs, rhs); }
-   static APInt foldUint(APInt lhs, APInt rhs) {
-@@ -687,9 +752,8 @@
-       : foldIntFn(isUnsignedInt ? foldUint : foldSint) {}
-   std::function<APInt(APInt, APInt)> foldIntFn;
- 
--  // TODO: Enable float folding.
--  std::optional<APFloat> operator()(APFloat lhs, APFloat rhs) {
--    return std::nullopt;  // return lhs <= rhs ? lhs : rhs;
-+  APFloat operator()(APFloat lhs, APFloat rhs) {
-+    return lhs <= rhs ? lhs : rhs;
-   }
-   APInt operator()(APInt lhs, APInt rhs) { return foldIntFn(lhs, rhs); }
-   static APInt foldUint(APInt lhs, APInt rhs) {
-@@ -706,11 +770,14 @@
-   LogicalResult matchAndRewrite(MaxOp op,
-                                 PatternRewriter& rewriter) const override {
-     auto resultType = op.getType();
-+    auto resultElementType = resultType.getElementType();
-     if (failed(validateShapeFoldDtype(rewriter, op, resultType)))
-       return failure();
- 
--    bool isUnsignedInt = resultType.getElementType().isUnsignedInteger();
--    auto res = foldBinaryOpIntOrFloat(rewriter, op, FoldMax(isUnsignedInt));
-+    bool isUnsignedIntOrBool = resultElementType.isUnsignedInteger() ||
-+                               resultElementType.isInteger(/*width=*/1);
-+    auto res =
-+        foldBinaryOpIntOrFloat(rewriter, op, FoldMax(isUnsignedIntOrBool));
-     if (failed(res)) return failure();
-     rewriter.replaceOpWithNewOp<mlir::stablehlo::ConstantOp>(op, res.value());
-     return success();
-@@ -723,11 +790,14 @@
-   LogicalResult matchAndRewrite(MinOp op,
-                                 PatternRewriter& rewriter) const override {
-     auto resultType = op.getType();
-+    auto resultElementType = resultType.getElementType();
-     if (failed(validateShapeFoldDtype(rewriter, op, resultType)))
-       return failure();
- 
--    bool isUnsignedInt = resultType.getElementType().isUnsignedInteger();
--    auto res = foldBinaryOpIntOrFloat(rewriter, op, FoldMin(isUnsignedInt));
-+    bool isUnsignedIntOrBool = resultElementType.isUnsignedInteger() ||
-+                               resultElementType.isInteger(/*width=*/1);
-+    auto res =
-+        foldBinaryOpIntOrFloat(rewriter, op, FoldMin(isUnsignedIntOrBool));
-     if (failed(res)) return failure();
-     rewriter.replaceOpWithNewOp<mlir::stablehlo::ConstantOp>(op, res.value());
-     return success();
-@@ -786,21 +856,36 @@
- 
-   LogicalResult matchAndRewrite(OrOp op,
-                                 PatternRewriter& rewriter) const override {
--    // TODO: Support more int types
-     auto resultType = op.getType();
--    if (!resultType.getElementType().isInteger(1))
--      return rewriter.notifyMatchFailure(op, "expected boolean element type");
--
--    auto res = foldBinaryOpIntOrFloat(rewriter, op, FoldOr{});
--    if (failed(res)) return failure();
--    rewriter.replaceOpWithNewOp<mlir::stablehlo::ConstantOp>(op, res.value());
--    return success();
--  }
--
--  struct FoldOr {
-+    auto resultElementType = resultType.getElementType();
-+    FailureOr<TypedAttr> result;
-+
-+    if (resultElementType.isInteger(/*width=*/1)) {
-+      result = foldBinaryOpIntOrFloat(rewriter, op, FoldLogicalOr{});
-+    } else if (resultElementType.isInteger()) {
-+      result = foldBinaryOpIntOrFloat(rewriter, op, FoldBitwiseOr{});
-+    } else {
-+      return rewriter.notifyMatchFailure(op, "Expected integral element type.");
-+    }
-+
-+    if (failed(result)) return failure();
-+    rewriter.replaceOpWithNewOp<mlir::stablehlo::ConstantOp>(op,
-+                                                             result.value());
-+    return success();
-+  }
-+
-+  struct FoldLogicalOr {
-     APInt operator()(APInt lhs, APInt rhs) const {
-       return APInt(lhs.getBitWidth(), !lhs.isZero() || !rhs.isZero());
-     }
-+    std::optional<APFloat> operator()(APFloat lhs, APFloat rhs) const {
-+      return std::nullopt;
-+    }
-+  };
-+
-+  struct FoldBitwiseOr {
-+    APInt operator()(APInt lhs, APInt rhs) const { return lhs | rhs; }
-+
-     std::optional<APFloat> operator()(APFloat lhs, APFloat rhs) const {
-       return std::nullopt;
-     }
-@@ -828,9 +913,12 @@
-         : foldIntFn(isUnsignedInt ? foldUint : foldSint) {}
-     std::function<APInt(APInt, APInt)> foldIntFn;
- 
--    // TODO: Enable float folding.
-     std::optional<APFloat> operator()(APFloat lhs, APFloat rhs) {
--      return std::nullopt;  // return lhs.remainder(rhs);
-+      // `APFloat::mod` requires both operands to have identical semantics.
-+      if (&lhs.getSemantics() != &rhs.getSemantics()) return std::nullopt;
-+
-+      lhs.mod(rhs);  // This modifies `lhs` in place.
-+      return lhs;    // `lhs` now holds the result.
-     }
-     APInt operator()(APInt lhs, APInt rhs) { return foldIntFn(lhs, rhs); }
-     static APInt foldUint(APInt lhs, APInt rhs) { return lhs.urem(rhs); }
-@@ -963,8 +1051,16 @@
-   struct FoldSign {
-     FoldSign(Type elementType) : elementType(elementType) {}
-     Type elementType;
--    // TODO: Enable float folding.
--    std::optional<APFloat> operator()(APFloat operand) { return std::nullopt; }
-+    double result;
-+    APFloat operator()(APFloat operand) {
-+      if (operand.isNegative())
-+        result = -1.0;
-+      else if (operand.isZero())
-+        result = 0.0;
-+      else
-+        result = 1.0;
-+      return getAPFloat(elementType, result);
-+    }
- 
-     APInt operator()(APInt operand) {
-       // SignOp only supports signed integers.
-@@ -1220,13 +1316,9 @@
- 
-     for (auto [inputValue, bodyArg] :
-          llvm::zip_equal(op.getOperands(), body.getArguments())) {
--      auto inputConstantOp = inputValue.getDefiningOp<ConstantOp>();
--      if (!inputConstantOp)
--        return rewriter.notifyMatchFailure(op, "Input must be a constant.");
--
--      auto inputConstantAttr =
--          dyn_cast_or_null<DenseElementsAttr>(inputConstantOp.getValue());
--      if (!inputConstantAttr)
-+      SplatElementsAttr constantSplatAttr;
-+      if (!matchPattern(inputValue, m_Constant(&constantSplatAttr)) ||
-+          !constantSplatAttr)
-         return rewriter.notifyMatchFailure(op,
-                                            "Input must be a splat constant.");
- 
-@@ -1236,7 +1328,7 @@
-             op, "Could not get the shape of the body argument.");
- 
-       bodyArgConstantAttrs.push_back(DenseElementsAttr::get(
--          bodyArgShapedType, inputConstantAttr.getSplatValue<Attribute>()));
-+          bodyArgShapedType, constantSplatAttr.getSplatValue<Attribute>()));
-     }
- 
-     for (BlockArgument bodyArg : body.getArguments()) {
-diff --ruN a/stablehlo/stablehlo/transforms/optimization/StablehloAggressiveSimplification.cpp b/stablehlo/stablehlo/transforms/optimization/StablehloAggressiveSimplification.cpp
---- stablehlo/stablehlo/transforms/optimization/StablehloAggressiveSimplification.cpp
-+++ stablehlo/stablehlo/transforms/optimization/StablehloAggressiveSimplification.cpp
-@@ -64,7 +64,7 @@
- static constexpr StablehloAggressiveSimplificationPassOptions kDefaultOptions;
- 
- static bool isIotaRange(ArrayRef<int64_t> dims) {
--  return llvm::all_of(llvm::enumerate(dims), [](const auto &it) {
-+  return llvm::all_of(llvm::enumerate(dims), [](const auto& it) {
-     return static_cast<int64_t>(it.index()) == it.value();
-   });
- }
-@@ -72,20 +72,20 @@
- template <typename OpType>
- struct SimplifyOpRewritePattern : OpRewritePattern<OpType> {
-   SimplifyOpRewritePattern(
--      MLIRContext *context,
--      const StablehloAggressiveSimplificationPassOptions &options,
-+      MLIRContext* context,
-+      const StablehloAggressiveSimplificationPassOptions& options,
-       PatternBenefit benefit = 1, ArrayRef<StringRef> generatedNames = {})
-       : OpRewritePattern<OpType>(context, benefit, generatedNames),
-         options(options) {}
- 
-   // Prevent `options` from binding to a temporary.
-   SimplifyOpRewritePattern(
--      MLIRContext *context,
--      StablehloAggressiveSimplificationPassOptions &&options,
-+      MLIRContext* context,
-+      StablehloAggressiveSimplificationPassOptions&& options,
-       PatternBenefit benefit = 1,
-       ArrayRef<StringRef> generatedNames = {}) = delete;
- 
--  const StablehloAggressiveSimplificationPassOptions &options;
-+  const StablehloAggressiveSimplificationPassOptions& options;
- };
- 
- /// Matches when either of the submatchers match.
-@@ -93,7 +93,7 @@
- struct m_AnyOf {
-   m_AnyOf(MatcherA a, MatcherB b) : matcherA(a), matcherB(b) {}
- 
--  bool match(Operation *op) { return matcherA.match(op) || matcherB.match(op); }
-+  bool match(Operation* op) { return matcherA.match(op) || matcherB.match(op); }
- 
-   MatcherA matcherA;
-   MatcherB matcherB;
-@@ -146,7 +146,7 @@
-   using SimplifyOpRewritePattern::SimplifyOpRewritePattern;
- 
-   LogicalResult matchAndRewrite(CompareOp op,
--                                PatternRewriter &rewriter) const override {
-+                                PatternRewriter& rewriter) const override {
-     RankedTensorType type = op.getType();
- 
-     // Bail out on non-integer comparison.
-@@ -211,7 +211,7 @@
-  public:
-   using SimplifyOpRewritePattern::SimplifyOpRewritePattern;
-   LogicalResult matchAndRewrite(ConcatenateOp op,
--                                PatternRewriter &rewriter) const override {
-+                                PatternRewriter& rewriter) const override {
-     if (op.getInputs().size() != 1 ||
-         op.getInputs().front().getType() != op.getType())
-       return rewriter.notifyMatchFailure(op, "not single operand noop-concat");
-@@ -227,7 +227,7 @@
-  public:
-   using SimplifyOpRewritePattern::SimplifyOpRewritePattern;
-   LogicalResult matchAndRewrite(ConcatenateOp op,
--                                PatternRewriter &rewriter) const override {
-+                                PatternRewriter& rewriter) const override {
-     auto axis = op.getDimension();
-     llvm::SmallVector<Value> newOperands = llvm::to_vector(
-         llvm::make_filter_range(op.getOperands(), [&](Value operand) {
-@@ -249,8 +249,8 @@
- class ConcatenateOpFlatten : public SimplifyOpRewritePattern<ConcatenateOp> {
-   using SimplifyOpRewritePattern::SimplifyOpRewritePattern;
-   LogicalResult matchAndRewrite(ConcatenateOp op,
--                                PatternRewriter &rewriter) const override {
--    auto getFlattenedOperands = [&](const Value &val) -> ValueRange {
-+                                PatternRewriter& rewriter) const override {
-+    auto getFlattenedOperands = [&](const Value& val) -> ValueRange {
-       auto definingOp = dyn_cast_or_null<ConcatenateOp>(val.getDefiningOp());
-       // To avoid inflate the memory footprint, only flatten the
-       // ConcatenateOp when it has only one use.
-@@ -293,7 +293,7 @@
-   using SimplifyOpRewritePattern::SimplifyOpRewritePattern;
- 
-   LogicalResult matchAndRewrite(CustomCallOp op,
--                                PatternRewriter &rewriter) const override {
-+                                PatternRewriter& rewriter) const override {
-     constexpr StringRef kMhloBackendConfigAttrName = "mhlo.backend_config";
- 
-     if (op.getApiVersion() != CustomCallApiVersion::API_VERSION_ORIGINAL)
-@@ -327,7 +327,7 @@
- /////////////////////////////////
- 
- // Used in DRR file.
--DenseI64ArrayAttr getMergedBroadcastDimensions(OpBuilder &b,
-+DenseI64ArrayAttr getMergedBroadcastDimensions(OpBuilder& b,
-                                                ArrayRef<int64_t> dims,
-                                                ArrayRef<int64_t> dimsParent) {
-   auto mergedDims = llvm::map_to_vector(
-@@ -350,8 +350,8 @@
- /// the op is used outside of the HLO dialect (e.g. in func.return). In these
- /// cases, we insert a stablehlo.convert to smooth things out.
- template <typename OpTy, typename... Args>
--static OpTy refineOpWithNewOp(PatternRewriter &rewriter, Operation *op,
--                              Args &&...args) {
-+static OpTy refineOpWithNewOp(PatternRewriter& rewriter, Operation* op,
-+                              Args&&... args) {
-   auto newOp = rewriter.create<OpTy>(op->getLoc(), std::forward<Args>(args)...);
- 
-   llvm::SmallVector<Value> replacementResults;
-@@ -360,7 +360,7 @@
-   for (auto [opResult, newOpResult] :
-        llvm::zip(op->getResults(), newOp->getResults())) {
-     Value replacementResult = newOpResult;
--    if (llvm::any_of(opResult.getUsers(), [&](Operation *user) {
-+    if (llvm::any_of(opResult.getUsers(), [&](Operation* user) {
-           return user->getDialect() != op->getDialect();
-         }))
-       replacementResult = rewriter.create<ConvertOp>(
-@@ -379,7 +379,7 @@
-   using SimplifyOpRewritePattern::SimplifyOpRewritePattern;
- 
-   LogicalResult matchAndRewrite(DynamicBroadcastInDimOp op,
--                                PatternRewriter &rewriter) const override {
-+                                PatternRewriter& rewriter) const override {
-     RankedTensorType operandType = op.getOperand().getType();
-     if (!operandType.hasStaticShape())
-       return rewriter.notifyMatchFailure(op, "requires operand static shape");
-@@ -410,7 +410,7 @@
- // DynamicGatherOp
- /////////////////////////////////
- 
--DenseI64ArrayAttr convertToI64Array(OpBuilder &b, Attribute attr) {
-+DenseI64ArrayAttr convertToI64Array(OpBuilder& b, Attribute attr) {
-   auto denseAttr = cast<ElementsAttr>(attr);
-   SmallVector<int64_t> result;
-   result.reserve(denseAttr.getNumElements());
-@@ -427,7 +427,7 @@
-   using SimplifyOpRewritePattern<DynamicIotaOp>::SimplifyOpRewritePattern;
- 
-   LogicalResult matchAndRewrite(DynamicIotaOp iota,
--                                PatternRewriter &rewriter) const override {
-+                                PatternRewriter& rewriter) const override {
-     // Result type has static shape, replace with iota.
-     auto resultTy = cast<ShapedType>(iota.getType());
-     if (!resultTy.hasStaticShape())
-@@ -447,7 +447,7 @@
-   using SimplifyOpRewritePattern<DynamicIotaOp>::SimplifyOpRewritePattern;
- 
-   LogicalResult matchAndRewrite(DynamicIotaOp iota,
--                                PatternRewriter &rewriter) const override {
-+                                PatternRewriter& rewriter) const override {
-     auto resultType = cast<ShapedType>(iota.getType());
-     if (resultType.getRank() < 2)
-       return rewriter.notifyMatchFailure(iota, "requires rank >= 2");
-@@ -496,7 +496,7 @@
-   using SimplifyOpRewritePattern::SimplifyOpRewritePattern;
- 
-   LogicalResult matchAndRewrite(DynamicReshapeOp op,
--                                PatternRewriter &rewriter) const override {
-+                                PatternRewriter& rewriter) const override {
-     // This is a noop when the output type is already a static shape.
-     RankedTensorType type = op.getType();
-     if (!type.hasStaticShape())
-@@ -516,8 +516,8 @@
-   using SimplifyOpRewritePattern::SimplifyOpRewritePattern;
- 
-   LogicalResult matchAndRewrite(DynamicReshapeOp op,
--                                PatternRewriter &rewriter) const override {
--    Operation *defOp = op.getOperand().getDefiningOp();
-+                                PatternRewriter& rewriter) const override {
-+    Operation* defOp = op.getOperand().getDefiningOp();
-     if (!defOp ||
-         !defOp->hasTrait<mlir::OpTrait::SameOperandsAndResultShape>()) {
-       return rewriter.notifyMatchFailure(
-@@ -549,7 +549,7 @@
-   using SimplifyOpRewritePattern<DynamicSliceOp>::SimplifyOpRewritePattern;
- 
-   LogicalResult matchAndRewrite(DynamicSliceOp dynamicSlice,
--                                PatternRewriter &rewriter) const override {
-+                                PatternRewriter& rewriter) const override {
-     Value input = dynamicSlice.getOperand();
-     auto inputType = cast<ShapedType>(input.getType());
-     if (!inputType.hasStaticShape())
-@@ -558,7 +558,7 @@
- 
-     auto sliceSizes = dynamicSlice.getSliceSizes();
-     SmallVector<int64_t, 4> tempStartIndices;
--    for (const auto &indexAndSliceStart :
-+    for (const auto& indexAndSliceStart :
-          llvm::enumerate(dynamicSlice.getStartIndices())) {
-       APInt val;
-       Value start = indexAndSliceStart.value();
-@@ -579,7 +579,7 @@
-     // pack them into a single tensor.
-     auto sliceStartIndices = rewriter.getDenseI64ArrayAttr(tempStartIndices);
-     SmallVector<int64_t, 4> tempSliceLimits;
--    for (const auto &[start, size] : llvm::zip(tempStartIndices, sliceSizes)) {
-+    for (const auto& [start, size] : llvm::zip(tempStartIndices, sliceSizes)) {
-       tempSliceLimits.push_back(start + size);
-     }
-     auto sliceLimits = rewriter.getDenseI64ArrayAttr(tempSliceLimits);
-@@ -605,7 +605,7 @@
-   using SimplifyOpRewritePattern<RealDynamicSliceOp>::SimplifyOpRewritePattern;
- 
-   LogicalResult matchAndRewrite(RealDynamicSliceOp op,
--                                PatternRewriter &rewriter) const override {
-+                                PatternRewriter& rewriter) const override {
-     // This rewrite only works for unit strides because DynamicSliceOp
-     // doesn't support strides (i.e. it implicitly has unit strides).
-     DenseIntElementsAttr stridesAttr;
-@@ -670,11 +670,11 @@
-   using SimplifyOpRewritePattern::SimplifyOpRewritePattern;
- 
-   LogicalResult matchAndRewrite(ReduceOp op,
--                                PatternRewriter &rewriter) const override {
-+                                PatternRewriter& rewriter) const override {
-     // If all returned values in the ReduceOp region exists outside the
-     // region, replace the ReduceOp with those values.
-     if (auto retOp = dyn_cast<ReturnOp>(op.getBody().front().getTerminator())) {
--      Region *retRegion = retOp->getParentRegion();
-+      Region* retRegion = retOp->getParentRegion();
-       if (llvm::any_of(retOp.getResults(), [retRegion](Value result) {
-             return result.getParentRegion() == retRegion;
-           }))
-@@ -693,7 +693,7 @@
-   using SimplifyOpRewritePattern::SimplifyOpRewritePattern;
- 
-   LogicalResult matchAndRewrite(ReduceOp op,
--                                PatternRewriter &rewriter) const override {
-+                                PatternRewriter& rewriter) const override {
-     // We require all reduce shapes to be the same, up to the element types, so
-     // we can just use the first operand and the first result as
-     // representatives.
-@@ -733,7 +733,7 @@
-   using SimplifyOpRewritePattern::SimplifyOpRewritePattern;
- 
-   LogicalResult matchAndRewrite(ReduceOp op,
--                                PatternRewriter &rewriter) const override {
-+                                PatternRewriter& rewriter) const override {
-     SmallVector<OpResult, 4> usedResults;
-     llvm::copy_if(op.getResults(), std::back_inserter(usedResults),
-                   [](OpResult result) { return !result.use_empty(); });
-@@ -745,7 +745,7 @@
-     const auto numOperands = op.getNumOperands();
-     const auto numOperandPairs = numOperands / pairSize;
- 
--    Block &reducerBlock = op.getBody().front();
-+    Block& reducerBlock = op.getBody().front();
-     auto retOp = cast<ReturnOp>(reducerBlock.getTerminator());
- 
-     assert(numOperandPairs == op.getNumResults() &&
-@@ -757,10 +757,10 @@
-       if (v.getParentRegion() == reducerBody) workList.push_back(v);
-     };
- 
--    SmallPtrSet<Operation *, 16> usedOps;
-+    SmallPtrSet<Operation*, 16> usedOps;
-     SmallBitVector usedArgs(numOperands);
-     SmallBitVector usedReturnOperands(numOperandPairs);
--    for (const auto &usedResult : usedResults) {
-+    for (const auto& usedResult : usedResults) {
-       auto resultNo = usedResult.getResultNumber();
-       usedReturnOperands.set(resultNo);
- 
-@@ -774,9 +774,9 @@
-           const auto pairNo = blockArg.getArgNumber() % numOperandPairs;
-           usedArgs.set(pairNo);
-           usedArgs.set(pairNo + numOperandPairs);
--        } else if (auto *defOp = definition.getDefiningOp()) {
-+        } else if (auto* defOp = definition.getDefiningOp()) {
-           usedOps.insert(defOp);
--          for (const auto &operand : defOp->getOperands())
-+          for (const auto& operand : defOp->getOperands())
-             addToWorkList(operand);
-         }
-       }
-@@ -785,7 +785,7 @@
-     const auto newNumOperandPairs = usedResults.size();
-     const auto newNumOperands = newNumOperandPairs * pairSize;
-     if (newNumOperands != usedArgs.count()) {
--      return rewriter.notifyMatchFailure(op, [&](Diagnostic &diag) {
-+      return rewriter.notifyMatchFailure(op, [&](Diagnostic& diag) {
-         diag << "non-conservative case: " << newNumOperandPairs
-              << " return results should be matched with " << newNumOperands
-              << " operands, but got " << usedArgs.count();
-@@ -809,7 +809,7 @@
-     auto newOp =
-         rewriter.create<ReduceOp>(op.getLoc(), newInputs, newInitVals,
-                                   op.getDimensionsAttr(), newElementTypes);
--    Block *newReducerBlock = rewriter.createBlock(&newOp.getBody());
-+    Block* newReducerBlock = rewriter.createBlock(&newOp.getBody());
- 
-     IRMapping mapper;
-     for (auto arg : reducerBlock.getArguments())
-@@ -818,11 +818,11 @@
-                    newReducerBlock->addArgument(arg.getType(), arg.getLoc()));
- 
-     rewriter.setInsertionPointToStart(newReducerBlock);
--    for (Operation &op : reducerBlock.getOperations())
-+    for (Operation& op : reducerBlock.getOperations())
-       if (usedOps.contains(&op)) rewriter.clone(op, mapper);
- 
-     SmallVector<Value> newReturnOperands;
--    for (const auto &en : llvm::enumerate(retOp.getOperands()))
-+    for (const auto& en : llvm::enumerate(retOp.getOperands()))
-       if (usedReturnOperands[en.index()])
-         newReturnOperands.push_back(mapper.lookup(en.value()));
- 
-@@ -830,7 +830,7 @@
- 
-     // Build new results list (unused entries will be null).
-     SmallVector<Value> newResults(op.getNumResults());
--    for (const auto &[i, result] : llvm::enumerate(usedResults)) {
-+    for (const auto& [i, result] : llvm::enumerate(usedResults)) {
-       newResults[result.getResultNumber()] = newOp.getResult(i);
-     }
- 
-@@ -851,7 +851,7 @@
-   using SimplifyOpRewritePattern::SimplifyOpRewritePattern;
- 
-   LogicalResult matchAndRewrite(GetDimensionSizeOp op,
--                                PatternRewriter &rewriter) const override {
-+                                PatternRewriter& rewriter) const override {
-     // Fold get_dimension_size when the queried dim is statically known.
-     RankedTensorType operandTy = op.getOperand().getType();
- 
-@@ -877,7 +877,7 @@
-   using SimplifyOpRewritePattern::SimplifyOpRewritePattern;
- 
-   LogicalResult matchAndRewrite(GatherOp gather,
--                                PatternRewriter &rewriter) const override {
-+                                PatternRewriter& rewriter) const override {
-     DenseIntElementsAttr index;
-     if (!matchPattern(gather.getStartIndices(), m_Constant(&index)))
-       return failure();
-@@ -952,7 +952,7 @@
-   using SimplifyOpRewritePattern<IotaOp>::SimplifyOpRewritePattern;
- 
-   LogicalResult matchAndRewrite(IotaOp iota,
--                                PatternRewriter &rewriter) const override {
-+                                PatternRewriter& rewriter) const override {
-     auto resultTy = cast<ShapedType>(iota.getType());
-     if (resultTy.getRank() < 2)
-       return rewriter.notifyMatchFailure(iota, "itoa not broadcastable");
-@@ -989,7 +989,7 @@
-   using SimplifyOpRewritePattern<PadOp>::SimplifyOpRewritePattern;
- 
-   LogicalResult matchAndRewrite(PadOp op,
--                                PatternRewriter &rewriter) const override {
-+                                PatternRewriter& rewriter) const override {
-     auto operand = op.getOperand();
-     auto padVal = op.getPaddingValue();
- 
-@@ -1028,7 +1028,7 @@
-   using SimplifyOpRewritePattern::SimplifyOpRewritePattern;
- 
-   LogicalResult matchAndRewrite(SelectOp op,
--                                PatternRewriter &rewriter) const override {
-+                                PatternRewriter& rewriter) const override {
-     RankedTensorType type = op.getType();
- 
-     Value trueVal = op.getOnTrue();
-@@ -1079,7 +1079,7 @@
-   using SimplifyOpRewritePattern::SimplifyOpRewritePattern;
- 
-   LogicalResult matchAndRewrite(SelectOp op,
--                                PatternRewriter &rewriter) const override {
-+                                PatternRewriter& rewriter) const override {
-     Value pred = op.getPred();
-     Value trueVal = op.getOnTrue();
-     Value falseVal = op.getOnFalse();
-@@ -1133,7 +1133,7 @@
-   using SimplifyOpRewritePattern<SliceOp>::SimplifyOpRewritePattern;
- 
-   LogicalResult matchAndRewrite(SliceOp slice,
--                                PatternRewriter &rewriter) const override {
-+                                PatternRewriter& rewriter) const override {
-     auto resultTy = cast<ShapedType>(slice.getType());
-     if (!resultTy.hasStaticShape())
-       return rewriter.notifyMatchFailure(slice, "result shape not static");
-@@ -1228,12 +1228,12 @@
-   using SimplifyOpRewritePattern<SortOp>::SimplifyOpRewritePattern;
- 
-   LogicalResult matchAndRewrite(SortOp op,
--                                PatternRewriter &rewriter) const override {
-+                                PatternRewriter& rewriter) const override {
-     DenseSet<unsigned> erasedArgs;
-     unsigned numOperands = op.getNumOperands();
-     for (unsigned i = 0; i < numOperands; ++i) {
-       if (!op.getResult(i).use_empty()) continue;
--      Block &block = op.getComparator().front();
-+      Block& block = op.getComparator().front();
-       if (!block.getArgument(i * 2).use_empty()) continue;
-       if (!block.getArgument(i * 2 + 1).use_empty()) continue;
-       erasedArgs.insert(i);
-@@ -1242,7 +1242,7 @@
- 
-     SmallVector<Value> newOperands;
-     BitVector erasedBlockArgs(op.getNumOperands() * 2);
--    for (const auto &en : llvm::enumerate(op.getInputs())) {
-+    for (const auto& en : llvm::enumerate(op.getInputs())) {
-       if (erasedArgs.contains(en.index())) {
-         erasedBlockArgs.set(en.index() * 2);
-         erasedBlockArgs.set(en.index() * 2 + 1);
-@@ -1253,7 +1253,7 @@
- 
-     auto newOp = rewriter.create<SortOp>(op.getLoc(), newOperands,
-                                          op.getDimension(), op.getIsStable());
--    Region &region = newOp.getComparator();
-+    Region& region = newOp.getComparator();
-     rewriter.inlineRegionBefore(op.getComparator(), region, region.end());
-     region.front().eraseArguments(erasedBlockArgs);
- 
-@@ -1278,7 +1278,7 @@
-   using SimplifyOpRewritePattern<SortOp>::SimplifyOpRewritePattern;
- 
-   LogicalResult matchAndRewrite(SortOp op,
--                                PatternRewriter &rewriter) const override {
-+                                PatternRewriter& rewriter) const override {
-     if (op.getResults().empty() ||
-         static_cast<int64_t>(op.getDimension()) != -1)
-       return rewriter.notifyMatchFailure(op,
-@@ -1304,7 +1304,7 @@
-   using SimplifyOpRewritePattern::SimplifyOpRewritePattern;
- 
-   LogicalResult matchAndRewrite(TransposeOp op,
--                                PatternRewriter &rewriter) const override {
-+                                PatternRewriter& rewriter) const override {
-     auto input = op.getOperand();
-     auto permutation = op.getPermutation();
- 
-@@ -1340,7 +1340,7 @@
-   using SimplifyOpRewritePattern<TupleOp>::SimplifyOpRewritePattern;
- 
-   LogicalResult matchAndRewrite(TupleOp op,
--                                PatternRewriter &rewriter) const override {
-+                                PatternRewriter& rewriter) const override {
-     if (op.getVal().empty())
-       return rewriter.notifyMatchFailure(op, "empty tuple");
- 
-@@ -1356,7 +1356,7 @@
-           op, "tuple predecessor type does not match");
- 
-     // Check that this is a repacking of the parent tuple.
--    for (const auto &elementAndIdx : llvm::enumerate(op.getVal())) {
-+    for (const auto& elementAndIdx : llvm::enumerate(op.getVal())) {
-       auto elementOp = elementAndIdx.value().getDefiningOp<GetTupleElementOp>();
-       if (!elementOp ||
-           elementOp.getIndexAttr().getInt() !=
-@@ -1385,9 +1385,9 @@
-   using SimplifyOpRewritePattern<WhileOp>::SimplifyOpRewritePattern;
- 
-   LogicalResult matchAndRewrite(WhileOp whileOp,
--                                PatternRewriter &rewriter) const override {
--    Block *cond = whileOp.SingleBlock::getBody(0);
--    Block *body = whileOp.SingleBlock::getBody(1);
-+                                PatternRewriter& rewriter) const override {
-+    Block* cond = whileOp.SingleBlock::getBody(0);
-+    Block* body = whileOp.SingleBlock::getBody(1);
-     auto bodyReturnOp = cast<ReturnOp>(body->getTerminator());
-     if (!llvm::any_of(llvm::zip(whileOp->getOperands(), body->getArguments(),
-                                 bodyReturnOp->getOperands()),
-@@ -1400,10 +1400,10 @@
-     SmallVector<Value> newOperands, resultsToReplace;
-     SmallVector<unsigned> invariantArgIdxs;
-     BitVector invariantArgIdxBitVector(cond->getNumArguments());
--    for (const auto &enumeratedOperands : llvm::enumerate(llvm::zip(
-+    for (const auto& enumeratedOperands : llvm::enumerate(llvm::zip(
-              whileOp.getOperands(), cond->getArguments(), body->getArguments(),
-              bodyReturnOp->getOperands(), whileOp->getResults()))) {
--      const auto &operands = enumeratedOperands.value();
-+      const auto& operands = enumeratedOperands.value();
-       Value whileOperand = std::get<0>(operands);
-       BlockArgument condBlockArg = std::get<1>(operands);
-       BlockArgument bodyBlockArg = std::get<2>(operands);
-@@ -1455,14 +1455,14 @@
- // Pattern: op(X : zero_extent_tensor) -> constant([])
- struct ZeroExtentToEmptyConstant final : RewritePattern {
-   explicit ZeroExtentToEmptyConstant(
--      MLIRContext *context,
-+      MLIRContext* context,
-       StablehloAggressiveSimplificationPassOptions options,
-       PatternBenefit benefit = 1)
-       : RewritePattern(MatchAnyOpTypeTag(), benefit, context),
-         options(options) {}
- 
--  LogicalResult matchAndRewrite(Operation *op,
--                                PatternRewriter &rewriter) const override {
-+  LogicalResult matchAndRewrite(Operation* op,
-+                                PatternRewriter& rewriter) const override {
-     auto loc = op->getLoc();
- 
-     if (!isa_and_present<StablehloDialect>(op->getDialect()))
-@@ -1492,10 +1492,10 @@
- 
-     // If one of the operands is a zero-extent tensor, replace the operand with
-     // an empty tensor.
--    for (OpOperand &operand : op->getOpOperands()) {
-+    for (OpOperand& operand : op->getOpOperands()) {
-       auto operandType = getMaybeZeroExtentType(operand.get().getType());
-       if (!operandType || operand.get().getDefiningOp<ConstantOp>()) continue;
--      Operation *owner = operand.getOwner();
-+      Operation* owner = operand.getOwner();
-       int operandNum = operand.getOperandNumber();
-       auto emptyConstantOp = rewriter.create<ConstantOp>(
-           loc, operandType.value(),
-@@ -1514,13 +1514,13 @@
- struct ReorderElementwiseAndShapeOp final
-     : OpTraitRewritePattern<OpTrait::Elementwise> {
-   explicit ReorderElementwiseAndShapeOp(
--      MLIRContext *context,
-+      MLIRContext* context,
-       StablehloAggressiveSimplificationPassOptions options,
-       PatternBenefit benefit = 1)
-       : OpTraitRewritePattern(context, benefit), options(options) {}
- 
--  LogicalResult matchAndRewrite(Operation *op,
--                                PatternRewriter &rewriter) const override {
-+  LogicalResult matchAndRewrite(Operation* op,
-+                                PatternRewriter& rewriter) const override {
-     if (op->getOperands().size() != 1)
-       return rewriter.notifyMatchFailure(op, "expected to be unary");
- 
-@@ -1575,7 +1575,7 @@
-       : StablehloAggressiveSimplificationPassBase() {}
- 
-   void runOnOperation() override {
--    MLIRContext *context = &getContext();
-+    MLIRContext* context = &getContext();
-     RewritePatternSet patterns(context);
- 
-     StablehloAggressiveSimplificationPassOptions options{
-@@ -1597,12 +1597,13 @@
- }  // namespace
- 
- void populateStablehloCanonicalizationPatterns(
--    MLIRContext *context, RewritePatternSet *patterns,
--    const StablehloAggressiveSimplificationPassOptions &options,
-+    MLIRContext* context, RewritePatternSet* patterns,
-+    const StablehloAggressiveSimplificationPassOptions& options,
-     PatternBenefit benefit) {
-   populateWithGenerated(*patterns);
-+  // TODO: Re-enable `CompareSelectIntoMinMax` after fixing legalization issue.
-   patterns->add<
--      CompareOpCanon, CompareSelectIntoMinMax, ConcatenateOpFlatten,
-+      CompareOpCanon, /*CompareSelectIntoMinMax,*/ ConcatenateOpFlatten,
-       ConcatenateOpNoop, ConcatenateOpRemoveEmpty,
-       CustomCallUnregisteredBackendConfigToFfi, DynamicIotaOpToBroadcast,
-       DynamicReshapeOpSameOperandAndResultShape, DynamicSliceOpToSlice,
-@@ -1614,8 +1615,11 @@
-       context, options, benefit);
- 
-   // Generic patterns
--  patterns->add<ReorderElementwiseAndShapeOp, ZeroExtentToEmptyConstant>(
--      context, options, benefit);
-+  // TODO: Re-enable `ReorderElementwiseAndShapeOp` after fixing BF16 precision
-+  // emulation issue in XLA-CPU.
-+  patterns->add<
-+      /*ReorderElementwiseAndShapeOp,*/
-+      ZeroExtentToEmptyConstant>(context, options, benefit);
- 
-   // TODO: Dynamism Refinements, consider merging with canonicalize dynamism
-   patterns
-@@ -1623,22 +1627,22 @@
-             DynamicReshapeOpIsStatic, DynamicIotaIsStatic>(context, options);
- }
- 
--void populateStablehloCanonicalizationPatterns(MLIRContext *context,
--                                               RewritePatternSet *patterns,
-+void populateStablehloCanonicalizationPatterns(MLIRContext* context,
-+                                               RewritePatternSet* patterns,
-                                                PatternBenefit benefit) {
-   populateStablehloCanonicalizationPatterns(context, patterns, kDefaultOptions,
-                                             benefit);
- }
- 
- void populateStablehloHloImportCanonicalizationPatterns(
--    MLIRContext *context, RewritePatternSet *patterns,
--    const StablehloAggressiveSimplificationPassOptions &options) {
-+    MLIRContext* context, RewritePatternSet* patterns,
-+    const StablehloAggressiveSimplificationPassOptions& options) {
-   patterns->add<ReshapeOp_RemoveNoop, GetTupleElementOp_UnpackTuple>(context);
-   patterns->add<TupleIsRepacking, WhileOpImplicitCapture>(context, options);
- }
- 
- void populateStablehloHloImportCanonicalizationPatterns(
--    MLIRContext *context, RewritePatternSet *patterns) {
-+    MLIRContext* context, RewritePatternSet* patterns) {
-   populateStablehloHloImportCanonicalizationPatterns(context, patterns,
-                                                      kDefaultOptions);
- }
-diff --ruN a/stablehlo/stablehlo/transforms/optimization/StablehloAggressiveSimplificationPatterns.td b/stablehlo/stablehlo/transforms/optimization/StablehloAggressiveSimplificationPatterns.td
---- stablehlo/stablehlo/transforms/optimization/StablehloAggressiveSimplificationPatterns.td
-+++ stablehlo/stablehlo/transforms/optimization/StablehloAggressiveSimplificationPatterns.td
-@@ -234,7 +234,7 @@
- //
- // No-op, but wrap in ConvertOp to preserve dynamic output shape. This can be
- // important if the result is returned, in which case refining the type would
--// require also updating the funciton signature.
-+// require also updating the function signature.
- def DynamicBroadcastInDimOp_ReplaceNoopWithConvert
-   : Pat<(StableHLO_DynamicBroadcastInDimOp:$op
-             $operand, $shape, IotaDims:$dims, $expanding, $nonexpanding),
-@@ -387,9 +387,10 @@
- 
- // Pattern: multiply(X, 0i) -> 0i
- //
--// Multiplication by 0. This fold is not trivial for floats in presence of NaNs.
-+// Multiplication by 0. This fold is not trivial for floats in presence of NaNs,
-+// so we currently only enable it for ints.
- def MulOp_FoldToZero
--  : Pat<(StableHLO_MulOp $lhs, (StableHLO_ConstantOp:$zero AnyZero:$value)),
-+  : Pat<(StableHLO_MulOp $lhs, (StableHLO_ConstantOp:$zero IntZero:$value)),
-         (replaceWithValue $zero)>;
- 
- // Pattern: multiply(X, 1i) -> X
 
