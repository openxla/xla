diff --git a/third_party/llvm/generated.patch b/third_party/llvm/generated.patch
index 09d0f82..4ae8803 100644
--- a/third_party/llvm/generated.patch
+++ b/third_party/llvm/generated.patch
@@ -1,964 +1,201 @@
 Auto generated patch. Do not edit or delete it, even if empty.
-diff -ruN --strip-trailing-cr a/clang/include/clang/Analysis/FlowSensitive/StorageLocation.h b/clang/include/clang/Analysis/FlowSensitive/StorageLocation.h
---- a/clang/include/clang/Analysis/FlowSensitive/StorageLocation.h
-+++ b/clang/include/clang/Analysis/FlowSensitive/StorageLocation.h
-@@ -17,7 +17,6 @@
- #include "clang/AST/Decl.h"
- #include "clang/AST/Type.h"
- #include "llvm/ADT/DenseMap.h"
--#include "llvm/ADT/StringRef.h"
- #include "llvm/Support/Debug.h"
- #include <cassert>
- 
-@@ -153,11 +152,6 @@
-     return {SyntheticFields.begin(), SyntheticFields.end()};
-   }
- 
--  /// Add a synthetic field, if none by that name is already present.
--  void addSyntheticField(llvm::StringRef Name, StorageLocation &Loc) {
--    SyntheticFields.insert({Name, &Loc});
--  }
--
-   /// Changes the child storage location for a field `D` of reference type.
-   /// All other fields cannot change their storage location and always retain
-   /// the storage location passed to the `RecordStorageLocation` constructor.
-@@ -170,11 +164,6 @@
-     Children[&D] = Loc;
-   }
- 
--  /// Add a child storage location for a field `D`, if not already present.
--  void addChild(const ValueDecl &D, StorageLocation *Loc) {
--    Children.insert({&D, Loc});
--  }
--
-   llvm::iterator_range<FieldToLoc::const_iterator> children() const {
-     return {Children.begin(), Children.end()};
-   }
-diff -ruN --strip-trailing-cr a/clang/include/clang/AST/DeclCXX.h b/clang/include/clang/AST/DeclCXX.h
---- a/clang/include/clang/AST/DeclCXX.h
-+++ b/clang/include/clang/AST/DeclCXX.h
-@@ -3826,7 +3826,7 @@
- 
- public:
-   EnumDecl *getEnumDecl() const {
--    return cast<clang::EnumType>(EnumType->getType())->getOriginalDecl();
-+    return EnumType->getType()->castAs<clang::EnumType>()->getOriginalDecl();
-   }
- 
-   static UsingEnumDecl *Create(ASTContext &C, DeclContext *DC,
-diff -ruN --strip-trailing-cr a/clang/lib/Analysis/FlowSensitive/Transfer.cpp b/clang/lib/Analysis/FlowSensitive/Transfer.cpp
---- a/clang/lib/Analysis/FlowSensitive/Transfer.cpp
-+++ b/clang/lib/Analysis/FlowSensitive/Transfer.cpp
-@@ -20,17 +20,14 @@
- #include "clang/AST/OperationKinds.h"
- #include "clang/AST/Stmt.h"
- #include "clang/AST/StmtVisitor.h"
--#include "clang/AST/Type.h"
- #include "clang/Analysis/FlowSensitive/ASTOps.h"
- #include "clang/Analysis/FlowSensitive/AdornedCFG.h"
- #include "clang/Analysis/FlowSensitive/DataflowAnalysisContext.h"
- #include "clang/Analysis/FlowSensitive/DataflowEnvironment.h"
- #include "clang/Analysis/FlowSensitive/NoopAnalysis.h"
- #include "clang/Analysis/FlowSensitive/RecordOps.h"
--#include "clang/Analysis/FlowSensitive/StorageLocation.h"
- #include "clang/Analysis/FlowSensitive/Value.h"
- #include "clang/Basic/Builtins.h"
--#include "clang/Basic/LLVM.h"
- #include "clang/Basic/OperatorKinds.h"
- #include "llvm/Support/Casting.h"
- #include <assert.h>
-@@ -290,7 +287,7 @@
-     }
-   }
- 
--  void VisitCastExpr(const CastExpr *S) {
-+  void VisitImplicitCastExpr(const ImplicitCastExpr *S) {
-     const Expr *SubExpr = S->getSubExpr();
-     assert(SubExpr != nullptr);
- 
-@@ -320,60 +317,6 @@
-       break;
-     }
+diff -ruN --strip-trailing-cr a/llvm/lib/Analysis/ScalarEvolution.cpp b/llvm/lib/Analysis/ScalarEvolution.cpp
+--- a/llvm/lib/Analysis/ScalarEvolution.cpp
++++ b/llvm/lib/Analysis/ScalarEvolution.cpp
+@@ -3217,26 +3217,18 @@
+       }
  
--    case CK_BaseToDerived: {
--      // This is a cast of (single-layer) pointer or reference to a record type.
--      // We should now model the fields for the derived type.
--
--      // Get the RecordStorageLocation for the record object underneath.
--      RecordStorageLocation *Loc = nullptr;
--      if (S->getType()->isPointerType()) {
--        auto *PV = Env.get<PointerValue>(*SubExpr);
--        assert(PV != nullptr);
--        if (PV == nullptr)
--          break;
--        Loc = cast<RecordStorageLocation>(&PV->getPointeeLoc());
--      } else {
--        assert(S->getType()->isRecordType());
--        if (SubExpr->isGLValue()) {
--          Loc = Env.get<RecordStorageLocation>(*SubExpr);
+       // Try to fold (C1 * D /u C2) -> C1/C2 * D, if C1 and C2 are powers-of-2,
+-      // D is a multiple of C2, and C1 is a multiple of C2. If C2 is a multiple
+-      // of C1, fold to (D /u (C2 /u C1)).
++      // D is a multiple of C2, and C1 is a multiple of C2.
+       const SCEV *D;
+       APInt C1V = LHSC->getAPInt();
+-      // (C1 * D /u C2) == -1 * -C1 * D /u C2 when C1 != INT_MIN. Don't treat -1
+-      // as -1 * 1, as it won't enable additional folds.
+-      if (C1V.isNegative() && !C1V.isMinSignedValue() && !C1V.isAllOnes())
++      // (C1 * D /u C2) == -1 * -C1 * D /u C2 when C1 != INT_MIN.
++      if (C1V.isNegative() && !C1V.isMinSignedValue())
+         C1V = C1V.abs();
+       const SCEVConstant *C2;
+       if (C1V.isPowerOf2() &&
+           match(Ops[1], m_scev_UDiv(m_SCEV(D), m_SCEVConstant(C2))) &&
+-          C2->getAPInt().isPowerOf2() &&
++          C2->getAPInt().isPowerOf2() && C1V.uge(C2->getAPInt()) &&
+           C1V.logBase2() <= getMinTrailingZeros(D)) {
+-        const SCEV *NewMul;
+-        if (C1V.uge(C2->getAPInt())) {
+-          NewMul = getMulExpr(getUDivExpr(getConstant(C1V), C2), D);
 -        } else {
--          Loc = &Env.getResultObjectLocation(*SubExpr);
--        }
--      }
--      if (!Loc) {
--        // Nowhere to add children or propagate from, so we're done.
--        break;
--      }
--
--      // Get the derived record type underneath the reference or pointer.
--      QualType Derived = S->getType().getNonReferenceType();
--      if (Derived->isPointerType()) {
--        Derived = Derived->getPointeeType();
--      }
--
--      // Add children to the storage location for fields (including synthetic
--      // fields) of the derived type and initialize their values.
--      for (const FieldDecl *Field :
--           Env.getDataflowAnalysisContext().getModeledFields(Derived)) {
--        assert(Field != nullptr);
--        QualType FieldType = Field->getType();
--        if (FieldType->isReferenceType()) {
--          Loc->addChild(*Field, nullptr);
--        } else {
--          Loc->addChild(*Field, &Env.createStorageLocation(FieldType));
--        }
--
--        for (const auto &Entry :
--             Env.getDataflowAnalysisContext().getSyntheticFields(Derived)) {
--          Loc->addSyntheticField(Entry.getKey(),
--                                 Env.createStorageLocation(Entry.getValue()));
+-          assert(C1V.ugt(1) && "C1 <= 1 should have been folded earlier");
+-          NewMul = getUDivExpr(D, getUDivExpr(C2, getConstant(C1V)));
 -        }
--      }
--      Env.initializeFieldsWithValues(*Loc, Derived);
--
--      // Fall through to propagate SubExpr's StorageLocation to the CastExpr.
--      [[fallthrough]];
--    }
-     case CK_IntegralCast:
-       // FIXME: This cast creates a new integral value from the
-       // subexpression. But, because we don't model integers, we don't
-@@ -381,9 +324,10 @@
-       // modeling is added, then update this code to create a fresh location and
-       // value.
-     case CK_UncheckedDerivedToBase:
--    case CK_DerivedToBase:
-     case CK_ConstructorConversion:
-     case CK_UserDefinedConversion:
-+      // FIXME: Add tests that excercise CK_UncheckedDerivedToBase,
-+      // CK_ConstructorConversion, and CK_UserDefinedConversion.
-     case CK_NoOp: {
-       // FIXME: Consider making `Environment::getStorageLocation` skip noop
-       // expressions (this and other similar expressions in the file) instead
-@@ -740,6 +684,15 @@
-     propagateValue(*SubExpr, *S, Env);
-   }
++        const SCEV *NewMul = getMulExpr(getUDivExpr(getConstant(C1V), C2), D);
+         return C1V == LHSC->getAPInt() ? NewMul : getNegativeSCEV(NewMul);
+       }
+     }
+diff -ruN --strip-trailing-cr a/llvm/test/Analysis/ScalarEvolution/mul-udiv-folds.ll b/llvm/test/Analysis/ScalarEvolution/mul-udiv-folds.ll
+--- a/llvm/test/Analysis/ScalarEvolution/mul-udiv-folds.ll
++++ b/llvm/test/Analysis/ScalarEvolution/mul-udiv-folds.ll
+@@ -21,7 +21,7 @@
+ ; CHECK-NEXT:    %gep.8 = getelementptr i8, ptr %A, i64 %iv
+ ; CHECK-NEXT:    --> {(((zext i32 %start to i64) /u 4) + %A),+,1}<%loop> U: full-set S: full-set Exits: (((zext i32 %start to i64) /u 2) + %A) LoopDispositions: { %loop: Computable }
+ ; CHECK-NEXT:    %gep.16 = getelementptr i16, ptr %A, i64 %iv
+-; CHECK-NEXT:    --> {(((zext i32 %start to i64) /u 2) + %A),+,2}<%loop> U: full-set S: full-set Exits: ((zext i32 %start to i64) + %A) LoopDispositions: { %loop: Computable }
++; CHECK-NEXT:    --> {((2 * ((zext i32 %start to i64) /u 4))<nuw><nsw> + %A),+,2}<%loop> U: full-set S: full-set Exits: ((zext i32 %start to i64) + %A) LoopDispositions: { %loop: Computable }
+ ; CHECK-NEXT:    %gep.32 = getelementptr i32, ptr %A, i64 %iv
+ ; CHECK-NEXT:    --> {((zext i32 %start to i64) + %A),+,4}<%loop> U: full-set S: full-set Exits: ((2 * (zext i32 %start to i64))<nuw><nsw> + %A) LoopDispositions: { %loop: Computable }
+ ; CHECK-NEXT:    %gep.40 = getelementptr <{ i32, i8 }>, ptr %A, i64 %iv
+diff -ruN --strip-trailing-cr a/llvm/test/Transforms/LoopStrengthReduce/duplicated-phis.ll b/llvm/test/Transforms/LoopStrengthReduce/duplicated-phis.ll
+--- a/llvm/test/Transforms/LoopStrengthReduce/duplicated-phis.ll
++++ b/llvm/test/Transforms/LoopStrengthReduce/duplicated-phis.ll
+@@ -18,7 +18,8 @@
+ ; CHECK:       [[FOR_BODY_PREHEADER_NEW]]:
+ ; CHECK-NEXT:    [[UNROLL_ITER:%.*]] = and i64 [[MUL]], -4
+ ; CHECK-NEXT:    [[TMP4:%.*]] = add i64 [[UNROLL_ITER]], -4
+-; CHECK-NEXT:    [[TMP3:%.*]] = lshr i64 [[TMP4]], 1
++; CHECK-NEXT:    [[TMP5:%.*]] = lshr i64 [[TMP4]], 2
++; CHECK-NEXT:    [[TMP3:%.*]] = shl nuw nsw i64 [[TMP5]], 1
+ ; CHECK-NEXT:    [[LSR_IV_NEXT:%.*]] = sub i64 -3, [[TMP3]]
+ ; CHECK-NEXT:    br label %[[FOR_BODY:.*]]
+ ; CHECK:       [[FOR_BODY]]:
+diff -ruN --strip-trailing-cr a/mlir/lib/Bindings/Python/IRCore.cpp b/mlir/lib/Bindings/Python/IRCore.cpp
+--- a/mlir/lib/Bindings/Python/IRCore.cpp
++++ b/mlir/lib/Bindings/Python/IRCore.cpp
+@@ -1079,23 +1079,38 @@
+ PyModule::PyModule(PyMlirContextRef contextRef, MlirModule module)
+     : BaseContextObject(std::move(contextRef)), module(module) {}
+ 
+-PyModule::~PyModule() { mlirModuleDestroy(module); }
++PyModule::~PyModule() {
++  nb::gil_scoped_acquire acquire;
++  auto &liveModules = getContext()->liveModules;
++  assert(liveModules.count(module.ptr) == 1 &&
++         "destroying module not in live map");
++  liveModules.erase(module.ptr);
++  mlirModuleDestroy(module);
++}
  
-+  void VisitCXXStaticCastExpr(const CXXStaticCastExpr *S) {
-+    if (S->getCastKind() == CK_NoOp) {
-+      const Expr *SubExpr = S->getSubExpr();
-+      assert(SubExpr != nullptr);
-+
-+      propagateValueOrStorageLocation(*SubExpr, *S, Env);
-+    }
+ PyModuleRef PyModule::forModule(MlirModule module) {
+   MlirContext context = mlirModuleGetContext(module);
+   PyMlirContextRef contextRef = PyMlirContext::forContext(context);
+ 
+-  // Create.
+-  PyModule *unownedModule = new PyModule(std::move(contextRef), module);
+-  // Note that the default return value policy on cast is `automatic_reference`,
+-  // which means "does not take ownership, does not call delete/dtor".
+-  // We use `take_ownership`, which means "Python will call the C++ destructor
+-  // and delete operator when the Python wrapper is garbage collected", because
+-  // MlirModule actually wraps OwningOpRef<ModuleOp> (see mlirModuleCreateParse
+-  // etc).
+-  nb::object pyRef = nb::cast(unownedModule, nb::rv_policy::take_ownership);
+-  unownedModule->handle = pyRef;
+-  return PyModuleRef(unownedModule, std::move(pyRef));
++  nb::gil_scoped_acquire acquire;
++  auto &liveModules = contextRef->liveModules;
++  auto it = liveModules.find(module.ptr);
++  if (it == liveModules.end()) {
++    // Create.
++    PyModule *unownedModule = new PyModule(std::move(contextRef), module);
++    // Note that the default return value policy on cast is automatic_reference,
++    // which does not take ownership (delete will not be called).
++    // Just be explicit.
++    nb::object pyRef = nb::cast(unownedModule, nb::rv_policy::take_ownership);
++    unownedModule->handle = pyRef;
++    liveModules[module.ptr] =
++        std::make_pair(unownedModule->handle, unownedModule);
++    return PyModuleRef(unownedModule, std::move(pyRef));
 +  }
-+
-   void VisitConditionalOperator(const ConditionalOperator *S) {
-     const Environment *TrueEnv = StmtToEnv.getEnvironment(*S->getTrueExpr());
-     const Environment *FalseEnv = StmtToEnv.getEnvironment(*S->getFalseExpr());
-diff -ruN --strip-trailing-cr a/clang/lib/AST/ASTImporter.cpp b/clang/lib/AST/ASTImporter.cpp
---- a/clang/lib/AST/ASTImporter.cpp
-+++ b/clang/lib/AST/ASTImporter.cpp
-@@ -1740,10 +1740,21 @@
++  // Use existing.
++  PyModule *existing = it->second.second;
++  nb::object pyRef = nb::borrow<nb::object>(it->second.first);
++  return PyModuleRef(existing, std::move(pyRef));
  }
  
- ExpectedType ASTNodeImporter::VisitTagType(const TagType *T) {
--  Expected<TagDecl *> ToDeclOrErr = import(T->getOriginalDecl());
-+  TagDecl *DeclForType = T->getOriginalDecl();
-+  Expected<TagDecl *> ToDeclOrErr = import(DeclForType);
-   if (!ToDeclOrErr)
-     return ToDeclOrErr.takeError();
- 
-+  if (DeclForType->isUsed()) {
-+    // If there is a definition of the 'OriginalDecl', it should be imported to
-+    // have all information for the type in the "To" AST. (In some cases no
-+    // other reference may exist to the definition decl and it would not be
-+    // imported otherwise.)
-+    Expected<TagDecl *> ToDefDeclOrErr = import(DeclForType->getDefinition());
-+    if (!ToDefDeclOrErr)
-+      return ToDefDeclOrErr.takeError();
-+  }
-+
-   if (T->isCanonicalUnqualified())
-     return Importer.getToContext().getCanonicalTagType(*ToDeclOrErr);
- 
-diff -ruN --strip-trailing-cr a/clang/lib/Sema/SemaDecl.cpp b/clang/lib/Sema/SemaDecl.cpp
---- a/clang/lib/Sema/SemaDecl.cpp
-+++ b/clang/lib/Sema/SemaDecl.cpp
-@@ -5291,10 +5291,8 @@
-     //   UNION_TYPE;   <- where UNION_TYPE is a typedef union.
-     if ((Tag && Tag->getDeclName()) ||
-         DS.getTypeSpecType() == DeclSpec::TST_typename) {
--      RecordDecl *Record = dyn_cast_or_null<RecordDecl>(Tag);
--      if (!Record)
--        Record = DS.getRepAsType().get()->getAsRecordDecl();
--
-+      RecordDecl *Record = Tag ? dyn_cast<RecordDecl>(Tag)
-+                               : DS.getRepAsType().get()->getAsRecordDecl();
-       if (Record && getLangOpts().MicrosoftExt) {
-         Diag(DS.getBeginLoc(), diag::ext_ms_anonymous_record)
-             << Record->isUnion() << DS.getSourceRange();
-@@ -18052,7 +18050,8 @@
-           }
-         }
-       } else if (auto *RD = dyn_cast<CXXRecordDecl>(PrevDecl);
--                 RD && RD->isInjectedClassName()) {
-+                 TUK == TagUseKind::Reference && RD &&
-+                 RD->isInjectedClassName()) {
-         // If lookup found the injected class name, the previous declaration is
-         // the class being injected into.
-         PrevDecl = cast<TagDecl>(RD->getDeclContext());
-@@ -18544,8 +18543,14 @@
-   if (PrevDecl)
-     CheckRedeclarationInModule(New, PrevDecl);
- 
--  if (TUK == TagUseKind::Definition && (!SkipBody || !SkipBody->ShouldSkip))
--    New->startDefinition();
-+  if (TUK == TagUseKind::Definition) {
-+    if (!SkipBody || !SkipBody->ShouldSkip) {
-+      New->startDefinition();
-+    } else {
-+      New->setCompleteDefinition();
-+      New->demoteThisDefinitionToDeclaration();
-+    }
-+  }
- 
-   ProcessDeclAttributeList(S, New, Attrs);
-   AddPragmaAttributes(S, New);
-diff -ruN --strip-trailing-cr a/clang/lib/Sema/SemaType.cpp b/clang/lib/Sema/SemaType.cpp
---- a/clang/lib/Sema/SemaType.cpp
-+++ b/clang/lib/Sema/SemaType.cpp
-@@ -9878,7 +9878,14 @@
-   S.DiagnoseUseOfDecl(ED, Loc);
- 
-   QualType Underlying = ED->getIntegerType();
--  assert(!Underlying.isNull());
-+  if (Underlying.isNull()) {
-+    // This is an enum without a fixed underlying type which we skipped parsing
-+    // the body because we saw its definition previously in another module.
-+    // Use the definition's integer type in that case.
-+    assert(ED->isThisDeclarationADemotedDefinition());
-+    Underlying = ED->getDefinition()->getIntegerType();
-+    assert(!Underlying.isNull());
-+  }
- 
-   return Underlying;
+ nb::object PyModule::createFromCapsule(nb::object capsule) {
+@@ -2084,6 +2099,8 @@
+   return PyInsertionPoint{block, std::move(nextOpRef)};
  }
-diff -ruN --strip-trailing-cr a/clang/lib/Serialization/ASTReaderDecl.cpp b/clang/lib/Serialization/ASTReaderDecl.cpp
---- a/clang/lib/Serialization/ASTReaderDecl.cpp
-+++ b/clang/lib/Serialization/ASTReaderDecl.cpp
-@@ -2107,6 +2107,8 @@
-     auto *Def = DD.Definition;
-     DD = std::move(MergeDD);
-     DD.Definition = Def;
-+    while ((Def = Def->getPreviousDecl()))
-+      cast<CXXRecordDecl>(Def)->DefinitionData = &DD;
-     return;
-   }
  
-diff -ruN --strip-trailing-cr a/clang/test/Analysis/ctu-import-type-decl-definition.c b/clang/test/Analysis/ctu-import-type-decl-definition.c
---- a/clang/test/Analysis/ctu-import-type-decl-definition.c
-+++ b/clang/test/Analysis/ctu-import-type-decl-definition.c
-@@ -0,0 +1,43 @@
-+// RUN: rm -rf %t
-+// RUN: mkdir -p %t
-+// RUN: split-file %s %t
-+
-+// RUN: %clang_cc1 -emit-pch -o %t/import.c.ast %t/import.c
-+
-+// RUN: %clang_extdef_map -- -x c %t/import.c >> %t/externalDefMap.txt
-+// RUN: sed -i 's/$/.ast/' %t/externalDefMap.txt
-+
-+// RUN: %clang_cc1 -analyze \
-+// RUN:   -analyzer-checker=core \
-+// RUN:   -analyzer-config experimental-enable-naive-ctu-analysis=true \
-+// RUN:   -analyzer-config display-ctu-progress=true \
-+// RUN:   -analyzer-config ctu-dir=%t \
-+// RUN:   -verify %t/main.c
-+
-+//--- main.c
-+
-+// expected-no-diagnostics
-+
-+typedef struct X_s X_t;
-+unsigned long f_import(struct X_s *xPtr);
-+
-+static void freeWriteFileResources(struct X_s *xPtr) {
-+  f_import(xPtr);
-+}
-+
-+//--- import.c
-+
-+typedef struct Y_s Y_t;
-+
-+struct Y_s {
-+};
-+
-+struct X_s {
-+  Y_t y;
-+};
-+
-+unsigned long f_import(struct X_s *xPtr) {
-+  if (xPtr != 0) {
-+  }
-+  return 0;
-+}
-diff -ruN --strip-trailing-cr a/clang/test/AST/ast-dump-decl.cpp b/clang/test/AST/ast-dump-decl.cpp
---- a/clang/test/AST/ast-dump-decl.cpp
-+++ b/clang/test/AST/ast-dump-decl.cpp
-@@ -990,3 +990,18 @@
-   // CHECK-NEXT:    `-RecordType [[TestInjectedClassName_RT]] 'A' injected
-   // CHECK-NEXT:      `-CXXRecord [[TestInjectedClassName_RD]] 'A'
- } // namespace InjectedClassName
-+
-+namespace TestGH155936 {
-+  struct Foo {
-+    struct A {
-+      struct Foo {};
-+    };
-+  };
-+  // CHECK-LABEL: Dumping TestGH155936:
-+  // CHECK: CXXRecordDecl 0x{{.+}} <{{.+}}> line:[[@LINE-6]]:10 struct Foo definition
-+  // CHECK: CXXRecordDecl 0x{{.+}} <col:3, col:10> col:10 implicit struct Foo
-+  // CHECK: CXXRecordDecl 0x{{.+}} <{{.+}}> line:[[@LINE-7]]:12 struct A definition
-+  // CHECK: CXXRecordDecl 0x{{.+}} <col:5, col:12> col:12 implicit struct A
-+  // CHECK: CXXRecordDecl 0x{{.+}} <line:[[@LINE-8]]:7, col:19> col:14 struct Foo definition
-+  // CHECH: CXXRecordDecl 0x{{.+}} <col:9, col:16> col:16 implicit struct Foo
-+} // namspace GH155936
-diff -ruN --strip-trailing-cr a/clang/test/Modules/GH154840.cpp b/clang/test/Modules/GH154840.cpp
---- a/clang/test/Modules/GH154840.cpp
-+++ b/clang/test/Modules/GH154840.cpp
-@@ -0,0 +1,97 @@
-+// RUN: rm -rf %t
-+// RUN: mkdir -p %t
-+// RUN: split-file %s %t
-+// RUN: cd %t
-+//
-+// RUN: %clang_cc1 -fmodule-name=A -fno-cxx-modules -emit-module -fmodules -xc++ A.cppmap -o A.pcm
-+// RUN: %clang_cc1 -fmodule-name=B -fno-cxx-modules -emit-module -fmodules -xc++ B.cppmap -o B.pcm -fmodule-file=A.pcm
-+// RUN: %clang_cc1 -fmodule-name=C -fno-cxx-modules -emit-module -fmodules -xc++ C.cppmap -o C.pcm -fmodule-file=A.pcm
-+// RUN: %clang_cc1 -fmodule-name=D -fno-cxx-modules -emit-module -fmodules -xc++ D.cppmap -o D.pcm -fmodule-file=A.pcm
-+// RUN: %clang_cc1 -fmodule-name=E -fno-cxx-modules -emit-module -fmodules -xc++ E.cppmap -o E.pcm -fmodule-file=D.pcm -fmodule-file=B.pcm -fmodule-file=C.pcm
-+// RUN: %clang_cc1 -fno-cxx-modules -fmodules -fmodule-file=B.pcm -fmodule-file=E.pcm -emit-llvm -o /dev/null S.cpp
-+
-+//--- A.h
-+namespace std {
-+
-+template <class T> void zz(T);
-+
-+template <class> struct vec {
-+  struct w {};
-+  struct xx {};
-+
-+  vec(vec &) { init(); }
-+  constexpr vec &operator=(const vec &);
-+  template <class U> constexpr void pb(U);
-+  constexpr void init();
-+
-+  w s;
-+};
-+
-+template <class T> constexpr void vec<T>::init() {
-+  xx yy;
-+  zz(yy);
-+}
-+
-+template <class T> constexpr vec<T> &vec<T>::operator=(const vec &) {
-+  pb(s);
-+  return *this;
-+}
-+
-+template <class T> template <class U> constexpr void vec<T>::pb(U) { init(); }
-+} // namespace std
-+
-+//--- A.cppmap
-+module "A" {
-+  header "A.h"
-+}
-+
-+//--- X.h
-+#pragma clang module import A
-+
-+namespace project {
-+  class thing : std::vec<thing> {};
-+} // namespace project
-+
-+//--- B.h
-+#include "X.h"
-+
-+//--- B.cppmap
-+module "B" {
-+  header "B.h"
-+}
-+
-+//--- C.h
-+#include "X.h"
-+
-+//--- C.cppmap
-+module "C" {
-+  header "C.h"
-+}
-+
-+//--- D.h
-+#include "X.h"
-+
-+//--- D.cppmap
-+module "D" {
-+  header "D.h"
-+}
-+
-+//--- Y.h
-+#include "X.h"
-+struct other {
-+  other() : data(data) {}
-+  std::vec<project::thing> data;
-+};
-+
-+//--- E.h
-+#include "Y.h"
-+
-+//--- E.cppmap
-+module "E" {
-+  header "E.h"
-+}
-+
-+//--- S.cpp
-+#pragma clang module import A
-+#pragma clang module import E
-+void func(std::vec<project::thing> *a, std::vec<project::thing> *b) { *a = *b; }
-diff -ruN --strip-trailing-cr a/clang/test/Modules/GH155028-1.cpp b/clang/test/Modules/GH155028-1.cpp
---- a/clang/test/Modules/GH155028-1.cpp
-+++ b/clang/test/Modules/GH155028-1.cpp
-@@ -0,0 +1,17 @@
-+// RUN: %clang_cc1 -std=c++20 -verify %s
-+// expected-no-diagnostics
-+
-+#pragma clang module build M
-+module "M" {
-+  module "A" {}
-+  module "B" {}
-+}
-+#pragma clang module contents
-+#pragma clang module begin M.A
-+enum E1 {};
-+#pragma clang module end
-+#pragma clang module begin M.B
-+enum E1 {};
-+using T = __underlying_type(E1);
-+#pragma clang module end
-+#pragma clang module endbuild
-diff -ruN --strip-trailing-cr a/clang/test/Sema/GH155794.c b/clang/test/Sema/GH155794.c
---- a/clang/test/Sema/GH155794.c
-+++ b/clang/test/Sema/GH155794.c
-@@ -0,0 +1,6 @@
-+// RUN: %clang_cc1 -fsyntax-only -verify -Wno-everything %s
-+
-+struct S {
-+  enum e1 {} // expected-error {{use of empty enum}} expected-error {{expected ';' after enum}}
-+  enum e2 {} // expected-error {{use of empty enum}}
-+}; // expected-error {{expected member name or ';' after declaration specifiers}}
-diff -ruN --strip-trailing-cr a/clang/test/SemaTemplate/using-decl.cpp b/clang/test/SemaTemplate/using-decl.cpp
---- a/clang/test/SemaTemplate/using-decl.cpp
-+++ b/clang/test/SemaTemplate/using-decl.cpp
-@@ -14,3 +14,15 @@
-   }
-   void e() { c<int>(); }
- }
-+
-+namespace UsingUsingEnum {
-+  namespace foo {
-+    enum class EnumOne {};
-+  }
-+  using foo::EnumOne;
++size_t PyMlirContext::getLiveModuleCount() { return liveModules.size(); }
 +
-+  template <class> void t() {
-+    using enum EnumOne;
-+  }
-+  template void t<void>();
-+} // namespace UsingUsingEnum
-diff -ruN --strip-trailing-cr a/clang/unittests/Analysis/FlowSensitive/TransferTest.cpp b/clang/unittests/Analysis/FlowSensitive/TransferTest.cpp
---- a/clang/unittests/Analysis/FlowSensitive/TransferTest.cpp
-+++ b/clang/unittests/Analysis/FlowSensitive/TransferTest.cpp
-@@ -9,25 +9,17 @@
- #include "TestingSupport.h"
- #include "clang/AST/ASTContext.h"
- #include "clang/AST/Decl.h"
--#include "clang/AST/Expr.h"
--#include "clang/AST/ExprCXX.h"
--#include "clang/AST/OperationKinds.h"
--#include "clang/ASTMatchers/ASTMatchFinder.h"
- #include "clang/ASTMatchers/ASTMatchers.h"
--#include "clang/Analysis/FlowSensitive/DataflowAnalysis.h"
- #include "clang/Analysis/FlowSensitive/DataflowAnalysisContext.h"
- #include "clang/Analysis/FlowSensitive/DataflowEnvironment.h"
- #include "clang/Analysis/FlowSensitive/NoopAnalysis.h"
--#include "clang/Analysis/FlowSensitive/NoopLattice.h"
- #include "clang/Analysis/FlowSensitive/RecordOps.h"
- #include "clang/Analysis/FlowSensitive/StorageLocation.h"
- #include "clang/Analysis/FlowSensitive/Value.h"
- #include "clang/Basic/LangStandard.h"
- #include "clang/Testing/TestAST.h"
- #include "llvm/ADT/SmallVector.h"
--#include "llvm/ADT/StringMap.h"
- #include "llvm/ADT/StringRef.h"
--#include "llvm/Support/Casting.h"
- #include "llvm/Testing/Support/Error.h"
- #include "gmock/gmock.h"
- #include "gtest/gtest.h"
-@@ -35,7 +27,6 @@
- #include <string>
- #include <string_view>
- #include <utility>
--#include <vector>
- 
- namespace clang {
- namespace dataflow {
-@@ -3550,7 +3541,7 @@
-   testFunction(Code, "noexceptTarget");
- }
- 
--TEST(TransferTest, StaticCastNoOp) {
-+TEST(TransferTest, StaticCast) {
-   std::string Code = R"(
-     void target(int Foo) {
-       int Bar = static_cast<int>(Foo);
-@@ -3570,13 +3561,6 @@
-         const ValueDecl *BarDecl = findValueDecl(ASTCtx, "Bar");
-         ASSERT_THAT(BarDecl, NotNull());
- 
--        const auto *Cast = ast_matchers::selectFirst<CXXStaticCastExpr>(
--            "cast",
--            ast_matchers::match(ast_matchers::cxxStaticCastExpr().bind("cast"),
--                                ASTCtx));
--        ASSERT_THAT(Cast, NotNull());
--        ASSERT_EQ(Cast->getCastKind(), CK_NoOp);
--
-         const auto *FooVal = Env.getValue(*FooDecl);
-         const auto *BarVal = Env.getValue(*BarDecl);
-         EXPECT_TRUE(isa<IntegerValue>(FooVal));
-@@ -3585,268 +3569,6 @@
-       });
- }
- 
--TEST(TransferTest, StaticCastBaseToDerived) {
--  std::string Code = R"cc(
--    struct Base {
--      char C;
--    };
--    struct Intermediate : public Base {
--      bool B;
--    };
--    struct Derived : public Intermediate {
--      int I;
--    };
--    Base& getBaseRef();
--    void target(Base* BPtr) {
--      Derived* DPtr = static_cast<Derived*>(BPtr);
--      DPtr->C;
--      DPtr->B;
--      DPtr->I;
--      Derived& DRef = static_cast<Derived&>(*BPtr);
--      DRef.C;
--      DRef.B;
--      DRef.I;
--      Derived& DRefFromFunc = static_cast<Derived&>(getBaseRef());
--      DRefFromFunc.C;
--      DRefFromFunc.B;
--      DRefFromFunc.I;
--      // [[p]]
--    }
--  )cc";
--  runDataflow(
--      Code,
--      [](const llvm::StringMap<DataflowAnalysisState<NoopLattice>> &Results,
--         ASTContext &ASTCtx) {
--        ASSERT_THAT(Results.keys(), UnorderedElementsAre("p"));
--        const Environment &Env = getEnvironmentAtAnnotation(Results, "p");
--
--        const ValueDecl *BPtrDecl = findValueDecl(ASTCtx, "BPtr");
--        ASSERT_THAT(BPtrDecl, NotNull());
--
--        const ValueDecl *DPtrDecl = findValueDecl(ASTCtx, "DPtr");
--        ASSERT_THAT(DPtrDecl, NotNull());
--
--        const ValueDecl *DRefDecl = findValueDecl(ASTCtx, "DRef");
--        ASSERT_THAT(DRefDecl, NotNull());
--
--        const ValueDecl *DRefFromFuncDecl =
--            findValueDecl(ASTCtx, "DRefFromFunc");
--        ASSERT_THAT(DRefFromFuncDecl, NotNull());
--
--        const auto *Cast = ast_matchers::selectFirst<CXXStaticCastExpr>(
--            "cast",
--            ast_matchers::match(ast_matchers::cxxStaticCastExpr().bind("cast"),
--                                ASTCtx));
--        ASSERT_THAT(Cast, NotNull());
--        ASSERT_EQ(Cast->getCastKind(), CK_BaseToDerived);
--
--        EXPECT_EQ(Env.getValue(*BPtrDecl), Env.getValue(*DPtrDecl));
--        EXPECT_EQ(&Env.get<PointerValue>(*BPtrDecl)->getPointeeLoc(),
--                  Env.getStorageLocation(*DRefDecl));
--        // For DRefFromFunc, not crashing when analyzing the field accesses is
--        // enough.
--      });
--}
--
--TEST(TransferTest, ExplicitDerivedToBaseCast) {
--  std::string Code = R"cc(
--    struct Base {};
--    struct Derived : public Base {};
--    void target(Derived D) {
--      (Base*)&D;
--      // [[p]]
--    }
--)cc";
--  runDataflow(
--      Code,
--      [](const llvm::StringMap<DataflowAnalysisState<NoopLattice>> &Results,
--         ASTContext &ASTCtx) {
--        ASSERT_THAT(Results.keys(), UnorderedElementsAre("p"));
--        const Environment &Env = getEnvironmentAtAnnotation(Results, "p");
--
--        auto *Cast = ast_matchers::selectFirst<ImplicitCastExpr>(
--            "cast", ast_matchers::match(
--                        ast_matchers::implicitCastExpr().bind("cast"), ASTCtx));
--        ASSERT_THAT(Cast, NotNull());
--        ASSERT_EQ(Cast->getCastKind(), CK_DerivedToBase);
--
--        auto *AddressOf = ast_matchers::selectFirst<UnaryOperator>(
--            "addressof",
--            ast_matchers::match(ast_matchers::unaryOperator().bind("addressof"),
--                                ASTCtx));
--        ASSERT_THAT(AddressOf, NotNull());
--        ASSERT_EQ(AddressOf->getOpcode(), UO_AddrOf);
--
--        EXPECT_EQ(Env.getValue(*Cast), Env.getValue(*AddressOf));
--      });
--}
--
--TEST(TransferTest, ConstructorConversion) {
--  std::string Code = R"cc(
--    struct Base {};
--    struct Derived : public Base {};
--    void target(Derived D) {
--      Base B = (Base)D;
--      // [[p]]
--    }
--)cc";
--  runDataflow(
--      Code,
--      [](const llvm::StringMap<DataflowAnalysisState<NoopLattice>> &Results,
--         ASTContext &ASTCtx) {
--        ASSERT_THAT(Results.keys(), UnorderedElementsAre("p"));
--        const Environment &Env = getEnvironmentAtAnnotation(Results, "p");
--
--        auto *Cast = ast_matchers::selectFirst<CStyleCastExpr>(
--            "cast", ast_matchers::match(
--                        ast_matchers::cStyleCastExpr().bind("cast"), ASTCtx));
--        ASSERT_THAT(Cast, NotNull());
--        ASSERT_EQ(Cast->getCastKind(), CK_ConstructorConversion);
--
--        auto &DLoc = getLocForDecl<StorageLocation>(ASTCtx, Env, "D");
--        auto &BLoc = getLocForDecl<StorageLocation>(ASTCtx, Env, "B");
--        EXPECT_NE(&BLoc, &DLoc);
--      });
--}
--
--TEST(TransferTest, UserDefinedConversion) {
--  std::string Code = R"cc(
--    struct To {};
--    struct From {
--        operator To();
--    };
--    void target(From F) {
--        To T = (To)F;
--        // [[p]]
--    }
--)cc";
--  runDataflow(
--      Code,
--      [](const llvm::StringMap<DataflowAnalysisState<NoopLattice>> &Results,
--         ASTContext &ASTCtx) {
--        ASSERT_THAT(Results.keys(), UnorderedElementsAre("p"));
--        const Environment &Env = getEnvironmentAtAnnotation(Results, "p");
--
--        auto *Cast = ast_matchers::selectFirst<ImplicitCastExpr>(
--            "cast", ast_matchers::match(
--                        ast_matchers::implicitCastExpr().bind("cast"), ASTCtx));
--        ASSERT_THAT(Cast, NotNull());
--        ASSERT_EQ(Cast->getCastKind(), CK_UserDefinedConversion);
--
--        auto &FLoc = getLocForDecl<StorageLocation>(ASTCtx, Env, "F");
--        auto &TLoc = getLocForDecl<StorageLocation>(ASTCtx, Env, "T");
--        EXPECT_NE(&TLoc, &FLoc);
--      });
--}
--
--TEST(TransferTest, ImplicitUncheckedDerivedToBaseCast) {
--  std::string Code = R"cc(
--    struct Base {
--      void method();
--    };
--    struct Derived : public Base {};
--    void target(Derived D) {
--      D.method();
--      // [[p]]
--    }
--)cc";
--  runDataflow(
--      Code,
--      [](const llvm::StringMap<DataflowAnalysisState<NoopLattice>> &Results,
--         ASTContext &ASTCtx) {
--        ASSERT_THAT(Results.keys(), UnorderedElementsAre("p"));
--        const Environment &Env = getEnvironmentAtAnnotation(Results, "p");
--
--        auto *Cast = ast_matchers::selectFirst<ImplicitCastExpr>(
--            "cast", ast_matchers::match(
--                        ast_matchers::implicitCastExpr().bind("cast"), ASTCtx));
--        ASSERT_THAT(Cast, NotNull());
--        ASSERT_EQ(Cast->getCastKind(), CK_UncheckedDerivedToBase);
--
--        auto &DLoc = getLocForDecl<StorageLocation>(ASTCtx, Env, "D");
--        EXPECT_EQ(Env.getStorageLocation(*Cast), &DLoc);
--      });
--}
--
--TEST(TransferTest, ImplicitDerivedToBaseCast) {
--  std::string Code = R"cc(
--    struct Base {};
--    struct Derived : public Base {};
--    void target() {
--      Base* B = new Derived();
--      // [[p]]
--    }
--)cc";
--  runDataflow(
--      Code,
--      [](const llvm::StringMap<DataflowAnalysisState<NoopLattice>> &Results,
--         ASTContext &ASTCtx) {
--        ASSERT_THAT(Results.keys(), UnorderedElementsAre("p"));
--        const Environment &Env = getEnvironmentAtAnnotation(Results, "p");
--
--        auto *Cast = ast_matchers::selectFirst<ImplicitCastExpr>(
--            "cast", ast_matchers::match(
--                        ast_matchers::implicitCastExpr().bind("cast"), ASTCtx));
--        ASSERT_THAT(Cast, NotNull());
--        ASSERT_EQ(Cast->getCastKind(), CK_DerivedToBase);
--
--        auto *New = ast_matchers::selectFirst<CXXNewExpr>(
--            "new", ast_matchers::match(ast_matchers::cxxNewExpr().bind("new"),
--                                       ASTCtx));
--        ASSERT_THAT(New, NotNull());
--
--        EXPECT_EQ(Env.getValue(*Cast), Env.getValue(*New));
--      });
--}
--
--TEST(TransferTest, ReinterpretCast) {
--  std::string Code = R"cc(
--    struct S {
--        int I;
--    };
--
--    void target(unsigned char* Bytes) {
--        S& SRef = reinterpret_cast<S&>(Bytes);
--        SRef.I;
--        S* SPtr = reinterpret_cast<S*>(Bytes);
--        SPtr->I;
--        // [[p]]
--    }
--  )cc";
--  runDataflow(Code, [](const llvm::StringMap<DataflowAnalysisState<NoopLattice>>
--                           &Results,
--                       ASTContext &ASTCtx) {
--    ASSERT_THAT(Results.keys(), UnorderedElementsAre("p"));
--    const Environment &Env = getEnvironmentAtAnnotation(Results, "p");
--    const ValueDecl *I = findValueDecl(ASTCtx, "I");
--    ASSERT_THAT(I, NotNull());
--
--    // No particular knowledge of I's value is modeled, but for both casts,
--    // the fields of S are modeled.
--
--    {
--      auto &Loc = getLocForDecl<RecordStorageLocation>(ASTCtx, Env, "SRef");
--      std::vector<const ValueDecl *> Children;
--      for (const auto &Entry : Loc.children()) {
--        Children.push_back(Entry.getFirst());
--      }
--
--      EXPECT_THAT(Children, UnorderedElementsAre(I));
--    }
--
--    {
--      auto &Loc = cast<RecordStorageLocation>(
--          getValueForDecl<PointerValue>(ASTCtx, Env, "SPtr").getPointeeLoc());
--      std::vector<const ValueDecl *> Children;
--      for (const auto &Entry : Loc.children()) {
--        Children.push_back(Entry.getFirst());
--      }
--
--      EXPECT_THAT(Children, UnorderedElementsAre(I));
--    }
--  });
--}
--
- TEST(TransferTest, IntegralCast) {
-   std::string Code = R"(
-     void target(int Foo) {
-diff -ruN --strip-trailing-cr a/clang-tools-extra/test/clang-tidy/check_clang_tidy.py b/clang-tools-extra/test/clang-tidy/check_clang_tidy.py
---- a/clang-tools-extra/test/clang-tidy/check_clang_tidy.py
-+++ b/clang-tools-extra/test/clang-tidy/check_clang_tidy.py
-@@ -391,9 +391,7 @@
-     args, extra_args = parser.parse_known_args()
-     if args.std is None:
-         _, extension = os.path.splitext(args.assume_filename or args.input_file_name)
--        args.std = [
--            "c++11-or-later" if extension in [".cpp", ".hpp", ".mm"] else "c99-or-later"
--        ]
-+        args.std = ["c99-or-later" if extension in [".c", ".m"] else "c++11-or-later"]
- 
-     return (args, extra_args)
- 
-diff -ruN --strip-trailing-cr a/lldb/source/Plugins/SymbolFile/NativePDB/SymbolFileNativePDB.cpp b/lldb/source/Plugins/SymbolFile/NativePDB/SymbolFileNativePDB.cpp
---- a/lldb/source/Plugins/SymbolFile/NativePDB/SymbolFileNativePDB.cpp
-+++ b/lldb/source/Plugins/SymbolFile/NativePDB/SymbolFileNativePDB.cpp
-@@ -1735,11 +1735,11 @@
-   }
- 
-   // Sort them before value searching is working properly.
--  m_func_full_names.Sort();
-+  m_func_full_names.Sort(std::less<uint32_t>());
-   m_func_full_names.SizeToFit();
--  m_func_method_names.Sort();
-+  m_func_method_names.Sort(std::less<uint32_t>());
-   m_func_method_names.SizeToFit();
--  m_func_base_names.Sort();
-+  m_func_base_names.Sort(std::less<uint32_t>());
-   m_func_base_names.SizeToFit();
+ nb::object PyInsertionPoint::contextEnter(nb::object insertPoint) {
+   return PyThreadContextEntry::pushInsertionPoint(insertPoint);
  }
- 
-@@ -2426,7 +2426,7 @@
- 
-   // After calling Append(), the type-name map needs to be sorted again to be
-   // able to look up a type by its name.
--  m_type_base_names.Sort();
-+  m_type_base_names.Sort(std::less<uint32_t>());
- 
-   // Now that we know the forward -> full mapping of all type indices, we can
-   // re-write all the indices.  At the end of this process, we want a mapping
-diff -ruN --strip-trailing-cr a/lldb/tools/lldb-dap/Handler/ModuleSymbolsRequestHandler.cpp b/lldb/tools/lldb-dap/Handler/ModuleSymbolsRequestHandler.cpp
---- a/lldb/tools/lldb-dap/Handler/ModuleSymbolsRequestHandler.cpp
-+++ b/lldb/tools/lldb-dap/Handler/ModuleSymbolsRequestHandler.cpp
-@@ -60,7 +60,7 @@
-     if (!symbol.IsValid())
-       continue;
- 
--    Symbol dap_symbol;
-+    Symbol dap_symbol = {};
-     dap_symbol.id = symbol.GetID();
-     dap_symbol.type = symbol.GetType();
-     dap_symbol.isDebug = symbol.IsDebug();
-diff -ruN --strip-trailing-cr a/lldb/tools/lldb-dap/src-ts/ui/symbols-provider.ts b/lldb/tools/lldb-dap/src-ts/ui/symbols-provider.ts
---- a/lldb/tools/lldb-dap/src-ts/ui/symbols-provider.ts
-+++ b/lldb/tools/lldb-dap/src-ts/ui/symbols-provider.ts
-@@ -61,18 +61,18 @@
-       return;
-     }
- 
--    this.showSymbolsForModule(session, selectedModule.module);
-+    await this.showSymbolsForModule(session, selectedModule.module);
-   }
- 
-   private async showSymbolsForModule(session: vscode.DebugSession, module: DebugProtocol.Module) {
-     try {
-       const symbols = await this.getSymbolsForModule(session, module.id.toString());
--      this.showSymbolsInNewTab(module.name.toString(), symbols);
-+      await this.showSymbolsInNewTab(module.name.toString(), symbols);
-     } catch (error) {
-       if (error instanceof Error) {
--        vscode.window.showErrorMessage("Failed to retrieve symbols: " + error.message);
-+        await vscode.window.showErrorMessage("Failed to retrieve symbols: " + error.message);
-       } else {
--        vscode.window.showErrorMessage("Failed to retrieve symbols due to an unknown error.");
-+        await vscode.window.showErrorMessage("Failed to retrieve symbols due to an unknown error.");
-       }
-       
-       return;
-@@ -106,7 +106,7 @@
-     const symbolsTableScriptPath = panel.webview.asWebviewUri(vscode.Uri.joinPath(this.getExtensionResourcePath(), "symbols-table-view.js"));
- 
-     panel.webview.html = getSymbolsTableHTMLContent(tabulatorJsPath, tabulatorCssPath, symbolsTableScriptPath);
--    panel.webview.postMessage({ command: "updateSymbols", symbols: symbols });
-+    await panel.webview.postMessage({ command: "updateSymbols", symbols: symbols });
-   }
- 
-   private getExtensionResourcePath(): vscode.Uri {
-diff -ruN --strip-trailing-cr a/utils/bazel/llvm-project-overlay/clang/BUILD.bazel b/utils/bazel/llvm-project-overlay/clang/BUILD.bazel
---- a/utils/bazel/llvm-project-overlay/clang/BUILD.bazel
-+++ b/utils/bazel/llvm-project-overlay/clang/BUILD.bazel
-@@ -58,6 +58,7 @@
-         "Refactoring",
-         "Sema",
-         "Serialization",
-+        "Trap",
-     ] for out in [
-         (
-             "include/clang/Basic/Diagnostic%sKinds.inc" % c,
-diff -ruN --strip-trailing-cr a/utils/bazel/llvm-project-overlay/mlir/BUILD.bazel b/utils/bazel/llvm-project-overlay/mlir/BUILD.bazel
---- a/utils/bazel/llvm-project-overlay/mlir/BUILD.bazel
-+++ b/utils/bazel/llvm-project-overlay/mlir/BUILD.bazel
-@@ -4167,6 +4167,7 @@
-         ":VectorToSCF",
-         ":VectorToSPIRV",
-         ":VectorToXeGPU",
-+        ":XeGPUToXeVM",
-         ":XeVMToLLVM",
-     ],
- )
-@@ -13945,6 +13946,37 @@
- )
- 
- cc_library(
-+    name = "XeGPUToXeVM",
-+    srcs = glob([
-+        "lib/Conversion/XeGPUToXeVM/*.cpp",
-+    ]),
-+    hdrs = glob([
-+        "include/mlir/Conversion/XeGPUToXeVM/*.h",
-+    ]),
-+    includes = ["include"],
-+    deps = [
-+        ":ArithDialect",
-+        ":ConversionPassIncGen",
-+        ":ConvertToLLVMInterface",
-+        ":GPUDialect",
-+        ":IR",
-+        ":IndexDialect",
-+        ":LLVMCommonConversion",
-+        ":LLVMDialect",
-+        ":MemRefDialect",
-+        ":Pass",
-+        ":SCFDialect",
-+        ":SCFTransforms",
-+        ":Support",
-+        ":TransformUtils",
-+        ":VectorDialect",
-+        ":XeGPUDialect",
-+        ":XeVMDialect",
-+        "//llvm:Support",
-+    ],
-+)
-+
-+cc_library(
-     name = "XeVMToLLVM",
-     srcs = glob([
-         "lib/Conversion/XeVMToLLVM/*.cpp",
+@@ -2923,6 +2940,7 @@
+              PyMlirContextRef ref = PyMlirContext::forContext(self.get());
+              return ref.releaseObject();
+            })
++      .def("_get_live_module_count", &PyMlirContext::getLiveModuleCount)
+       .def_prop_ro(MLIR_PYTHON_CAPI_PTR_ATTR, &PyMlirContext::getCapsule)
+       .def(MLIR_PYTHON_CAPI_FACTORY_ATTR, &PyMlirContext::createFromCapsule)
+       .def("__enter__", &PyMlirContext::contextEnter)
+diff -ruN --strip-trailing-cr a/mlir/lib/Bindings/Python/IRModule.h b/mlir/lib/Bindings/Python/IRModule.h
+--- a/mlir/lib/Bindings/Python/IRModule.h
++++ b/mlir/lib/Bindings/Python/IRModule.h
+@@ -218,6 +218,10 @@
+   /// Gets the count of live context objects. Used for testing.
+   static size_t getLiveCount();
+ 
++  /// Gets the count of live modules associated with this context.
++  /// Used for testing.
++  size_t getLiveModuleCount();
++
+   /// Enter and exit the context manager.
+   static nanobind::object contextEnter(nanobind::object context);
+   void contextExit(const nanobind::object &excType,
+@@ -244,6 +248,14 @@
+   static nanobind::ft_mutex live_contexts_mutex;
+   static LiveContextMap &getLiveContexts();
+ 
++  // Interns all live modules associated with this context. Modules tracked
++  // in this map are valid. When a module is invalidated, it is removed
++  // from this map, and while it still exists as an instance, any
++  // attempt to access it will raise an error.
++  using LiveModuleMap =
++      llvm::DenseMap<const void *, std::pair<nanobind::handle, PyModule *>>;
++  LiveModuleMap liveModules;
++
+   bool emitErrorDiagnostics = false;
+ 
+   MlirContext context;
+diff -ruN --strip-trailing-cr a/mlir/test/python/ir/module.py b/mlir/test/python/ir/module.py
+--- a/mlir/test/python/ir/module.py
++++ b/mlir/test/python/ir/module.py
+@@ -121,6 +121,7 @@
+ def testModuleOperation():
+     ctx = Context()
+     module = Module.parse(r"""module @successfulParse {}""", ctx)
++    assert ctx._get_live_module_count() == 1
+     op1 = module.operation
+     # CHECK: module @successfulParse
+     print(op1)
+@@ -145,6 +146,7 @@
+     op1 = None
+     op2 = None
+     gc.collect()
++    assert ctx._get_live_module_count() == 0
+ 
+ 
+ # CHECK-LABEL: TEST: testModuleCapsule
+@@ -152,17 +154,17 @@
+ def testModuleCapsule():
+     ctx = Context()
+     module = Module.parse(r"""module @successfulParse {}""", ctx)
++    assert ctx._get_live_module_count() == 1
+     # CHECK: "mlir.ir.Module._CAPIPtr"
+     module_capsule = module._CAPIPtr
+     print(module_capsule)
+     module_dup = Module._CAPICreate(module_capsule)
+-    assert module is not module_dup
++    assert module is module_dup
+     assert module == module_dup
+-    module._clear_mlir_module()
+-    assert module != module_dup
+     assert module_dup.context is ctx
+     # Gc and verify destructed.
+     module = None
+     module_capsule = None
+     module_dup = None
+     gc.collect()
++    assert ctx._get_live_module_count() == 0
diff --git a/third_party/llvm/workspace.bzl b/third_party/llvm/workspace.bzl
index 983f65d..a1e6ebe 100644
--- a/third_party/llvm/workspace.bzl
+++ b/third_party/llvm/workspace.bzl
@@ -4,8 +4,8 @@ load("//third_party:repo.bzl", "tf_http_archive")
 
 def repo(name):
     """Imports LLVM."""
-    LLVM_COMMIT = "5bca8f2f97d23c3562544e959702826eb20696af"
-    LLVM_SHA256 = "d0e5d52ce939c396f3fa8533d7a1f911ed059e072d4797e3f9cb15043a6fd113"
+    LLVM_COMMIT = "ba9d1c41c41d568a798e0a8c38a89d294647c28d"
+    LLVM_SHA256 = "10e9f0629eddcc514a84ea826bbfd43ef4a60d96fe4985440d42238c10b5bfb8"
 
     tf_http_archive(
         name = name,
diff --git a/third_party/stablehlo/temporary.patch b/third_party/stablehlo/temporary.patch
index 3079fad..a8075e2 100755
--- a/third_party/stablehlo/temporary.patch
+++ b/third_party/stablehlo/temporary.patch
@@ -1,3 +1,168 @@
+diff --ruN a/stablehlo/stablehlo/conversions/tosa/tests/legalize_quant_ops_to_tosa_rescale.mlir b/stablehlo/stablehlo/conversions/tosa/tests/legalize_quant_ops_to_tosa_rescale.mlir
+--- stablehlo/stablehlo/conversions/tosa/tests/legalize_quant_ops_to_tosa_rescale.mlir
++++ stablehlo/stablehlo/conversions/tosa/tests/legalize_quant_ops_to_tosa_rescale.mlir
+@@ -11,10 +11,10 @@
+   // CHECK-DAG: %[[MULTIPLIER_2:.+]] = "tosa.const"() <{values = dense<1431655765> : tensor<1xi32>}>
+   // CHECK-DAG: %[[ZP_MINUS_1:.+]] = "tosa.const"() <{values = dense<-1> : tensor<1xi8>}>
+   // CHECK-DAG: %[[ZP_0:.+]] = "tosa.const"() <{values = dense<0> : tensor<1xi32>}>
+-  // CHECK-DAG: %[[V0:.+]] = tosa.rescale %arg0, %[[MULTIPLIER_2]], %[[SHIFT13]], %[[ZP_MINUS_1]], %[[ZP_0]] {input_unsigned = false, output_unsigned = false, per_channel = false, rounding_mode = "SINGLE_ROUND", scale32 = true}
+-  // CHECK-DAG: %[[V1:.+]] = tosa.rescale %arg1, %[[MULTIPLIER_1]], %[[SHIFT11]], %[[ZP_MINUS_1]], %[[ZP_0]] {input_unsigned = false, output_unsigned = false, per_channel = false, rounding_mode = "SINGLE_ROUND", scale32 = true}
++  // CHECK-DAG: %[[V0:.+]] = tosa.rescale %arg0, %[[MULTIPLIER_2]], %[[SHIFT13]], %[[ZP_MINUS_1]], %[[ZP_0]] {input_unsigned = false, output_unsigned = false, per_channel = false, rounding_mode = SINGLE_ROUND, scale32 = true}
++  // CHECK-DAG: %[[V1:.+]] = tosa.rescale %arg1, %[[MULTIPLIER_1]], %[[SHIFT11]], %[[ZP_MINUS_1]], %[[ZP_0]] {input_unsigned = false, output_unsigned = false, per_channel = false, rounding_mode = SINGLE_ROUND, scale32 = true}
+   // CHECK: %[[V2:.+]] = stablehlo.add %[[V0]], %[[V1]] : tensor<2x2xi32>
+-  // CHECK: %[[V3:.+]] = tosa.rescale %[[V2]], %[[MULTIPLIER_1]], %[[SHIFT50]], %[[ZP_0]], %[[ZP_MINUS_1]] {input_unsigned = false, output_unsigned = false, per_channel = false, rounding_mode = "SINGLE_ROUND", scale32 = true}
++  // CHECK: %[[V3:.+]] = tosa.rescale %[[V2]], %[[MULTIPLIER_1]], %[[SHIFT50]], %[[ZP_0]], %[[ZP_MINUS_1]] {input_unsigned = false, output_unsigned = false, per_channel = false, rounding_mode = SINGLE_ROUND, scale32 = true}
+   // CHECK: return %[[V3]] : tensor<2x2x!quant.uniform<i8:f32, 1.500000e-01:-1>>
+   %0 = "stablehlo.add"(%arg0, %arg1) : (tensor<2x2x!quant.uniform<i8:f32, 0.025:-1>>, tensor<2x2x!quant.uniform<i8:f32, 0.075:-1>>)
+             -> tensor<2x2x!quant.uniform<i8:f32, 1.5e-01:-1>>
+@@ -32,10 +32,10 @@
+   // CHECK-DAG: %[[MULTIPLIER_2:.+]] = "tosa.const"() <{values = dense<1431655765> : tensor<1xi32>}>
+   // CHECK-DAG: %[[ZP_MINUS_1:.+]] = "tosa.const"() <{values = dense<-1> : tensor<1xi8>}>
+   // CHECK-DAG: %[[ZP_0:.+]] = "tosa.const"() <{values = dense<0> : tensor<1xi32>}>
+-  // CHECK-DAG: %[[V0:.+]] = tosa.rescale %arg0, %[[MULTIPLIER_2]], %[[SHIFT13]], %[[ZP_MINUS_1]], %[[ZP_0]] {input_unsigned = false, output_unsigned = false, per_channel = false, rounding_mode = "SINGLE_ROUND", scale32 = true}
+-  // CHECK-DAG: %[[V1:.+]] = tosa.rescale %arg1, %[[MULTIPLIER_1]], %[[SHIFT11]], %[[ZP_MINUS_1]], %[[ZP_0]] {input_unsigned = false, output_unsigned = false, per_channel = false, rounding_mode = "SINGLE_ROUND", scale32 = true}
++  // CHECK-DAG: %[[V0:.+]] = tosa.rescale %arg0, %[[MULTIPLIER_2]], %[[SHIFT13]], %[[ZP_MINUS_1]], %[[ZP_0]] {input_unsigned = false, output_unsigned = false, per_channel = false, rounding_mode = SINGLE_ROUND, scale32 = true}
++  // CHECK-DAG: %[[V1:.+]] = tosa.rescale %arg1, %[[MULTIPLIER_1]], %[[SHIFT11]], %[[ZP_MINUS_1]], %[[ZP_0]] {input_unsigned = false, output_unsigned = false, per_channel = false, rounding_mode = SINGLE_ROUND, scale32 = true}
+   // CHECK: %[[V2:.+]] = stablehlo.subtract %[[V0]], %[[V1]] : tensor<2x2xi32>
+-  // CHECK: %[[V3:.+]] = tosa.rescale %[[V2]], %[[MULTIPLIER_1]], %[[SHIFT50]], %[[ZP_0]], %[[ZP_MINUS_1]] {input_unsigned = false, output_unsigned = false, per_channel = false, rounding_mode = "SINGLE_ROUND", scale32 = true}
++  // CHECK: %[[V3:.+]] = tosa.rescale %[[V2]], %[[MULTIPLIER_1]], %[[SHIFT50]], %[[ZP_0]], %[[ZP_MINUS_1]] {input_unsigned = false, output_unsigned = false, per_channel = false, rounding_mode = SINGLE_ROUND, scale32 = true}
+   // CHECK: return %[[V3]] : tensor<2x2x!quant.uniform<i8:f32, 1.500000e-01:-1>>
+   %0 = "stablehlo.subtract"(%arg0, %arg1) : (tensor<2x2x!quant.uniform<i8:f32, 0.025:-1>>, tensor<2x2x!quant.uniform<i8:f32, 0.075:-1>>)
+             -> tensor<2x2x!quant.uniform<i8:f32, 1.5e-01:-1>>
+@@ -52,10 +52,10 @@
+   // CHECK-DAG: %[[MULTIPLIER_2:.+]] = "tosa.const"() <{values = dense<1717986918> : tensor<1xi32>}>
+   // CHECK-DAG: %[[ZP_MINUS_1:.+]] = "tosa.const"() <{values = dense<-1> : tensor<1xi8>}>
+   // CHECK-DAG: %[[ZP_0:.+]] = "tosa.const"() <{values = dense<0> : tensor<1xi32>}>
+-  // CHECK-DAG: %[[V0:.+]] = tosa.rescale %arg0, %[[MULTIPLIER_1]], %[[SHIFT30]], %[[ZP_MINUS_1]], %[[ZP_0]] {input_unsigned = false, output_unsigned = false, per_channel = false, rounding_mode = "SINGLE_ROUND", scale32 = true}
+-  // CHECK-DAG: %[[V1:.+]] = tosa.rescale %arg1, %[[MULTIPLIER_1]], %[[SHIFT30]], %[[ZP_MINUS_1]], %[[ZP_0]] {input_unsigned = false, output_unsigned = false, per_channel = false, rounding_mode = "SINGLE_ROUND", scale32 = true}
++  // CHECK-DAG: %[[V0:.+]] = tosa.rescale %arg0, %[[MULTIPLIER_1]], %[[SHIFT30]], %[[ZP_MINUS_1]], %[[ZP_0]] {input_unsigned = false, output_unsigned = false, per_channel = false, rounding_mode = SINGLE_ROUND, scale32 = true}
++  // CHECK-DAG: %[[V1:.+]] = tosa.rescale %arg1, %[[MULTIPLIER_1]], %[[SHIFT30]], %[[ZP_MINUS_1]], %[[ZP_0]] {input_unsigned = false, output_unsigned = false, per_channel = false, rounding_mode = SINGLE_ROUND, scale32 = true}
+   // CHECK: %[[V2:.+]] = stablehlo.multiply %[[V0]], %[[V1]] : tensor<2x2xi32>
+-  // CHECK: %[[V3:.+]] = tosa.rescale %[[V2]], %[[MULTIPLIER_2]], %[[SHIFT37]], %[[ZP_0]], %[[ZP_MINUS_1]] {input_unsigned = false, output_unsigned = false, per_channel = false, rounding_mode = "SINGLE_ROUND", scale32 = true}
++  // CHECK: %[[V3:.+]] = tosa.rescale %[[V2]], %[[MULTIPLIER_2]], %[[SHIFT37]], %[[ZP_0]], %[[ZP_MINUS_1]] {input_unsigned = false, output_unsigned = false, per_channel = false, rounding_mode = SINGLE_ROUND, scale32 = true}
+   // CHECK: return %[[V3]] : tensor<2x2x!quant.uniform<i8:f32, 1.500000e-01:-1>>
+   %0 = "stablehlo.multiply"(%arg0, %arg1) : (tensor<2x2x!quant.uniform<i8:f32, 0.025:-1>>, tensor<2x2x!quant.uniform<i8:f32, 0.075:-1>>)
+             -> tensor<2x2x!quant.uniform<i8:f32, 1.5e-01:-1>>
+@@ -74,10 +74,10 @@
+   // CHECK-DAG: %[[ZP_MINUS_2:.+]] = "tosa.const"() <{values = dense<-2> : tensor<1xi8>}>
+   // CHECK-DAG: %[[ZP_MINUS_1:.+]] = "tosa.const"() <{values = dense<-1> : tensor<1xi8>}>
+   // CHECK-DAG: %[[ZP_0:.+]] = "tosa.const"() <{values = dense<0> : tensor<1xi32>}>
+-  // CHECK-DAG: %[[V0:.+]] = tosa.rescale %arg0, %[[MULTIPLIER_1]], %[[SHIFT30]], %[[ZP_MINUS_1]], %[[ZP_0]] {input_unsigned = false, output_unsigned = false, per_channel = false, rounding_mode = "SINGLE_ROUND", scale32 = true}
+-  // CHECK-DAG: %[[V1:.+]] = tosa.rescale %arg1, %[[MULTIPLIER_1]], %[[SHIFT30]], %[[ZP_MINUS_2]], %[[ZP_0]] {input_unsigned = false, output_unsigned = false, per_channel = false, rounding_mode = "SINGLE_ROUND", scale32 = true}
++  // CHECK-DAG: %[[V0:.+]] = tosa.rescale %arg0, %[[MULTIPLIER_1]], %[[SHIFT30]], %[[ZP_MINUS_1]], %[[ZP_0]] {input_unsigned = false, output_unsigned = false, per_channel = false, rounding_mode = SINGLE_ROUND, scale32 = true}
++  // CHECK-DAG: %[[V1:.+]] = tosa.rescale %arg1, %[[MULTIPLIER_1]], %[[SHIFT30]], %[[ZP_MINUS_2]], %[[ZP_0]] {input_unsigned = false, output_unsigned = false, per_channel = false, rounding_mode = SINGLE_ROUND, scale32 = true}
+   // CHECK: %[[V2:.+]] = stablehlo.divide %[[V0]], %[[V1]] : tensor<2x2xi32>
+-  // CHECK: %[[V3:.+]] = tosa.rescale %[[V2]], %[[MULTIPLIER_2]], %[[SHIFT37]], %[[ZP_0]], %[[ZP_MINUS_3]] {input_unsigned = false, output_unsigned = false, per_channel = false, rounding_mode = "SINGLE_ROUND", scale32 = true}
++  // CHECK: %[[V3:.+]] = tosa.rescale %[[V2]], %[[MULTIPLIER_2]], %[[SHIFT37]], %[[ZP_0]], %[[ZP_MINUS_3]] {input_unsigned = false, output_unsigned = false, per_channel = false, rounding_mode = SINGLE_ROUND, scale32 = true}
+   // CHECK: return %[[V3]] : tensor<2x2x!quant.uniform<i8:f32, 1.500000e-01:-3>>
+   %0 = "stablehlo.divide"(%arg0, %arg1) : (tensor<2x2x!quant.uniform<i8:f32, 0.025:-1>>, tensor<2x2x!quant.uniform<i8:f32, 0.075:-2>>)
+             -> tensor<2x2x!quant.uniform<i8:f32, 1.5e-01:-3>>
+@@ -97,10 +97,10 @@
+   // CHECK-DAG: %[[SHIFT12:.+]] = "tosa.const"() <{values = dense<12> : tensor<1xi8>}>
+   // CHECK-DAG: %[[ZP_MINUS_1:.+]] = "tosa.const"() <{values = dense<-1> : tensor<1xi8>}>
+   // CHECK-DAG: %[[ZP_0:.+]] = "tosa.const"() <{values = dense<0> : tensor<1xi32>}>
+-  // CHECK-DAG: %[[V0:.+]] = tosa.rescale %arg0, %[[MULTIPLIER_2]], %[[SHIFT12]], %[[ZP_MINUS_1]], %[[ZP_0]] {input_unsigned = false, output_unsigned = false, per_channel = false, rounding_mode = "SINGLE_ROUND", scale32 = true}
+-  // CHECK-DAG: %[[V1:.+]] = tosa.rescale %arg1, %[[MULTIPLIER_1]], %[[SHIFT10]], %[[ZP_MINUS_2]], %[[ZP_0]] {input_unsigned = false, output_unsigned = false, per_channel = false, rounding_mode = "SINGLE_ROUND", scale32 = true}
++  // CHECK-DAG: %[[V0:.+]] = tosa.rescale %arg0, %[[MULTIPLIER_2]], %[[SHIFT12]], %[[ZP_MINUS_1]], %[[ZP_0]] {input_unsigned = false, output_unsigned = false, per_channel = false, rounding_mode = SINGLE_ROUND, scale32 = true}
++  // CHECK-DAG: %[[V1:.+]] = tosa.rescale %arg1, %[[MULTIPLIER_1]], %[[SHIFT10]], %[[ZP_MINUS_2]], %[[ZP_0]] {input_unsigned = false, output_unsigned = false, per_channel = false, rounding_mode = SINGLE_ROUND, scale32 = true}
+   // CHECK: %[[V2:.+]] = stablehlo.maximum %[[V0]], %[[V1]] : tensor<2x2xi32>
+-  // CHECK: %[[V3:.+]] = tosa.rescale %[[V2]], %[[MULTIPLIER_1]], %[[SHIFT51]], %[[ZP_0]], %[[ZP_MINUS_3]] {input_unsigned = false, output_unsigned = false, per_channel = false, rounding_mode = "SINGLE_ROUND", scale32 = true}
++  // CHECK: %[[V3:.+]] = tosa.rescale %[[V2]], %[[MULTIPLIER_1]], %[[SHIFT51]], %[[ZP_0]], %[[ZP_MINUS_3]] {input_unsigned = false, output_unsigned = false, per_channel = false, rounding_mode = SINGLE_ROUND, scale32 = true}
+   // CHECK: return %[[V3]] : tensor<2x2x!quant.uniform<i8:f32, 1.500000e-01:-3>>
+   %0 = "stablehlo.maximum"(%arg0, %arg1) : (tensor<2x2x!quant.uniform<i8:f32, 0.025:-1>>, tensor<2x2x!quant.uniform<i8:f32, 0.075:-2>>)
+             -> tensor<2x2x!quant.uniform<i8:f32, 1.5e-01:-3>>
+@@ -120,10 +120,10 @@
+   // CHECK-DAG: %[[SHIFT12:.+]] = "tosa.const"() <{values = dense<12> : tensor<1xi8>}>
+   // CHECK-DAG: %[[ZP_MINUS_1:.+]] = "tosa.const"() <{values = dense<-1> : tensor<1xi8>}>
+   // CHECK-DAG: %[[ZP_0:.+]] = "tosa.const"() <{values = dense<0> : tensor<1xi32>}>
+-  // CHECK-DAG: %[[V0:.+]] = tosa.rescale %arg0, %[[MULTIPLIER_2]], %[[SHIFT12]], %[[ZP_MINUS_1]], %[[ZP_0]] {input_unsigned = false, output_unsigned = false, per_channel = false, rounding_mode = "SINGLE_ROUND", scale32 = true}
+-  // CHECK-DAG: %[[V1:.+]] = tosa.rescale %arg1, %[[MULTIPLIER_1]], %[[SHIFT10]], %[[ZP_MINUS_2]], %[[ZP_0]] {input_unsigned = false, output_unsigned = false, per_channel = false, rounding_mode = "SINGLE_ROUND", scale32 = true}
++  // CHECK-DAG: %[[V0:.+]] = tosa.rescale %arg0, %[[MULTIPLIER_2]], %[[SHIFT12]], %[[ZP_MINUS_1]], %[[ZP_0]] {input_unsigned = false, output_unsigned = false, per_channel = false, rounding_mode = SINGLE_ROUND, scale32 = true}
++  // CHECK-DAG: %[[V1:.+]] = tosa.rescale %arg1, %[[MULTIPLIER_1]], %[[SHIFT10]], %[[ZP_MINUS_2]], %[[ZP_0]] {input_unsigned = false, output_unsigned = false, per_channel = false, rounding_mode = SINGLE_ROUND, scale32 = true}
+   // CHECK: %[[V2:.+]] = stablehlo.minimum %[[V0]], %[[V1]] : tensor<2x2xi32>
+-  // CHECK: %[[V3:.+]] = tosa.rescale %[[V2]], %[[MULTIPLIER_1]], %[[SHIFT51]], %[[ZP_0]], %[[ZP_MINUS_3]] {input_unsigned = false, output_unsigned = false, per_channel = false, rounding_mode = "SINGLE_ROUND", scale32 = true}
++  // CHECK: %[[V3:.+]] = tosa.rescale %[[V2]], %[[MULTIPLIER_1]], %[[SHIFT51]], %[[ZP_0]], %[[ZP_MINUS_3]] {input_unsigned = false, output_unsigned = false, per_channel = false, rounding_mode = SINGLE_ROUND, scale32 = true}
+   // CHECK: return %[[V3]] : tensor<2x2x!quant.uniform<i8:f32, 1.500000e-01:-3>>
+   %0 = "stablehlo.minimum"(%arg0, %arg1) : (tensor<2x2x!quant.uniform<i8:f32, 0.025:-1>>, tensor<2x2x!quant.uniform<i8:f32, 0.075:-2>>)
+             -> tensor<2x2x!quant.uniform<i8:f32, 1.5e-01:-3>>
+@@ -140,9 +140,9 @@
+   // CHECK-DAG: %[[SHIFT30:.+]] = "tosa.const"() <{values = dense<30> : tensor<1xi8>}>
+   // CHECK-DAG: %[[ZP_MINUS_1:.+]] = "tosa.const"() <{values = dense<-1> : tensor<1xi8>}>
+   // CHECK-DAG: %[[ZP_0:.+]] = "tosa.const"() <{values = dense<0> : tensor<1xi32>}>
+-  // CHECK: %[[V0:.+]] = tosa.rescale %arg0, %[[MULTIPLIER_2]], %[[SHIFT30]], %[[ZP_MINUS_1]], %[[ZP_0]] {input_unsigned = false, output_unsigned = false, per_channel = false, rounding_mode = "SINGLE_ROUND", scale32 = true}
++  // CHECK: %[[V0:.+]] = tosa.rescale %arg0, %[[MULTIPLIER_2]], %[[SHIFT30]], %[[ZP_MINUS_1]], %[[ZP_0]] {input_unsigned = false, output_unsigned = false, per_channel = false, rounding_mode = SINGLE_ROUND, scale32 = true}
+   // CHECK: %[[V1:.+]] = stablehlo.abs %[[V0]] : tensor<20x20xi32>
+-  // CHECK: %[[V3:.+]] = tosa.rescale %[[V1]], %[[MULTIPLIER_1]], %[[SHIFT33]], %[[ZP_0]], %[[ZP_MINUS_128]] {input_unsigned = false, output_unsigned = false, per_channel = false, rounding_mode = "SINGLE_ROUND", scale32 = true}
++  // CHECK: %[[V3:.+]] = tosa.rescale %[[V1]], %[[MULTIPLIER_1]], %[[SHIFT33]], %[[ZP_0]], %[[ZP_MINUS_128]] {input_unsigned = false, output_unsigned = false, per_channel = false, rounding_mode = SINGLE_ROUND, scale32 = true}
+   // CHECK: return %[[V3]] : tensor<20x20x!quant.uniform<i8:f32, 1.500000e-01:-128>>
+   %0 = "stablehlo.abs"(%arg0) : (tensor<20x20x!quant.uniform<i8:f32, 0.025:-1>>) -> tensor<20x20x!quant.uniform<i8:f32, 1.5e-01:-128>>
+   return %0 : tensor<20x20x!quant.uniform<i8:f32, 1.5e-01:-128>>
+@@ -159,8 +159,8 @@
+   // CHECK-DAG: %[[SHIFT12:.+]] = "tosa.const"() <{values = dense<12> : tensor<1xi8>}>
+   // CHECK-DAG: %[[ZP_MINUS_1:.+]] = "tosa.const"() <{values = dense<-1> : tensor<1xi8>}>
+   // CHECK-DAG: %[[ZP_0:.+]] = "tosa.const"() <{values = dense<0> : tensor<1xi32>}>
+-  // CHECK: %[[V0:.+]] = tosa.rescale %arg0, %[[MULTIPLIER_2]], %[[SHIFT12]], %[[ZP_MINUS_1]], %[[ZP_0]] {input_unsigned = false, output_unsigned = false, per_channel = false, rounding_mode = "SINGLE_ROUND", scale32 = true}
+-  // CHECK: %[[V1:.+]] = tosa.rescale %arg1, %[[MULTIPLIER_1]], %[[SHIFT10]], %[[ZP_MINUS_2]], %[[ZP_0]] {input_unsigned = false, output_unsigned = false, per_channel = false, rounding_mode = "SINGLE_ROUND", scale32 = true}
++  // CHECK: %[[V0:.+]] = tosa.rescale %arg0, %[[MULTIPLIER_2]], %[[SHIFT12]], %[[ZP_MINUS_1]], %[[ZP_0]] {input_unsigned = false, output_unsigned = false, per_channel = false, rounding_mode = SINGLE_ROUND, scale32 = true}
++  // CHECK: %[[V1:.+]] = tosa.rescale %arg1, %[[MULTIPLIER_1]], %[[SHIFT10]], %[[ZP_MINUS_2]], %[[ZP_0]] {input_unsigned = false, output_unsigned = false, per_channel = false, rounding_mode = SINGLE_ROUND, scale32 = true}
+   // CHECK: %[[V2:.+]] = stablehlo.compare GE, %[[V0]], %[[V1]], TOTALORDER :
+   // CHECK: return %[[V2]]
+   %0 = stablehlo.compare GE, %arg0, %arg1, TOTALORDER : (tensor<20x20x!quant.uniform<i8:f32, 0.025:-1>>, tensor<20x20x!quant.uniform<i8:f32, 0.075:-2>>) -> tensor<20x20xi1>
+@@ -177,8 +177,8 @@
+   // CHECK-DAG: %[[SHIFT15:.+]] = "tosa.const"() <{values = dense<15> : tensor<1xi8>}>
+   // CHECK-DAG: %[[ZP16_0:.+]] = "tosa.const"() <{values = dense<0> : tensor<1xi16>}>
+   // CHECK-DAG: %[[ZP32_0:.+]] = "tosa.const"() <{values = dense<0> : tensor<1xi32>}>
+-  // CHECK: %[[V0:.+]] = tosa.rescale %arg0, %[[MULTIPLIER_2]], %[[SHIFT17]], %[[ZP16_0]], %[[ZP32_0]] {input_unsigned = false, output_unsigned = false, per_channel = false, rounding_mode = "SINGLE_ROUND", scale32 = true}
+-  // CHECK: %[[V1:.+]] = tosa.rescale %arg1, %[[MULTIPLIER_1]], %[[SHIFT15]], %[[ZP16_0]], %[[ZP32_0]] {input_unsigned = false, output_unsigned = false, per_channel = false, rounding_mode = "SINGLE_ROUND", scale32 = true}
++  // CHECK: %[[V0:.+]] = tosa.rescale %arg0, %[[MULTIPLIER_2]], %[[SHIFT17]], %[[ZP16_0]], %[[ZP32_0]] {input_unsigned = false, output_unsigned = false, per_channel = false, rounding_mode = SINGLE_ROUND, scale32 = true}
++  // CHECK: %[[V1:.+]] = tosa.rescale %arg1, %[[MULTIPLIER_1]], %[[SHIFT15]], %[[ZP16_0]], %[[ZP32_0]] {input_unsigned = false, output_unsigned = false, per_channel = false, rounding_mode = SINGLE_ROUND, scale32 = true}
+   // CHECK: %[[V2:.+]] = stablehlo.compare LT, %[[V0]], %[[V1]], TOTALORDER :
+   // CHECK: return %[[V2]]
+   %0 = stablehlo.compare LT, %arg0, %arg1, TOTALORDER : (tensor<20x20x!quant.uniform<i16:f32, 0.025:0>>, tensor<20x20x!quant.uniform<i16:f32, 0.075:0>>) -> tensor<20x20xi1>
+diff --ruN a/stablehlo/stablehlo/conversions/tosa/tests/legalize_tosa_rescale_to_stablehlo.mlir b/stablehlo/stablehlo/conversions/tosa/tests/legalize_tosa_rescale_to_stablehlo.mlir
+--- stablehlo/stablehlo/conversions/tosa/tests/legalize_tosa_rescale_to_stablehlo.mlir
++++ stablehlo/stablehlo/conversions/tosa/tests/legalize_tosa_rescale_to_stablehlo.mlir
+@@ -7,7 +7,7 @@
+   %shift = "tosa.const"() {values = dense<13> : tensor<1xi8>} : () -> tensor<1xi8>
+   %input_zp = "tosa.const"() {values = dense<-1> : tensor<1xi8>} : () -> tensor<1xi8>
+   %output_zp = "tosa.const"() {values = dense<0> : tensor<1xi32>} : () -> tensor<1xi32>
+-  %0 = tosa.rescale %arg0, %multiplier, %shift, %input_zp, %output_zp {input_unsigned = false, output_unsigned = false, per_channel = false, rounding_mode = "SINGLE_ROUND", scale32 = true} :
++  %0 = tosa.rescale %arg0, %multiplier, %shift, %input_zp, %output_zp {input_unsigned = false, output_unsigned = false, per_channel = false, rounding_mode = SINGLE_ROUND, scale32 = true} :
+             (tensor<2x2x!quant.uniform<i8:f32, 0.025:-1>>, tensor<1xi32>, tensor<1xi8>, tensor<1xi8>, tensor<1xi32>) -> tensor<2x2xi32>
+ 
+   // convert input quantized type to storage type
+diff --ruN a/stablehlo/stablehlo/conversions/tosa/transforms/StablehloQuantLegalizeToTosaRescale.cpp b/stablehlo/stablehlo/conversions/tosa/transforms/StablehloQuantLegalizeToTosaRescale.cpp
+--- stablehlo/stablehlo/conversions/tosa/transforms/StablehloQuantLegalizeToTosaRescale.cpp
++++ stablehlo/stablehlo/conversions/tosa/transforms/StablehloQuantLegalizeToTosaRescale.cpp
+@@ -70,12 +70,14 @@
+       outputZpVal.has_value() &&
+       "buildRescale: Failed to create output zero-point tensor for RescaleOp.");
+ 
+-  std::string roundingMode = doubleRound ? "DOUBLE_ROUND" : "SINGLE_ROUND";
++  auto roundingMode =
++      doubleRound ? RoundingMode::DOUBLE_ROUND : RoundingMode::SINGLE_ROUND;
+ 
+   auto rescale_op = rewriter.create<RescaleOp>(
+       loc, outputType, inputVal, multiplierVal, shiftVal, inputZpVal.value(),
+       outputZpVal.value(), rewriter.getBoolAttr(scale32),
+-      rewriter.getStringAttr(roundingMode), rewriter.getBoolAttr(perChannel),
++      RoundingModeAttr::get(rewriter.getContext(), roundingMode),
++      rewriter.getBoolAttr(perChannel),
+       /*input_unsigned=*/rewriter.getBoolAttr(false),
+       /*output_unsigned=*/rewriter.getBoolAttr(false));
+ 
+diff --ruN a/stablehlo/stablehlo/conversions/tosa/transforms/TosaRescaleLegalizeToStablehlo.cpp b/stablehlo/stablehlo/conversions/tosa/transforms/TosaRescaleLegalizeToStablehlo.cpp
+--- stablehlo/stablehlo/conversions/tosa/transforms/TosaRescaleLegalizeToStablehlo.cpp
++++ stablehlo/stablehlo/conversions/tosa/transforms/TosaRescaleLegalizeToStablehlo.cpp
+@@ -68,7 +68,7 @@
+   auto roundingMode = op.getRoundingMode();
+   bool perChannel = op.getPerChannel();
+ 
+-  if (perChannel || roundingMode != "SINGLE_ROUND" || !scale32) {
++  if (perChannel || roundingMode != RoundingMode::SINGLE_ROUND || !scale32) {
+     return rewriter.notifyMatchFailure(
+         op,
+         "per_channel, double_round, or scale32=false are not yet supported");
 diff --ruN a/stablehlo/stablehlo/dialect/StablehloOps.cpp b/stablehlo/stablehlo/dialect/StablehloOps.cpp
 --- stablehlo/stablehlo/dialect/StablehloOps.cpp
 +++ stablehlo/stablehlo/dialect/StablehloOps.cpp
