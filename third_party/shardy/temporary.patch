diff --git a/shardy/dialect/mpmd/ir/fragment_execution_rules.cc b/shardy/dialect/mpmd/ir/fragment_execution_rules.cc
index 8494e32..a4cbe58 100644
--- a/shardy/dialect/mpmd/ir/fragment_execution_rules.cc
+++ b/shardy/dialect/mpmd/ir/fragment_execution_rules.cc
@@ -65,7 +65,7 @@ bool ParseFragmentOrigin(llvm::cl::Option& opt, llvm::StringRef& arg,
   if (!arg.consume_front("(")) {
     return false;
   }
-  if (arg.consumeInteger(10, origin.transpose_count)) {
+  if (!arg.consumeInteger(10, origin.transpose_count)) {
     return opt.error("Expected a transpose count");
   }
   if (!arg.consume_front(")")) {
@@ -93,6 +93,7 @@ bool ParseFragmentInfo(llvm::cl::Option& opt, llvm::StringRef& arg,
   if (!arg.consume_front("]")) {
     return opt.error("Expected ']'");
   }
+  bool is_weight_gradient_parsed = false;
   while (arg.consume_front(",")) {
     if (arg.consume_front("stage=")) {
       if (info.stage_id.has_value()) {
@@ -112,23 +113,24 @@ bool ParseFragmentInfo(llvm::cl::Option& opt, llvm::StringRef& arg,
         return opt.error("Expected an integer value for 'call_counter'");
       }
       info.call_counter = call_counter;
-    } else if (arg.consume_front("split_type=")) {
-      if (info.split_type.has_value()) {
-        return opt.error("'split_type' specified more than once");
+    } else if (arg.consume_front("is_weight_gradient=")) {
+      if (is_weight_gradient_parsed) {
+        return opt.error("'is_weight_gradient' specified more than once");
       }
-      if (arg.consume_front("kKeepTransferred")) {
-        info.split_type = SplitFragmentType::kKeepTransferred;
-      } else if (arg.consume_front("kDropTransferred")) {
-        info.split_type = SplitFragmentType::kDropTransferred;
+      is_weight_gradient_parsed = true;
+      bool is_weight_gradient_val;
+      if (arg.consume_front("true")) {
+        is_weight_gradient_val = true;
+      } else if (arg.consume_front("false")) {
+        is_weight_gradient_val = false;
       } else {
-        return opt.error(
-            "Expected 'kKeepTransferred' or 'kDropTransferred' for "
-            "'split_type'");
+        return opt.error("Expected 'true' or 'false' for 'is_weight_gradient'");
       }
+      info.is_weight_gradient = is_weight_gradient_val;
     } else {
       return opt.error(
           "Expected 'stage=', 'call_counter=', or "
-          "'split_type=' after ','");
+          "'is_weight_gradient=' after ','");
     }
   }
   if (!arg.consume_front(")")) {
@@ -146,13 +148,8 @@ FragmentInfo GetFragmentInfo(FragmentOp fragment) {
   }
   std::optional<int64_t> call_counter = TryToFindCallCounter(fragment);
   std::vector<FragmentOrigin> origins = GetFragmentOrigins(fragment);
-  std::optional<SplitFragmentType> split_type;
-  if (IsSplitKeepTransferred(fragment)) {
-    split_type = SplitFragmentType::kKeepTransferred;
-  } else if (IsSplitDropTransferred(fragment)) {
-    split_type = SplitFragmentType::kDropTransferred;
-  }
-  return FragmentInfo{origins, stage_id, call_counter, split_type};
+  bool is_weight_gradient = IsSplitDropTransferred(fragment);
+  return FragmentInfo{origins, stage_id, call_counter, is_weight_gradient};
 }
 
 void SetFragmentInfo(FragmentOp fragment, const FragmentInfo& metadata,
@@ -177,20 +174,11 @@ void SetFragmentInfo(FragmentOp fragment, const FragmentInfo& metadata,
     fragment->removeAttr(kCallCounterAttrName);
   }
 
-  // Handle split type attributes
-  if (metadata.split_type.has_value()) {
-    if (*metadata.split_type == SplitFragmentType::kDropTransferred) {
-      fragment->setAttr(kSplitDropTransferredAttrName,
-                        UnitAttr::get(rewriter.getContext()));
-      fragment->removeAttr(kSplitKeepTransferredAttrName);
-    } else if (*metadata.split_type == SplitFragmentType::kKeepTransferred) {
-      fragment->setAttr(kSplitKeepTransferredAttrName,
-                        UnitAttr::get(rewriter.getContext()));
-      fragment->removeAttr(kSplitDropTransferredAttrName);
-    }
+  if (metadata.is_weight_gradient) {
+    fragment->setAttr(kSplitDropTransferredAttrName,
+                      UnitAttr::get(rewriter.getContext()));
   } else {
     fragment->removeAttr(kSplitDropTransferredAttrName);
-    fragment->removeAttr(kSplitKeepTransferredAttrName);
   }
 }
 
@@ -199,7 +187,6 @@ void SetFragmentInfo(FragmentOp fragment, const FragmentInfo& metadata,
 namespace llvm::cl {
 
 using ::mlir::mpmd::FragmentMergeRule;
-using ::mlir::mpmd::FragmentScheduleRule;
 
 template class basic_parser<FragmentMergeRule>;
 
@@ -241,39 +228,4 @@ void parser<FragmentMergeRule>::printOptionDiff(const Option& opt,
 
 void parser<FragmentMergeRule>::anchor() {}
 
-template class basic_parser<FragmentScheduleRule>;
-
-// Parses a fragment schedule rule string of the form
-// "FragmentScheduleRule(ordered_fragments=[<fragment1>-><fragment2>...])"
-// <fragment>s are FragmentInfo strings.
-bool parser<FragmentScheduleRule>::parse(Option& opt, StringRef, StringRef arg,
-                                         FragmentScheduleRule& value) {
-  if (!arg.consume_front(FragmentScheduleRule::kFragmentScheduleRulePrefix)) {
-    return opt.error("Expected '" +
-                     FragmentScheduleRule::kFragmentScheduleRulePrefix + "'");
-  }
-  while (!arg.starts_with("]")) {
-    if (mlir::mpmd::ParseFragmentInfo(opt, arg,
-                                      value.ordered_fragments.emplace_back())) {
-      return true;  // opt.error was called inside ParseFragmentInfo
-    }
-    if (!arg.consume_front("->")) {
-      break;
-    }
-  }
-  if (!arg.consume_front("])")) {
-    return opt.error("Expected '])'");
-  }
-  return false;
-}
-
-void parser<FragmentScheduleRule>::printOptionDiff(
-    const Option& opt, const FragmentScheduleRule& value,
-    const OptVal& defaultValue, size_t globalWidth) const {
-  printOptionName(opt, globalWidth);
-  outs() << "= " << value << "\n";
-}
-
-void parser<FragmentScheduleRule>::anchor() {}
-
 }  // namespace llvm::cl
diff --git a/shardy/dialect/mpmd/ir/fragment_execution_rules.h b/shardy/dialect/mpmd/ir/fragment_execution_rules.h
index 2e186ad..981ad6a 100644
--- a/shardy/dialect/mpmd/ir/fragment_execution_rules.h
+++ b/shardy/dialect/mpmd/ir/fragment_execution_rules.h
@@ -26,7 +26,6 @@ limitations under the License.
 #include "llvm/ADT/DenseMapInfo.h"
 #include "llvm/ADT/Hashing.h"
 #include "llvm/ADT/STLExtras.h"
-#include "llvm/ADT/StringRef.h"
 #include "llvm/Support/CommandLine.h"
 #include "llvm/Support/raw_ostream.h"
 #include "mlir/IR/PatternMatch.h"
@@ -67,30 +66,17 @@ struct FragmentOrigin {
   }
 };
 
-// Enum to represent the type of fragment split behavior.
-// These values are determined by the presence of specific MLIR attributes
-// on fragment operations during compilation.
-enum class SplitFragmentType {
-  // Indicates this fragment portion retains transferred data from the original
-  // fragment. Set when the fragment has the kSplitKeepTransferredAttrName
-  // attribute.
-  kKeepTransferred,
-  // Indicates this fragment portion drops transferred data from the original
-  // fragment. Set when the fragment has the kSplitDropTransferredAttrName
-  // attribute.
-  kDropTransferred
-};
-
 // Holds the metadata of a fragment.
 struct FragmentInfo {
   std::vector<FragmentOrigin> origins;
   std::optional<int> stage_id;
   std::optional<int> call_counter;
-  std::optional<SplitFragmentType> split_type;
+  bool is_weight_gradient = false;
 
   bool operator==(const FragmentInfo& other) const {
     return llvm::equal(origins, other.origins) && stage_id == other.stage_id &&
-           call_counter == other.call_counter && split_type == other.split_type;
+           call_counter == other.call_counter &&
+           is_weight_gradient == other.is_weight_gradient;
   }
 
   bool operator!=(const FragmentInfo& other) const { return !(*this == other); }
@@ -106,17 +92,8 @@ struct FragmentInfo {
     if (info.call_counter.has_value()) {
       os << ",call_counter=" << info.call_counter.value();
     }
-    if (info.split_type.has_value()) {
-      os << ",split_type=";
-      switch (info.split_type.value()) {
-        case SplitFragmentType::kKeepTransferred:
-          os << "kKeepTransferred";
-          break;
-        case SplitFragmentType::kDropTransferred:
-          os << "kDropTransferred";
-          break;
-      }
-    }
+    os << ",is_weight_gradient="
+       << (info.is_weight_gradient ? "true" : "false");
     os << ")";
     return os;
   }
@@ -126,7 +103,7 @@ struct FragmentInfoMapInfo : public DenseMapInfo<FragmentInfo> {
   static unsigned getHashValue(const FragmentInfo& info) {
     return llvm::hash_combine(llvm::hash_combine_range(info.origins),
                               info.stage_id, info.call_counter,
-                              info.split_type);
+                              info.is_weight_gradient);
   }
   static bool isEqual(const FragmentInfo& lhs, const FragmentInfo& rhs) {
     return lhs == rhs;
@@ -136,14 +113,14 @@ struct FragmentInfoMapInfo : public DenseMapInfo<FragmentInfo> {
     return FragmentInfo{/*origins=*/{},
                         /*stage_id=*/DenseMapInfo<int>::getEmptyKey(),
                         /*call_counter=*/DenseMapInfo<int>::getEmptyKey(),
-                        /*split_type=*/std::nullopt};
+                        /*is_weight_gradient=*/false};
   }
 
   static inline FragmentInfo getTombstoneKey() {
     return FragmentInfo{/*origins=*/{},
                         /*stage_id=*/DenseMapInfo<int>::getTombstoneKey(),
                         /*call_counter=*/DenseMapInfo<int>::getTombstoneKey(),
-                        /*split_type=*/SplitFragmentType::kDropTransferred};
+                        /*is_weight_gradient=*/true};
   }
 };
 
@@ -165,27 +142,6 @@ struct FragmentMergeRule {
 
 using FragmentMergeRules = std::vector<FragmentMergeRule>;
 
-// Describes a rule for scheduling fragments. A rule is defined by an ordered
-// sequence of fragments. This ordering dictates the execution order of the
-// fragments on a given mesh.
-struct FragmentScheduleRule {
-  // The sequence of fragments to be scheduled. The order of fragments in this
-  // vector defines their execution order.
-  std::vector<FragmentInfo> ordered_fragments;
-
-  static constexpr llvm::StringRef kFragmentScheduleRulePrefix =
-      "FragmentScheduleRule(ordered_fragments=[";
-
-  friend llvm::raw_ostream& operator<<(llvm::raw_ostream& os,
-                                       const FragmentScheduleRule& rule) {
-    os << kFragmentScheduleRulePrefix;
-    llvm::interleave(rule.ordered_fragments, os, "->");
-    return os << "])";
-  }
-};
-
-using FragmentScheduleRules = std::vector<FragmentScheduleRule>;
-
 // Returns the fragment info of a fragment op.
 FragmentInfo GetFragmentInfo(FragmentOp fragment);
 
@@ -213,22 +169,6 @@ class parser<mlir::mpmd::FragmentMergeRule>
   void anchor() override;
 };
 
-extern template class basic_parser<mlir::mpmd::FragmentScheduleRule>;
-
-template <>
-class parser<mlir::mpmd::FragmentScheduleRule>
-    : public basic_parser<mlir::mpmd::FragmentScheduleRule> {
- public:
-  parser(Option& opt) : basic_parser(opt) {}
-  bool parse(Option& opt, StringRef argName, StringRef arg,
-             mlir::mpmd::FragmentScheduleRule& value);
-  StringRef getValueName() const override { return "fragment-schedule-rule"; }
-  void printOptionDiff(const Option& opt,
-                       const mlir::mpmd::FragmentScheduleRule& value,
-                       const OptVal& defaultValue, size_t globalWidth) const;
-  void anchor() override;
-};
-
 }  // namespace llvm::cl
 
 #endif  // SHARDY_DIALECT_MPMD_IR_FRAGMENT_EXECUTION_RULES_H_
diff --git a/shardy/dialect/mpmd/ir/fragment_execution_rules_test.cc b/shardy/dialect/mpmd/ir/fragment_execution_rules_test.cc
index 174ac0b..cb91dc1 100644
--- a/shardy/dialect/mpmd/ir/fragment_execution_rules_test.cc
+++ b/shardy/dialect/mpmd/ir/fragment_execution_rules_test.cc
@@ -20,7 +20,6 @@ limitations under the License.
 #include <vector>
 
 #include "llvm/ADT/STLExtras.h"
-#include "llvm/Support/CommandLine.h"
 #include "llvm/Support/raw_ostream.h"
 #include "mlir/IR/BuiltinOps.h"
 #include "mlir/IR/MLIRContext.h"
@@ -48,7 +47,7 @@ void ExpectFragmentInfoEq(FragmentInfo actual, FragmentInfo expected) {
   EXPECT_THAT(actual.origins, ElementsAreArray(expected.origins));
   EXPECT_EQ(actual.stage_id, expected.stage_id);
   EXPECT_EQ(actual.call_counter, expected.call_counter);
-  EXPECT_EQ(actual.split_type, expected.split_type);
+  EXPECT_EQ(actual.is_weight_gradient, expected.is_weight_gradient);
   // Compare full struct in case any fields were missed above.
   EXPECT_EQ(actual, expected);
 }
@@ -58,12 +57,11 @@ FragmentOrigin MakeFragmentOrigin(const std::string& computation_name,
   return {computation_name, transpose_count};
 }
 
-FragmentInfo MakeFragmentInfo(
-    const std::vector<FragmentOrigin>& origins,
-    std::optional<int> stage_id = std::nullopt,
-    std::optional<int> call_counter = std::nullopt,
-    std::optional<SplitFragmentType> split_type = std::nullopt) {
-  return {origins, stage_id, call_counter, split_type};
+FragmentInfo MakeFragmentInfo(const std::vector<FragmentOrigin>& origins,
+                              std::optional<int> stage_id = std::nullopt,
+                              std::optional<int> call_counter = std::nullopt,
+                              bool is_weight_gradient = false) {
+  return {origins, stage_id, call_counter, is_weight_gradient};
 }
 
 FragmentMergeRule MakeFragmentMergeRule(
@@ -71,48 +69,6 @@ FragmentMergeRule MakeFragmentMergeRule(
   return {sources, target};
 }
 
-FragmentScheduleRule MakeFragmentScheduleRule(
-    const std::vector<FragmentInfo>& ordered_fragments) {
-  return {ordered_fragments};
-}
-
-// LLVM's command line classes (OptionCategory, opt) store StringRef arguments
-// directly without copying the underlying string data. When these objects are
-// created with temporary string literals in test functions, the backing strings
-// go out of scope after the test completes, leaving dangling pointers in the
-// static GlobalParser->RegisteredOptionCategories.
-//
-// The functions below use static storage to ensure string literals have static
-// storage duration, avoiding the need for manual cleanup. The parser helper
-// functions encapsulate opt/parser creation and provide a clean interface for
-// tests without exposing StringRef lifetime concerns.
-
-llvm::cl::OptionCategory& getTestOptionCategory() {
-  static llvm::cl::OptionCategory category("Test Options");
-  return category;
-}
-
-bool parseFragmentMergeRule(llvm::StringRef rule_str, FragmentMergeRule& rule) {
-  static llvm::cl::opt<FragmentMergeRule> rule_opt(
-      "fragment-merge-rule",
-      llvm::cl::desc("Fragment merge rule for testing parser functionality"),
-      llvm::cl::cat(getTestOptionCategory()));
-  static llvm::cl::parser<FragmentMergeRule> parser(rule_opt);
-
-  return parser.parse(rule_opt, "test-rule", rule_str, rule);
-}
-
-bool parseFragmentScheduleRule(llvm::StringRef rule_str,
-                               FragmentScheduleRule& rule) {
-  static llvm::cl::opt<FragmentScheduleRule> rule_opt(
-      "fragment-schedule-rule",
-      llvm::cl::desc("Fragment schedule rule for testing parser functionality"),
-      llvm::cl::cat(getTestOptionCategory()));
-  static llvm::cl::parser<FragmentScheduleRule> parser(rule_opt);
-
-  return parser.parse(rule_opt, "test-rule", rule_str, rule);
-}
-
 TEST(GetFragmentInfoTest, GetFragmentInfo) {
   const std::string kProgram = R"mlir(
     !mesh_1_tensor_4_8_f32 = !mpmd.mesh_tensor<"m1", tensor<4x8xf32>>
@@ -140,7 +96,7 @@ TEST(GetFragmentInfoTest, GetFragmentInfo) {
       MakeFragmentInfo(
           {MakeFragmentOrigin("f1", 123), MakeFragmentOrigin("f2", 123)},
           /*stage_id=*/std::nullopt,
-          /*call_counter=*/std::nullopt, /*split_type=*/std::nullopt));
+          /*call_counter=*/std::nullopt, /*is_weight_gradient=*/false));
 }
 
 struct SetFragmentInfoTestParams {
@@ -188,14 +144,13 @@ INSTANTIATE_TEST_SUITE_P(
         SetFragmentInfoTestParams{
             "WithStageAndCallCounter",
             MakeFragmentInfo({MakeFragmentOrigin("f3", 456)}, /*stage_id=*/1,
-                             /*call_counter=*/2, /*split_type=*/std::nullopt)},
+                             /*call_counter=*/2, /*is_weight_gradient=*/false)},
         SetFragmentInfoTestParams{
             "WithWeightGradient",
-            MakeFragmentInfo(
-                {MakeFragmentOrigin("f4", 789)},
-                /*stage_id=*/std::nullopt,
-                /*call_counter=*/std::nullopt,
-                /*split_type=*/SplitFragmentType::kDropTransferred)}),
+            MakeFragmentInfo({MakeFragmentOrigin("f4", 789)},
+                             /*stage_id=*/std::nullopt,
+                             /*call_counter=*/std::nullopt,
+                             /*is_weight_gradient=*/true)}),
     [](const testing::TestParamInfo<SetFragmentInfoTest::ParamType>& info) {
       return info.param.test_name;
     });
@@ -226,7 +181,7 @@ TEST(SetFragmentInfoTest, RemovesSplitDropTransferred) {
   FragmentInfo info = MakeFragmentInfo({MakeFragmentOrigin("f1", 0)},
                                        /*stage_id=*/std::nullopt,
                                        /*call_counter=*/std::nullopt,
-                                       /*split_type=*/std::nullopt);
+                                       /*is_weight_gradient=*/false);
   SetFragmentInfo(fragment_op, info, rewriter);
 
   EXPECT_FALSE(fragment_op->hasAttr(kSplitDropTransferredAttrName));
@@ -255,33 +210,30 @@ INSTANTIATE_TEST_SUITE_P(
     PrintFragmentInfo, PrintFragmentInfoTest,
     testing::Values(
         PrintFragmentInfoTestParams{
-            "NoSplitType",
+            "AllFields",
             MakeFragmentInfo({MakeFragmentOrigin("f1", 123),
                               MakeFragmentOrigin("f2", 456)},
-                             /*stage_id=*/1, /*call_counter=*/2,
-                             /*split_type=*/std::nullopt),
-            "FragmentInfo(origins=[\"f1\"(123),\"f2\"(456)],stage=1,call_"
-            "counter=2)"},
+                             /*stage_id=*/1, /*call_counter=*/2),
+            "FragmentInfo(origins=[\"f1\"(123),\"f2\"(456)],stage=1,"
+            "call_counter=2,is_weight_gradient=false)"},
         PrintFragmentInfoTestParams{
-            "WithSplitTypeDropTransferred",
-            MakeFragmentInfo(
-                {MakeFragmentOrigin("f1", 123)}, /*stage_id=*/1,
-                /*call_counter=*/2,
-                /*split_type=*/SplitFragmentType::kDropTransferred),
+            "WithWeightGradientTrue",
+            MakeFragmentInfo({MakeFragmentOrigin("f1", 123)}, /*stage_id=*/1,
+                             /*call_counter=*/2,
+                             /*is_weight_gradient=*/true),
             "FragmentInfo(origins=[\"f1\"(123)],stage=1,call_counter=2,"
-            "split_type=kDropTransferred)"},
+            "is_weight_gradient=true)"},
         PrintFragmentInfoTestParams{
-            "WithSplitTypeKeepTransferred",
-            MakeFragmentInfo(
-                {MakeFragmentOrigin("f1", 123)}, /*stage_id=*/1,
-                /*call_counter=*/2,
-                /*split_type=*/SplitFragmentType::kKeepTransferred),
+            "WithWeightGradientFalse",
+            MakeFragmentInfo({MakeFragmentOrigin("f1", 123)}, /*stage_id=*/1,
+                             /*call_counter=*/2,
+                             /*is_weight_gradient=*/false),
             "FragmentInfo(origins=[\"f1\"(123)],stage=1,call_counter=2,"
-            "split_type=kKeepTransferred)"},
+            "is_weight_gradient=false)"},
         PrintFragmentInfoTestParams{
             "OnlyRequiredFields",
             MakeFragmentInfo({MakeFragmentOrigin("f1", 123)}),
-            "FragmentInfo(origins=[\"f1\"(123)])"}),
+            "FragmentInfo(origins=[\"f1\"(123)],is_weight_gradient=false)"}),
     [](const testing::TestParamInfo<PrintFragmentInfoTest::ParamType>& info) {
       return info.param.test_name;
     });
@@ -293,151 +245,20 @@ TEST(FragmentMergeRule, PrintFragmentMergeRule) {
       MakeFragmentInfo(
           {MakeFragmentOrigin("f1", 123), MakeFragmentOrigin("f2", 456)},
           /*stage_id=*/1, /*call_counter=*/std::nullopt,
-          /*split_type=*/std::nullopt));
+          /*is_weight_gradient=*/false));
   std::string str;
   llvm::raw_string_ostream os(str);
   os << rule;
-  EXPECT_THAT(str, Eq("FragmentMergeRule(sources=["
-                      "FragmentInfo(origins=[\"f1\"(123)],stage=1),"
-                      "FragmentInfo(origins=[\"f2\"(456)],stage=1)],"
-                      "target=FragmentInfo(origins=["
-                      "\"f1\"(123),\"f2\"(456)],stage=1))"));
+  EXPECT_THAT(
+      str,
+      Eq("FragmentMergeRule(sources=["
+         "FragmentInfo(origins=[\"f1\"(123)],stage=1,is_weight_gradient=false),"
+         "FragmentInfo(origins=[\"f2\"(456)],stage=1,is_weight_gradient=false)]"
+         ","
+         "target=FragmentInfo(origins=["
+         "\"f1\"(123),\"f2\"(456)],stage=1,is_weight_gradient=false))"));
 }
 
-TEST(FragmentMergeRuleParser, ParseValidRule) {
-  FragmentMergeRule expected_rule = MakeFragmentMergeRule(
-      {MakeFragmentInfo({MakeFragmentOrigin("f1", 123)}, /*stage_id=*/1,
-                        /*call_counter=*/std::nullopt,
-                        /*split_type=*/std::nullopt),
-       MakeFragmentInfo({MakeFragmentOrigin("f2", 456)},
-                        /*stage_id=*/1,
-                        /*call_counter=*/std::nullopt,
-                        /*split_type=*/SplitFragmentType::kDropTransferred)},
-      MakeFragmentInfo(
-          {MakeFragmentOrigin("f1", 123), MakeFragmentOrigin("f2", 456)},
-          /*stage_id=*/1,
-          /*call_counter=*/std::nullopt,
-          /*split_type=*/std::nullopt));
-  // We first construct the rule and print it to a string. Then we parse that
-  // string to ensure that the printed form of a rule is directly compatible
-  // with the format the parser expects.
-  std::string rule_str;
-  llvm::raw_string_ostream os(rule_str);
-  os << expected_rule;
-
-  FragmentMergeRule rule;
-  bool result = parseFragmentMergeRule(rule_str, rule);
-
-  EXPECT_FALSE(result);
-
-  ASSERT_EQ(rule.sources.size(), 2);
-  ExpectFragmentInfoEq(rule.sources[0], expected_rule.sources[0]);
-  ExpectFragmentInfoEq(rule.sources[1], expected_rule.sources[1]);
-  ExpectFragmentInfoEq(rule.target, expected_rule.target);
-}
-
-struct InvalidRuleTestParams {
-  std::string test_name;
-  std::string invalid_rule_str;
-};
-
-class FragmentMergeRuleParserInvalidSyntaxTest
-    : public ::testing::TestWithParam<InvalidRuleTestParams> {};
-
-TEST_P(FragmentMergeRuleParserInvalidSyntaxTest, ParseInvalidRule) {
-  const auto& params = GetParam();
-  FragmentMergeRule rule;
-  bool result = parseFragmentMergeRule(params.invalid_rule_str, rule);
-
-  EXPECT_TRUE(result);
-}
-
-INSTANTIATE_TEST_SUITE_P(
-    FragmentMergeRuleParser, FragmentMergeRuleParserInvalidSyntaxTest,
-    testing::Values(
-        InvalidRuleTestParams{"MissingPrefix",
-                              "sources=[FragmentInfo(origins=[\"f1\"(123)])]"},
-        InvalidRuleTestParams{
-            "MissingSources",
-            "FragmentMergeRule(target=FragmentInfo(origins=[\"f1\"(123)]))"},
-        InvalidRuleTestParams{"MissingTarget",
-                              "FragmentMergeRule(sources=[FragmentInfo(origins="
-                              "[\"f1\"(123)])])"}),
-    [](const testing::TestParamInfo<
-        FragmentMergeRuleParserInvalidSyntaxTest::ParamType>& info) {
-      return info.param.test_name;
-    });
-
-TEST(FragmentScheduleRule, PrintFragmentScheduleRule) {
-  FragmentScheduleRule rule = MakeFragmentScheduleRule(
-      {MakeFragmentInfo({MakeFragmentOrigin("f1", 123)}, /*stage_id=*/1),
-       MakeFragmentInfo({MakeFragmentOrigin("f2", 456)}, /*stage_id=*/2)});
-  std::string str;
-  llvm::raw_string_ostream os(str);
-  os << rule;
-  EXPECT_THAT(str, Eq("FragmentScheduleRule(ordered_fragments=["
-                      "FragmentInfo(origins=[\"f1\"(123)],stage=1)->"
-                      "FragmentInfo(origins=[\"f2\"(456)],stage=2)])"));
-}
-
-TEST(FragmentScheduleRuleParser, ParseValidRule) {
-  FragmentScheduleRule expected_rule = MakeFragmentScheduleRule(
-      {MakeFragmentInfo({MakeFragmentOrigin("f1", 123)}, /*stage_id=*/1,
-                        /*call_counter=*/std::nullopt,
-                        /*split_type=*/std::nullopt),
-       MakeFragmentInfo({MakeFragmentOrigin("f2", 456)},
-                        /*stage_id=*/1,
-                        /*call_counter=*/std::nullopt,
-                        /*split_type=*/SplitFragmentType::kDropTransferred)});
-  // We first construct the rule and print it to a string. Then we parse that
-  // string to ensure that the printed form of a rule is directly compatible
-  // with the format the parser expects.
-  std::string rule_str;
-  llvm::raw_string_ostream os(rule_str);
-  os << expected_rule;
-
-  FragmentScheduleRule rule;
-  bool result = parseFragmentScheduleRule(rule_str, rule);
-
-  EXPECT_FALSE(result);
-
-  ASSERT_EQ(rule.ordered_fragments.size(), 2);
-  ExpectFragmentInfoEq(rule.ordered_fragments[0],
-                       expected_rule.ordered_fragments[0]);
-  ExpectFragmentInfoEq(rule.ordered_fragments[1],
-                       expected_rule.ordered_fragments[1]);
-}
-
-class FragmentScheduleRuleParserInvalidSyntaxTest
-    : public ::testing::TestWithParam<InvalidRuleTestParams> {};
-
-TEST_P(FragmentScheduleRuleParserInvalidSyntaxTest, ParseInvalidRule) {
-  const auto& params = GetParam();
-  FragmentScheduleRule rule;
-  bool result = parseFragmentScheduleRule(params.invalid_rule_str, rule);
-
-  EXPECT_TRUE(result);
-}
-
-INSTANTIATE_TEST_SUITE_P(
-    FragmentScheduleRuleParser, FragmentScheduleRuleParserInvalidSyntaxTest,
-    testing::Values(
-        InvalidRuleTestParams{"MissingPrefix",
-                              "[FragmentInfo(origins=[\"f1\"(123)])->"
-                              "FragmentInfo(origins=[\"f2\"(456)])])"},
-        InvalidRuleTestParams{
-            "MissingArrow",
-            "FragmentScheduleRule(ordered_fragments=[FragmentInfo(origins=["
-            "\"f1\"(123)]) FragmentInfo(origins=[\"f2\"(456)])])"},
-        InvalidRuleTestParams{
-            "MissingClosingBrackets",
-            "FragmentScheduleRule(ordered_fragments=[FragmentInfo(origins=["
-            "\"f1\"(123)])->FragmentInfo(origins=[\"f2\"(456)])"}),
-    [](const testing::TestParamInfo<
-        FragmentScheduleRuleParserInvalidSyntaxTest::ParamType>& info) {
-      return info.param.test_name;
-    });
-
 TEST(FragmentInfoMapInfoTest, IsEqual) {
   FragmentInfo info1 = MakeFragmentInfo({MakeFragmentOrigin("f1", 123)});
   FragmentInfo info2 = MakeFragmentInfo({MakeFragmentOrigin("f1", 123)});
diff --git a/shardy/dialect/sdy/transforms/export/insert_explicit_reshards.cc b/shardy/dialect/sdy/transforms/export/insert_explicit_reshards.cc
index 51cea14..1cc061d 100644
--- a/shardy/dialect/sdy/transforms/export/insert_explicit_reshards.cc
+++ b/shardy/dialect/sdy/transforms/export/insert_explicit_reshards.cc
@@ -348,23 +348,6 @@ void insertAllReduceOnOpIfUnreducedToReplicated(
   }
 }
 
-bool isOnFullVersion(Operation* op, const bool enableFullVersion) {
-  return (enableFullVersion ||
-          op->getName().getStringRef() == "mhlo.ragged_dot" ||
-          // There are 3 cases.
-          // 1. Diff sharding -> insert explicit reshards.
-          // 2. Same sharding, concat dim is replicated -> no need to
-          // insert explicit reshards
-          // 3. Same sharding, concat dim is partitioned -> skip
-          // explicit reshard to avoid potential issues like
-          // b/393584711#comment3.
-          (isa<stablehlo::ConcatenateOp>(op) &&
-           differentOperandShardingFromFirstResult(op)) ||
-          // To avoid copies of the same functions with mismatching shardings
-          // on the arguments onto multiple callsites.
-          isa<NamedComputationOp>(op));
-}
-
 struct InsertExplicitReshardsPass
     : public impl::InsertExplicitReshardsPassBase<InsertExplicitReshardsPass> {
   using InsertExplicitReshardsPassBase::InsertExplicitReshardsPassBase;
@@ -375,7 +358,18 @@ struct InsertExplicitReshardsPass
     SymbolTable symbolTable(funcOp->getParentOfType<ModuleOp>());
 
     funcOp->walk([&](Operation* op) {
-      const bool onFullVersion = isOnFullVersion(op, enableFullVersion);
+      const bool onFullVersion =
+          enableFullVersion ||
+          op->getName().getStringRef() == "mhlo.ragged_dot" ||
+          // There are 3 cases.
+          // 1. Diff sharding -> insert explicit reshards.
+          // 2. Same sharding, concat dim is replicated -> no need to
+          // insert explicit reshards
+          // 3. Same sharding, concat dim is partitioned -> skip
+          // explicit reshard to avoid potential issues like
+          // b/393584711#comment3.
+          (isa<stablehlo::ConcatenateOp>(op) &&
+           differentOperandShardingFromFirstResult(op));
 
       if (op->hasTrait<OpTrait::IsTerminator>()) {
         if (isa<func::ReturnOp>(op)) {
diff --git a/shardy/dialect/sdy/transforms/export/test/insert_explicit_reshards.mlir b/shardy/dialect/sdy/transforms/export/test/insert_explicit_reshards.mlir
index 77049c3..e21d0cf 100644
--- a/shardy/dialect/sdy/transforms/export/test/insert_explicit_reshards.mlir
+++ b/shardy/dialect/sdy/transforms/export/test/insert_explicit_reshards.mlir
@@ -81,7 +81,7 @@ func.func @manual_computation(%arg0: tensor<208xf32> {sdy.sharding = #sdy.shardi
   // CHECK-NEXT: return %[[MANUAL_COMP]]
   %0 = sdy.manual_computation(%arg0)
     in_shardings=[<@mesh, [{"x"}], unreduced={"y"}>] out_shardings=[<@mesh, [{"x"}]>] manual_axes={"x"} (%arg1: tensor<104xf32>) {
-    %1 = stablehlo.abs %arg1 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{}], unreduced={"y"}>]>} : tensor<104xf32>
+    %1 = stablehlo.abs %arg1 {sdy.sharding=#sdy.sharding_per_value<[<@mesh, [{}], unreduced={"y"}>]>} : tensor<104xf32>
     sdy.return %1 : tensor<104xf32>
   } : (tensor<208xf32>) -> tensor<208xf32>
   return %0 : tensor<208xf32>
@@ -435,61 +435,3 @@ func.func @concatenate_same_shardings_func_result_different_sharding(%arg0: tens
   %0 = stablehlo.concatenate %arg0, %arg1, dim = 1 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"x"}, {}, {}]>]>} : (tensor<4x32x256xf32>, tensor<4x48x256xf32>) -> tensor<4x80x256xf32>
   return %0 : tensor<4x80x256xf32>
 }
-
-//===----------------------------------------------------------------------===//
-// Named computations tests
-// More tests are in insert_explicit_reshards/data_flow_ops.mlir
-//===----------------------------------------------------------------------===//
-
-// CHECK-LABEL: func @named_computation
-func.func @named_computation(%arg0: tensor<210xf32> {sdy.sharding = #sdy.sharding<@mesh, [{"x"}]>}) -> (tensor<210xf32> {sdy.sharding = #sdy.sharding<@mesh, [{"z"}]>}) {
-  // CHECK: %[[RESHARD:.*]] = sdy.reshard %arg0 <@mesh, [{"y"}]> : tensor<210xf32>
-  // CHECK-NEXT: sdy.named_computation<"foo">(%[[RESHARD]])
-  %0 = sdy.named_computation<"foo">(%arg0) in_shardings=[<@mesh, [{"y"}]>] out_shardings=[<@mesh, [{"z"}]>] (%arg1: tensor<210xf32>) {
-    %2 = stablehlo.abs %arg1 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"y"}]>]>} : tensor<210xf32>
-    // CHECK: %[[RESHARD:.*]] = sdy.reshard %{{.*}} <@mesh, [{"z"}]> : tensor<210xf32>
-    // CHECK-NEXT: sdy.return %[[RESHARD]] : tensor<210xf32>
-    sdy.return %2 : tensor<210xf32>
-  } : (tensor<210xf32>) -> (tensor<210xf32>)
-  %1 = stablehlo.negate %0 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"z"}]>]>} : tensor<210xf32>
-  return %1 : tensor<210xf32>
-}
-
-// CHECK-LABEL: func @one_argument_to_multiple_named_computations
-func.func @one_argument_to_multiple_named_computations(%arg0: tensor<210xf32> {sdy.sharding = #sdy.sharding<@mesh, [{"x"}]>}) -> (tensor<210xf32> {sdy.sharding = #sdy.sharding<@mesh, [{"z"}]>}) {
-  // CHECK: %[[RESHARD0:.*]] = sdy.reshard %arg0 <@mesh, [{"z"}]> : tensor<210xf32>
-  // CHECK: %[[RESHARD1:.*]] = sdy.reshard %arg0 <@mesh, [{"y"}]> : tensor<210xf32>
-  // CHECK-NEXT: %[[NC0:.*]] = sdy.named_computation<"foo">(%[[RESHARD1]])
-  %0 = sdy.named_computation<"foo">(%arg0) in_shardings=[<@mesh, [{"y"}]>] out_shardings=[<@mesh, [{"y"}]>] (%arg1: tensor<210xf32>) {
-    %2 = stablehlo.abs %arg1 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"y"}]>]>} : tensor<210xf32>
-    sdy.return %2 : tensor<210xf32>
-  } : (tensor<210xf32>) -> (tensor<210xf32>)
-  // CHECK: %[[NC1:.*]] = sdy.named_computation<"foo">(%[[RESHARD0]])
-  %1 = sdy.named_computation<"foo">(%arg0) in_shardings=[<@mesh, [{"z"}]>] out_shardings=[<@mesh, [{"z"}]>] (%arg1: tensor<210xf32>) {
-    %2 = stablehlo.abs %arg1 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"z"}]>]>} : tensor<210xf32>
-    sdy.return %2 : tensor<210xf32>
-  } : (tensor<210xf32>) -> (tensor<210xf32>)
-  // CHECK: %[[ADD:.*]] = stablehlo.add %[[NC0]], %[[NC1]]
-  // CHECK-NEXT: return %[[ADD]]
-  %3 = stablehlo.add %0, %1 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"z"}]>]>} : tensor<210xf32>
-  return %3 : tensor<210xf32>
-}
-
-// CHECK-LABEL: func @different_arguments_to_multiple_named_computations_with_same_input_output_shardings
-func.func @different_arguments_to_multiple_named_computations_with_same_input_output_shardings(%arg0: tensor<210xf32> {sdy.sharding = #sdy.sharding<@mesh, [{"x"}]>}) -> (tensor<210xf32> {sdy.sharding = #sdy.sharding<@mesh, [{"y"}]>}) {
-  // CHECK: %[[RESHARD:.*]] = sdy.reshard %arg0 <@mesh, [{"y"}]> : tensor<210xf32>
-  // CHECK-NEXT: %[[NC0:.*]] = sdy.named_computation<"foo">(%[[RESHARD]])
-  %0 = sdy.named_computation<"foo">(%arg0) in_shardings=[<@mesh, [{"y"}]>] out_shardings=[<@mesh, [{"y"}]>] (%arg1: tensor<210xf32>) {
-    %3 = stablehlo.abs %arg1 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"y"}]>]>} : tensor<210xf32>
-    sdy.return %3 : tensor<210xf32>
-  } : (tensor<210xf32>) -> (tensor<210xf32>)
-  // CHECK: %[[NEGATE:.*]] = stablehlo.negate %arg0 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"y"}]>]>}
-  // CHECK-NEXT: %[[NC0:.*]] = sdy.named_computation<"foo">(%[[NEGATE]])
-  %1 = stablehlo.negate %arg0 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"y"}]>]>} : tensor<210xf32>
-  %2 = sdy.named_computation<"foo">(%1) in_shardings=[<@mesh, [{"y"}]>] out_shardings=[<@mesh, [{"y"}]>] (%arg1: tensor<210xf32>) {
-    %3 = stablehlo.abs %arg1 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"y"}]>]>} : tensor<210xf32>
-    sdy.return %3 : tensor<210xf32>
-  } : (tensor<210xf32>) -> (tensor<210xf32>)
-  %4 = stablehlo.add %0, %2 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"y"}]>]>} : tensor<210xf32>
-  return %4 : tensor<210xf32>
-}
diff --git a/shardy/integrations/python/jax/mpmd/jaxlib/BUILD b/shardy/integrations/python/jax/mpmd/jaxlib/BUILD
deleted file mode 100644
index 8520538..0000000
--- a/shardy/integrations/python/jax/mpmd/jaxlib/BUILD
+++ /dev/null
@@ -1,35 +0,0 @@
-# load("@rules_cc//cc:cc_library.bzl", "cc_library")
-
-package(default_visibility = ["//visibility:public"])
-
-cc_library(
-    name = "mpmd_program",
-    srcs = ["mpmd_program.cc"],
-    hdrs = ["mpmd_program.h"],
-    deps = [
-        ":throw_error",
-        "//shardy/common:logging",
-        "//shardy/dialect/mpmd/ir:dialect",
-        "//shardy/dialect/mpmd/ir:fragment_execution_rules",
-        "//shardy/dialect/mpmd/ir:register",
-        "//shardy/dialect/mpmd/transforms/export:passes",
-        "//shardy/dialect/mpmd/transforms/export:utils",
-        "//shardy/dialect/mpmd/transforms/import:mesh_assignment_map",
-        "//shardy/dialect/mpmd/transforms/import:passes",
-        "//shardy/dialect/mpmd/transforms/optimize:passes",
-        "//shardy/dialect/mpmd/transforms/optimize:pipeline_schedule",
-        "//shardy/dialect/mpmd/transforms/sharding_propagation:passes",
-        "@llvm-project//llvm:Support",
-        "@llvm-project//mlir:FuncDialect",
-        "@llvm-project//mlir:IR",
-        "@llvm-project//mlir:Pass",
-        "@llvm-project//mlir:Support",
-    ],
-)
-
-cc_library(
-    name = "throw_error",
-    hdrs = ["throw_error.h"],
-    copts = ["-fexceptions"],
-    features = ["-use_header_modules"],
-)
diff --git a/shardy/integrations/python/jax/mpmd/jaxlib/mpmd_program.cc b/shardy/integrations/python/jax/mpmd/jaxlib/mpmd_program.cc
deleted file mode 100644
index 7891c30..0000000
--- a/shardy/integrations/python/jax/mpmd/jaxlib/mpmd_program.cc
+++ /dev/null
@@ -1,274 +0,0 @@
-/* Copyright 2025 The MPMD Authors.
-
-Licensed under the Apache License, Version 2.0 (the "License");
-you may not use this file except in compliance with the License.
-You may obtain a copy of the License at
-
-    http://www.apache.org/licenses/LICENSE-2.0
-
-Unless required by applicable law or agreed to in writing, software
-distributed under the License is distributed on an "AS IS" BASIS,
-WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
-See the License for the specific language governing permissions and
-limitations under the License.
-==============================================================================*/
-
-#include "shardy/integrations/python/jax/mpmd/jaxlib/mpmd_program.h"
-
-#include <cstdint>
-#include <map>
-#include <optional>
-#include <set>
-#include <string>
-#include <utility>
-#include <variant>
-#include <vector>
-
-#include "llvm/ADT/SmallVector.h"
-#include "mlir/Dialect/Func/IR/FuncOps.h"
-#include "mlir/IR/Builders.h"
-#include "mlir/IR/BuiltinAttributes.h"
-#include "mlir/IR/BuiltinOps.h"
-#include "mlir/IR/Diagnostics.h"
-#include "mlir/IR/OperationSupport.h"
-#include "mlir/Pass/PassManager.h"
-#include "mlir/Support/LogicalResult.h"
-#include "shardy/common/logging.h"
-#include "shardy/dialect/mpmd/ir/register.h"
-#include "shardy/dialect/mpmd/ir/utils.h"
-#include "shardy/dialect/mpmd/transforms/export/passes.h"
-#include "shardy/dialect/mpmd/transforms/export/utils.h"
-#include "shardy/dialect/mpmd/transforms/import/mesh_assignment_map.h"
-#include "shardy/dialect/mpmd/transforms/import/passes.h"
-#include "shardy/dialect/mpmd/transforms/optimize/passes.h"
-#include "shardy/dialect/mpmd/transforms/optimize/pipeline_schedule.h"
-#include "shardy/dialect/mpmd/transforms/sharding_propagation/passes.h"
-#include "shardy/integrations/python/jax/mpmd/jaxlib/throw_error.h"
-
-namespace mlir::mpmd {
-
-namespace {
-
-// Sets `jax.buffer_donor` attribute on the donated arguments that do not have
-// either `jax.buffer_donor` or `tf.aliasing_output` attributes set.
-// It is necessary to do this for cases when JAX does not have sufficient info
-// to mark `jax.buffer_donor` attributes. It is expected that every array
-// corresponding to an index in `donate_argnums` is safe to donate as these
-// have been marked as donatable by users.
-void SetArgDonationAttributes(mlir::func::FuncOp func_op,
-                              const std::vector<int64_t>& donate_argnums) {
-  for (int64_t arg_num : donate_argnums) {
-    if (!func_op.getArgAttrOfType<mlir::BoolAttr>(arg_num,
-                                                  kBufferDonationAttrName) &&
-        !func_op.getArgAttrOfType<mlir::IntegerAttr>(arg_num,
-                                                     kAliasingAttrName)) {
-      func_op.setArgAttr(arg_num, kBufferDonationAttrName,
-                         mlir::BoolAttr::get(func_op.getContext(), true));
-    }
-  }
-}
-
-// Verifies that only donated arguments have `jax.buffer_donor` or
-// `tf.aliasing_output` attributes set.
-void VerifyOnlyDonatedArgsHaveDonationAttributes(
-    mlir::func::FuncOp func_op, const std::vector<int64_t>& donate_argnums) {
-  std::set<int64_t> donated_argnum_set(donate_argnums.begin(),
-                                       donate_argnums.end());
-  for (int64_t arg_num = 0; arg_num < func_op.getNumArguments(); ++arg_num) {
-    if (donated_argnum_set.count(arg_num) == 0) {
-      if (func_op.getArgAttrOfType<mlir::BoolAttr>(
-              arg_num, mlir::mpmd::kBufferDonationAttrName) ||
-          func_op.getArgAttrOfType<mlir::IntegerAttr>(
-              arg_num, mlir::mpmd::kAliasingAttrName)) {
-        ThrowError("Argument " + std::to_string(arg_num) +
-                   " that is not donated cannot have `jax.buffer_donor` "
-                   "nor `tf.aliasing_output` attributes set");
-      }
-    }
-  }
-}
-
-}  // namespace
-
-PartitioningOptions ParsePartitioningOptions(
-    std::map<std::string, std::variant<std::string, bool>> options) {
-  PartitioningOptions parsed_options;
-#define PARSE_BOOL_OPTION(field)                             \
-  if (auto it = options.find(#field); it != options.end()) { \
-    parsed_options.field = std::get<bool>(it->second);       \
-  }
-
-  PARSE_BOOL_OPTION(mpmd_infer_transfers);
-  PARSE_BOOL_OPTION(mpmd_infer_cross_mesh_reductions);
-  PARSE_BOOL_OPTION(mpmd_merge_inferred_with_cloning_during_import);
-  PARSE_BOOL_OPTION(mpmd_gspmd_propagate_sharding_across_meshes);
-  PARSE_BOOL_OPTION(mpmd_allow_intra_mesh_transfer);
-  PARSE_BOOL_OPTION(mpmd_fragment_remat);
-  PARSE_BOOL_OPTION(mpmd_split_bwd_fragments);
-  PARSE_BOOL_OPTION(mpmd_assume_homogeneous_devices);
-#undef PARSE_BOOL_OPTION
-
-  if (auto it = options.find("mpmd_pipeline_schedule"); it != options.end()) {
-    std::string schedule_str = std::get<std::string>(it->second);
-    if (std::optional<PipelineSchedule> parsed_schedule =
-            ParsePipelineSchedule(schedule_str)) {
-      parsed_options.mpmd_pipeline_schedule = *parsed_schedule;
-    } else {
-      SDY_LOG(FATAL) << "Invalid pipeline schedule: " << schedule_str;
-    }
-  }
-  return parsed_options;
-}
-
-ErrorDiagnosticHandler::ErrorDiagnosticHandler(mlir::MLIRContext* context)
-    : mlir::SourceMgrDiagnosticHandler(source_mgr_, context, diag_stream_),
-      diag_stream_(diag_str_) {
-  setHandler([&](mlir::Diagnostic& diag) { return HandleDiagnostic(diag); });
-  // Set it to a large number to avoid truncation of the call stack.
-  // We don't currently have a use-case where we'd prefer to truncate it.
-  setCallStackLimit(100);
-}
-
-ErrorDiagnosticHandler::~ErrorDiagnosticHandler() {
-  SDY_CHECK(consumed_) << "Error must be thrown before destruction";
-}
-
-void ErrorDiagnosticHandler::ConsumeStatus(mlir::LogicalResult result) {
-  consumed_ = true;
-  if (mlir::failed(result) && error_str_.empty()) {
-    return ThrowError("Unknown MLIR failure");
-  }
-  return ThrowError(error_str_);
-}
-
-mlir::LogicalResult ErrorDiagnosticHandler::HandleDiagnostic(
-    mlir::Diagnostic& diag) {
-  // Emit the diagnostic and flush the stream.
-  diag_str_.clear();
-  emitDiagnostic(diag);
-  diag_stream_.flush();
-
-  // Emit non-errors to VLOG instead of the internal status.
-  if (diag.getSeverity() != mlir::DiagnosticSeverity::Error) {
-    SDY_LOG(INFO) << diag_str_;
-    return mlir::success();
-  }
-
-  error_str_ = diag_str_;
-
-  // Return success to show that we consumed the diagnostic.
-  return mlir::success();
-}
-
-PartitioningResult MpmdProgram::ApplyPartitioning(PartitioningPhase phases) {
-  if ((phases & ~PartitioningPhase::kAll) != 0) {
-    // Check that no undefined phase bits are set.
-    ThrowError("Invalid PartitioningPhase: " + std::to_string(phases));
-  }
-  loadAllRequiredDialects(module->getContext());
-
-  mlir::func::FuncOp main_func = GetMainFunction(module);
-  SetTopology(named_meshes, main_func);
-  SetArgDonationAttributes(main_func, donate_argnums);
-
-  // It is not necessary to do this
-  // validation after the export pipeline because here we're only checking that
-  // the attributes set on the main func are consistent with the received donate
-  // args.
-  VerifyOnlyDonatedArgsHaveDonationAttributes(main_func, donate_argnums);
-
-  SDY_LOG(INFO) << "Importing function named " << func_name
-                << " for MPMD partitioning.";
-
-  Import(module);
-
-  SDY_LOG(INFO) << "Optimizing function named " << func_name
-                << " for pipeline parallelism.";
-  Optimize(module);
-
-  SDY_LOG(INFO) << "Applying SDY propagation to function named " << func_name
-                << ".";
-  PropagateSharding(module);
-
-  SDY_LOG(INFO) << "Exporting MPMD function named " << func_name << ".";
-  Export(module);
-
-  return PartitioningResult(module);
-}
-
-#undef RETURN_IF_ERROR
-
-void MpmdProgram::Import(ModuleOp module) {
-  PassManager pm(module->getName());
-  pm.enableVerifier(false);
-
-  ImportOptions import_options;
-  import_options.nameToMeshAssignment = {std::move(assignment)};
-  import_options.inputIndexToMeshAssignment = {
-      ConvertMeshVectorToMap(input_meshes)};
-  import_options.outputIndexToMeshAssignment = {
-      ConvertMeshVectorToMap(output_meshes)};
-  import_options.mergeAfterScheduling = options.mpmd_merge_after_scheduling;
-  import_options.absorbInferredFragmentsOnEntryPointFunction =
-      options.mpmd_absorb_inferred_fragments_on_entry_point_function;
-  import_options.cloneInferredFragments =
-      options.mpmd_merge_inferred_with_cloning_during_import;
-  import_options.inferMeshOptions = {
-      options.mpmd_infer_transfers,
-      options.mpmd_infer_cross_mesh_reductions,
-  };
-  addImportPipeline(pm, import_options);
-  ErrorDiagnosticHandler diagnostic_handler(module.getContext());
-  return diagnostic_handler.ConsumeStatus(pm.run(module));
-}
-
-void MpmdProgram::Optimize(ModuleOp module) {
-  PassManager pm(module->getName());
-  pm.enableVerifier(false);
-
-  OptimizeOptions optimize_options;
-  optimize_options.fragmentMergeRules = llvm::to_vector(fragment_merge_rules);
-  optimize_options.mergeAfterScheduling = options.mpmd_merge_after_scheduling;
-  optimize_options.splitBwdFragments = options.mpmd_split_bwd_fragments;
-  optimize_options.applyFragmentRemat = options.mpmd_fragment_remat;
-  optimize_options.mergeRematFragments = options.mpmd_merge_remat_fragments;
-  optimize_options.absorbInferredFragmentsOnEntryPointFunction =
-      options.mpmd_absorb_inferred_fragments_on_entry_point_function;
-  optimize_options.cloneInferredFragments =
-      options.mpmd_merge_inferred_with_cloning_during_import;
-  optimize_options.pipelineSchedule = options.mpmd_pipeline_schedule;
-  addOptimizePipeline(pm, optimize_options);
-
-  ErrorDiagnosticHandler diagnostic_handler(module.getContext());
-  return diagnostic_handler.ConsumeStatus(pm.run(module));
-}
-
-void MpmdProgram::PropagateSharding(ModuleOp module) {
-  PassManager pm(module->getName());
-  pm.enableVerifier(false);
-
-  addShardingPropagationPipeline(pm, "");
-  module->setAttr(kIsSdyPartitioned, Builder(module).getBoolAttr(true));
-
-  ErrorDiagnosticHandler diagnostic_handler(module.getContext());
-  return diagnostic_handler.ConsumeStatus(pm.run(module));
-}
-
-void MpmdProgram::Export(ModuleOp module) {
-  PassManager pm(module->getName());
-  pm.enableVerifier(false);
-
-  ExportOptions export_options;
-  export_options.copyConstantsFromProducerToConsumer =
-      options.mpmd_copy_constant_creation_from_producer_to_consumer;
-  export_options.groupFragmentsAcrossMeshes =
-      options.mpmd_assume_homogeneous_devices;
-  export_options.applyMergeTransfers = options.mpmd_apply_merge_transfers_pass;
-  export_options.verboseLogging = true;
-  addExportPipeline(pm, export_options);
-
-  ErrorDiagnosticHandler diagnostic_handler(module.getContext());
-  return diagnostic_handler.ConsumeStatus(pm.run(module));
-}
-
-}  // namespace mlir::mpmd
diff --git a/shardy/integrations/python/jax/mpmd/jaxlib/mpmd_program.h b/shardy/integrations/python/jax/mpmd/jaxlib/mpmd_program.h
deleted file mode 100644
index da4da35..0000000
--- a/shardy/integrations/python/jax/mpmd/jaxlib/mpmd_program.h
+++ /dev/null
@@ -1,140 +0,0 @@
-/* Copyright 2025 The MPMD Authors.
-
-Licensed under the Apache License, Version 2.0 (the "License");
-you may not use this file except in compliance with the License.
-You may obtain a copy of the License at
-
-    http://www.apache.org/licenses/LICENSE-2.0
-
-Unless required by applicable law or agreed to in writing, software
-distributed under the License is distributed on an "AS IS" BASIS,
-WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
-See the License for the specific language governing permissions and
-limitations under the License.
-==============================================================================*/
-
-#ifndef SHARDY_INTEGRATIONS_PYTHON_JAX_MPMD_JAXLIB_MPMD_PROGRAM_H_
-#define SHARDY_INTEGRATIONS_PYTHON_JAX_MPMD_JAXLIB_MPMD_PROGRAM_H_
-
-#include <cstdint>
-#include <map>
-#include <optional>
-#include <string>
-#include <utility>
-#include <variant>
-#include <vector>
-
-#include "llvm/Support/SourceMgr.h"
-#include "llvm/Support/raw_ostream.h"
-#include "mlir/IR/BuiltinOps.h"
-#include "mlir/IR/Diagnostics.h"
-#include "mlir/IR/MLIRContext.h"
-#include "mlir/Support/LLVM.h"
-#include "shardy/dialect/mpmd/ir/fragment_execution_rules.h"
-#include "shardy/dialect/mpmd/ir/utils.h"
-#include "shardy/dialect/mpmd/transforms/import/mesh_assignment_map.h"
-#include "shardy/dialect/mpmd/transforms/optimize/pipeline_schedule.h"
-
-namespace mlir::mpmd {
-
-// Represents phases of the partitioning pipeline. This is used as a bitmask to
-// specify which phases to run.
-//
-// A bitmask is chosen for extensibility and to simplify the control flow within
-// `ApplyPartitioning`. With a bitmask, determining whether to run a specific
-// phase is a simple bitwise AND. The trade-off is that this is less type-safe
-// and does not enforce a specific ordering. This is acceptable as the Python
-// API layer is responsible for enforcing a valid sequence of phases.
-enum PartitioningPhase : int32_t {
-  kNone = 0,
-  kImport = 1 << 0,
-  kPartition = 1 << 1,
-  kAll = kImport | kPartition,
-};
-
-struct PartitioningResult {
-  mlir::ModuleOp mpmd_module;
-  // Partition specs and mesh names of each input and output of the MPMD
-  // module's main function.
-  mlir::mpmd::FunctionIOShardingSpecsAndMeshes
-      module_io_sharding_specs_and_meshes;
-
-  explicit PartitioningResult(mlir::ModuleOp mpmd_module)
-      : mpmd_module(mpmd_module),
-        module_io_sharding_specs_and_meshes(
-            ExtractFunctionIOShardingSpecsAndMeshes(
-                GetMainFunction(mpmd_module))) {}
-};
-
-class ErrorDiagnosticHandler : public mlir::SourceMgrDiagnosticHandler {
- public:
-  explicit ErrorDiagnosticHandler(mlir::MLIRContext* context);
-
-  // Destruction CHECK-fails if ConsumeStatus has not been called.
-  ~ErrorDiagnosticHandler();
-
-  // Returns a runtime error if it fails if it is non-OK, or an error, if
-  // `result` is mlir::failed. If the aggregate status is OK and
-  // mlir::succeeded(result), does nothing.
-  void ConsumeStatus(mlir::LogicalResult result);
-
- private:
-  mlir::LogicalResult HandleDiagnostic(mlir::Diagnostic& diag);
-
-  std::string diag_str_;
-  std::string error_str_;
-  llvm::raw_string_ostream diag_stream_;
-  llvm::SourceMgr source_mgr_;
-  bool consumed_ = false;
-};
-
-// Basic options for MPMD partitioning. We should improve how this is kept in
-// sync with the python version.
-struct PartitioningOptions {
-  bool mpmd_infer_transfers = false;
-  bool mpmd_infer_cross_mesh_reductions = false;
-  bool mpmd_merge_inferred_with_cloning_during_import = false;
-  bool mpmd_gspmd_propagate_sharding_across_meshes = false;
-  bool mpmd_allow_intra_mesh_transfer = false;
-  bool mpmd_fragment_remat = false;
-  bool mpmd_merge_remat_fragments = false;
-  bool mpmd_split_bwd_fragments = false;
-  PipelineSchedule mpmd_pipeline_schedule = PipelineSchedule::kGPipe;
-  bool mpmd_assume_homogeneous_devices = false;
-  bool mpmd_absorb_inferred_fragments_on_entry_point_function = false;
-  bool mpmd_copy_constant_creation_from_producer_to_consumer = false;
-  bool mpmd_apply_merge_transfers_pass = false;
-  bool mpmd_merge_after_scheduling = false;
-};
-
-PartitioningOptions ParsePartitioningOptions(
-    std::map<std::string, std::variant<std::string, bool>> options);
-
-// Struct used for holding information needed for partitioning a MPMD program.
-struct MpmdProgram {
-  mlir::ModuleOp module;
-  std::string func_name;
-  PartitioningOptions options;
-  const std::vector<std::pair<std::string, FlatMesh>>& named_meshes;
-  const mlir::mpmd::UserAssignmentMap& assignment;
-  const std::vector<std::optional<std::string>>& input_meshes;
-  const std::vector<std::optional<std::string>>& output_meshes;
-  const std::vector<int64_t>& donate_argnums;
-  const mlir::mpmd::FragmentMergeRules& fragment_merge_rules;
-
-  // Runs the PartIR MPMD partitioning passes on the MPMD program.
-  //
-  // Raises a runtime error if it fails.
-  PartitioningResult ApplyPartitioning(PartitioningPhase phases);
-
- private:
-  // Raises a runtime error if these functions fail.
-  void Import(mlir::ModuleOp module);
-  void Optimize(mlir::ModuleOp module);
-  void PropagateSharding(mlir::ModuleOp module);
-  void Export(mlir::ModuleOp module);
-};
-
-}  // namespace mlir::mpmd
-
-#endif  // SHARDY_INTEGRATIONS_PYTHON_JAX_MPMD_JAXLIB_MPMD_PROGRAM_H_
diff --git a/shardy/integrations/python/jax/mpmd/jaxlib/throw_error.h b/shardy/integrations/python/jax/mpmd/jaxlib/throw_error.h
deleted file mode 100644
index d342c73..0000000
--- a/shardy/integrations/python/jax/mpmd/jaxlib/throw_error.h
+++ /dev/null
@@ -1,30 +0,0 @@
-/* Copyright 2025 The MPMD Authors.
-
-Licensed under the Apache License, Version 2.0 (the "License");
-you may not use this file except in compliance with the License.
-You may obtain a copy of the License at
-
-    http://www.apache.org/licenses/LICENSE-2.0
-
-Unless required by applicable law or agreed to in writing, software
-distributed under the License is distributed on an "AS IS" BASIS,
-WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
-See the License for the specific language governing permissions and
-limitations under the License.
-==============================================================================*/
-
-#ifndef THIRD_PARTY_OPENXLA_SHARDY_SRC_SHARDY_INTEGRATIONS_PYTHON_JAX_MPMD_JAXLIB_THROW_ERROR_H_
-#define THIRD_PARTY_OPENXLA_SHARDY_SRC_SHARDY_INTEGRATIONS_PYTHON_JAX_MPMD_JAXLIB_THROW_ERROR_H_
-
-#include <stdexcept>
-#include <string>
-
-namespace mlir::mpmd {
-
-// Throws a runtime error with the given message. We do this to avoid depending
-// on absl, since we're only propagating the error to python.
-inline void ThrowError(std::string src) { throw std::runtime_error(src); }
-
-}  // namespace mlir::mpmd
-
-#endif  // THIRD_PARTY_OPENXLA_SHARDY_SRC_SHARDY_INTEGRATIONS_PYTHON_JAX_MPMD_JAXLIB_THROW_ERROR_H_
diff --git a/shardy/integrations/python/jax/mpmd/types.py b/shardy/integrations/python/jax/mpmd/types.py
index 9fd4543..557e2a2 100644
--- a/shardy/integrations/python/jax/mpmd/types.py
+++ b/shardy/integrations/python/jax/mpmd/types.py
@@ -17,7 +17,6 @@
 
 from collections.abc import Mapping, Sequence
 import dataclasses
-import enum
 from typing import Any
 
 import jax
@@ -49,20 +48,6 @@ class FragmentOrigin:
   transpose_count: int = 0
 
 
-@enum.unique
-class SplitFragmentType(enum.Enum):
-  """Fragment split behavior for transferred data.
-
-  These values indicate how fragment portions handle transferred data from
-  the original fragment if the fragment is split during compilation:
-  - KEEP_TRANSFERRED: Fragment portion retains transferred data
-  - DROP_TRANSFERRED: Fragment portion drops transferred data
-  """
-
-  KEEP_TRANSFERRED = enum.auto()
-  DROP_TRANSFERRED = enum.auto()
-
-
 @dataclasses.dataclass(frozen=True)
 class FragmentInfo:
   """A fragment of a computation."""
@@ -70,7 +55,7 @@ class FragmentInfo:
   origins: Sequence[FragmentOrigin]
   stage_id: int | None = None
   call_counter: int | None = None
-  split_type: SplitFragmentType | None = None
+  is_weight_gradient: bool = False
 
 
 @dataclasses.dataclass(frozen=True)
diff --git a/third_party/llvm/generated.patch b/third_party/llvm/generated.patch
index 09d0f82..1dc4d80 100644
--- a/third_party/llvm/generated.patch
+++ b/third_party/llvm/generated.patch
@@ -34,18 +34,6 @@ diff -ruN --strip-trailing-cr a/clang/include/clang/Analysis/FlowSensitive/Stora
    llvm::iterator_range<FieldToLoc::const_iterator> children() const {
      return {Children.begin(), Children.end()};
    }
-diff -ruN --strip-trailing-cr a/clang/include/clang/AST/DeclCXX.h b/clang/include/clang/AST/DeclCXX.h
---- a/clang/include/clang/AST/DeclCXX.h
-+++ b/clang/include/clang/AST/DeclCXX.h
-@@ -3826,7 +3826,7 @@
- 
- public:
-   EnumDecl *getEnumDecl() const {
--    return cast<clang::EnumType>(EnumType->getType())->getOriginalDecl();
-+    return EnumType->getType()->castAs<clang::EnumType>()->getOriginalDecl();
-   }
- 
-   static UsingEnumDecl *Create(ASTContext &C, DeclContext *DC,
 diff -ruN --strip-trailing-cr a/clang/lib/Analysis/FlowSensitive/Transfer.cpp b/clang/lib/Analysis/FlowSensitive/Transfer.cpp
 --- a/clang/lib/Analysis/FlowSensitive/Transfer.cpp
 +++ b/clang/lib/Analysis/FlowSensitive/Transfer.cpp
@@ -165,326 +153,19 @@ diff -ruN --strip-trailing-cr a/clang/lib/Analysis/FlowSensitive/Transfer.cpp b/
    void VisitConditionalOperator(const ConditionalOperator *S) {
      const Environment *TrueEnv = StmtToEnv.getEnvironment(*S->getTrueExpr());
      const Environment *FalseEnv = StmtToEnv.getEnvironment(*S->getFalseExpr());
-diff -ruN --strip-trailing-cr a/clang/lib/AST/ASTImporter.cpp b/clang/lib/AST/ASTImporter.cpp
---- a/clang/lib/AST/ASTImporter.cpp
-+++ b/clang/lib/AST/ASTImporter.cpp
-@@ -1740,10 +1740,21 @@
- }
- 
- ExpectedType ASTNodeImporter::VisitTagType(const TagType *T) {
--  Expected<TagDecl *> ToDeclOrErr = import(T->getOriginalDecl());
-+  TagDecl *DeclForType = T->getOriginalDecl();
-+  Expected<TagDecl *> ToDeclOrErr = import(DeclForType);
-   if (!ToDeclOrErr)
-     return ToDeclOrErr.takeError();
- 
-+  if (DeclForType->isUsed()) {
-+    // If there is a definition of the 'OriginalDecl', it should be imported to
-+    // have all information for the type in the "To" AST. (In some cases no
-+    // other reference may exist to the definition decl and it would not be
-+    // imported otherwise.)
-+    Expected<TagDecl *> ToDefDeclOrErr = import(DeclForType->getDefinition());
-+    if (!ToDefDeclOrErr)
-+      return ToDefDeclOrErr.takeError();
-+  }
-+
-   if (T->isCanonicalUnqualified())
-     return Importer.getToContext().getCanonicalTagType(*ToDeclOrErr);
- 
-diff -ruN --strip-trailing-cr a/clang/lib/Sema/SemaDecl.cpp b/clang/lib/Sema/SemaDecl.cpp
---- a/clang/lib/Sema/SemaDecl.cpp
-+++ b/clang/lib/Sema/SemaDecl.cpp
-@@ -5291,10 +5291,8 @@
-     //   UNION_TYPE;   <- where UNION_TYPE is a typedef union.
-     if ((Tag && Tag->getDeclName()) ||
-         DS.getTypeSpecType() == DeclSpec::TST_typename) {
--      RecordDecl *Record = dyn_cast_or_null<RecordDecl>(Tag);
--      if (!Record)
--        Record = DS.getRepAsType().get()->getAsRecordDecl();
--
-+      RecordDecl *Record = Tag ? dyn_cast<RecordDecl>(Tag)
-+                               : DS.getRepAsType().get()->getAsRecordDecl();
-       if (Record && getLangOpts().MicrosoftExt) {
-         Diag(DS.getBeginLoc(), diag::ext_ms_anonymous_record)
-             << Record->isUnion() << DS.getSourceRange();
-@@ -18052,7 +18050,8 @@
-           }
-         }
-       } else if (auto *RD = dyn_cast<CXXRecordDecl>(PrevDecl);
--                 RD && RD->isInjectedClassName()) {
-+                 TUK == TagUseKind::Reference && RD &&
-+                 RD->isInjectedClassName()) {
-         // If lookup found the injected class name, the previous declaration is
-         // the class being injected into.
-         PrevDecl = cast<TagDecl>(RD->getDeclContext());
-@@ -18544,8 +18543,14 @@
-   if (PrevDecl)
-     CheckRedeclarationInModule(New, PrevDecl);
- 
--  if (TUK == TagUseKind::Definition && (!SkipBody || !SkipBody->ShouldSkip))
--    New->startDefinition();
-+  if (TUK == TagUseKind::Definition) {
-+    if (!SkipBody || !SkipBody->ShouldSkip) {
-+      New->startDefinition();
-+    } else {
-+      New->setCompleteDefinition();
-+      New->demoteThisDefinitionToDeclaration();
-+    }
-+  }
- 
-   ProcessDeclAttributeList(S, New, Attrs);
-   AddPragmaAttributes(S, New);
-diff -ruN --strip-trailing-cr a/clang/lib/Sema/SemaType.cpp b/clang/lib/Sema/SemaType.cpp
---- a/clang/lib/Sema/SemaType.cpp
-+++ b/clang/lib/Sema/SemaType.cpp
-@@ -9878,7 +9878,14 @@
-   S.DiagnoseUseOfDecl(ED, Loc);
- 
-   QualType Underlying = ED->getIntegerType();
--  assert(!Underlying.isNull());
-+  if (Underlying.isNull()) {
-+    // This is an enum without a fixed underlying type which we skipped parsing
-+    // the body because we saw its definition previously in another module.
-+    // Use the definition's integer type in that case.
-+    assert(ED->isThisDeclarationADemotedDefinition());
-+    Underlying = ED->getDefinition()->getIntegerType();
-+    assert(!Underlying.isNull());
-+  }
- 
-   return Underlying;
- }
-diff -ruN --strip-trailing-cr a/clang/lib/Serialization/ASTReaderDecl.cpp b/clang/lib/Serialization/ASTReaderDecl.cpp
---- a/clang/lib/Serialization/ASTReaderDecl.cpp
-+++ b/clang/lib/Serialization/ASTReaderDecl.cpp
-@@ -2107,6 +2107,8 @@
-     auto *Def = DD.Definition;
-     DD = std::move(MergeDD);
-     DD.Definition = Def;
-+    while ((Def = Def->getPreviousDecl()))
-+      cast<CXXRecordDecl>(Def)->DefinitionData = &DD;
-     return;
+diff -ruN --strip-trailing-cr a/clang/lib/AST/ASTContext.cpp b/clang/lib/AST/ASTContext.cpp
+--- a/clang/lib/AST/ASTContext.cpp
++++ b/clang/lib/AST/ASTContext.cpp
+@@ -5316,7 +5316,8 @@
    }
  
-diff -ruN --strip-trailing-cr a/clang/test/Analysis/ctu-import-type-decl-definition.c b/clang/test/Analysis/ctu-import-type-decl-definition.c
---- a/clang/test/Analysis/ctu-import-type-decl-definition.c
-+++ b/clang/test/Analysis/ctu-import-type-decl-definition.c
-@@ -0,0 +1,43 @@
-+// RUN: rm -rf %t
-+// RUN: mkdir -p %t
-+// RUN: split-file %s %t
-+
-+// RUN: %clang_cc1 -emit-pch -o %t/import.c.ast %t/import.c
-+
-+// RUN: %clang_extdef_map -- -x c %t/import.c >> %t/externalDefMap.txt
-+// RUN: sed -i 's/$/.ast/' %t/externalDefMap.txt
-+
-+// RUN: %clang_cc1 -analyze \
-+// RUN:   -analyzer-checker=core \
-+// RUN:   -analyzer-config experimental-enable-naive-ctu-analysis=true \
-+// RUN:   -analyzer-config display-ctu-progress=true \
-+// RUN:   -analyzer-config ctu-dir=%t \
-+// RUN:   -verify %t/main.c
-+
-+//--- main.c
-+
-+// expected-no-diagnostics
-+
-+typedef struct X_s X_t;
-+unsigned long f_import(struct X_s *xPtr);
-+
-+static void freeWriteFileResources(struct X_s *xPtr) {
-+  f_import(xPtr);
-+}
-+
-+//--- import.c
-+
-+typedef struct Y_s Y_t;
-+
-+struct Y_s {
-+};
-+
-+struct X_s {
-+  Y_t y;
-+};
-+
-+unsigned long f_import(struct X_s *xPtr) {
-+  if (xPtr != 0) {
-+  }
-+  return 0;
-+}
-diff -ruN --strip-trailing-cr a/clang/test/AST/ast-dump-decl.cpp b/clang/test/AST/ast-dump-decl.cpp
---- a/clang/test/AST/ast-dump-decl.cpp
-+++ b/clang/test/AST/ast-dump-decl.cpp
-@@ -990,3 +990,18 @@
-   // CHECK-NEXT:    `-RecordType [[TestInjectedClassName_RT]] 'A' injected
-   // CHECK-NEXT:      `-CXXRecord [[TestInjectedClassName_RD]] 'A'
- } // namespace InjectedClassName
-+
-+namespace TestGH155936 {
-+  struct Foo {
-+    struct A {
-+      struct Foo {};
-+    };
-+  };
-+  // CHECK-LABEL: Dumping TestGH155936:
-+  // CHECK: CXXRecordDecl 0x{{.+}} <{{.+}}> line:[[@LINE-6]]:10 struct Foo definition
-+  // CHECK: CXXRecordDecl 0x{{.+}} <col:3, col:10> col:10 implicit struct Foo
-+  // CHECK: CXXRecordDecl 0x{{.+}} <{{.+}}> line:[[@LINE-7]]:12 struct A definition
-+  // CHECK: CXXRecordDecl 0x{{.+}} <col:5, col:12> col:12 implicit struct A
-+  // CHECK: CXXRecordDecl 0x{{.+}} <line:[[@LINE-8]]:7, col:19> col:14 struct Foo definition
-+  // CHECH: CXXRecordDecl 0x{{.+}} <col:9, col:16> col:16 implicit struct Foo
-+} // namspace GH155936
-diff -ruN --strip-trailing-cr a/clang/test/Modules/GH154840.cpp b/clang/test/Modules/GH154840.cpp
---- a/clang/test/Modules/GH154840.cpp
-+++ b/clang/test/Modules/GH154840.cpp
-@@ -0,0 +1,97 @@
-+// RUN: rm -rf %t
-+// RUN: mkdir -p %t
-+// RUN: split-file %s %t
-+// RUN: cd %t
-+//
-+// RUN: %clang_cc1 -fmodule-name=A -fno-cxx-modules -emit-module -fmodules -xc++ A.cppmap -o A.pcm
-+// RUN: %clang_cc1 -fmodule-name=B -fno-cxx-modules -emit-module -fmodules -xc++ B.cppmap -o B.pcm -fmodule-file=A.pcm
-+// RUN: %clang_cc1 -fmodule-name=C -fno-cxx-modules -emit-module -fmodules -xc++ C.cppmap -o C.pcm -fmodule-file=A.pcm
-+// RUN: %clang_cc1 -fmodule-name=D -fno-cxx-modules -emit-module -fmodules -xc++ D.cppmap -o D.pcm -fmodule-file=A.pcm
-+// RUN: %clang_cc1 -fmodule-name=E -fno-cxx-modules -emit-module -fmodules -xc++ E.cppmap -o E.pcm -fmodule-file=D.pcm -fmodule-file=B.pcm -fmodule-file=C.pcm
-+// RUN: %clang_cc1 -fno-cxx-modules -fmodules -fmodule-file=B.pcm -fmodule-file=E.pcm -emit-llvm -o /dev/null S.cpp
-+
-+//--- A.h
-+namespace std {
-+
-+template <class T> void zz(T);
-+
-+template <class> struct vec {
-+  struct w {};
-+  struct xx {};
-+
-+  vec(vec &) { init(); }
-+  constexpr vec &operator=(const vec &);
-+  template <class U> constexpr void pb(U);
-+  constexpr void init();
-+
-+  w s;
-+};
-+
-+template <class T> constexpr void vec<T>::init() {
-+  xx yy;
-+  zz(yy);
-+}
-+
-+template <class T> constexpr vec<T> &vec<T>::operator=(const vec &) {
-+  pb(s);
-+  return *this;
-+}
-+
-+template <class T> template <class U> constexpr void vec<T>::pb(U) { init(); }
-+} // namespace std
-+
-+//--- A.cppmap
-+module "A" {
-+  header "A.h"
-+}
-+
-+//--- X.h
-+#pragma clang module import A
-+
-+namespace project {
-+  class thing : std::vec<thing> {};
-+} // namespace project
-+
-+//--- B.h
-+#include "X.h"
-+
-+//--- B.cppmap
-+module "B" {
-+  header "B.h"
-+}
-+
-+//--- C.h
-+#include "X.h"
-+
-+//--- C.cppmap
-+module "C" {
-+  header "C.h"
-+}
-+
-+//--- D.h
-+#include "X.h"
-+
-+//--- D.cppmap
-+module "D" {
-+  header "D.h"
-+}
-+
-+//--- Y.h
-+#include "X.h"
-+struct other {
-+  other() : data(data) {}
-+  std::vec<project::thing> data;
-+};
-+
-+//--- E.h
-+#include "Y.h"
-+
-+//--- E.cppmap
-+module "E" {
-+  header "E.h"
-+}
-+
-+//--- S.cpp
-+#pragma clang module import A
-+#pragma clang module import E
-+void func(std::vec<project::thing> *a, std::vec<project::thing> *b) { *a = *b; }
-diff -ruN --strip-trailing-cr a/clang/test/Modules/GH155028-1.cpp b/clang/test/Modules/GH155028-1.cpp
---- a/clang/test/Modules/GH155028-1.cpp
-+++ b/clang/test/Modules/GH155028-1.cpp
-@@ -0,0 +1,17 @@
-+// RUN: %clang_cc1 -std=c++20 -verify %s
-+// expected-no-diagnostics
-+
-+#pragma clang module build M
-+module "M" {
-+  module "A" {}
-+  module "B" {}
-+}
-+#pragma clang module contents
-+#pragma clang module begin M.A
-+enum E1 {};
-+#pragma clang module end
-+#pragma clang module begin M.B
-+enum E1 {};
-+using T = __underlying_type(E1);
-+#pragma clang module end
-+#pragma clang module endbuild
-diff -ruN --strip-trailing-cr a/clang/test/Sema/GH155794.c b/clang/test/Sema/GH155794.c
---- a/clang/test/Sema/GH155794.c
-+++ b/clang/test/Sema/GH155794.c
-@@ -0,0 +1,6 @@
-+// RUN: %clang_cc1 -fsyntax-only -verify -Wno-everything %s
-+
-+struct S {
-+  enum e1 {} // expected-error {{use of empty enum}} expected-error {{expected ';' after enum}}
-+  enum e2 {} // expected-error {{use of empty enum}}
-+}; // expected-error {{expected member name or ';' after declaration specifiers}}
-diff -ruN --strip-trailing-cr a/clang/test/SemaTemplate/using-decl.cpp b/clang/test/SemaTemplate/using-decl.cpp
---- a/clang/test/SemaTemplate/using-decl.cpp
-+++ b/clang/test/SemaTemplate/using-decl.cpp
-@@ -14,3 +14,15 @@
-   }
-   void e() { c<int>(); }
- }
-+
-+namespace UsingUsingEnum {
-+  namespace foo {
-+    enum class EnumOne {};
-+  }
-+  using foo::EnumOne;
-+
-+  template <class> void t() {
-+    using enum EnumOne;
-+  }
-+  template void t<void>();
-+} // namespace UsingUsingEnum
+   llvm::FoldingSetNodeID ID;
+-  TypedefType::Profile(ID, Keyword, Qualifier, Decl, UnderlyingType);
++  TypedefType::Profile(ID, Keyword, Qualifier, Decl,
++                       *TypeMatchesDeclOrNone ? QualType() : UnderlyingType);
+ 
+   void *InsertPos = nullptr;
+   if (FoldingSetPlaceholder<TypedefType> *Placeholder =
 diff -ruN --strip-trailing-cr a/clang/unittests/Analysis/FlowSensitive/TransferTest.cpp b/clang/unittests/Analysis/FlowSensitive/TransferTest.cpp
 --- a/clang/unittests/Analysis/FlowSensitive/TransferTest.cpp
 +++ b/clang/unittests/Analysis/FlowSensitive/TransferTest.cpp
@@ -814,151 +495,553 @@ diff -ruN --strip-trailing-cr a/clang/unittests/Analysis/FlowSensitive/TransferT
  TEST(TransferTest, IntegralCast) {
    std::string Code = R"(
      void target(int Foo) {
-diff -ruN --strip-trailing-cr a/clang-tools-extra/test/clang-tidy/check_clang_tidy.py b/clang-tools-extra/test/clang-tidy/check_clang_tidy.py
---- a/clang-tools-extra/test/clang-tidy/check_clang_tidy.py
-+++ b/clang-tools-extra/test/clang-tidy/check_clang_tidy.py
-@@ -391,9 +391,7 @@
-     args, extra_args = parser.parse_known_args()
-     if args.std is None:
-         _, extension = os.path.splitext(args.assume_filename or args.input_file_name)
--        args.std = [
--            "c++11-or-later" if extension in [".cpp", ".hpp", ".mm"] else "c99-or-later"
--        ]
-+        args.std = ["c99-or-later" if extension in [".c", ".m"] else "c++11-or-later"]
+diff -ruN --strip-trailing-cr a/llvm/include/llvm/Linker/IRMover.h b/llvm/include/llvm/Linker/IRMover.h
+--- a/llvm/include/llvm/Linker/IRMover.h
++++ b/llvm/include/llvm/Linker/IRMover.h
+@@ -10,6 +10,7 @@
+ #define LLVM_LINKER_IRMOVER_H
  
-     return (args, extra_args)
+ #include "llvm/ADT/ArrayRef.h"
++#include "llvm/ADT/DenseMap.h"
+ #include "llvm/ADT/DenseSet.h"
+ #include "llvm/ADT/FunctionExtras.h"
+ #include "llvm/Support/Compiler.h"
+@@ -19,6 +20,8 @@
+ class Error;
+ class GlobalValue;
+ class Metadata;
++class MDNode;
++class NamedMDNode;
+ class Module;
+ class StructType;
+ class TrackingMDRef;
+@@ -67,6 +70,8 @@
+   using LazyCallback =
+       llvm::unique_function<void(GlobalValue &GV, ValueAdder Add)>;
  
-diff -ruN --strip-trailing-cr a/lldb/source/Plugins/SymbolFile/NativePDB/SymbolFileNativePDB.cpp b/lldb/source/Plugins/SymbolFile/NativePDB/SymbolFileNativePDB.cpp
---- a/lldb/source/Plugins/SymbolFile/NativePDB/SymbolFileNativePDB.cpp
-+++ b/lldb/source/Plugins/SymbolFile/NativePDB/SymbolFileNativePDB.cpp
-@@ -1735,11 +1735,11 @@
-   }
++  using NamedMDNodesT = DenseMap<const NamedMDNode *, DenseSet<const MDNode *>>;
++
+   /// Move in the provide values in \p ValuesToLink from \p Src.
+   ///
+   /// - \p AddLazyFor is a call back that the IRMover will call when a global
+@@ -86,6 +91,7 @@
+   Module &Composite;
+   IdentifiedStructTypeSet IdentifiedStructTypes;
+   MDMapT SharedMDs; ///< A Metadata map to use for all calls to \a move().
++  NamedMDNodesT NamedMDNodes; ///< Cache for IRMover::linkNamedMDNodes().
+ };
  
-   // Sort them before value searching is working properly.
--  m_func_full_names.Sort();
-+  m_func_full_names.Sort(std::less<uint32_t>());
-   m_func_full_names.SizeToFit();
--  m_func_method_names.Sort();
-+  m_func_method_names.Sort(std::less<uint32_t>());
-   m_func_method_names.SizeToFit();
--  m_func_base_names.Sort();
-+  m_func_base_names.Sort(std::less<uint32_t>());
-   m_func_base_names.SizeToFit();
- }
+ } // End llvm namespace
+diff -ruN --strip-trailing-cr a/llvm/lib/Linker/IRMover.cpp b/llvm/lib/Linker/IRMover.cpp
+--- a/llvm/lib/Linker/IRMover.cpp
++++ b/llvm/lib/Linker/IRMover.cpp
+@@ -293,7 +293,7 @@
+   std::unique_ptr<Module> SrcM;
  
-@@ -2426,7 +2426,7 @@
+   // Lookup table to optimize IRMover::linkNamedMDNodes().
+-  DenseMap<StringRef, DenseSet<MDNode *>> NamedMDNodes;
++  IRMover::NamedMDNodesT &NamedMDNodes;
  
-   // After calling Append(), the type-name map needs to be sorted again to be
-   // able to look up a type by its name.
--  m_type_base_names.Sort();
-+  m_type_base_names.Sort(std::less<uint32_t>());
+   /// See IRMover::move().
+   IRMover::LazyCallback AddLazyFor;
+@@ -440,10 +440,12 @@
+   IRLinker(Module &DstM, MDMapT &SharedMDs,
+            IRMover::IdentifiedStructTypeSet &Set, std::unique_ptr<Module> SrcM,
+            ArrayRef<GlobalValue *> ValuesToLink,
+-           IRMover::LazyCallback AddLazyFor, bool IsPerformingImport)
+-      : DstM(DstM), SrcM(std::move(SrcM)), AddLazyFor(std::move(AddLazyFor)),
+-        TypeMap(Set), GValMaterializer(*this), LValMaterializer(*this),
+-        SharedMDs(SharedMDs), IsPerformingImport(IsPerformingImport),
++           IRMover::LazyCallback AddLazyFor, bool IsPerformingImport,
++           IRMover::NamedMDNodesT &NamedMDNodes)
++      : DstM(DstM), SrcM(std::move(SrcM)), NamedMDNodes(NamedMDNodes),
++        AddLazyFor(std::move(AddLazyFor)), TypeMap(Set),
++        GValMaterializer(*this), LValMaterializer(*this), SharedMDs(SharedMDs),
++        IsPerformingImport(IsPerformingImport),
+         Mapper(ValueMap, RF_ReuseAndMutateDistinctMDs | RF_IgnoreMissingLocals,
+                &TypeMap, &GValMaterializer),
+         IndirectSymbolMCID(Mapper.registerAlternateMappingContext(
+@@ -1138,7 +1140,7 @@
  
-   // Now that we know the forward -> full mapping of all type indices, we can
-   // re-write all the indices.  At the end of this process, we want a mapping
-diff -ruN --strip-trailing-cr a/lldb/tools/lldb-dap/Handler/ModuleSymbolsRequestHandler.cpp b/lldb/tools/lldb-dap/Handler/ModuleSymbolsRequestHandler.cpp
---- a/lldb/tools/lldb-dap/Handler/ModuleSymbolsRequestHandler.cpp
-+++ b/lldb/tools/lldb-dap/Handler/ModuleSymbolsRequestHandler.cpp
-@@ -60,7 +60,7 @@
-     if (!symbol.IsValid())
-       continue;
+     NamedMDNode *DestNMD = DstM.getOrInsertNamedMetadata(NMD.getName());
  
--    Symbol dap_symbol;
-+    Symbol dap_symbol = {};
-     dap_symbol.id = symbol.GetID();
-     dap_symbol.type = symbol.GetType();
-     dap_symbol.isDebug = symbol.IsDebug();
-diff -ruN --strip-trailing-cr a/lldb/tools/lldb-dap/src-ts/ui/symbols-provider.ts b/lldb/tools/lldb-dap/src-ts/ui/symbols-provider.ts
---- a/lldb/tools/lldb-dap/src-ts/ui/symbols-provider.ts
-+++ b/lldb/tools/lldb-dap/src-ts/ui/symbols-provider.ts
-@@ -61,18 +61,18 @@
-       return;
-     }
- 
--    this.showSymbolsForModule(session, selectedModule.module);
-+    await this.showSymbolsForModule(session, selectedModule.module);
-   }
- 
-   private async showSymbolsForModule(session: vscode.DebugSession, module: DebugProtocol.Module) {
-     try {
-       const symbols = await this.getSymbolsForModule(session, module.id.toString());
--      this.showSymbolsInNewTab(module.name.toString(), symbols);
-+      await this.showSymbolsInNewTab(module.name.toString(), symbols);
-     } catch (error) {
-       if (error instanceof Error) {
--        vscode.window.showErrorMessage("Failed to retrieve symbols: " + error.message);
-+        await vscode.window.showErrorMessage("Failed to retrieve symbols: " + error.message);
+-    auto &Inserted = NamedMDNodes[DestNMD->getName()];
++    auto &Inserted = NamedMDNodes[DestNMD];
+     if (Inserted.empty()) {
+       // Must be the first module, copy everything from DestNMD.
+       Inserted.insert(DestNMD->operands().begin(), DestNMD->operands().end());
+@@ -1683,6 +1685,6 @@
+                     LazyCallback AddLazyFor, bool IsPerformingImport) {
+   IRLinker TheIRLinker(Composite, SharedMDs, IdentifiedStructTypes,
+                        std::move(Src), ValuesToLink, std::move(AddLazyFor),
+-                       IsPerformingImport);
++                       IsPerformingImport, NamedMDNodes);
+   return TheIRLinker.run();
+ }
+diff -ruN --strip-trailing-cr a/llvm/lib/Transforms/Vectorize/SLPVectorizer.cpp b/llvm/lib/Transforms/Vectorize/SLPVectorizer.cpp
+--- a/llvm/lib/Transforms/Vectorize/SLPVectorizer.cpp
++++ b/llvm/lib/Transforms/Vectorize/SLPVectorizer.cpp
+@@ -5574,7 +5574,23 @@
+       if (auto *SD = dyn_cast<ScheduleData>(Data)) {
+         SD->setScheduled(/*Scheduled=*/true);
+         LLVM_DEBUG(dbgs() << "SLP:   schedule " << *SD << "\n");
+-        ProcessBundleMember(SD, {});
++        SmallVector<std::unique_ptr<ScheduleBundle>> PseudoBundles;
++        SmallVector<ScheduleBundle *> Bundles;
++        Instruction *In = SD->getInst();
++        if (R.isVectorized(In)) {
++          ArrayRef<TreeEntry *> Entries = R.getTreeEntries(In);
++          for (TreeEntry *TE : Entries) {
++            if (!isa<ExtractValueInst, ExtractElementInst, CallBase>(In) &&
++                In->getNumOperands() != TE->getNumOperands())
++              continue;
++            auto &BundlePtr =
++                PseudoBundles.emplace_back(std::make_unique<ScheduleBundle>());
++            BundlePtr->setTreeEntry(TE);
++            BundlePtr->add(SD);
++            Bundles.push_back(BundlePtr.get());
++          }
++        }
++        ProcessBundleMember(SD, Bundles);
        } else {
--        vscode.window.showErrorMessage("Failed to retrieve symbols due to an unknown error.");
-+        await vscode.window.showErrorMessage("Failed to retrieve symbols due to an unknown error.");
-       }
-       
-       return;
-@@ -106,7 +106,7 @@
-     const symbolsTableScriptPath = panel.webview.asWebviewUri(vscode.Uri.joinPath(this.getExtensionResourcePath(), "symbols-table-view.js"));
- 
-     panel.webview.html = getSymbolsTableHTMLContent(tabulatorJsPath, tabulatorCssPath, symbolsTableScriptPath);
--    panel.webview.postMessage({ command: "updateSymbols", symbols: symbols });
-+    await panel.webview.postMessage({ command: "updateSymbols", symbols: symbols });
-   }
+         ScheduleBundle &Bundle = *cast<ScheduleBundle>(Data);
+         Bundle.setScheduled(/*Scheduled=*/true);
+@@ -20772,6 +20788,14 @@
+           continue;
+         }
+         auto *SD = cast<ScheduleData>(SE);
++        if (SD->hasValidDependencies() &&
++            (!S.areInstructionsWithCopyableElements() ||
++             !S.isCopyableElement(SD->getInst())) &&
++            !getScheduleCopyableData(SD->getInst()).empty() && EI.UserTE &&
++            EI.UserTE->hasState() &&
++            (!EI.UserTE->hasCopyableElements() ||
++             !EI.UserTE->isCopyableElement(SD->getInst())))
++          SD->clearDirectDependencies();
+         for (const Use &U : SD->getInst()->operands()) {
+           unsigned &NumOps =
+               UserOpToNumOps
+@@ -20853,23 +20877,7 @@
+   for (Value *V : VL) {
+     if (S.isNonSchedulable(V))
+       continue;
+-    // For copybales with parent nodes, which do not need to be scheduled, the
+-    // parents should not be commutative, otherwise may incorrectly handle deps
+-    // because of the potential reordering of commutative operations.
+-    if ((S.isCopyableElement(V) && EI.UserTE && !EI.UserTE->isGather() &&
+-         EI.UserTE->hasState() && EI.UserTE->doesNotNeedToSchedule() &&
+-         any_of(EI.UserTE->Scalars,
+-                [&](Value *V) {
+-                  if (isa<PoisonValue>(V))
+-                    return false;
+-                  auto *I = dyn_cast<Instruction>(V);
+-                  return isCommutative(
+-                      (I && EI.UserTE->isAltShuffle())
+-                          ? EI.UserTE->getMatchingMainOpOrAltOp(I)
+-                          : EI.UserTE->getMainOp(),
+-                      V);
+-                })) ||
+-        !extendSchedulingRegion(V, S)) {
++    if (!extendSchedulingRegion(V, S)) {
+       // If the scheduling region got new instructions at the lower end (or it
+       // is a new region for the first bundle). This makes it necessary to
+       // recalculate all dependencies.
+@@ -21889,6 +21897,10 @@
+     return TryProcessInstruction(BitWidth);
+   case Instruction::ZExt:
+   case Instruction::SExt:
++    if (E.UserTreeIndex.UserTE && E.UserTreeIndex.UserTE->hasState() &&
++        E.UserTreeIndex.UserTE->getOpcode() == Instruction::BitCast &&
++        E.UserTreeIndex.UserTE->getMainOp()->getType()->isFPOrFPVectorTy())
++      return false;
+     IsProfitableToDemote = true;
+     return TryProcessInstruction(BitWidth);
  
-   private getExtensionResourcePath(): vscode.Uri {
-diff -ruN --strip-trailing-cr a/utils/bazel/llvm-project-overlay/clang/BUILD.bazel b/utils/bazel/llvm-project-overlay/clang/BUILD.bazel
---- a/utils/bazel/llvm-project-overlay/clang/BUILD.bazel
-+++ b/utils/bazel/llvm-project-overlay/clang/BUILD.bazel
-@@ -58,6 +58,7 @@
-         "Refactoring",
-         "Sema",
-         "Serialization",
-+        "Trap",
-     ] for out in [
-         (
-             "include/clang/Basic/Diagnostic%sKinds.inc" % c,
-diff -ruN --strip-trailing-cr a/utils/bazel/llvm-project-overlay/mlir/BUILD.bazel b/utils/bazel/llvm-project-overlay/mlir/BUILD.bazel
---- a/utils/bazel/llvm-project-overlay/mlir/BUILD.bazel
-+++ b/utils/bazel/llvm-project-overlay/mlir/BUILD.bazel
-@@ -4167,6 +4167,7 @@
-         ":VectorToSCF",
-         ":VectorToSPIRV",
-         ":VectorToXeGPU",
-+        ":XeGPUToXeVM",
-         ":XeVMToLLVM",
-     ],
+diff -ruN --strip-trailing-cr a/llvm/test/Transforms/SLPVectorizer/X86/copyable-with-non-scheduled-parent-node.ll b/llvm/test/Transforms/SLPVectorizer/X86/copyable-with-non-scheduled-parent-node.ll
+--- a/llvm/test/Transforms/SLPVectorizer/X86/copyable-with-non-scheduled-parent-node.ll
++++ b/llvm/test/Transforms/SLPVectorizer/X86/copyable-with-non-scheduled-parent-node.ll
+@@ -4,20 +4,15 @@
+ define i64 @test(ptr %a) {
+ ; CHECK-LABEL: define i64 @test(
+ ; CHECK-SAME: ptr [[A:%.*]]) #[[ATTR0:[0-9]+]] {
+-; CHECK-NEXT:    [[TMP1:%.*]] = add i64 0, 0
+ ; CHECK-NEXT:    [[TMP2:%.*]] = load i64, ptr [[A]], align 4
+-; CHECK-NEXT:    [[TMP3:%.*]] = add i64 [[TMP2]], 0
+-; CHECK-NEXT:    [[TMP4:%.*]] = add i64 1, [[TMP1]]
+-; CHECK-NEXT:    [[TMP5:%.*]] = ashr i64 0, 1
+-; CHECK-NEXT:    [[TMP6:%.*]] = ashr i64 0, 0
++; CHECK-NEXT:    [[TMP7:%.*]] = insertelement <4 x i64> <i64 poison, i64 0, i64 0, i64 0>, i64 [[TMP2]], i32 0
++; CHECK-NEXT:    [[TMP3:%.*]] = add <4 x i64> zeroinitializer, [[TMP7]]
++; CHECK-NEXT:    [[TMP4:%.*]] = add <4 x i64> <i64 0, i64 0, i64 0, i64 1>, [[TMP3]]
++; CHECK-NEXT:    [[TMP5:%.*]] = shufflevector <4 x i64> [[TMP4]], <4 x i64> poison, <6 x i32> <i32 0, i32 1, i32 2, i32 3, i32 poison, i32 poison>
++; CHECK-NEXT:    [[TMP6:%.*]] = shufflevector <6 x i64> [[TMP5]], <6 x i64> <i64 0, i64 0, i64 undef, i64 undef, i64 undef, i64 undef>, <6 x i32> <i32 0, i32 1, i32 2, i32 3, i32 6, i32 7>
+ ; CHECK-NEXT:    br label %[[BB7:.*]]
+ ; CHECK:       [[BB7]]:
+-; CHECK-NEXT:    [[TMP8:%.*]] = phi i64 [ [[TMP3]], [[TMP0:%.*]] ]
+-; CHECK-NEXT:    [[TMP9:%.*]] = phi i64 [ 0, [[TMP0]] ]
+-; CHECK-NEXT:    [[TMP10:%.*]] = phi i64 [ [[TMP6]], [[TMP0]] ]
+-; CHECK-NEXT:    [[TMP11:%.*]] = phi i64 [ [[TMP5]], [[TMP0]] ]
+-; CHECK-NEXT:    [[TMP12:%.*]] = phi i64 [ 0, [[TMP0]] ]
+-; CHECK-NEXT:    [[TMP13:%.*]] = phi i64 [ [[TMP4]], [[TMP0]] ]
++; CHECK-NEXT:    [[TMP8:%.*]] = phi <6 x i64> [ [[TMP6]], [[TMP0:%.*]] ]
+ ; CHECK-NEXT:    ret i64 0
+ ;
+   %1 = add i64 0, 0
+diff -ruN --strip-trailing-cr a/llvm/test/Transforms/SLPVectorizer/X86/original-inst-scheduled-after-copyable.ll b/llvm/test/Transforms/SLPVectorizer/X86/original-inst-scheduled-after-copyable.ll
+--- a/llvm/test/Transforms/SLPVectorizer/X86/original-inst-scheduled-after-copyable.ll
++++ b/llvm/test/Transforms/SLPVectorizer/X86/original-inst-scheduled-after-copyable.ll
+@@ -0,0 +1,89 @@
++; NOTE: Assertions have been autogenerated by utils/update_test_checks.py UTC_ARGS: --version 5
++; RUN: opt -S --passes=slp-vectorizer -mtriple=x86_64-unknown-linux-gnu -slp-threshold=-10 < %s | FileCheck %s
++
++define void @test(ptr %0, i32 %1, i32 %2) {
++; CHECK-LABEL: define void @test(
++; CHECK-SAME: ptr [[TMP0:%.*]], i32 [[TMP1:%.*]], i32 [[TMP2:%.*]]) {
++; CHECK-NEXT:  [[ENTRY:.*:]]
++; CHECK-NEXT:    [[TMP3:%.*]] = getelementptr i8, ptr [[TMP0]], i64 48
++; CHECK-NEXT:    [[TMP5:%.*]] = getelementptr i8, ptr [[TMP0]], i64 56
++; CHECK-NEXT:    [[TMP7:%.*]] = and i32 [[TMP2]], [[TMP1]]
++; CHECK-NEXT:    [[ADD_NARROWED_I_I:%.*]] = shl i32 [[TMP1]], 1
++; CHECK-NEXT:    [[TMP10:%.*]] = lshr i32 [[TMP7]], 1
++; CHECK-NEXT:    [[TMP18:%.*]] = zext i32 [[ADD_NARROWED_I_I]] to i64
++; CHECK-NEXT:    [[TMP19:%.*]] = add i64 [[TMP18]], -1
++; CHECK-NEXT:    [[TMP21:%.*]] = trunc i64 [[TMP19]] to i32
++; CHECK-NEXT:    [[TMP28:%.*]] = insertelement <2 x i32> poison, i32 [[TMP21]], i32 0
++; CHECK-NEXT:    [[TMP11:%.*]] = shufflevector <2 x i32> [[TMP28]], <2 x i32> poison, <2 x i32> zeroinitializer
++; CHECK-NEXT:    [[TMP12:%.*]] = and <2 x i32> [[TMP11]], splat (i32 -2)
++; CHECK-NEXT:    [[TMP13:%.*]] = insertelement <2 x i32> <i32 poison, i32 -2>, i32 [[TMP1]], i32 0
++; CHECK-NEXT:    [[TMP14:%.*]] = or <2 x i32> [[TMP13]], [[TMP12]]
++; CHECK-NEXT:    [[TMP15:%.*]] = xor <2 x i32> [[TMP13]], [[TMP12]]
++; CHECK-NEXT:    [[TMP16:%.*]] = shufflevector <2 x i32> [[TMP14]], <2 x i32> [[TMP15]], <2 x i32> <i32 0, i32 3>
++; CHECK-NEXT:    [[TMP17:%.*]] = load <2 x i32>, ptr [[TMP5]], align 8
++; CHECK-NEXT:    [[TMP32:%.*]] = insertelement <2 x i32> <i32 1, i32 poison>, i32 [[TMP1]], i32 1
++; CHECK-NEXT:    [[TMP33:%.*]] = and <2 x i32> [[TMP17]], [[TMP32]]
++; CHECK-NEXT:    call void @llvm.stackrestore.p0(ptr null)
++; CHECK-NEXT:    [[TMP20:%.*]] = shufflevector <2 x i32> [[TMP33]], <2 x i32> poison, <2 x i32> <i32 poison, i32 0>
++; CHECK-NEXT:    [[TMP34:%.*]] = insertelement <2 x i32> [[TMP20]], i32 [[TMP10]], i32 0
++; CHECK-NEXT:    [[TMP22:%.*]] = zext <2 x i32> [[TMP34]] to <2 x i64>
++; CHECK-NEXT:    [[TMP23:%.*]] = zext <2 x i32> [[TMP33]] to <2 x i64>
++; CHECK-NEXT:    [[TMP35:%.*]] = shl <2 x i64> [[TMP23]], splat (i64 1)
++; CHECK-NEXT:    [[TMP25:%.*]] = or <2 x i64> [[TMP35]], [[TMP22]]
++; CHECK-NEXT:    [[TMP26:%.*]] = trunc <2 x i64> [[TMP25]] to <2 x i32>
++; CHECK-NEXT:    [[TMP27:%.*]] = trunc <2 x i64> [[TMP25]] to <2 x i32>
++; CHECK-NEXT:    [[TMP24:%.*]] = tail call i32 asm sideeffect "", "=r,0,~{dirflag},~{fpsr},~{flags}"(i32 0)
++; CHECK-NEXT:    store <2 x i32> [[TMP16]], ptr [[TMP3]], align 16
++; CHECK-NEXT:    [[TMP29:%.*]] = shufflevector <2 x i32> [[TMP32]], <2 x i32> poison, <2 x i32> <i32 1, i32 1>
++; CHECK-NEXT:    [[TMP30:%.*]] = and <2 x i32> [[TMP29]], [[TMP26]]
++; CHECK-NEXT:    [[TMP31:%.*]] = or <2 x i32> [[TMP30]], [[TMP27]]
++; CHECK-NEXT:    store <2 x i32> [[TMP31]], ptr [[TMP5]], align 8
++; CHECK-NEXT:    ret void
++;
++entry:
++  %3 = getelementptr i8, ptr %0, i64 48
++  %4 = getelementptr i8, ptr %0, i64 52
++  %5 = getelementptr i8, ptr %0, i64 56
++  %6 = getelementptr i8, ptr %0, i64 60
++  %.pre21.i = load i32, ptr %5, align 8
++  %.pre23.i = load i32, ptr %6, align 4
++  %7 = and i32 %2, %1
++  %8 = and i32 %.pre21.i, 1
++  %9 = and i32 %1, %.pre23.i
++  call void @llvm.stackrestore.p0(ptr null)
++  %add.narrowed.i.i = shl i32 %1, 1
++  %10 = lshr i32 %7, 1
++  %11 = zext i32 %10 to i64
++  %12 = zext i32 %8 to i64
++  %reass.add1.i = shl i64 %12, 1
++  %13 = or i64 %reass.add1.i, %11
++  %14 = trunc i64 %13 to i32
++  %15 = zext i32 %9 to i64
++  %reass.add2.i = shl i64 %15, 1
++  %16 = or i64 %reass.add2.i, %12
++  %17 = trunc i64 %16 to i32
++  %18 = zext i32 %add.narrowed.i.i to i64
++  %19 = add i64 %18, -1
++  %20 = trunc i64 %19 to i32
++  %21 = trunc i64 %19 to i32
++  %22 = trunc i64 %13 to i32
++  %23 = trunc i64 %16 to i32
++  %24 = tail call i32 asm sideeffect "", "=r,0,~{dirflag},~{fpsr},~{flags}"(i32 0)
++  %25 = and i32 %20, -2
++  %26 = or i32 %1, %25
++  store i32 %26, ptr %3, align 16
++  %27 = and i32 %21, -2
++  %28 = xor i32 %27, -2
++  store i32 %28, ptr %4, align 4
++  %29 = and i32 %1, %14
++  %30 = or i32 %29, %22
++  store i32 %30, ptr %5, align 8
++  %31 = and i32 %1, %17
++  %32 = or i32 %31, %23
++  store i32 %32, ptr %6, align 4
++  ret void
++}
++
++declare void @llvm.stackrestore.p0(ptr) #0
++
++attributes #0 = { nocallback nofree nosync nounwind willreturn }
+diff -ruN --strip-trailing-cr a/llvm/test/Transforms/SLPVectorizer/X86/parent-bitcast-with-fp.ll b/llvm/test/Transforms/SLPVectorizer/X86/parent-bitcast-with-fp.ll
+--- a/llvm/test/Transforms/SLPVectorizer/X86/parent-bitcast-with-fp.ll
++++ b/llvm/test/Transforms/SLPVectorizer/X86/parent-bitcast-with-fp.ll
+@@ -0,0 +1,36 @@
++; NOTE: Assertions have been autogenerated by utils/update_test_checks.py UTC_ARGS: --version 5
++; RUN: opt -S --passes=slp-vectorizer -mtriple=x86_64-unknown-linux-gnu < %s | FileCheck %s
++
++define i1 @test(i32 %0) {
++; CHECK-LABEL: define i1 @test(
++; CHECK-SAME: i32 [[TMP0:%.*]]) {
++; CHECK-NEXT:  [[ENTRY:.*:]]
++; CHECK-NEXT:    [[CONV22_I_I:%.*]] = sext i32 [[TMP0]] to i64
++; CHECK-NEXT:    [[TMP1:%.*]] = bitcast i64 [[CONV22_I_I]] to double
++; CHECK-NEXT:    [[TMP2:%.*]] = fadd double [[TMP1]], 0.000000e+00
++; CHECK-NEXT:    [[ADD_I_I_I:%.*]] = select i1 false, double 0.000000e+00, double [[TMP2]]
++; CHECK-NEXT:    [[TMP3:%.*]] = bitcast double [[ADD_I_I_I]] to i64
++; CHECK-NEXT:    [[CMP3998_I_I:%.*]] = icmp ne i64 [[TMP3]], [[CONV22_I_I]]
++; CHECK-NEXT:    [[CONV22_1_I_I:%.*]] = sext i32 0 to i64
++; CHECK-NEXT:    [[TMP4:%.*]] = bitcast i64 [[CONV22_1_I_I]] to double
++; CHECK-NEXT:    [[TMP5:%.*]] = fadd double [[TMP4]], 0.000000e+00
++; CHECK-NEXT:    [[ADD_I_1_I_I:%.*]] = select i1 false, double 0.000000e+00, double [[TMP5]]
++; CHECK-NEXT:    [[TMP6:%.*]] = bitcast double [[ADD_I_1_I_I]] to i64
++; CHECK-NEXT:    [[CMP3998_1_I_I:%.*]] = icmp ne i64 [[TMP6]], [[CONV22_1_I_I]]
++; CHECK-NEXT:    ret i1 [[CMP3998_1_I_I]]
++;
++entry:
++  %conv22.i.i = sext i32 %0 to i64
++  %1 = bitcast i64 %conv22.i.i to double
++  %2 = fadd double %1, 0.000000e+00
++  %add.i.i.i = select i1 false, double 0.000000e+00, double %2
++  %3 = bitcast double %add.i.i.i to i64
++  %cmp3998.i.i = icmp ne i64 %3, %conv22.i.i
++  %conv22.1.i.i = sext i32 0 to i64
++  %4 = bitcast i64 %conv22.1.i.i to double
++  %5 = fadd double %4, 0.000000e+00
++  %add.i.1.i.i = select i1 false, double 0.000000e+00, double %5
++  %6 = bitcast double %add.i.1.i.i to i64
++  %cmp3998.1.i.i = icmp ne i64 %6, %conv22.1.i.i
++  ret i1 %cmp3998.1.i.i
++}
+diff -ruN --strip-trailing-cr a/llvm/test/Transforms/SLPVectorizer/X86/parent-node-non-schedulable.ll b/llvm/test/Transforms/SLPVectorizer/X86/parent-node-non-schedulable.ll
+--- a/llvm/test/Transforms/SLPVectorizer/X86/parent-node-non-schedulable.ll
++++ b/llvm/test/Transforms/SLPVectorizer/X86/parent-node-non-schedulable.ll
+@@ -0,0 +1,172 @@
++; NOTE: Assertions have been autogenerated by utils/update_test_checks.py UTC_ARGS: --version 5
++; RUN: opt -S --passes=slp-vectorizer -S -mtriple=i686-unknown-linux-android29 -mattr=+sse2 < %s | FileCheck %s
++
++define void @test(ptr %0, i64 %1, i64 %2, i1 %3, i64 %4, i64 %5) {
++; CHECK-LABEL: define void @test(
++; CHECK-SAME: ptr [[TMP0:%.*]], i64 [[TMP1:%.*]], i64 [[TMP2:%.*]], i1 [[TMP3:%.*]], i64 [[TMP4:%.*]], i64 [[TMP5:%.*]]) #[[ATTR0:[0-9]+]] {
++; CHECK-NEXT:    [[TMP7:%.*]] = getelementptr i8, ptr [[TMP0]], i32 240
++; CHECK-NEXT:    [[TMP8:%.*]] = getelementptr i8, ptr [[TMP0]], i32 128
++; CHECK-NEXT:    [[TMP9:%.*]] = insertelement <4 x i64> poison, i64 [[TMP1]], i32 0
++; CHECK-NEXT:    [[TMP10:%.*]] = shufflevector <4 x i64> [[TMP9]], <4 x i64> poison, <4 x i32> zeroinitializer
++; CHECK-NEXT:    [[TMP11:%.*]] = insertelement <4 x i64> <i64 1, i64 1, i64 1, i64 poison>, i64 [[TMP2]], i32 3
++; CHECK-NEXT:    [[TMP12:%.*]] = add <4 x i64> [[TMP10]], [[TMP11]]
++; CHECK-NEXT:    [[TMP13:%.*]] = load <2 x i64>, ptr [[TMP7]], align 4
++; CHECK-NEXT:    [[TMP14:%.*]] = load i64, ptr null, align 4
++; CHECK-NEXT:    [[TMP15:%.*]] = load <2 x i64>, ptr [[TMP8]], align 4
++; CHECK-NEXT:    [[TMP16:%.*]] = shufflevector <2 x i64> [[TMP13]], <2 x i64> [[TMP15]], <6 x i32> <i32 0, i32 1, i32 poison, i32 3, i32 2, i32 2>
++; CHECK-NEXT:    [[TMP17:%.*]] = insertelement <6 x i64> poison, i64 [[TMP14]], i32 0
++; CHECK-NEXT:    [[TMP18:%.*]] = shufflevector <6 x i64> [[TMP17]], <6 x i64> poison, <6 x i32> <i32 poison, i32 poison, i32 0, i32 poison, i32 poison, i32 poison>
++; CHECK-NEXT:    [[TMP19:%.*]] = shufflevector <6 x i64> [[TMP16]], <6 x i64> [[TMP18]], <6 x i32> <i32 0, i32 1, i32 8, i32 3, i32 4, i32 5>
++; CHECK-NEXT:    [[TMP20:%.*]] = shufflevector <4 x i64> [[TMP10]], <4 x i64> poison, <6 x i32> <i32 0, i32 1, i32 2, i32 3, i32 poison, i32 0>
++; CHECK-NEXT:    [[TMP21:%.*]] = shufflevector <6 x i64> [[TMP20]], <6 x i64> <i64 0, i64 0, i64 0, i64 0, i64 0, i64 poison>, <6 x i32> <i32 6, i32 7, i32 8, i32 9, i32 10, i32 0>
++; CHECK-NEXT:    [[TMP22:%.*]] = add <6 x i64> [[TMP19]], [[TMP21]]
++; CHECK-NEXT:    [[TMP23:%.*]] = shufflevector <2 x i64> [[TMP13]], <2 x i64> poison, <4 x i32> <i32 0, i32 1, i32 0, i32 1>
++; CHECK-NEXT:    [[TMP24:%.*]] = shufflevector <4 x i64> [[TMP10]], <4 x i64> [[TMP23]], <4 x i32> <i32 0, i32 1, i32 4, i32 5>
++; CHECK-NEXT:    [[TMP25:%.*]] = sub <4 x i64> zeroinitializer, [[TMP24]]
++; CHECK-NEXT:    [[TMP26:%.*]] = sub <6 x i64> zeroinitializer, [[TMP22]]
++; CHECK-NEXT:    [[TMP27:%.*]] = shufflevector <6 x i64> [[TMP19]], <6 x i64> poison, <2 x i32> <i32 2, i32 2>
++; CHECK-NEXT:    [[TMP28:%.*]] = add <2 x i64> [[TMP27]], splat (i64 1)
++; CHECK-NEXT:    [[TMP29:%.*]] = ashr <2 x i64> [[TMP28]], splat (i64 14)
++; CHECK-NEXT:    [[TMP30:%.*]] = shufflevector <6 x i64> [[TMP26]], <6 x i64> poison, <14 x i32> <i32 poison, i32 poison, i32 poison, i32 poison, i32 poison, i32 poison, i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 poison, i32 poison>
++; CHECK-NEXT:    [[TMP31:%.*]] = shufflevector <4 x i64> [[TMP12]], <4 x i64> poison, <14 x i32> <i32 0, i32 1, i32 2, i32 3, i32 poison, i32 poison, i32 poison, i32 poison, i32 poison, i32 poison, i32 poison, i32 poison, i32 poison, i32 poison>
++; CHECK-NEXT:    [[TMP32:%.*]] = shufflevector <14 x i64> [[TMP30]], <14 x i64> [[TMP31]], <14 x i32> <i32 14, i32 15, i32 16, i32 17, i32 poison, i32 poison, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 poison, i32 poison>
++; CHECK-NEXT:    [[TMP33:%.*]] = shufflevector <4 x i64> [[TMP25]], <4 x i64> poison, <14 x i32> <i32 0, i32 1, i32 2, i32 3, i32 poison, i32 poison, i32 poison, i32 poison, i32 poison, i32 poison, i32 poison, i32 poison, i32 poison, i32 poison>
++; CHECK-NEXT:    [[TMP34:%.*]] = shufflevector <14 x i64> [[TMP32]], <14 x i64> [[TMP33]], <14 x i32> <i32 0, i32 1, i32 2, i32 3, i32 14, i32 15, i32 16, i32 17, i32 8, i32 9, i32 10, i32 11, i32 poison, i32 poison>
++; CHECK-NEXT:    [[TMP35:%.*]] = shufflevector <2 x i64> [[TMP29]], <2 x i64> poison, <14 x i32> <i32 0, i32 1, i32 poison, i32 poison, i32 poison, i32 poison, i32 poison, i32 poison, i32 poison, i32 poison, i32 poison, i32 poison, i32 poison, i32 poison>
++; CHECK-NEXT:    [[TMP36:%.*]] = shufflevector <14 x i64> [[TMP34]], <14 x i64> [[TMP35]], <14 x i32> <i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 14, i32 15>
++; CHECK-NEXT:    br i1 [[TMP3]], label %[[BB52:.*]], label %[[BB37:.*]]
++; CHECK:       [[BB37]]:
++; CHECK-NEXT:    [[TMP38:%.*]] = add <4 x i64> [[TMP10]], splat (i64 1)
++; CHECK-NEXT:    [[TMP39:%.*]] = shufflevector <4 x i64> [[TMP10]], <4 x i64> poison, <2 x i32> zeroinitializer
++; CHECK-NEXT:    [[TMP40:%.*]] = add <2 x i64> [[TMP39]], splat (i64 1)
++; CHECK-NEXT:    [[TMP41:%.*]] = lshr <2 x i64> [[TMP39]], splat (i64 1)
++; CHECK-NEXT:    [[TMP42:%.*]] = add <2 x i64> [[TMP40]], [[TMP41]]
++; CHECK-NEXT:    [[TMP43:%.*]] = shufflevector <4 x i64> [[TMP10]], <4 x i64> [[TMP11]], <10 x i32> <i32 0, i32 7, i32 poison, i32 poison, i32 poison, i32 poison, i32 poison, i32 poison, i32 poison, i32 poison>
++; CHECK-NEXT:    [[TMP44:%.*]] = insertelement <10 x i64> [[TMP43]], i64 [[TMP4]], i32 6
++; CHECK-NEXT:    [[TMP45:%.*]] = insertelement <10 x i64> [[TMP44]], i64 [[TMP5]], i32 7
++; CHECK-NEXT:    [[TMP46:%.*]] = shufflevector <4 x i64> [[TMP38]], <4 x i64> poison, <10 x i32> <i32 poison, i32 poison, i32 poison, i32 poison, i32 0, i32 1, i32 2, i32 3, i32 poison, i32 poison>
++; CHECK-NEXT:    [[TMP47:%.*]] = shufflevector <2 x i64> [[TMP42]], <2 x i64> poison, <10 x i32> <i32 0, i32 1, i32 poison, i32 poison, i32 poison, i32 poison, i32 poison, i32 poison, i32 poison, i32 poison>
++; CHECK-NEXT:    [[TMP48:%.*]] = shufflevector <10 x i64> [[TMP46]], <10 x i64> [[TMP47]], <10 x i32> <i32 poison, i32 poison, i32 poison, i32 poison, i32 4, i32 5, i32 6, i32 7, i32 10, i32 11>
++; CHECK-NEXT:    [[TMP49:%.*]] = shufflevector <10 x i64> [[TMP48]], <10 x i64> [[TMP45]], <10 x i32> <i32 10, i32 11, i32 4, i32 5, i32 6, i32 7, i32 16, i32 17, i32 8, i32 9>
++; CHECK-NEXT:    [[TMP50:%.*]] = shufflevector <10 x i64> [[TMP49]], <10 x i64> poison, <14 x i32> <i32 0, i32 1, i32 0, i32 2, i32 0, i32 3, i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 0, i32 0>
++; CHECK-NEXT:    [[TMP51:%.*]] = ashr <14 x i64> [[TMP50]], splat (i64 2)
++; CHECK-NEXT:    br label %[[BB52]]
++; CHECK:       [[BB52]]:
++; CHECK-NEXT:    [[TMP53:%.*]] = phi <14 x i64> [ [[TMP51]], %[[BB37]] ], [ [[TMP36]], [[TMP6:%.*]] ]
++; CHECK-NEXT:    [[TMP54:%.*]] = extractelement <14 x i64> [[TMP53]], i32 0
++; CHECK-NEXT:    [[TMP55:%.*]] = extractelement <14 x i64> [[TMP53]], i32 13
++; CHECK-NEXT:    [[TMP56:%.*]] = or i64 [[TMP54]], [[TMP55]]
++; CHECK-NEXT:    [[TMP57:%.*]] = extractelement <14 x i64> [[TMP53]], i32 4
++; CHECK-NEXT:    [[TMP58:%.*]] = extractelement <14 x i64> [[TMP53]], i32 12
++; CHECK-NEXT:    [[TMP59:%.*]] = or i64 [[TMP57]], [[TMP58]]
++; CHECK-NEXT:    [[TMP60:%.*]] = extractelement <14 x i64> [[TMP53]], i32 1
++; CHECK-NEXT:    [[TMP61:%.*]] = extractelement <14 x i64> [[TMP53]], i32 2
++; CHECK-NEXT:    [[TMP62:%.*]] = or i64 [[TMP60]], [[TMP61]]
++; CHECK-NEXT:    [[TMP63:%.*]] = or i64 [[TMP59]], [[TMP56]]
++; CHECK-NEXT:    [[TMP64:%.*]] = extractelement <14 x i64> [[TMP53]], i32 5
++; CHECK-NEXT:    [[TMP65:%.*]] = extractelement <14 x i64> [[TMP53]], i32 8
++; CHECK-NEXT:    [[TMP66:%.*]] = or i64 [[TMP64]], [[TMP65]]
++; CHECK-NEXT:    [[TMP67:%.*]] = extractelement <14 x i64> [[TMP53]], i32 3
++; CHECK-NEXT:    [[TMP68:%.*]] = or i64 [[TMP67]], [[TMP62]]
++; CHECK-NEXT:    [[TMP69:%.*]] = extractelement <14 x i64> [[TMP53]], i32 9
++; CHECK-NEXT:    [[TMP70:%.*]] = or i64 [[TMP69]], [[TMP66]]
++; CHECK-NEXT:    [[TMP71:%.*]] = extractelement <14 x i64> [[TMP53]], i32 6
++; CHECK-NEXT:    [[TMP72:%.*]] = or i64 [[TMP71]], [[TMP70]]
++; CHECK-NEXT:    [[TMP73:%.*]] = or i64 [[TMP63]], [[TMP72]]
++; CHECK-NEXT:    [[TMP74:%.*]] = extractelement <14 x i64> [[TMP53]], i32 10
++; CHECK-NEXT:    [[TMP75:%.*]] = or i64 [[TMP74]], [[TMP73]]
++; CHECK-NEXT:    store i64 [[TMP68]], ptr [[TMP0]], align 4
++; CHECK-NEXT:    [[TMP76:%.*]] = extractelement <14 x i64> [[TMP53]], i32 11
++; CHECK-NEXT:    store i64 [[TMP76]], ptr null, align 4
++; CHECK-NEXT:    [[TMP77:%.*]] = extractelement <14 x i64> [[TMP53]], i32 7
++; CHECK-NEXT:    store i64 [[TMP77]], ptr [[TMP0]], align 4
++; CHECK-NEXT:    store i64 [[TMP75]], ptr null, align 4
++; CHECK-NEXT:    ret void
++;
++  %7 = getelementptr i8, ptr %0, i32 248
++  %8 = load i64, ptr %7, align 4
++  %9 = getelementptr i8, ptr %0, i32 240
++  %10 = load i64, ptr %9, align 4
++  %11 = load i64, ptr null, align 4
++  %12 = add i64 %1, 1
++  %13 = add i64 %1, 1
++  %14 = add i64 %1, %2
++  %15 = getelementptr i8, ptr %0, i32 136
++  %16 = load i64, ptr %15, align 4
++  %17 = getelementptr i8, ptr %0, i32 128
++  %18 = load i64, ptr %17, align 4
++  %19 = add i64 %18, %1
++  %20 = sub i64 0, %18
++  %21 = sub i64 0, %16
++  %22 = sub i64 0, %11
++  %23 = add i64 %1, 1
++  %24 = sub i64 0, %1
++  %25 = sub i64 0, %1
++  %26 = sub i64 0, %10
++  %27 = sub i64 0, %8
++  %28 = sub i64 0, %19
++  %29 = add i64 %11, 1
++  %30 = ashr i64 %29, 14
++  %31 = add i64 %11, 1
++  %32 = ashr i64 %31, 14
++  br i1 %3, label %58, label %33
++
++33:
++  %34 = ashr i64 %2, 2
++  %35 = ashr i64 %1, 2
++  %36 = add i64 %1, 1
++  %37 = ashr i64 %36, 2
++  %38 = add i64 %1, 1
++  %39 = lshr i64 %1, 1
++  %40 = add i64 %38, %39
++  %41 = ashr i64 %40, 2
++  %42 = add i64 %1, 1
++  %43 = lshr i64 %1, 1
++  %44 = add i64 %42, %43
++  %45 = ashr i64 %44, 2
++  %46 = ashr i64 %5, 2
++  %47 = ashr i64 %4, 2
++  %48 = ashr i64 %1, 2
++  %49 = ashr i64 %1, 2
++  %50 = ashr i64 %1, 2
++  %51 = ashr i64 %1, 2
++  %52 = add i64 %1, 1
++  %53 = ashr i64 %52, 2
++  %54 = add i64 %1, 1
++  %55 = ashr i64 %54, 2
++  %56 = add i64 %1, 1
++  %57 = ashr i64 %56, 2
++  br label %58
++
++58:
++  %59 = phi i64 [ %51, %33 ], [ %24, %6 ]
++  %60 = phi i64 [ %50, %33 ], [ %32, %6 ]
++  %61 = phi i64 [ %53, %33 ], [ %25, %6 ]
++  %62 = phi i64 [ %55, %33 ], [ %26, %6 ]
++  %63 = phi i64 [ %57, %33 ], [ %27, %6 ]
++  %64 = phi i64 [ %49, %33 ], [ %30, %6 ]
++  %65 = phi i64 [ %48, %33 ], [ %23, %6 ]
++  %66 = phi i64 [ %47, %33 ], [ %22, %6 ]
++  %67 = phi i64 [ %46, %33 ], [ %21, %6 ]
++  %68 = phi i64 [ %45, %33 ], [ %20, %6 ]
++  %69 = phi i64 [ %41, %33 ], [ %28, %6 ]
++  %70 = phi i64 [ %34, %33 ], [ %12, %6 ]
++  %71 = phi i64 [ %35, %33 ], [ %13, %6 ]
++  %72 = phi i64 [ %37, %33 ], [ %14, %6 ]
++  %73 = or i64 %65, %64
++  %74 = or i64 %59, %60
++  %75 = or i64 %70, %71
++  %76 = or i64 %74, %73
++  %77 = or i64 %61, %66
++  %78 = or i64 %72, %75
++  %79 = or i64 %67, %77
++  %80 = or i64 %62, %79
++  %81 = or i64 %76, %80
++  %82 = or i64 %68, %81
++  store i64 %78, ptr %0, align 4
++  store i64 %69, ptr null, align 4
++  store i64 %63, ptr %0, align 4
++  store i64 %82, ptr null, align 4
++  ret void
++}
++
+diff -ruN --strip-trailing-cr a/utils/bazel/llvm-project-overlay/libc/BUILD.bazel b/utils/bazel/llvm-project-overlay/libc/BUILD.bazel
+--- a/utils/bazel/llvm-project-overlay/libc/BUILD.bazel
++++ b/utils/bazel/llvm-project-overlay/libc/BUILD.bazel
+@@ -3749,6 +3749,14 @@
  )
-@@ -13945,6 +13946,37 @@
+ 
+ libc_math_function(
++    name = "fmodbf16",
++    additional_deps = [
++        ":__support_fputil_bfloat16",
++        ":__support_fputil_generic_fmod",
++    ],
++)
++
++libc_math_function(
+     name = "fmodf",
+     additional_deps = [
+         ":__support_fputil_generic_fmod",
+diff -ruN --strip-trailing-cr a/utils/bazel/llvm-project-overlay/libc/test/src/math/smoke/BUILD.bazel b/utils/bazel/llvm-project-overlay/libc/test/src/math/smoke/BUILD.bazel
+--- a/utils/bazel/llvm-project-overlay/libc/test/src/math/smoke/BUILD.bazel
++++ b/utils/bazel/llvm-project-overlay/libc/test/src/math/smoke/BUILD.bazel
+@@ -739,6 +739,16 @@
  )
  
- cc_library(
-+    name = "XeGPUToXeVM",
-+    srcs = glob([
-+        "lib/Conversion/XeGPUToXeVM/*.cpp",
-+    ]),
-+    hdrs = glob([
-+        "include/mlir/Conversion/XeGPUToXeVM/*.h",
-+    ]),
-+    includes = ["include"],
+ math_test(
++    name = "fmodbf16",
++    hdrs = [
++        "FModTest.h",
++    ],
 +    deps = [
-+        ":ArithDialect",
-+        ":ConversionPassIncGen",
-+        ":ConvertToLLVMInterface",
-+        ":GPUDialect",
-+        ":IR",
-+        ":IndexDialect",
-+        ":LLVMCommonConversion",
-+        ":LLVMDialect",
-+        ":MemRefDialect",
-+        ":Pass",
-+        ":SCFDialect",
-+        ":SCFTransforms",
-+        ":Support",
-+        ":TransformUtils",
-+        ":VectorDialect",
-+        ":XeGPUDialect",
-+        ":XeVMDialect",
-+        "//llvm:Support",
++        "//libc:__support_fputil_bfloat16",
 +    ],
 +)
 +
-+cc_library(
-     name = "XeVMToLLVM",
-     srcs = glob([
-         "lib/Conversion/XeVMToLLVM/*.cpp",
++math_test(
+     name = "fmodf",
+     hdrs = ["FModTest.h"],
+ )
+diff -ruN --strip-trailing-cr a/utils/bazel/llvm-project-overlay/llvm/BUILD.bazel b/utils/bazel/llvm-project-overlay/llvm/BUILD.bazel
+--- a/utils/bazel/llvm-project-overlay/llvm/BUILD.bazel
++++ b/utils/bazel/llvm-project-overlay/llvm/BUILD.bazel
+@@ -2223,7 +2223,6 @@
+             "lib/Target/AArch64/AArch64GenDisassemblerTables.inc": [
+                 "-gen-disassembler",
+                 "-ignore-non-decodable-operands",
+-                "-ignore-fully-defined-operands",
+             ],
+             "lib/Target/AArch64/AArch64GenSystemOperands.inc": ["-gen-searchable-tables"],
+             "lib/Target/AArch64/AArch64GenExegesis.inc": ["-gen-exegesis"],
diff --git a/third_party/llvm/workspace.bzl b/third_party/llvm/workspace.bzl
index 983f65d..f671196 100644
--- a/third_party/llvm/workspace.bzl
+++ b/third_party/llvm/workspace.bzl
@@ -4,8 +4,8 @@ load("//third_party:repo.bzl", "tf_http_archive")
 
 def repo(name):
     """Imports LLVM."""
-    LLVM_COMMIT = "5bca8f2f97d23c3562544e959702826eb20696af"
-    LLVM_SHA256 = "d0e5d52ce939c396f3fa8533d7a1f911ed059e072d4797e3f9cb15043a6fd113"
+    LLVM_COMMIT = "a1de9aca1150bd749a3cdad1d1e26eb6a8855fe2"
+    LLVM_SHA256 = "4b99bf2c212bcd27ac90315f6d8ce82f2d0aeaea257c9b49ddf29ef7a1bba175"
 
     tf_http_archive(
         name = name,
diff --git a/third_party/stablehlo/temporary.patch b/third_party/stablehlo/temporary.patch
index 3079fad..a8075e2 100755
--- a/third_party/stablehlo/temporary.patch
+++ b/third_party/stablehlo/temporary.patch
@@ -1,3 +1,168 @@
+diff --ruN a/stablehlo/stablehlo/conversions/tosa/tests/legalize_quant_ops_to_tosa_rescale.mlir b/stablehlo/stablehlo/conversions/tosa/tests/legalize_quant_ops_to_tosa_rescale.mlir
+--- stablehlo/stablehlo/conversions/tosa/tests/legalize_quant_ops_to_tosa_rescale.mlir
++++ stablehlo/stablehlo/conversions/tosa/tests/legalize_quant_ops_to_tosa_rescale.mlir
+@@ -11,10 +11,10 @@
+   // CHECK-DAG: %[[MULTIPLIER_2:.+]] = "tosa.const"() <{values = dense<1431655765> : tensor<1xi32>}>
+   // CHECK-DAG: %[[ZP_MINUS_1:.+]] = "tosa.const"() <{values = dense<-1> : tensor<1xi8>}>
+   // CHECK-DAG: %[[ZP_0:.+]] = "tosa.const"() <{values = dense<0> : tensor<1xi32>}>
+-  // CHECK-DAG: %[[V0:.+]] = tosa.rescale %arg0, %[[MULTIPLIER_2]], %[[SHIFT13]], %[[ZP_MINUS_1]], %[[ZP_0]] {input_unsigned = false, output_unsigned = false, per_channel = false, rounding_mode = "SINGLE_ROUND", scale32 = true}
+-  // CHECK-DAG: %[[V1:.+]] = tosa.rescale %arg1, %[[MULTIPLIER_1]], %[[SHIFT11]], %[[ZP_MINUS_1]], %[[ZP_0]] {input_unsigned = false, output_unsigned = false, per_channel = false, rounding_mode = "SINGLE_ROUND", scale32 = true}
++  // CHECK-DAG: %[[V0:.+]] = tosa.rescale %arg0, %[[MULTIPLIER_2]], %[[SHIFT13]], %[[ZP_MINUS_1]], %[[ZP_0]] {input_unsigned = false, output_unsigned = false, per_channel = false, rounding_mode = SINGLE_ROUND, scale32 = true}
++  // CHECK-DAG: %[[V1:.+]] = tosa.rescale %arg1, %[[MULTIPLIER_1]], %[[SHIFT11]], %[[ZP_MINUS_1]], %[[ZP_0]] {input_unsigned = false, output_unsigned = false, per_channel = false, rounding_mode = SINGLE_ROUND, scale32 = true}
+   // CHECK: %[[V2:.+]] = stablehlo.add %[[V0]], %[[V1]] : tensor<2x2xi32>
+-  // CHECK: %[[V3:.+]] = tosa.rescale %[[V2]], %[[MULTIPLIER_1]], %[[SHIFT50]], %[[ZP_0]], %[[ZP_MINUS_1]] {input_unsigned = false, output_unsigned = false, per_channel = false, rounding_mode = "SINGLE_ROUND", scale32 = true}
++  // CHECK: %[[V3:.+]] = tosa.rescale %[[V2]], %[[MULTIPLIER_1]], %[[SHIFT50]], %[[ZP_0]], %[[ZP_MINUS_1]] {input_unsigned = false, output_unsigned = false, per_channel = false, rounding_mode = SINGLE_ROUND, scale32 = true}
+   // CHECK: return %[[V3]] : tensor<2x2x!quant.uniform<i8:f32, 1.500000e-01:-1>>
+   %0 = "stablehlo.add"(%arg0, %arg1) : (tensor<2x2x!quant.uniform<i8:f32, 0.025:-1>>, tensor<2x2x!quant.uniform<i8:f32, 0.075:-1>>)
+             -> tensor<2x2x!quant.uniform<i8:f32, 1.5e-01:-1>>
+@@ -32,10 +32,10 @@
+   // CHECK-DAG: %[[MULTIPLIER_2:.+]] = "tosa.const"() <{values = dense<1431655765> : tensor<1xi32>}>
+   // CHECK-DAG: %[[ZP_MINUS_1:.+]] = "tosa.const"() <{values = dense<-1> : tensor<1xi8>}>
+   // CHECK-DAG: %[[ZP_0:.+]] = "tosa.const"() <{values = dense<0> : tensor<1xi32>}>
+-  // CHECK-DAG: %[[V0:.+]] = tosa.rescale %arg0, %[[MULTIPLIER_2]], %[[SHIFT13]], %[[ZP_MINUS_1]], %[[ZP_0]] {input_unsigned = false, output_unsigned = false, per_channel = false, rounding_mode = "SINGLE_ROUND", scale32 = true}
+-  // CHECK-DAG: %[[V1:.+]] = tosa.rescale %arg1, %[[MULTIPLIER_1]], %[[SHIFT11]], %[[ZP_MINUS_1]], %[[ZP_0]] {input_unsigned = false, output_unsigned = false, per_channel = false, rounding_mode = "SINGLE_ROUND", scale32 = true}
++  // CHECK-DAG: %[[V0:.+]] = tosa.rescale %arg0, %[[MULTIPLIER_2]], %[[SHIFT13]], %[[ZP_MINUS_1]], %[[ZP_0]] {input_unsigned = false, output_unsigned = false, per_channel = false, rounding_mode = SINGLE_ROUND, scale32 = true}
++  // CHECK-DAG: %[[V1:.+]] = tosa.rescale %arg1, %[[MULTIPLIER_1]], %[[SHIFT11]], %[[ZP_MINUS_1]], %[[ZP_0]] {input_unsigned = false, output_unsigned = false, per_channel = false, rounding_mode = SINGLE_ROUND, scale32 = true}
+   // CHECK: %[[V2:.+]] = stablehlo.subtract %[[V0]], %[[V1]] : tensor<2x2xi32>
+-  // CHECK: %[[V3:.+]] = tosa.rescale %[[V2]], %[[MULTIPLIER_1]], %[[SHIFT50]], %[[ZP_0]], %[[ZP_MINUS_1]] {input_unsigned = false, output_unsigned = false, per_channel = false, rounding_mode = "SINGLE_ROUND", scale32 = true}
++  // CHECK: %[[V3:.+]] = tosa.rescale %[[V2]], %[[MULTIPLIER_1]], %[[SHIFT50]], %[[ZP_0]], %[[ZP_MINUS_1]] {input_unsigned = false, output_unsigned = false, per_channel = false, rounding_mode = SINGLE_ROUND, scale32 = true}
+   // CHECK: return %[[V3]] : tensor<2x2x!quant.uniform<i8:f32, 1.500000e-01:-1>>
+   %0 = "stablehlo.subtract"(%arg0, %arg1) : (tensor<2x2x!quant.uniform<i8:f32, 0.025:-1>>, tensor<2x2x!quant.uniform<i8:f32, 0.075:-1>>)
+             -> tensor<2x2x!quant.uniform<i8:f32, 1.5e-01:-1>>
+@@ -52,10 +52,10 @@
+   // CHECK-DAG: %[[MULTIPLIER_2:.+]] = "tosa.const"() <{values = dense<1717986918> : tensor<1xi32>}>
+   // CHECK-DAG: %[[ZP_MINUS_1:.+]] = "tosa.const"() <{values = dense<-1> : tensor<1xi8>}>
+   // CHECK-DAG: %[[ZP_0:.+]] = "tosa.const"() <{values = dense<0> : tensor<1xi32>}>
+-  // CHECK-DAG: %[[V0:.+]] = tosa.rescale %arg0, %[[MULTIPLIER_1]], %[[SHIFT30]], %[[ZP_MINUS_1]], %[[ZP_0]] {input_unsigned = false, output_unsigned = false, per_channel = false, rounding_mode = "SINGLE_ROUND", scale32 = true}
+-  // CHECK-DAG: %[[V1:.+]] = tosa.rescale %arg1, %[[MULTIPLIER_1]], %[[SHIFT30]], %[[ZP_MINUS_1]], %[[ZP_0]] {input_unsigned = false, output_unsigned = false, per_channel = false, rounding_mode = "SINGLE_ROUND", scale32 = true}
++  // CHECK-DAG: %[[V0:.+]] = tosa.rescale %arg0, %[[MULTIPLIER_1]], %[[SHIFT30]], %[[ZP_MINUS_1]], %[[ZP_0]] {input_unsigned = false, output_unsigned = false, per_channel = false, rounding_mode = SINGLE_ROUND, scale32 = true}
++  // CHECK-DAG: %[[V1:.+]] = tosa.rescale %arg1, %[[MULTIPLIER_1]], %[[SHIFT30]], %[[ZP_MINUS_1]], %[[ZP_0]] {input_unsigned = false, output_unsigned = false, per_channel = false, rounding_mode = SINGLE_ROUND, scale32 = true}
+   // CHECK: %[[V2:.+]] = stablehlo.multiply %[[V0]], %[[V1]] : tensor<2x2xi32>
+-  // CHECK: %[[V3:.+]] = tosa.rescale %[[V2]], %[[MULTIPLIER_2]], %[[SHIFT37]], %[[ZP_0]], %[[ZP_MINUS_1]] {input_unsigned = false, output_unsigned = false, per_channel = false, rounding_mode = "SINGLE_ROUND", scale32 = true}
++  // CHECK: %[[V3:.+]] = tosa.rescale %[[V2]], %[[MULTIPLIER_2]], %[[SHIFT37]], %[[ZP_0]], %[[ZP_MINUS_1]] {input_unsigned = false, output_unsigned = false, per_channel = false, rounding_mode = SINGLE_ROUND, scale32 = true}
+   // CHECK: return %[[V3]] : tensor<2x2x!quant.uniform<i8:f32, 1.500000e-01:-1>>
+   %0 = "stablehlo.multiply"(%arg0, %arg1) : (tensor<2x2x!quant.uniform<i8:f32, 0.025:-1>>, tensor<2x2x!quant.uniform<i8:f32, 0.075:-1>>)
+             -> tensor<2x2x!quant.uniform<i8:f32, 1.5e-01:-1>>
+@@ -74,10 +74,10 @@
+   // CHECK-DAG: %[[ZP_MINUS_2:.+]] = "tosa.const"() <{values = dense<-2> : tensor<1xi8>}>
+   // CHECK-DAG: %[[ZP_MINUS_1:.+]] = "tosa.const"() <{values = dense<-1> : tensor<1xi8>}>
+   // CHECK-DAG: %[[ZP_0:.+]] = "tosa.const"() <{values = dense<0> : tensor<1xi32>}>
+-  // CHECK-DAG: %[[V0:.+]] = tosa.rescale %arg0, %[[MULTIPLIER_1]], %[[SHIFT30]], %[[ZP_MINUS_1]], %[[ZP_0]] {input_unsigned = false, output_unsigned = false, per_channel = false, rounding_mode = "SINGLE_ROUND", scale32 = true}
+-  // CHECK-DAG: %[[V1:.+]] = tosa.rescale %arg1, %[[MULTIPLIER_1]], %[[SHIFT30]], %[[ZP_MINUS_2]], %[[ZP_0]] {input_unsigned = false, output_unsigned = false, per_channel = false, rounding_mode = "SINGLE_ROUND", scale32 = true}
++  // CHECK-DAG: %[[V0:.+]] = tosa.rescale %arg0, %[[MULTIPLIER_1]], %[[SHIFT30]], %[[ZP_MINUS_1]], %[[ZP_0]] {input_unsigned = false, output_unsigned = false, per_channel = false, rounding_mode = SINGLE_ROUND, scale32 = true}
++  // CHECK-DAG: %[[V1:.+]] = tosa.rescale %arg1, %[[MULTIPLIER_1]], %[[SHIFT30]], %[[ZP_MINUS_2]], %[[ZP_0]] {input_unsigned = false, output_unsigned = false, per_channel = false, rounding_mode = SINGLE_ROUND, scale32 = true}
+   // CHECK: %[[V2:.+]] = stablehlo.divide %[[V0]], %[[V1]] : tensor<2x2xi32>
+-  // CHECK: %[[V3:.+]] = tosa.rescale %[[V2]], %[[MULTIPLIER_2]], %[[SHIFT37]], %[[ZP_0]], %[[ZP_MINUS_3]] {input_unsigned = false, output_unsigned = false, per_channel = false, rounding_mode = "SINGLE_ROUND", scale32 = true}
++  // CHECK: %[[V3:.+]] = tosa.rescale %[[V2]], %[[MULTIPLIER_2]], %[[SHIFT37]], %[[ZP_0]], %[[ZP_MINUS_3]] {input_unsigned = false, output_unsigned = false, per_channel = false, rounding_mode = SINGLE_ROUND, scale32 = true}
+   // CHECK: return %[[V3]] : tensor<2x2x!quant.uniform<i8:f32, 1.500000e-01:-3>>
+   %0 = "stablehlo.divide"(%arg0, %arg1) : (tensor<2x2x!quant.uniform<i8:f32, 0.025:-1>>, tensor<2x2x!quant.uniform<i8:f32, 0.075:-2>>)
+             -> tensor<2x2x!quant.uniform<i8:f32, 1.5e-01:-3>>
+@@ -97,10 +97,10 @@
+   // CHECK-DAG: %[[SHIFT12:.+]] = "tosa.const"() <{values = dense<12> : tensor<1xi8>}>
+   // CHECK-DAG: %[[ZP_MINUS_1:.+]] = "tosa.const"() <{values = dense<-1> : tensor<1xi8>}>
+   // CHECK-DAG: %[[ZP_0:.+]] = "tosa.const"() <{values = dense<0> : tensor<1xi32>}>
+-  // CHECK-DAG: %[[V0:.+]] = tosa.rescale %arg0, %[[MULTIPLIER_2]], %[[SHIFT12]], %[[ZP_MINUS_1]], %[[ZP_0]] {input_unsigned = false, output_unsigned = false, per_channel = false, rounding_mode = "SINGLE_ROUND", scale32 = true}
+-  // CHECK-DAG: %[[V1:.+]] = tosa.rescale %arg1, %[[MULTIPLIER_1]], %[[SHIFT10]], %[[ZP_MINUS_2]], %[[ZP_0]] {input_unsigned = false, output_unsigned = false, per_channel = false, rounding_mode = "SINGLE_ROUND", scale32 = true}
++  // CHECK-DAG: %[[V0:.+]] = tosa.rescale %arg0, %[[MULTIPLIER_2]], %[[SHIFT12]], %[[ZP_MINUS_1]], %[[ZP_0]] {input_unsigned = false, output_unsigned = false, per_channel = false, rounding_mode = SINGLE_ROUND, scale32 = true}
++  // CHECK-DAG: %[[V1:.+]] = tosa.rescale %arg1, %[[MULTIPLIER_1]], %[[SHIFT10]], %[[ZP_MINUS_2]], %[[ZP_0]] {input_unsigned = false, output_unsigned = false, per_channel = false, rounding_mode = SINGLE_ROUND, scale32 = true}
+   // CHECK: %[[V2:.+]] = stablehlo.maximum %[[V0]], %[[V1]] : tensor<2x2xi32>
+-  // CHECK: %[[V3:.+]] = tosa.rescale %[[V2]], %[[MULTIPLIER_1]], %[[SHIFT51]], %[[ZP_0]], %[[ZP_MINUS_3]] {input_unsigned = false, output_unsigned = false, per_channel = false, rounding_mode = "SINGLE_ROUND", scale32 = true}
++  // CHECK: %[[V3:.+]] = tosa.rescale %[[V2]], %[[MULTIPLIER_1]], %[[SHIFT51]], %[[ZP_0]], %[[ZP_MINUS_3]] {input_unsigned = false, output_unsigned = false, per_channel = false, rounding_mode = SINGLE_ROUND, scale32 = true}
+   // CHECK: return %[[V3]] : tensor<2x2x!quant.uniform<i8:f32, 1.500000e-01:-3>>
+   %0 = "stablehlo.maximum"(%arg0, %arg1) : (tensor<2x2x!quant.uniform<i8:f32, 0.025:-1>>, tensor<2x2x!quant.uniform<i8:f32, 0.075:-2>>)
+             -> tensor<2x2x!quant.uniform<i8:f32, 1.5e-01:-3>>
+@@ -120,10 +120,10 @@
+   // CHECK-DAG: %[[SHIFT12:.+]] = "tosa.const"() <{values = dense<12> : tensor<1xi8>}>
+   // CHECK-DAG: %[[ZP_MINUS_1:.+]] = "tosa.const"() <{values = dense<-1> : tensor<1xi8>}>
+   // CHECK-DAG: %[[ZP_0:.+]] = "tosa.const"() <{values = dense<0> : tensor<1xi32>}>
+-  // CHECK-DAG: %[[V0:.+]] = tosa.rescale %arg0, %[[MULTIPLIER_2]], %[[SHIFT12]], %[[ZP_MINUS_1]], %[[ZP_0]] {input_unsigned = false, output_unsigned = false, per_channel = false, rounding_mode = "SINGLE_ROUND", scale32 = true}
+-  // CHECK-DAG: %[[V1:.+]] = tosa.rescale %arg1, %[[MULTIPLIER_1]], %[[SHIFT10]], %[[ZP_MINUS_2]], %[[ZP_0]] {input_unsigned = false, output_unsigned = false, per_channel = false, rounding_mode = "SINGLE_ROUND", scale32 = true}
++  // CHECK-DAG: %[[V0:.+]] = tosa.rescale %arg0, %[[MULTIPLIER_2]], %[[SHIFT12]], %[[ZP_MINUS_1]], %[[ZP_0]] {input_unsigned = false, output_unsigned = false, per_channel = false, rounding_mode = SINGLE_ROUND, scale32 = true}
++  // CHECK-DAG: %[[V1:.+]] = tosa.rescale %arg1, %[[MULTIPLIER_1]], %[[SHIFT10]], %[[ZP_MINUS_2]], %[[ZP_0]] {input_unsigned = false, output_unsigned = false, per_channel = false, rounding_mode = SINGLE_ROUND, scale32 = true}
+   // CHECK: %[[V2:.+]] = stablehlo.minimum %[[V0]], %[[V1]] : tensor<2x2xi32>
+-  // CHECK: %[[V3:.+]] = tosa.rescale %[[V2]], %[[MULTIPLIER_1]], %[[SHIFT51]], %[[ZP_0]], %[[ZP_MINUS_3]] {input_unsigned = false, output_unsigned = false, per_channel = false, rounding_mode = "SINGLE_ROUND", scale32 = true}
++  // CHECK: %[[V3:.+]] = tosa.rescale %[[V2]], %[[MULTIPLIER_1]], %[[SHIFT51]], %[[ZP_0]], %[[ZP_MINUS_3]] {input_unsigned = false, output_unsigned = false, per_channel = false, rounding_mode = SINGLE_ROUND, scale32 = true}
+   // CHECK: return %[[V3]] : tensor<2x2x!quant.uniform<i8:f32, 1.500000e-01:-3>>
+   %0 = "stablehlo.minimum"(%arg0, %arg1) : (tensor<2x2x!quant.uniform<i8:f32, 0.025:-1>>, tensor<2x2x!quant.uniform<i8:f32, 0.075:-2>>)
+             -> tensor<2x2x!quant.uniform<i8:f32, 1.5e-01:-3>>
+@@ -140,9 +140,9 @@
+   // CHECK-DAG: %[[SHIFT30:.+]] = "tosa.const"() <{values = dense<30> : tensor<1xi8>}>
+   // CHECK-DAG: %[[ZP_MINUS_1:.+]] = "tosa.const"() <{values = dense<-1> : tensor<1xi8>}>
+   // CHECK-DAG: %[[ZP_0:.+]] = "tosa.const"() <{values = dense<0> : tensor<1xi32>}>
+-  // CHECK: %[[V0:.+]] = tosa.rescale %arg0, %[[MULTIPLIER_2]], %[[SHIFT30]], %[[ZP_MINUS_1]], %[[ZP_0]] {input_unsigned = false, output_unsigned = false, per_channel = false, rounding_mode = "SINGLE_ROUND", scale32 = true}
++  // CHECK: %[[V0:.+]] = tosa.rescale %arg0, %[[MULTIPLIER_2]], %[[SHIFT30]], %[[ZP_MINUS_1]], %[[ZP_0]] {input_unsigned = false, output_unsigned = false, per_channel = false, rounding_mode = SINGLE_ROUND, scale32 = true}
+   // CHECK: %[[V1:.+]] = stablehlo.abs %[[V0]] : tensor<20x20xi32>
+-  // CHECK: %[[V3:.+]] = tosa.rescale %[[V1]], %[[MULTIPLIER_1]], %[[SHIFT33]], %[[ZP_0]], %[[ZP_MINUS_128]] {input_unsigned = false, output_unsigned = false, per_channel = false, rounding_mode = "SINGLE_ROUND", scale32 = true}
++  // CHECK: %[[V3:.+]] = tosa.rescale %[[V1]], %[[MULTIPLIER_1]], %[[SHIFT33]], %[[ZP_0]], %[[ZP_MINUS_128]] {input_unsigned = false, output_unsigned = false, per_channel = false, rounding_mode = SINGLE_ROUND, scale32 = true}
+   // CHECK: return %[[V3]] : tensor<20x20x!quant.uniform<i8:f32, 1.500000e-01:-128>>
+   %0 = "stablehlo.abs"(%arg0) : (tensor<20x20x!quant.uniform<i8:f32, 0.025:-1>>) -> tensor<20x20x!quant.uniform<i8:f32, 1.5e-01:-128>>
+   return %0 : tensor<20x20x!quant.uniform<i8:f32, 1.5e-01:-128>>
+@@ -159,8 +159,8 @@
+   // CHECK-DAG: %[[SHIFT12:.+]] = "tosa.const"() <{values = dense<12> : tensor<1xi8>}>
+   // CHECK-DAG: %[[ZP_MINUS_1:.+]] = "tosa.const"() <{values = dense<-1> : tensor<1xi8>}>
+   // CHECK-DAG: %[[ZP_0:.+]] = "tosa.const"() <{values = dense<0> : tensor<1xi32>}>
+-  // CHECK: %[[V0:.+]] = tosa.rescale %arg0, %[[MULTIPLIER_2]], %[[SHIFT12]], %[[ZP_MINUS_1]], %[[ZP_0]] {input_unsigned = false, output_unsigned = false, per_channel = false, rounding_mode = "SINGLE_ROUND", scale32 = true}
+-  // CHECK: %[[V1:.+]] = tosa.rescale %arg1, %[[MULTIPLIER_1]], %[[SHIFT10]], %[[ZP_MINUS_2]], %[[ZP_0]] {input_unsigned = false, output_unsigned = false, per_channel = false, rounding_mode = "SINGLE_ROUND", scale32 = true}
++  // CHECK: %[[V0:.+]] = tosa.rescale %arg0, %[[MULTIPLIER_2]], %[[SHIFT12]], %[[ZP_MINUS_1]], %[[ZP_0]] {input_unsigned = false, output_unsigned = false, per_channel = false, rounding_mode = SINGLE_ROUND, scale32 = true}
++  // CHECK: %[[V1:.+]] = tosa.rescale %arg1, %[[MULTIPLIER_1]], %[[SHIFT10]], %[[ZP_MINUS_2]], %[[ZP_0]] {input_unsigned = false, output_unsigned = false, per_channel = false, rounding_mode = SINGLE_ROUND, scale32 = true}
+   // CHECK: %[[V2:.+]] = stablehlo.compare GE, %[[V0]], %[[V1]], TOTALORDER :
+   // CHECK: return %[[V2]]
+   %0 = stablehlo.compare GE, %arg0, %arg1, TOTALORDER : (tensor<20x20x!quant.uniform<i8:f32, 0.025:-1>>, tensor<20x20x!quant.uniform<i8:f32, 0.075:-2>>) -> tensor<20x20xi1>
+@@ -177,8 +177,8 @@
+   // CHECK-DAG: %[[SHIFT15:.+]] = "tosa.const"() <{values = dense<15> : tensor<1xi8>}>
+   // CHECK-DAG: %[[ZP16_0:.+]] = "tosa.const"() <{values = dense<0> : tensor<1xi16>}>
+   // CHECK-DAG: %[[ZP32_0:.+]] = "tosa.const"() <{values = dense<0> : tensor<1xi32>}>
+-  // CHECK: %[[V0:.+]] = tosa.rescale %arg0, %[[MULTIPLIER_2]], %[[SHIFT17]], %[[ZP16_0]], %[[ZP32_0]] {input_unsigned = false, output_unsigned = false, per_channel = false, rounding_mode = "SINGLE_ROUND", scale32 = true}
+-  // CHECK: %[[V1:.+]] = tosa.rescale %arg1, %[[MULTIPLIER_1]], %[[SHIFT15]], %[[ZP16_0]], %[[ZP32_0]] {input_unsigned = false, output_unsigned = false, per_channel = false, rounding_mode = "SINGLE_ROUND", scale32 = true}
++  // CHECK: %[[V0:.+]] = tosa.rescale %arg0, %[[MULTIPLIER_2]], %[[SHIFT17]], %[[ZP16_0]], %[[ZP32_0]] {input_unsigned = false, output_unsigned = false, per_channel = false, rounding_mode = SINGLE_ROUND, scale32 = true}
++  // CHECK: %[[V1:.+]] = tosa.rescale %arg1, %[[MULTIPLIER_1]], %[[SHIFT15]], %[[ZP16_0]], %[[ZP32_0]] {input_unsigned = false, output_unsigned = false, per_channel = false, rounding_mode = SINGLE_ROUND, scale32 = true}
+   // CHECK: %[[V2:.+]] = stablehlo.compare LT, %[[V0]], %[[V1]], TOTALORDER :
+   // CHECK: return %[[V2]]
+   %0 = stablehlo.compare LT, %arg0, %arg1, TOTALORDER : (tensor<20x20x!quant.uniform<i16:f32, 0.025:0>>, tensor<20x20x!quant.uniform<i16:f32, 0.075:0>>) -> tensor<20x20xi1>
+diff --ruN a/stablehlo/stablehlo/conversions/tosa/tests/legalize_tosa_rescale_to_stablehlo.mlir b/stablehlo/stablehlo/conversions/tosa/tests/legalize_tosa_rescale_to_stablehlo.mlir
+--- stablehlo/stablehlo/conversions/tosa/tests/legalize_tosa_rescale_to_stablehlo.mlir
++++ stablehlo/stablehlo/conversions/tosa/tests/legalize_tosa_rescale_to_stablehlo.mlir
+@@ -7,7 +7,7 @@
+   %shift = "tosa.const"() {values = dense<13> : tensor<1xi8>} : () -> tensor<1xi8>
+   %input_zp = "tosa.const"() {values = dense<-1> : tensor<1xi8>} : () -> tensor<1xi8>
+   %output_zp = "tosa.const"() {values = dense<0> : tensor<1xi32>} : () -> tensor<1xi32>
+-  %0 = tosa.rescale %arg0, %multiplier, %shift, %input_zp, %output_zp {input_unsigned = false, output_unsigned = false, per_channel = false, rounding_mode = "SINGLE_ROUND", scale32 = true} :
++  %0 = tosa.rescale %arg0, %multiplier, %shift, %input_zp, %output_zp {input_unsigned = false, output_unsigned = false, per_channel = false, rounding_mode = SINGLE_ROUND, scale32 = true} :
+             (tensor<2x2x!quant.uniform<i8:f32, 0.025:-1>>, tensor<1xi32>, tensor<1xi8>, tensor<1xi8>, tensor<1xi32>) -> tensor<2x2xi32>
+ 
+   // convert input quantized type to storage type
+diff --ruN a/stablehlo/stablehlo/conversions/tosa/transforms/StablehloQuantLegalizeToTosaRescale.cpp b/stablehlo/stablehlo/conversions/tosa/transforms/StablehloQuantLegalizeToTosaRescale.cpp
+--- stablehlo/stablehlo/conversions/tosa/transforms/StablehloQuantLegalizeToTosaRescale.cpp
++++ stablehlo/stablehlo/conversions/tosa/transforms/StablehloQuantLegalizeToTosaRescale.cpp
+@@ -70,12 +70,14 @@
+       outputZpVal.has_value() &&
+       "buildRescale: Failed to create output zero-point tensor for RescaleOp.");
+ 
+-  std::string roundingMode = doubleRound ? "DOUBLE_ROUND" : "SINGLE_ROUND";
++  auto roundingMode =
++      doubleRound ? RoundingMode::DOUBLE_ROUND : RoundingMode::SINGLE_ROUND;
+ 
+   auto rescale_op = rewriter.create<RescaleOp>(
+       loc, outputType, inputVal, multiplierVal, shiftVal, inputZpVal.value(),
+       outputZpVal.value(), rewriter.getBoolAttr(scale32),
+-      rewriter.getStringAttr(roundingMode), rewriter.getBoolAttr(perChannel),
++      RoundingModeAttr::get(rewriter.getContext(), roundingMode),
++      rewriter.getBoolAttr(perChannel),
+       /*input_unsigned=*/rewriter.getBoolAttr(false),
+       /*output_unsigned=*/rewriter.getBoolAttr(false));
+ 
+diff --ruN a/stablehlo/stablehlo/conversions/tosa/transforms/TosaRescaleLegalizeToStablehlo.cpp b/stablehlo/stablehlo/conversions/tosa/transforms/TosaRescaleLegalizeToStablehlo.cpp
+--- stablehlo/stablehlo/conversions/tosa/transforms/TosaRescaleLegalizeToStablehlo.cpp
++++ stablehlo/stablehlo/conversions/tosa/transforms/TosaRescaleLegalizeToStablehlo.cpp
+@@ -68,7 +68,7 @@
+   auto roundingMode = op.getRoundingMode();
+   bool perChannel = op.getPerChannel();
+ 
+-  if (perChannel || roundingMode != "SINGLE_ROUND" || !scale32) {
++  if (perChannel || roundingMode != RoundingMode::SINGLE_ROUND || !scale32) {
+     return rewriter.notifyMatchFailure(
+         op,
+         "per_channel, double_round, or scale32=false are not yet supported");
 diff --ruN a/stablehlo/stablehlo/dialect/StablehloOps.cpp b/stablehlo/stablehlo/dialect/StablehloOps.cpp
 --- stablehlo/stablehlo/dialect/StablehloOps.cpp
 +++ stablehlo/stablehlo/dialect/StablehloOps.cpp
