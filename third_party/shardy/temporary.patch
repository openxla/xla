diff --git a/third_party/llvm/generated.patch b/third_party/llvm/generated.patch
index 265b4fe..fff0951 100644
--- a/third_party/llvm/generated.patch
+++ b/third_party/llvm/generated.patch
@@ -1,1408 +1,3172 @@
 Auto generated patch. Do not edit or delete it, even if empty.
-diff -ruN --strip-trailing-cr a/clang/include/clang/Basic/SourceManager.h b/clang/include/clang/Basic/SourceManager.h
---- a/clang/include/clang/Basic/SourceManager.h
-+++ b/clang/include/clang/Basic/SourceManager.h
-@@ -824,12 +824,6 @@
+diff -ruN --strip-trailing-cr a/llvm/lib/Target/NVPTX/NVPTXISelLowering.cpp b/llvm/lib/Target/NVPTX/NVPTXISelLowering.cpp
+--- a/llvm/lib/Target/NVPTX/NVPTXISelLowering.cpp
++++ b/llvm/lib/Target/NVPTX/NVPTXISelLowering.cpp
+@@ -731,6 +731,8 @@
+   setTruncStoreAction(MVT::f32, MVT::bf16, Expand);
+   setTruncStoreAction(MVT::f64, MVT::bf16, Expand);
+   setTruncStoreAction(MVT::f64, MVT::f32, Expand);
++  setTruncStoreAction(MVT::v2f32, MVT::v2f16, Expand);
++  setTruncStoreAction(MVT::v2f32, MVT::v2bf16, Expand);
  
-   mutable std::unique_ptr<SrcMgr::SLocEntry> FakeSLocEntryForRecovery;
+   // PTX does not support load / store predicate registers
+   setOperationAction(ISD::LOAD, MVT::i1, Custom);
+@@ -5060,12 +5062,6 @@
+           return !U.getUser()->use_empty();
+         }
  
--  /// Cache for filenames used in diagnostics. See 'getNameForDiagnostic()'.
--  mutable llvm::StringMap<StringRef> DiagNames;
+-        // Handle CopyToReg nodes that will become dead after our replacement
+-        if (U.getUser()->getOpcode() == ISD::CopyToReg) {
+-          DeadCopyToRegs.push_back(U.getUser());
+-          return true;
+-        }
 -
--  /// Allocator for absolute/short names.
--  mutable llvm::BumpPtrAllocator DiagNameAlloc;
--
-   /// Lazily computed map of macro argument chunks to their expanded
-   /// source location.
-   using MacroArgsMap = std::map<unsigned, SourceLocation>;
-@@ -1854,16 +1848,6 @@
-   /// \return Location of the top-level macro caller.
-   SourceLocation getTopMacroCallerLoc(SourceLocation Loc) const;
+         // Otherwise, this use prevents us from splitting a value.
+         return false;
+       }))
+@@ -5132,10 +5128,6 @@
+   for (unsigned I : seq(NewLoad->getNumValues() - NewNumOutputs))
+     Results.push_back(NewLoad.getValue(NewNumOutputs + I));
  
--  /// Retrieve the name of a file suitable for diagnostics.
--  // FIXME: Passing in the DiagnosticOptions here is a workaround for the
--  // fact that installapi does some weird things with DiagnosticsEngines,
--  // which causes the 'Diag' member of SourceManager (or at least the
--  // DiagnosticsOptions member thereof) to be a dangling reference
--  // sometimes. We should probably fix that or decouple the two classes
--  // to avoid this issue entirely.
--  StringRef getNameForDiagnostic(StringRef Filename,
--                                 const DiagnosticOptions &Opts) const;
+-  // Remove dead CopyToReg nodes by folding them into the chain they reference
+-  for (SDNode *CTR : DeadCopyToRegs)
+-    DCI.CombineTo(CTR, CTR->getOperand(0));
 -
- private:
-   friend class ASTReader;
-   friend class ASTWriter;
-diff -ruN --strip-trailing-cr a/clang/lib/Basic/SourceManager.cpp b/clang/lib/Basic/SourceManager.cpp
---- a/clang/lib/Basic/SourceManager.cpp
-+++ b/clang/lib/Basic/SourceManager.cpp
-@@ -2390,75 +2390,3 @@
-   assert(ID.isValid());
-   SourceMgr->setMainFileID(ID);
+   return DCI.DAG.getMergeValues(Results, DL);
  }
--
--StringRef
--SourceManager::getNameForDiagnostic(StringRef Filename,
--                                    const DiagnosticOptions &Opts) const {
--  OptionalFileEntryRef File = getFileManager().getOptionalFileRef(Filename);
--  if (!File)
--    return Filename;
--
--  bool SimplifyPath = [&] {
--    if (Opts.AbsolutePath)
--      return true;
--
--    // Try to simplify paths that contain '..' in any case since paths to
--    // standard library headers especially tend to get quite long otherwise.
--    // Only do that for local filesystems though to avoid slowing down
--    // compilation too much.
--    if (!File->getName().contains(".."))
--      return false;
--
--    // If we're not on Windows, check if we're on a network file system and
--    // avoid simplifying the path in that case since that can be slow. On
--    // Windows, the check for a local filesystem is already slow, so skip it.
--#ifndef _WIN32
--    if (!llvm::sys::fs::is_local(File->getName()))
--      return false;
--#endif
--
--    return true;
--  }();
--
--  if (!SimplifyPath)
--    return Filename;
--
--  // This may involve computing canonical names, so cache the result.
--  StringRef &CacheEntry = DiagNames[Filename];
--  if (!CacheEntry.empty())
--    return CacheEntry;
--
--  // We want to print a simplified absolute path, i. e. without "dots".
--  //
--  // The hardest part here are the paths like "<part1>/<link>/../<part2>".
--  // On Unix-like systems, we cannot just collapse "<link>/..", because
--  // paths are resolved sequentially, and, thereby, the path
--  // "<part1>/<part2>" may point to a different location. That is why
--  // we use FileManager::getCanonicalName(), which expands all indirections
--  // with llvm::sys::fs::real_path() and caches the result.
--  //
--  // On the other hand, it would be better to preserve as much of the
--  // original path as possible, because that helps a user to recognize it.
--  // real_path() expands all links, which sometimes too much. Luckily,
--  // on Windows we can just use llvm::sys::path::remove_dots(), because,
--  // on that system, both aforementioned paths point to the same place.
--  SmallString<256> TempBuf;
--#ifdef _WIN32
--  TempBuf = File->getName();
--  llvm::sys::fs::make_absolute(TempBuf);
--  llvm::sys::path::native(TempBuf);
--  llvm::sys::path::remove_dots(TempBuf, /* remove_dot_dot */ true);
--#else
--  TempBuf = getFileManager().getCanonicalName(*File);
--#endif
--
--  // In some cases, the resolved path may actually end up being longer (e.g.
--  // if it was originally a relative path), so just retain whichever one
--  // ends up being shorter.
--  if (!Opts.AbsolutePath && TempBuf.size() > Filename.size())
--    CacheEntry = Filename;
--  else
--    CacheEntry = TempBuf.str().copy(DiagNameAlloc);
--
--  return CacheEntry;
--}
-diff -ruN --strip-trailing-cr a/clang/lib/Frontend/SARIFDiagnostic.cpp b/clang/lib/Frontend/SARIFDiagnostic.cpp
---- a/clang/lib/Frontend/SARIFDiagnostic.cpp
-+++ b/clang/lib/Frontend/SARIFDiagnostic.cpp
-@@ -163,7 +163,36 @@
  
- llvm::StringRef SARIFDiagnostic::emitFilename(StringRef Filename,
-                                               const SourceManager &SM) {
--  return SM.getNameForDiagnostic(Filename, DiagOpts);
-+  if (DiagOpts.AbsolutePath) {
-+    auto File = SM.getFileManager().getOptionalFileRef(Filename);
-+    if (File) {
-+      // We want to print a simplified absolute path, i. e. without "dots".
-+      //
-+      // The hardest part here are the paths like "<part1>/<link>/../<part2>".
-+      // On Unix-like systems, we cannot just collapse "<link>/..", because
-+      // paths are resolved sequentially, and, thereby, the path
-+      // "<part1>/<part2>" may point to a different location. That is why
-+      // we use FileManager::getCanonicalName(), which expands all indirections
-+      // with llvm::sys::fs::real_path() and caches the result.
-+      //
-+      // On the other hand, it would be better to preserve as much of the
-+      // original path as possible, because that helps a user to recognize it.
-+      // real_path() expands all links, which is sometimes too much. Luckily,
-+      // on Windows we can just use llvm::sys::path::remove_dots(), because,
-+      // on that system, both aforementioned paths point to the same place.
-+#ifdef _WIN32
-+      SmallString<256> TmpFilename = File->getName();
-+      llvm::sys::fs::make_absolute(TmpFilename);
-+      llvm::sys::path::native(TmpFilename);
-+      llvm::sys::path::remove_dots(TmpFilename, /* remove_dot_dot */ true);
-+      Filename = StringRef(TmpFilename.data(), TmpFilename.size());
-+#else
-+      Filename = SM.getFileManager().getCanonicalName(*File);
-+#endif
-+    }
-+  }
-+
-+  return Filename;
+@@ -6544,4 +6536,4 @@
+   default:
+     break;
+   }
+-}
+\ No newline at end of file
++}
+diff -ruN --strip-trailing-cr a/llvm/test/CodeGen/NVPTX/bf16x2-instructions.ll b/llvm/test/CodeGen/NVPTX/bf16x2-instructions.ll
+--- a/llvm/test/CodeGen/NVPTX/bf16x2-instructions.ll
++++ b/llvm/test/CodeGen/NVPTX/bf16x2-instructions.ll
+@@ -359,11 +359,12 @@
+ define <2 x bfloat> @test_fptrunc_2xfloat(<2 x float> %a) #0 {
+ ; CHECK-LABEL: test_fptrunc_2xfloat(
+ ; CHECK:       {
+-; CHECK-NEXT:    .reg .b64 %rd<2>;
++; CHECK-NEXT:    .reg .b32 %r<4>;
+ ; CHECK-EMPTY:
+ ; CHECK-NEXT:  // %bb.0:
+-; CHECK-NEXT:    ld.param.b64 %rd1, [test_fptrunc_2xfloat_param_0];
+-; CHECK-NEXT:    st.param.b32 [func_retval0], %rd1;
++; CHECK-NEXT:    ld.param.v2.b32 {%r1, %r2}, [test_fptrunc_2xfloat_param_0];
++; CHECK-NEXT:    cvt.rn.bf16x2.f32 %r3, %r2, %r1;
++; CHECK-NEXT:    st.param.b32 [func_retval0], %r3;
+ ; CHECK-NEXT:    ret;
+   %r = fptrunc <2 x float> %a to <2 x bfloat>
+   ret <2 x bfloat> %r
+diff -ruN --strip-trailing-cr a/llvm/test/CodeGen/NVPTX/f16x2-instructions.ll b/llvm/test/CodeGen/NVPTX/f16x2-instructions.ll
+--- a/llvm/test/CodeGen/NVPTX/f16x2-instructions.ll
++++ b/llvm/test/CodeGen/NVPTX/f16x2-instructions.ll
+@@ -45,11 +45,12 @@
+ define half @test_extract_0(<2 x half> %a) #0 {
+ ; CHECK-LABEL: test_extract_0(
+ ; CHECK:       {
+-; CHECK-NEXT:    .reg .b16 %rs<3>;
++; CHECK-NEXT:    .reg .b16 %rs<2>;
+ ; CHECK-NEXT:    .reg .b32 %r<2>;
+ ; CHECK-EMPTY:
+ ; CHECK-NEXT:  // %bb.0:
+-; CHECK-NEXT:    ld.param.v2.b16 {%rs1, %rs2}, [test_extract_0_param_0];
++; CHECK-NEXT:    ld.param.b32 %r1, [test_extract_0_param_0];
++; CHECK-NEXT:    { .reg .b16 tmp; mov.b32 {%rs1, tmp}, %r1; }
+ ; CHECK-NEXT:    st.param.b16 [func_retval0], %rs1;
+ ; CHECK-NEXT:    ret;
+   %e = extractelement <2 x half> %a, i32 0
+@@ -59,12 +60,13 @@
+ define half @test_extract_1(<2 x half> %a) #0 {
+ ; CHECK-LABEL: test_extract_1(
+ ; CHECK:       {
+-; CHECK-NEXT:    .reg .b16 %rs<3>;
++; CHECK-NEXT:    .reg .b16 %rs<2>;
+ ; CHECK-NEXT:    .reg .b32 %r<2>;
+ ; CHECK-EMPTY:
+ ; CHECK-NEXT:  // %bb.0:
+-; CHECK-NEXT:    ld.param.v2.b16 {%rs1, %rs2}, [test_extract_1_param_0];
+-; CHECK-NEXT:    st.param.b16 [func_retval0], %rs2;
++; CHECK-NEXT:    ld.param.b32 %r1, [test_extract_1_param_0];
++; CHECK-NEXT:    { .reg .b16 tmp; mov.b32 {tmp, %rs1}, %r1; }
++; CHECK-NEXT:    st.param.b16 [func_retval0], %rs1;
+ ; CHECK-NEXT:    ret;
+   %e = extractelement <2 x half> %a, i32 1
+   ret half %e
+@@ -80,8 +82,9 @@
+ ; CHECK-EMPTY:
+ ; CHECK-NEXT:  // %bb.0:
+ ; CHECK-NEXT:    ld.param.b64 %rd1, [test_extract_i_param_1];
+-; CHECK-NEXT:    ld.param.v2.b16 {%rs1, %rs2}, [test_extract_i_param_0];
++; CHECK-NEXT:    ld.param.b32 %r1, [test_extract_i_param_0];
+ ; CHECK-NEXT:    setp.eq.b64 %p1, %rd1, 0;
++; CHECK-NEXT:    mov.b32 {%rs1, %rs2}, %r1;
+ ; CHECK-NEXT:    selp.b16 %rs3, %rs1, %rs2, %p1;
+ ; CHECK-NEXT:    st.param.b16 [func_retval0], %rs3;
+ ; CHECK-NEXT:    ret;
+@@ -107,14 +110,16 @@
+ ; CHECK-NOF16-NEXT:    .reg .b32 %r<10>;
+ ; CHECK-NOF16-EMPTY:
+ ; CHECK-NOF16-NEXT:  // %bb.0:
+-; CHECK-NOF16-NEXT:    ld.param.v2.b16 {%rs1, %rs2}, [test_fadd_param_0];
+-; CHECK-NOF16-NEXT:    ld.param.v2.b16 {%rs3, %rs4}, [test_fadd_param_1];
+-; CHECK-NOF16-NEXT:    cvt.f32.f16 %r3, %rs4;
+-; CHECK-NOF16-NEXT:    cvt.f32.f16 %r4, %rs2;
++; CHECK-NOF16-NEXT:    ld.param.b32 %r2, [test_fadd_param_1];
++; CHECK-NOF16-NEXT:    ld.param.b32 %r1, [test_fadd_param_0];
++; CHECK-NOF16-NEXT:    mov.b32 {%rs1, %rs2}, %r2;
++; CHECK-NOF16-NEXT:    cvt.f32.f16 %r3, %rs2;
++; CHECK-NOF16-NEXT:    mov.b32 {%rs3, %rs4}, %r1;
++; CHECK-NOF16-NEXT:    cvt.f32.f16 %r4, %rs4;
+ ; CHECK-NOF16-NEXT:    add.rn.f32 %r5, %r4, %r3;
+ ; CHECK-NOF16-NEXT:    cvt.rn.f16.f32 %rs5, %r5;
+-; CHECK-NOF16-NEXT:    cvt.f32.f16 %r6, %rs3;
+-; CHECK-NOF16-NEXT:    cvt.f32.f16 %r7, %rs1;
++; CHECK-NOF16-NEXT:    cvt.f32.f16 %r6, %rs1;
++; CHECK-NOF16-NEXT:    cvt.f32.f16 %r7, %rs3;
+ ; CHECK-NOF16-NEXT:    add.rn.f32 %r8, %r7, %r6;
+ ; CHECK-NOF16-NEXT:    cvt.rn.f16.f32 %rs6, %r8;
+ ; CHECK-NOF16-NEXT:    mov.b32 %r9, {%rs6, %rs5};
+@@ -143,7 +148,8 @@
+ ; CHECK-NOF16-NEXT:    .reg .b32 %r<7>;
+ ; CHECK-NOF16-EMPTY:
+ ; CHECK-NOF16-NEXT:  // %bb.0:
+-; CHECK-NOF16-NEXT:    ld.param.v2.b16 {%rs1, %rs2}, [test_fadd_imm_0_param_0];
++; CHECK-NOF16-NEXT:    ld.param.b32 %r1, [test_fadd_imm_0_param_0];
++; CHECK-NOF16-NEXT:    mov.b32 {%rs1, %rs2}, %r1;
+ ; CHECK-NOF16-NEXT:    cvt.f32.f16 %r2, %rs2;
+ ; CHECK-NOF16-NEXT:    add.rn.f32 %r3, %r2, 0f40000000;
+ ; CHECK-NOF16-NEXT:    cvt.rn.f16.f32 %rs3, %r3;
+@@ -175,7 +181,8 @@
+ ; CHECK-NOF16-NEXT:    .reg .b32 %r<7>;
+ ; CHECK-NOF16-EMPTY:
+ ; CHECK-NOF16-NEXT:  // %bb.0:
+-; CHECK-NOF16-NEXT:    ld.param.v2.b16 {%rs1, %rs2}, [test_fadd_imm_1_param_0];
++; CHECK-NOF16-NEXT:    ld.param.b32 %r1, [test_fadd_imm_1_param_0];
++; CHECK-NOF16-NEXT:    mov.b32 {%rs1, %rs2}, %r1;
+ ; CHECK-NOF16-NEXT:    cvt.f32.f16 %r2, %rs2;
+ ; CHECK-NOF16-NEXT:    add.rn.f32 %r3, %r2, 0f40000000;
+ ; CHECK-NOF16-NEXT:    cvt.rn.f16.f32 %rs3, %r3;
+@@ -207,14 +214,16 @@
+ ; CHECK-NOF16-NEXT:    .reg .b32 %r<10>;
+ ; CHECK-NOF16-EMPTY:
+ ; CHECK-NOF16-NEXT:  // %bb.0:
+-; CHECK-NOF16-NEXT:    ld.param.v2.b16 {%rs1, %rs2}, [test_fsub_param_0];
+-; CHECK-NOF16-NEXT:    ld.param.v2.b16 {%rs3, %rs4}, [test_fsub_param_1];
+-; CHECK-NOF16-NEXT:    cvt.f32.f16 %r3, %rs4;
+-; CHECK-NOF16-NEXT:    cvt.f32.f16 %r4, %rs2;
++; CHECK-NOF16-NEXT:    ld.param.b32 %r2, [test_fsub_param_1];
++; CHECK-NOF16-NEXT:    ld.param.b32 %r1, [test_fsub_param_0];
++; CHECK-NOF16-NEXT:    mov.b32 {%rs1, %rs2}, %r2;
++; CHECK-NOF16-NEXT:    cvt.f32.f16 %r3, %rs2;
++; CHECK-NOF16-NEXT:    mov.b32 {%rs3, %rs4}, %r1;
++; CHECK-NOF16-NEXT:    cvt.f32.f16 %r4, %rs4;
+ ; CHECK-NOF16-NEXT:    sub.rn.f32 %r5, %r4, %r3;
+ ; CHECK-NOF16-NEXT:    cvt.rn.f16.f32 %rs5, %r5;
+-; CHECK-NOF16-NEXT:    cvt.f32.f16 %r6, %rs3;
+-; CHECK-NOF16-NEXT:    cvt.f32.f16 %r7, %rs1;
++; CHECK-NOF16-NEXT:    cvt.f32.f16 %r6, %rs1;
++; CHECK-NOF16-NEXT:    cvt.f32.f16 %r7, %rs3;
+ ; CHECK-NOF16-NEXT:    sub.rn.f32 %r8, %r7, %r6;
+ ; CHECK-NOF16-NEXT:    cvt.rn.f16.f32 %rs6, %r8;
+ ; CHECK-NOF16-NEXT:    mov.b32 %r9, {%rs6, %rs5};
+@@ -242,7 +251,8 @@
+ ; CHECK-NOF16-NEXT:    .reg .b32 %r<8>;
+ ; CHECK-NOF16-EMPTY:
+ ; CHECK-NOF16-NEXT:  // %bb.0:
+-; CHECK-NOF16-NEXT:    ld.param.v2.b16 {%rs1, %rs2}, [test_fneg_param_0];
++; CHECK-NOF16-NEXT:    ld.param.b32 %r1, [test_fneg_param_0];
++; CHECK-NOF16-NEXT:    mov.b32 {%rs1, %rs2}, %r1;
+ ; CHECK-NOF16-NEXT:    cvt.f32.f16 %r2, %rs2;
+ ; CHECK-NOF16-NEXT:    mov.b32 %r3, 0f00000000;
+ ; CHECK-NOF16-NEXT:    sub.rn.f32 %r4, %r3, %r2;
+@@ -275,14 +285,16 @@
+ ; CHECK-NOF16-NEXT:    .reg .b32 %r<10>;
+ ; CHECK-NOF16-EMPTY:
+ ; CHECK-NOF16-NEXT:  // %bb.0:
+-; CHECK-NOF16-NEXT:    ld.param.v2.b16 {%rs1, %rs2}, [test_fmul_param_0];
+-; CHECK-NOF16-NEXT:    ld.param.v2.b16 {%rs3, %rs4}, [test_fmul_param_1];
+-; CHECK-NOF16-NEXT:    cvt.f32.f16 %r3, %rs4;
+-; CHECK-NOF16-NEXT:    cvt.f32.f16 %r4, %rs2;
++; CHECK-NOF16-NEXT:    ld.param.b32 %r2, [test_fmul_param_1];
++; CHECK-NOF16-NEXT:    ld.param.b32 %r1, [test_fmul_param_0];
++; CHECK-NOF16-NEXT:    mov.b32 {%rs1, %rs2}, %r2;
++; CHECK-NOF16-NEXT:    cvt.f32.f16 %r3, %rs2;
++; CHECK-NOF16-NEXT:    mov.b32 {%rs3, %rs4}, %r1;
++; CHECK-NOF16-NEXT:    cvt.f32.f16 %r4, %rs4;
+ ; CHECK-NOF16-NEXT:    mul.rn.f32 %r5, %r4, %r3;
+ ; CHECK-NOF16-NEXT:    cvt.rn.f16.f32 %rs5, %r5;
+-; CHECK-NOF16-NEXT:    cvt.f32.f16 %r6, %rs3;
+-; CHECK-NOF16-NEXT:    cvt.f32.f16 %r7, %rs1;
++; CHECK-NOF16-NEXT:    cvt.f32.f16 %r6, %rs1;
++; CHECK-NOF16-NEXT:    cvt.f32.f16 %r7, %rs3;
+ ; CHECK-NOF16-NEXT:    mul.rn.f32 %r8, %r7, %r6;
+ ; CHECK-NOF16-NEXT:    cvt.rn.f16.f32 %rs6, %r8;
+ ; CHECK-NOF16-NEXT:    mov.b32 %r9, {%rs6, %rs5};
+@@ -299,14 +311,16 @@
+ ; CHECK-NEXT:    .reg .b32 %r<10>;
+ ; CHECK-EMPTY:
+ ; CHECK-NEXT:  // %bb.0:
+-; CHECK-NEXT:    ld.param.v2.b16 {%rs1, %rs2}, [test_fdiv_param_0];
+-; CHECK-NEXT:    ld.param.v2.b16 {%rs3, %rs4}, [test_fdiv_param_1];
+-; CHECK-NEXT:    cvt.f32.f16 %r3, %rs4;
+-; CHECK-NEXT:    cvt.f32.f16 %r4, %rs2;
++; CHECK-NEXT:    ld.param.b32 %r2, [test_fdiv_param_1];
++; CHECK-NEXT:    ld.param.b32 %r1, [test_fdiv_param_0];
++; CHECK-NEXT:    mov.b32 {%rs1, %rs2}, %r2;
++; CHECK-NEXT:    cvt.f32.f16 %r3, %rs2;
++; CHECK-NEXT:    mov.b32 {%rs3, %rs4}, %r1;
++; CHECK-NEXT:    cvt.f32.f16 %r4, %rs4;
+ ; CHECK-NEXT:    div.rn.f32 %r5, %r4, %r3;
+ ; CHECK-NEXT:    cvt.rn.f16.f32 %rs5, %r5;
+-; CHECK-NEXT:    cvt.f32.f16 %r6, %rs3;
+-; CHECK-NEXT:    cvt.f32.f16 %r7, %rs1;
++; CHECK-NEXT:    cvt.f32.f16 %r6, %rs1;
++; CHECK-NEXT:    cvt.f32.f16 %r7, %rs3;
+ ; CHECK-NEXT:    div.rn.f32 %r8, %r7, %r6;
+ ; CHECK-NEXT:    cvt.rn.f16.f32 %rs6, %r8;
+ ; CHECK-NEXT:    mov.b32 %r9, {%rs6, %rs5};
+@@ -331,10 +345,12 @@
+ ; CHECK-NEXT:    .reg .b32 %r<18>;
+ ; CHECK-EMPTY:
+ ; CHECK-NEXT:  // %bb.0:
+-; CHECK-NEXT:    ld.param.v2.b16 {%rs1, %rs2}, [test_frem_param_0];
+-; CHECK-NEXT:    ld.param.v2.b16 {%rs3, %rs4}, [test_frem_param_1];
+-; CHECK-NEXT:    cvt.f32.f16 %r3, %rs4;
+-; CHECK-NEXT:    cvt.f32.f16 %r4, %rs2;
++; CHECK-NEXT:    ld.param.b32 %r2, [test_frem_param_1];
++; CHECK-NEXT:    ld.param.b32 %r1, [test_frem_param_0];
++; CHECK-NEXT:    mov.b32 {%rs1, %rs2}, %r2;
++; CHECK-NEXT:    cvt.f32.f16 %r3, %rs2;
++; CHECK-NEXT:    mov.b32 {%rs3, %rs4}, %r1;
++; CHECK-NEXT:    cvt.f32.f16 %r4, %rs4;
+ ; CHECK-NEXT:    div.rn.f32 %r5, %r4, %r3;
+ ; CHECK-NEXT:    cvt.rzi.f32.f32 %r6, %r5;
+ ; CHECK-NEXT:    neg.f32 %r7, %r6;
+@@ -342,8 +358,8 @@
+ ; CHECK-NEXT:    testp.infinite.f32 %p1, %r3;
+ ; CHECK-NEXT:    selp.f32 %r9, %r4, %r8, %p1;
+ ; CHECK-NEXT:    cvt.rn.f16.f32 %rs5, %r9;
+-; CHECK-NEXT:    cvt.f32.f16 %r10, %rs3;
+-; CHECK-NEXT:    cvt.f32.f16 %r11, %rs1;
++; CHECK-NEXT:    cvt.f32.f16 %r10, %rs1;
++; CHECK-NEXT:    cvt.f32.f16 %r11, %rs3;
+ ; CHECK-NEXT:    div.rn.f32 %r12, %r11, %r10;
+ ; CHECK-NEXT:    cvt.rzi.f32.f32 %r13, %r12;
+ ; CHECK-NEXT:    neg.f32 %r14, %r13;
+@@ -535,11 +551,13 @@
+ ; CHECK-F16-NEXT:  // %bb.0:
+ ; CHECK-F16-NEXT:    ld.param.b32 %r4, [test_select_cc_param_3];
+ ; CHECK-F16-NEXT:    ld.param.b32 %r3, [test_select_cc_param_2];
+-; CHECK-F16-NEXT:    ld.param.v2.b16 {%rs1, %rs2}, [test_select_cc_param_0];
++; CHECK-F16-NEXT:    ld.param.b32 %r2, [test_select_cc_param_1];
++; CHECK-F16-NEXT:    ld.param.b32 %r1, [test_select_cc_param_0];
+ ; CHECK-F16-NEXT:    setp.neu.f16x2 %p1|%p2, %r3, %r4;
+-; CHECK-F16-NEXT:    ld.param.v2.b16 {%rs3, %rs4}, [test_select_cc_param_1];
+-; CHECK-F16-NEXT:    selp.b16 %rs5, %rs2, %rs4, %p2;
+-; CHECK-F16-NEXT:    selp.b16 %rs6, %rs1, %rs3, %p1;
++; CHECK-F16-NEXT:    mov.b32 {%rs1, %rs2}, %r2;
++; CHECK-F16-NEXT:    mov.b32 {%rs3, %rs4}, %r1;
++; CHECK-F16-NEXT:    selp.b16 %rs5, %rs4, %rs2, %p2;
++; CHECK-F16-NEXT:    selp.b16 %rs6, %rs3, %rs1, %p1;
+ ; CHECK-F16-NEXT:    st.param.v2.b16 [func_retval0], {%rs6, %rs5};
+ ; CHECK-F16-NEXT:    ret;
+ ;
+@@ -550,18 +568,22 @@
+ ; CHECK-NOF16-NEXT:    .reg .b32 %r<9>;
+ ; CHECK-NOF16-EMPTY:
+ ; CHECK-NOF16-NEXT:  // %bb.0:
+-; CHECK-NOF16-NEXT:    ld.param.v2.b16 {%rs1, %rs2}, [test_select_cc_param_0];
+-; CHECK-NOF16-NEXT:    ld.param.v2.b16 {%rs3, %rs4}, [test_select_cc_param_3];
+-; CHECK-NOF16-NEXT:    cvt.f32.f16 %r5, %rs3;
+-; CHECK-NOF16-NEXT:    ld.param.v2.b16 {%rs5, %rs6}, [test_select_cc_param_2];
+-; CHECK-NOF16-NEXT:    cvt.f32.f16 %r6, %rs5;
++; CHECK-NOF16-NEXT:    ld.param.b32 %r4, [test_select_cc_param_3];
++; CHECK-NOF16-NEXT:    ld.param.b32 %r3, [test_select_cc_param_2];
++; CHECK-NOF16-NEXT:    ld.param.b32 %r2, [test_select_cc_param_1];
++; CHECK-NOF16-NEXT:    ld.param.b32 %r1, [test_select_cc_param_0];
++; CHECK-NOF16-NEXT:    mov.b32 {%rs1, %rs2}, %r4;
++; CHECK-NOF16-NEXT:    cvt.f32.f16 %r5, %rs1;
++; CHECK-NOF16-NEXT:    mov.b32 {%rs3, %rs4}, %r3;
++; CHECK-NOF16-NEXT:    cvt.f32.f16 %r6, %rs3;
+ ; CHECK-NOF16-NEXT:    setp.neu.f32 %p1, %r6, %r5;
+-; CHECK-NOF16-NEXT:    cvt.f32.f16 %r7, %rs4;
+-; CHECK-NOF16-NEXT:    cvt.f32.f16 %r8, %rs6;
++; CHECK-NOF16-NEXT:    cvt.f32.f16 %r7, %rs2;
++; CHECK-NOF16-NEXT:    cvt.f32.f16 %r8, %rs4;
+ ; CHECK-NOF16-NEXT:    setp.neu.f32 %p2, %r8, %r7;
+-; CHECK-NOF16-NEXT:    ld.param.v2.b16 {%rs7, %rs8}, [test_select_cc_param_1];
+-; CHECK-NOF16-NEXT:    selp.b16 %rs9, %rs2, %rs8, %p2;
+-; CHECK-NOF16-NEXT:    selp.b16 %rs10, %rs1, %rs7, %p1;
++; CHECK-NOF16-NEXT:    mov.b32 {%rs5, %rs6}, %r2;
++; CHECK-NOF16-NEXT:    mov.b32 {%rs7, %rs8}, %r1;
++; CHECK-NOF16-NEXT:    selp.b16 %rs9, %rs8, %rs6, %p2;
++; CHECK-NOF16-NEXT:    selp.b16 %rs10, %rs7, %rs5, %p1;
+ ; CHECK-NOF16-NEXT:    st.param.v2.b16 [func_retval0], {%rs10, %rs9};
+ ; CHECK-NOF16-NEXT:    ret;
+   %cc = fcmp une <2 x half> %c, %d
+@@ -579,11 +601,13 @@
+ ; CHECK-F16-NEXT:  // %bb.0:
+ ; CHECK-F16-NEXT:    ld.param.b32 %r2, [test_select_cc_f32_f16_param_3];
+ ; CHECK-F16-NEXT:    ld.param.b32 %r1, [test_select_cc_f32_f16_param_2];
+-; CHECK-F16-NEXT:    ld.param.v2.b32 {%r3, %r4}, [test_select_cc_f32_f16_param_0];
++; CHECK-F16-NEXT:    ld.param.b64 %rd2, [test_select_cc_f32_f16_param_1];
++; CHECK-F16-NEXT:    ld.param.b64 %rd1, [test_select_cc_f32_f16_param_0];
+ ; CHECK-F16-NEXT:    setp.neu.f16x2 %p1|%p2, %r1, %r2;
+-; CHECK-F16-NEXT:    ld.param.v2.b32 {%r5, %r6}, [test_select_cc_f32_f16_param_1];
+-; CHECK-F16-NEXT:    selp.f32 %r7, %r4, %r6, %p2;
+-; CHECK-F16-NEXT:    selp.f32 %r8, %r3, %r5, %p1;
++; CHECK-F16-NEXT:    mov.b64 {%r3, %r4}, %rd2;
++; CHECK-F16-NEXT:    mov.b64 {%r5, %r6}, %rd1;
++; CHECK-F16-NEXT:    selp.f32 %r7, %r6, %r4, %p2;
++; CHECK-F16-NEXT:    selp.f32 %r8, %r5, %r3, %p1;
+ ; CHECK-F16-NEXT:    st.param.v2.b32 [func_retval0], {%r8, %r7};
+ ; CHECK-F16-NEXT:    ret;
+ ;
+@@ -595,18 +619,22 @@
+ ; CHECK-NOF16-NEXT:    .reg .b64 %rd<3>;
+ ; CHECK-NOF16-EMPTY:
+ ; CHECK-NOF16-NEXT:  // %bb.0:
+-; CHECK-NOF16-NEXT:    ld.param.v2.b32 {%r3, %r4}, [test_select_cc_f32_f16_param_0];
+-; CHECK-NOF16-NEXT:    ld.param.v2.b16 {%rs1, %rs2}, [test_select_cc_f32_f16_param_3];
+-; CHECK-NOF16-NEXT:    cvt.f32.f16 %r5, %rs1;
+-; CHECK-NOF16-NEXT:    ld.param.v2.b16 {%rs3, %rs4}, [test_select_cc_f32_f16_param_2];
+-; CHECK-NOF16-NEXT:    cvt.f32.f16 %r6, %rs3;
+-; CHECK-NOF16-NEXT:    setp.neu.f32 %p1, %r6, %r5;
+-; CHECK-NOF16-NEXT:    cvt.f32.f16 %r7, %rs2;
+-; CHECK-NOF16-NEXT:    cvt.f32.f16 %r8, %rs4;
+-; CHECK-NOF16-NEXT:    setp.neu.f32 %p2, %r8, %r7;
+-; CHECK-NOF16-NEXT:    ld.param.v2.b32 {%r9, %r10}, [test_select_cc_f32_f16_param_1];
+-; CHECK-NOF16-NEXT:    selp.f32 %r11, %r4, %r10, %p2;
+-; CHECK-NOF16-NEXT:    selp.f32 %r12, %r3, %r9, %p1;
++; CHECK-NOF16-NEXT:    ld.param.b32 %r2, [test_select_cc_f32_f16_param_3];
++; CHECK-NOF16-NEXT:    ld.param.b32 %r1, [test_select_cc_f32_f16_param_2];
++; CHECK-NOF16-NEXT:    ld.param.b64 %rd2, [test_select_cc_f32_f16_param_1];
++; CHECK-NOF16-NEXT:    ld.param.b64 %rd1, [test_select_cc_f32_f16_param_0];
++; CHECK-NOF16-NEXT:    mov.b32 {%rs1, %rs2}, %r2;
++; CHECK-NOF16-NEXT:    cvt.f32.f16 %r3, %rs1;
++; CHECK-NOF16-NEXT:    mov.b32 {%rs3, %rs4}, %r1;
++; CHECK-NOF16-NEXT:    cvt.f32.f16 %r4, %rs3;
++; CHECK-NOF16-NEXT:    setp.neu.f32 %p1, %r4, %r3;
++; CHECK-NOF16-NEXT:    cvt.f32.f16 %r5, %rs2;
++; CHECK-NOF16-NEXT:    cvt.f32.f16 %r6, %rs4;
++; CHECK-NOF16-NEXT:    setp.neu.f32 %p2, %r6, %r5;
++; CHECK-NOF16-NEXT:    mov.b64 {%r7, %r8}, %rd2;
++; CHECK-NOF16-NEXT:    mov.b64 {%r9, %r10}, %rd1;
++; CHECK-NOF16-NEXT:    selp.f32 %r11, %r10, %r8, %p2;
++; CHECK-NOF16-NEXT:    selp.f32 %r12, %r9, %r7, %p1;
+ ; CHECK-NOF16-NEXT:    st.param.v2.b32 [func_retval0], {%r12, %r11};
+ ; CHECK-NOF16-NEXT:    ret;
+                                            <2 x half> %c, <2 x half> %d) #0 {
+@@ -624,14 +652,18 @@
+ ; CHECK-NEXT:    .reg .b64 %rd<3>;
+ ; CHECK-EMPTY:
+ ; CHECK-NEXT:  // %bb.0:
+-; CHECK-NEXT:    ld.param.v2.b16 {%rs1, %rs2}, [test_select_cc_f16_f32_param_0];
+-; CHECK-NEXT:    ld.param.v2.b32 {%r3, %r4}, [test_select_cc_f16_f32_param_2];
+-; CHECK-NEXT:    ld.param.v2.b32 {%r5, %r6}, [test_select_cc_f16_f32_param_3];
+-; CHECK-NEXT:    setp.neu.f32 %p1, %r3, %r5;
+-; CHECK-NEXT:    setp.neu.f32 %p2, %r4, %r6;
+-; CHECK-NEXT:    ld.param.v2.b16 {%rs3, %rs4}, [test_select_cc_f16_f32_param_1];
+-; CHECK-NEXT:    selp.b16 %rs5, %rs2, %rs4, %p2;
+-; CHECK-NEXT:    selp.b16 %rs6, %rs1, %rs3, %p1;
++; CHECK-NEXT:    ld.param.b64 %rd2, [test_select_cc_f16_f32_param_3];
++; CHECK-NEXT:    ld.param.b64 %rd1, [test_select_cc_f16_f32_param_2];
++; CHECK-NEXT:    ld.param.b32 %r2, [test_select_cc_f16_f32_param_1];
++; CHECK-NEXT:    ld.param.b32 %r1, [test_select_cc_f16_f32_param_0];
++; CHECK-NEXT:    mov.b64 {%r3, %r4}, %rd2;
++; CHECK-NEXT:    mov.b64 {%r5, %r6}, %rd1;
++; CHECK-NEXT:    setp.neu.f32 %p1, %r5, %r3;
++; CHECK-NEXT:    setp.neu.f32 %p2, %r6, %r4;
++; CHECK-NEXT:    mov.b32 {%rs1, %rs2}, %r2;
++; CHECK-NEXT:    mov.b32 {%rs3, %rs4}, %r1;
++; CHECK-NEXT:    selp.b16 %rs5, %rs4, %rs2, %p2;
++; CHECK-NEXT:    selp.b16 %rs6, %rs3, %rs1, %p1;
+ ; CHECK-NEXT:    st.param.v2.b16 [func_retval0], {%rs6, %rs5};
+ ; CHECK-NEXT:    ret;
+                                           <2 x float> %c, <2 x float> %d) #0 {
+@@ -664,13 +696,15 @@
+ ; CHECK-NOF16-NEXT:    .reg .b32 %r<7>;
+ ; CHECK-NOF16-EMPTY:
+ ; CHECK-NOF16-NEXT:  // %bb.0:
+-; CHECK-NOF16-NEXT:    ld.param.v2.b16 {%rs1, %rs2}, [test_fcmp_une_param_0];
+-; CHECK-NOF16-NEXT:    ld.param.v2.b16 {%rs3, %rs4}, [test_fcmp_une_param_1];
+-; CHECK-NOF16-NEXT:    cvt.f32.f16 %r3, %rs4;
+-; CHECK-NOF16-NEXT:    cvt.f32.f16 %r4, %rs2;
++; CHECK-NOF16-NEXT:    ld.param.b32 %r2, [test_fcmp_une_param_1];
++; CHECK-NOF16-NEXT:    ld.param.b32 %r1, [test_fcmp_une_param_0];
++; CHECK-NOF16-NEXT:    mov.b32 {%rs1, %rs2}, %r2;
++; CHECK-NOF16-NEXT:    cvt.f32.f16 %r3, %rs2;
++; CHECK-NOF16-NEXT:    mov.b32 {%rs3, %rs4}, %r1;
++; CHECK-NOF16-NEXT:    cvt.f32.f16 %r4, %rs4;
+ ; CHECK-NOF16-NEXT:    setp.neu.f32 %p1, %r4, %r3;
+-; CHECK-NOF16-NEXT:    cvt.f32.f16 %r5, %rs3;
+-; CHECK-NOF16-NEXT:    cvt.f32.f16 %r6, %rs1;
++; CHECK-NOF16-NEXT:    cvt.f32.f16 %r5, %rs1;
++; CHECK-NOF16-NEXT:    cvt.f32.f16 %r6, %rs3;
+ ; CHECK-NOF16-NEXT:    setp.neu.f32 %p2, %r6, %r5;
+ ; CHECK-NOF16-NEXT:    selp.b16 %rs5, -1, 0, %p2;
+ ; CHECK-NOF16-NEXT:    st.param.b8 [func_retval0], %rs5;
+@@ -705,13 +739,15 @@
+ ; CHECK-NOF16-NEXT:    .reg .b32 %r<7>;
+ ; CHECK-NOF16-EMPTY:
+ ; CHECK-NOF16-NEXT:  // %bb.0:
+-; CHECK-NOF16-NEXT:    ld.param.v2.b16 {%rs1, %rs2}, [test_fcmp_ueq_param_0];
+-; CHECK-NOF16-NEXT:    ld.param.v2.b16 {%rs3, %rs4}, [test_fcmp_ueq_param_1];
+-; CHECK-NOF16-NEXT:    cvt.f32.f16 %r3, %rs4;
+-; CHECK-NOF16-NEXT:    cvt.f32.f16 %r4, %rs2;
++; CHECK-NOF16-NEXT:    ld.param.b32 %r2, [test_fcmp_ueq_param_1];
++; CHECK-NOF16-NEXT:    ld.param.b32 %r1, [test_fcmp_ueq_param_0];
++; CHECK-NOF16-NEXT:    mov.b32 {%rs1, %rs2}, %r2;
++; CHECK-NOF16-NEXT:    cvt.f32.f16 %r3, %rs2;
++; CHECK-NOF16-NEXT:    mov.b32 {%rs3, %rs4}, %r1;
++; CHECK-NOF16-NEXT:    cvt.f32.f16 %r4, %rs4;
+ ; CHECK-NOF16-NEXT:    setp.equ.f32 %p1, %r4, %r3;
+-; CHECK-NOF16-NEXT:    cvt.f32.f16 %r5, %rs3;
+-; CHECK-NOF16-NEXT:    cvt.f32.f16 %r6, %rs1;
++; CHECK-NOF16-NEXT:    cvt.f32.f16 %r5, %rs1;
++; CHECK-NOF16-NEXT:    cvt.f32.f16 %r6, %rs3;
+ ; CHECK-NOF16-NEXT:    setp.equ.f32 %p2, %r6, %r5;
+ ; CHECK-NOF16-NEXT:    selp.b16 %rs5, -1, 0, %p2;
+ ; CHECK-NOF16-NEXT:    st.param.b8 [func_retval0], %rs5;
+@@ -746,13 +782,15 @@
+ ; CHECK-NOF16-NEXT:    .reg .b32 %r<7>;
+ ; CHECK-NOF16-EMPTY:
+ ; CHECK-NOF16-NEXT:  // %bb.0:
+-; CHECK-NOF16-NEXT:    ld.param.v2.b16 {%rs1, %rs2}, [test_fcmp_ugt_param_0];
+-; CHECK-NOF16-NEXT:    ld.param.v2.b16 {%rs3, %rs4}, [test_fcmp_ugt_param_1];
+-; CHECK-NOF16-NEXT:    cvt.f32.f16 %r3, %rs4;
+-; CHECK-NOF16-NEXT:    cvt.f32.f16 %r4, %rs2;
++; CHECK-NOF16-NEXT:    ld.param.b32 %r2, [test_fcmp_ugt_param_1];
++; CHECK-NOF16-NEXT:    ld.param.b32 %r1, [test_fcmp_ugt_param_0];
++; CHECK-NOF16-NEXT:    mov.b32 {%rs1, %rs2}, %r2;
++; CHECK-NOF16-NEXT:    cvt.f32.f16 %r3, %rs2;
++; CHECK-NOF16-NEXT:    mov.b32 {%rs3, %rs4}, %r1;
++; CHECK-NOF16-NEXT:    cvt.f32.f16 %r4, %rs4;
+ ; CHECK-NOF16-NEXT:    setp.gtu.f32 %p1, %r4, %r3;
+-; CHECK-NOF16-NEXT:    cvt.f32.f16 %r5, %rs3;
+-; CHECK-NOF16-NEXT:    cvt.f32.f16 %r6, %rs1;
++; CHECK-NOF16-NEXT:    cvt.f32.f16 %r5, %rs1;
++; CHECK-NOF16-NEXT:    cvt.f32.f16 %r6, %rs3;
+ ; CHECK-NOF16-NEXT:    setp.gtu.f32 %p2, %r6, %r5;
+ ; CHECK-NOF16-NEXT:    selp.b16 %rs5, -1, 0, %p2;
+ ; CHECK-NOF16-NEXT:    st.param.b8 [func_retval0], %rs5;
+@@ -787,13 +825,15 @@
+ ; CHECK-NOF16-NEXT:    .reg .b32 %r<7>;
+ ; CHECK-NOF16-EMPTY:
+ ; CHECK-NOF16-NEXT:  // %bb.0:
+-; CHECK-NOF16-NEXT:    ld.param.v2.b16 {%rs1, %rs2}, [test_fcmp_uge_param_0];
+-; CHECK-NOF16-NEXT:    ld.param.v2.b16 {%rs3, %rs4}, [test_fcmp_uge_param_1];
+-; CHECK-NOF16-NEXT:    cvt.f32.f16 %r3, %rs4;
+-; CHECK-NOF16-NEXT:    cvt.f32.f16 %r4, %rs2;
++; CHECK-NOF16-NEXT:    ld.param.b32 %r2, [test_fcmp_uge_param_1];
++; CHECK-NOF16-NEXT:    ld.param.b32 %r1, [test_fcmp_uge_param_0];
++; CHECK-NOF16-NEXT:    mov.b32 {%rs1, %rs2}, %r2;
++; CHECK-NOF16-NEXT:    cvt.f32.f16 %r3, %rs2;
++; CHECK-NOF16-NEXT:    mov.b32 {%rs3, %rs4}, %r1;
++; CHECK-NOF16-NEXT:    cvt.f32.f16 %r4, %rs4;
+ ; CHECK-NOF16-NEXT:    setp.geu.f32 %p1, %r4, %r3;
+-; CHECK-NOF16-NEXT:    cvt.f32.f16 %r5, %rs3;
+-; CHECK-NOF16-NEXT:    cvt.f32.f16 %r6, %rs1;
++; CHECK-NOF16-NEXT:    cvt.f32.f16 %r5, %rs1;
++; CHECK-NOF16-NEXT:    cvt.f32.f16 %r6, %rs3;
+ ; CHECK-NOF16-NEXT:    setp.geu.f32 %p2, %r6, %r5;
+ ; CHECK-NOF16-NEXT:    selp.b16 %rs5, -1, 0, %p2;
+ ; CHECK-NOF16-NEXT:    st.param.b8 [func_retval0], %rs5;
+@@ -828,13 +868,15 @@
+ ; CHECK-NOF16-NEXT:    .reg .b32 %r<7>;
+ ; CHECK-NOF16-EMPTY:
+ ; CHECK-NOF16-NEXT:  // %bb.0:
+-; CHECK-NOF16-NEXT:    ld.param.v2.b16 {%rs1, %rs2}, [test_fcmp_ult_param_0];
+-; CHECK-NOF16-NEXT:    ld.param.v2.b16 {%rs3, %rs4}, [test_fcmp_ult_param_1];
+-; CHECK-NOF16-NEXT:    cvt.f32.f16 %r3, %rs4;
+-; CHECK-NOF16-NEXT:    cvt.f32.f16 %r4, %rs2;
++; CHECK-NOF16-NEXT:    ld.param.b32 %r2, [test_fcmp_ult_param_1];
++; CHECK-NOF16-NEXT:    ld.param.b32 %r1, [test_fcmp_ult_param_0];
++; CHECK-NOF16-NEXT:    mov.b32 {%rs1, %rs2}, %r2;
++; CHECK-NOF16-NEXT:    cvt.f32.f16 %r3, %rs2;
++; CHECK-NOF16-NEXT:    mov.b32 {%rs3, %rs4}, %r1;
++; CHECK-NOF16-NEXT:    cvt.f32.f16 %r4, %rs4;
+ ; CHECK-NOF16-NEXT:    setp.ltu.f32 %p1, %r4, %r3;
+-; CHECK-NOF16-NEXT:    cvt.f32.f16 %r5, %rs3;
+-; CHECK-NOF16-NEXT:    cvt.f32.f16 %r6, %rs1;
++; CHECK-NOF16-NEXT:    cvt.f32.f16 %r5, %rs1;
++; CHECK-NOF16-NEXT:    cvt.f32.f16 %r6, %rs3;
+ ; CHECK-NOF16-NEXT:    setp.ltu.f32 %p2, %r6, %r5;
+ ; CHECK-NOF16-NEXT:    selp.b16 %rs5, -1, 0, %p2;
+ ; CHECK-NOF16-NEXT:    st.param.b8 [func_retval0], %rs5;
+@@ -869,13 +911,15 @@
+ ; CHECK-NOF16-NEXT:    .reg .b32 %r<7>;
+ ; CHECK-NOF16-EMPTY:
+ ; CHECK-NOF16-NEXT:  // %bb.0:
+-; CHECK-NOF16-NEXT:    ld.param.v2.b16 {%rs1, %rs2}, [test_fcmp_ule_param_0];
+-; CHECK-NOF16-NEXT:    ld.param.v2.b16 {%rs3, %rs4}, [test_fcmp_ule_param_1];
+-; CHECK-NOF16-NEXT:    cvt.f32.f16 %r3, %rs4;
+-; CHECK-NOF16-NEXT:    cvt.f32.f16 %r4, %rs2;
++; CHECK-NOF16-NEXT:    ld.param.b32 %r2, [test_fcmp_ule_param_1];
++; CHECK-NOF16-NEXT:    ld.param.b32 %r1, [test_fcmp_ule_param_0];
++; CHECK-NOF16-NEXT:    mov.b32 {%rs1, %rs2}, %r2;
++; CHECK-NOF16-NEXT:    cvt.f32.f16 %r3, %rs2;
++; CHECK-NOF16-NEXT:    mov.b32 {%rs3, %rs4}, %r1;
++; CHECK-NOF16-NEXT:    cvt.f32.f16 %r4, %rs4;
+ ; CHECK-NOF16-NEXT:    setp.leu.f32 %p1, %r4, %r3;
+-; CHECK-NOF16-NEXT:    cvt.f32.f16 %r5, %rs3;
+-; CHECK-NOF16-NEXT:    cvt.f32.f16 %r6, %rs1;
++; CHECK-NOF16-NEXT:    cvt.f32.f16 %r5, %rs1;
++; CHECK-NOF16-NEXT:    cvt.f32.f16 %r6, %rs3;
+ ; CHECK-NOF16-NEXT:    setp.leu.f32 %p2, %r6, %r5;
+ ; CHECK-NOF16-NEXT:    selp.b16 %rs5, -1, 0, %p2;
+ ; CHECK-NOF16-NEXT:    st.param.b8 [func_retval0], %rs5;
+@@ -911,13 +955,15 @@
+ ; CHECK-NOF16-NEXT:    .reg .b32 %r<7>;
+ ; CHECK-NOF16-EMPTY:
+ ; CHECK-NOF16-NEXT:  // %bb.0:
+-; CHECK-NOF16-NEXT:    ld.param.v2.b16 {%rs1, %rs2}, [test_fcmp_uno_param_0];
+-; CHECK-NOF16-NEXT:    ld.param.v2.b16 {%rs3, %rs4}, [test_fcmp_uno_param_1];
+-; CHECK-NOF16-NEXT:    cvt.f32.f16 %r3, %rs4;
+-; CHECK-NOF16-NEXT:    cvt.f32.f16 %r4, %rs2;
++; CHECK-NOF16-NEXT:    ld.param.b32 %r2, [test_fcmp_uno_param_1];
++; CHECK-NOF16-NEXT:    ld.param.b32 %r1, [test_fcmp_uno_param_0];
++; CHECK-NOF16-NEXT:    mov.b32 {%rs1, %rs2}, %r2;
++; CHECK-NOF16-NEXT:    cvt.f32.f16 %r3, %rs2;
++; CHECK-NOF16-NEXT:    mov.b32 {%rs3, %rs4}, %r1;
++; CHECK-NOF16-NEXT:    cvt.f32.f16 %r4, %rs4;
+ ; CHECK-NOF16-NEXT:    setp.nan.f32 %p1, %r4, %r3;
+-; CHECK-NOF16-NEXT:    cvt.f32.f16 %r5, %rs3;
+-; CHECK-NOF16-NEXT:    cvt.f32.f16 %r6, %rs1;
++; CHECK-NOF16-NEXT:    cvt.f32.f16 %r5, %rs1;
++; CHECK-NOF16-NEXT:    cvt.f32.f16 %r6, %rs3;
+ ; CHECK-NOF16-NEXT:    setp.nan.f32 %p2, %r6, %r5;
+ ; CHECK-NOF16-NEXT:    selp.b16 %rs5, -1, 0, %p2;
+ ; CHECK-NOF16-NEXT:    st.param.b8 [func_retval0], %rs5;
+@@ -952,13 +998,15 @@
+ ; CHECK-NOF16-NEXT:    .reg .b32 %r<7>;
+ ; CHECK-NOF16-EMPTY:
+ ; CHECK-NOF16-NEXT:  // %bb.0:
+-; CHECK-NOF16-NEXT:    ld.param.v2.b16 {%rs1, %rs2}, [test_fcmp_one_param_0];
+-; CHECK-NOF16-NEXT:    ld.param.v2.b16 {%rs3, %rs4}, [test_fcmp_one_param_1];
+-; CHECK-NOF16-NEXT:    cvt.f32.f16 %r3, %rs4;
+-; CHECK-NOF16-NEXT:    cvt.f32.f16 %r4, %rs2;
++; CHECK-NOF16-NEXT:    ld.param.b32 %r2, [test_fcmp_one_param_1];
++; CHECK-NOF16-NEXT:    ld.param.b32 %r1, [test_fcmp_one_param_0];
++; CHECK-NOF16-NEXT:    mov.b32 {%rs1, %rs2}, %r2;
++; CHECK-NOF16-NEXT:    cvt.f32.f16 %r3, %rs2;
++; CHECK-NOF16-NEXT:    mov.b32 {%rs3, %rs4}, %r1;
++; CHECK-NOF16-NEXT:    cvt.f32.f16 %r4, %rs4;
+ ; CHECK-NOF16-NEXT:    setp.ne.f32 %p1, %r4, %r3;
+-; CHECK-NOF16-NEXT:    cvt.f32.f16 %r5, %rs3;
+-; CHECK-NOF16-NEXT:    cvt.f32.f16 %r6, %rs1;
++; CHECK-NOF16-NEXT:    cvt.f32.f16 %r5, %rs1;
++; CHECK-NOF16-NEXT:    cvt.f32.f16 %r6, %rs3;
+ ; CHECK-NOF16-NEXT:    setp.ne.f32 %p2, %r6, %r5;
+ ; CHECK-NOF16-NEXT:    selp.b16 %rs5, -1, 0, %p2;
+ ; CHECK-NOF16-NEXT:    st.param.b8 [func_retval0], %rs5;
+@@ -993,13 +1041,15 @@
+ ; CHECK-NOF16-NEXT:    .reg .b32 %r<7>;
+ ; CHECK-NOF16-EMPTY:
+ ; CHECK-NOF16-NEXT:  // %bb.0:
+-; CHECK-NOF16-NEXT:    ld.param.v2.b16 {%rs1, %rs2}, [test_fcmp_oeq_param_0];
+-; CHECK-NOF16-NEXT:    ld.param.v2.b16 {%rs3, %rs4}, [test_fcmp_oeq_param_1];
+-; CHECK-NOF16-NEXT:    cvt.f32.f16 %r3, %rs4;
+-; CHECK-NOF16-NEXT:    cvt.f32.f16 %r4, %rs2;
++; CHECK-NOF16-NEXT:    ld.param.b32 %r2, [test_fcmp_oeq_param_1];
++; CHECK-NOF16-NEXT:    ld.param.b32 %r1, [test_fcmp_oeq_param_0];
++; CHECK-NOF16-NEXT:    mov.b32 {%rs1, %rs2}, %r2;
++; CHECK-NOF16-NEXT:    cvt.f32.f16 %r3, %rs2;
++; CHECK-NOF16-NEXT:    mov.b32 {%rs3, %rs4}, %r1;
++; CHECK-NOF16-NEXT:    cvt.f32.f16 %r4, %rs4;
+ ; CHECK-NOF16-NEXT:    setp.eq.f32 %p1, %r4, %r3;
+-; CHECK-NOF16-NEXT:    cvt.f32.f16 %r5, %rs3;
+-; CHECK-NOF16-NEXT:    cvt.f32.f16 %r6, %rs1;
++; CHECK-NOF16-NEXT:    cvt.f32.f16 %r5, %rs1;
++; CHECK-NOF16-NEXT:    cvt.f32.f16 %r6, %rs3;
+ ; CHECK-NOF16-NEXT:    setp.eq.f32 %p2, %r6, %r5;
+ ; CHECK-NOF16-NEXT:    selp.b16 %rs5, -1, 0, %p2;
+ ; CHECK-NOF16-NEXT:    st.param.b8 [func_retval0], %rs5;
+@@ -1034,13 +1084,15 @@
+ ; CHECK-NOF16-NEXT:    .reg .b32 %r<7>;
+ ; CHECK-NOF16-EMPTY:
+ ; CHECK-NOF16-NEXT:  // %bb.0:
+-; CHECK-NOF16-NEXT:    ld.param.v2.b16 {%rs1, %rs2}, [test_fcmp_ogt_param_0];
+-; CHECK-NOF16-NEXT:    ld.param.v2.b16 {%rs3, %rs4}, [test_fcmp_ogt_param_1];
+-; CHECK-NOF16-NEXT:    cvt.f32.f16 %r3, %rs4;
+-; CHECK-NOF16-NEXT:    cvt.f32.f16 %r4, %rs2;
++; CHECK-NOF16-NEXT:    ld.param.b32 %r2, [test_fcmp_ogt_param_1];
++; CHECK-NOF16-NEXT:    ld.param.b32 %r1, [test_fcmp_ogt_param_0];
++; CHECK-NOF16-NEXT:    mov.b32 {%rs1, %rs2}, %r2;
++; CHECK-NOF16-NEXT:    cvt.f32.f16 %r3, %rs2;
++; CHECK-NOF16-NEXT:    mov.b32 {%rs3, %rs4}, %r1;
++; CHECK-NOF16-NEXT:    cvt.f32.f16 %r4, %rs4;
+ ; CHECK-NOF16-NEXT:    setp.gt.f32 %p1, %r4, %r3;
+-; CHECK-NOF16-NEXT:    cvt.f32.f16 %r5, %rs3;
+-; CHECK-NOF16-NEXT:    cvt.f32.f16 %r6, %rs1;
++; CHECK-NOF16-NEXT:    cvt.f32.f16 %r5, %rs1;
++; CHECK-NOF16-NEXT:    cvt.f32.f16 %r6, %rs3;
+ ; CHECK-NOF16-NEXT:    setp.gt.f32 %p2, %r6, %r5;
+ ; CHECK-NOF16-NEXT:    selp.b16 %rs5, -1, 0, %p2;
+ ; CHECK-NOF16-NEXT:    st.param.b8 [func_retval0], %rs5;
+@@ -1075,13 +1127,15 @@
+ ; CHECK-NOF16-NEXT:    .reg .b32 %r<7>;
+ ; CHECK-NOF16-EMPTY:
+ ; CHECK-NOF16-NEXT:  // %bb.0:
+-; CHECK-NOF16-NEXT:    ld.param.v2.b16 {%rs1, %rs2}, [test_fcmp_oge_param_0];
+-; CHECK-NOF16-NEXT:    ld.param.v2.b16 {%rs3, %rs4}, [test_fcmp_oge_param_1];
+-; CHECK-NOF16-NEXT:    cvt.f32.f16 %r3, %rs4;
+-; CHECK-NOF16-NEXT:    cvt.f32.f16 %r4, %rs2;
++; CHECK-NOF16-NEXT:    ld.param.b32 %r2, [test_fcmp_oge_param_1];
++; CHECK-NOF16-NEXT:    ld.param.b32 %r1, [test_fcmp_oge_param_0];
++; CHECK-NOF16-NEXT:    mov.b32 {%rs1, %rs2}, %r2;
++; CHECK-NOF16-NEXT:    cvt.f32.f16 %r3, %rs2;
++; CHECK-NOF16-NEXT:    mov.b32 {%rs3, %rs4}, %r1;
++; CHECK-NOF16-NEXT:    cvt.f32.f16 %r4, %rs4;
+ ; CHECK-NOF16-NEXT:    setp.ge.f32 %p1, %r4, %r3;
+-; CHECK-NOF16-NEXT:    cvt.f32.f16 %r5, %rs3;
+-; CHECK-NOF16-NEXT:    cvt.f32.f16 %r6, %rs1;
++; CHECK-NOF16-NEXT:    cvt.f32.f16 %r5, %rs1;
++; CHECK-NOF16-NEXT:    cvt.f32.f16 %r6, %rs3;
+ ; CHECK-NOF16-NEXT:    setp.ge.f32 %p2, %r6, %r5;
+ ; CHECK-NOF16-NEXT:    selp.b16 %rs5, -1, 0, %p2;
+ ; CHECK-NOF16-NEXT:    st.param.b8 [func_retval0], %rs5;
+@@ -1116,13 +1170,15 @@
+ ; CHECK-NOF16-NEXT:    .reg .b32 %r<7>;
+ ; CHECK-NOF16-EMPTY:
+ ; CHECK-NOF16-NEXT:  // %bb.0:
+-; CHECK-NOF16-NEXT:    ld.param.v2.b16 {%rs1, %rs2}, [test_fcmp_olt_param_0];
+-; CHECK-NOF16-NEXT:    ld.param.v2.b16 {%rs3, %rs4}, [test_fcmp_olt_param_1];
+-; CHECK-NOF16-NEXT:    cvt.f32.f16 %r3, %rs4;
+-; CHECK-NOF16-NEXT:    cvt.f32.f16 %r4, %rs2;
++; CHECK-NOF16-NEXT:    ld.param.b32 %r2, [test_fcmp_olt_param_1];
++; CHECK-NOF16-NEXT:    ld.param.b32 %r1, [test_fcmp_olt_param_0];
++; CHECK-NOF16-NEXT:    mov.b32 {%rs1, %rs2}, %r2;
++; CHECK-NOF16-NEXT:    cvt.f32.f16 %r3, %rs2;
++; CHECK-NOF16-NEXT:    mov.b32 {%rs3, %rs4}, %r1;
++; CHECK-NOF16-NEXT:    cvt.f32.f16 %r4, %rs4;
+ ; CHECK-NOF16-NEXT:    setp.lt.f32 %p1, %r4, %r3;
+-; CHECK-NOF16-NEXT:    cvt.f32.f16 %r5, %rs3;
+-; CHECK-NOF16-NEXT:    cvt.f32.f16 %r6, %rs1;
++; CHECK-NOF16-NEXT:    cvt.f32.f16 %r5, %rs1;
++; CHECK-NOF16-NEXT:    cvt.f32.f16 %r6, %rs3;
+ ; CHECK-NOF16-NEXT:    setp.lt.f32 %p2, %r6, %r5;
+ ; CHECK-NOF16-NEXT:    selp.b16 %rs5, -1, 0, %p2;
+ ; CHECK-NOF16-NEXT:    st.param.b8 [func_retval0], %rs5;
+@@ -1157,13 +1213,15 @@
+ ; CHECK-NOF16-NEXT:    .reg .b32 %r<7>;
+ ; CHECK-NOF16-EMPTY:
+ ; CHECK-NOF16-NEXT:  // %bb.0:
+-; CHECK-NOF16-NEXT:    ld.param.v2.b16 {%rs1, %rs2}, [test_fcmp_ole_param_0];
+-; CHECK-NOF16-NEXT:    ld.param.v2.b16 {%rs3, %rs4}, [test_fcmp_ole_param_1];
+-; CHECK-NOF16-NEXT:    cvt.f32.f16 %r3, %rs4;
+-; CHECK-NOF16-NEXT:    cvt.f32.f16 %r4, %rs2;
++; CHECK-NOF16-NEXT:    ld.param.b32 %r2, [test_fcmp_ole_param_1];
++; CHECK-NOF16-NEXT:    ld.param.b32 %r1, [test_fcmp_ole_param_0];
++; CHECK-NOF16-NEXT:    mov.b32 {%rs1, %rs2}, %r2;
++; CHECK-NOF16-NEXT:    cvt.f32.f16 %r3, %rs2;
++; CHECK-NOF16-NEXT:    mov.b32 {%rs3, %rs4}, %r1;
++; CHECK-NOF16-NEXT:    cvt.f32.f16 %r4, %rs4;
+ ; CHECK-NOF16-NEXT:    setp.le.f32 %p1, %r4, %r3;
+-; CHECK-NOF16-NEXT:    cvt.f32.f16 %r5, %rs3;
+-; CHECK-NOF16-NEXT:    cvt.f32.f16 %r6, %rs1;
++; CHECK-NOF16-NEXT:    cvt.f32.f16 %r5, %rs1;
++; CHECK-NOF16-NEXT:    cvt.f32.f16 %r6, %rs3;
+ ; CHECK-NOF16-NEXT:    setp.le.f32 %p2, %r6, %r5;
+ ; CHECK-NOF16-NEXT:    selp.b16 %rs5, -1, 0, %p2;
+ ; CHECK-NOF16-NEXT:    st.param.b8 [func_retval0], %rs5;
+@@ -1198,13 +1256,15 @@
+ ; CHECK-NOF16-NEXT:    .reg .b32 %r<7>;
+ ; CHECK-NOF16-EMPTY:
+ ; CHECK-NOF16-NEXT:  // %bb.0:
+-; CHECK-NOF16-NEXT:    ld.param.v2.b16 {%rs1, %rs2}, [test_fcmp_ord_param_0];
+-; CHECK-NOF16-NEXT:    ld.param.v2.b16 {%rs3, %rs4}, [test_fcmp_ord_param_1];
+-; CHECK-NOF16-NEXT:    cvt.f32.f16 %r3, %rs4;
+-; CHECK-NOF16-NEXT:    cvt.f32.f16 %r4, %rs2;
++; CHECK-NOF16-NEXT:    ld.param.b32 %r2, [test_fcmp_ord_param_1];
++; CHECK-NOF16-NEXT:    ld.param.b32 %r1, [test_fcmp_ord_param_0];
++; CHECK-NOF16-NEXT:    mov.b32 {%rs1, %rs2}, %r2;
++; CHECK-NOF16-NEXT:    cvt.f32.f16 %r3, %rs2;
++; CHECK-NOF16-NEXT:    mov.b32 {%rs3, %rs4}, %r1;
++; CHECK-NOF16-NEXT:    cvt.f32.f16 %r4, %rs4;
+ ; CHECK-NOF16-NEXT:    setp.num.f32 %p1, %r4, %r3;
+-; CHECK-NOF16-NEXT:    cvt.f32.f16 %r5, %rs3;
+-; CHECK-NOF16-NEXT:    cvt.f32.f16 %r6, %rs1;
++; CHECK-NOF16-NEXT:    cvt.f32.f16 %r5, %rs1;
++; CHECK-NOF16-NEXT:    cvt.f32.f16 %r6, %rs3;
+ ; CHECK-NOF16-NEXT:    setp.num.f32 %p2, %r6, %r5;
+ ; CHECK-NOF16-NEXT:    selp.b16 %rs5, -1, 0, %p2;
+ ; CHECK-NOF16-NEXT:    st.param.b8 [func_retval0], %rs5;
+@@ -1222,7 +1282,8 @@
+ ; CHECK-NEXT:    .reg .b32 %r<4>;
+ ; CHECK-EMPTY:
+ ; CHECK-NEXT:  // %bb.0:
+-; CHECK-NEXT:    ld.param.v2.b16 {%rs1, %rs2}, [test_fptosi_i32_param_0];
++; CHECK-NEXT:    ld.param.b32 %r1, [test_fptosi_i32_param_0];
++; CHECK-NEXT:    mov.b32 {%rs1, %rs2}, %r1;
+ ; CHECK-NEXT:    cvt.rzi.s32.f16 %r2, %rs2;
+ ; CHECK-NEXT:    cvt.rzi.s32.f16 %r3, %rs1;
+ ; CHECK-NEXT:    st.param.v2.b32 [func_retval0], {%r3, %r2};
+@@ -1239,7 +1300,8 @@
+ ; CHECK-NEXT:    .reg .b64 %rd<3>;
+ ; CHECK-EMPTY:
+ ; CHECK-NEXT:  // %bb.0:
+-; CHECK-NEXT:    ld.param.v2.b16 {%rs1, %rs2}, [test_fptosi_i64_param_0];
++; CHECK-NEXT:    ld.param.b32 %r1, [test_fptosi_i64_param_0];
++; CHECK-NEXT:    mov.b32 {%rs1, %rs2}, %r1;
+ ; CHECK-NEXT:    cvt.rzi.s64.f16 %rd1, %rs2;
+ ; CHECK-NEXT:    cvt.rzi.s64.f16 %rd2, %rs1;
+ ; CHECK-NEXT:    st.param.v2.b64 [func_retval0], {%rd2, %rd1};
+@@ -1255,7 +1317,8 @@
+ ; CHECK-NEXT:    .reg .b32 %r<4>;
+ ; CHECK-EMPTY:
+ ; CHECK-NEXT:  // %bb.0:
+-; CHECK-NEXT:    ld.param.v2.b16 {%rs1, %rs2}, [test_fptoui_2xi32_param_0];
++; CHECK-NEXT:    ld.param.b32 %r1, [test_fptoui_2xi32_param_0];
++; CHECK-NEXT:    mov.b32 {%rs1, %rs2}, %r1;
+ ; CHECK-NEXT:    cvt.rzi.u32.f16 %r2, %rs2;
+ ; CHECK-NEXT:    cvt.rzi.u32.f16 %r3, %rs1;
+ ; CHECK-NEXT:    st.param.v2.b32 [func_retval0], {%r3, %r2};
+@@ -1272,7 +1335,8 @@
+ ; CHECK-NEXT:    .reg .b64 %rd<3>;
+ ; CHECK-EMPTY:
+ ; CHECK-NEXT:  // %bb.0:
+-; CHECK-NEXT:    ld.param.v2.b16 {%rs1, %rs2}, [test_fptoui_2xi64_param_0];
++; CHECK-NEXT:    ld.param.b32 %r1, [test_fptoui_2xi64_param_0];
++; CHECK-NEXT:    mov.b32 {%rs1, %rs2}, %r1;
+ ; CHECK-NEXT:    cvt.rzi.u64.f16 %rd1, %rs2;
+ ; CHECK-NEXT:    cvt.rzi.u64.f16 %rd2, %rs1;
+ ; CHECK-NEXT:    st.param.v2.b64 [func_retval0], {%rd2, %rd1};
+@@ -1369,16 +1433,17 @@
+ ; CHECK-NOF16-EMPTY:
+ ; CHECK-NOF16-NEXT:  // %bb.0:
+ ; CHECK-NOF16-NEXT:    ld.param.v2.b32 {%r1, %r2}, [test_uitofp_2xi32_fadd_param_0];
++; CHECK-NOF16-NEXT:    ld.param.b32 %r3, [test_uitofp_2xi32_fadd_param_1];
+ ; CHECK-NOF16-NEXT:    cvt.rn.f16.u32 %rs1, %r1;
+ ; CHECK-NOF16-NEXT:    cvt.rn.f16.u32 %rs2, %r2;
+-; CHECK-NOF16-NEXT:    ld.param.v2.b16 {%rs3, %rs4}, [test_uitofp_2xi32_fadd_param_1];
+-; CHECK-NOF16-NEXT:    cvt.f32.f16 %r4, %rs4;
+-; CHECK-NOF16-NEXT:    cvt.f32.f16 %r5, %rs2;
+-; CHECK-NOF16-NEXT:    add.rn.f32 %r6, %r4, %r5;
++; CHECK-NOF16-NEXT:    cvt.f32.f16 %r4, %rs2;
++; CHECK-NOF16-NEXT:    mov.b32 {%rs3, %rs4}, %r3;
++; CHECK-NOF16-NEXT:    cvt.f32.f16 %r5, %rs4;
++; CHECK-NOF16-NEXT:    add.rn.f32 %r6, %r5, %r4;
+ ; CHECK-NOF16-NEXT:    cvt.rn.f16.f32 %rs5, %r6;
+-; CHECK-NOF16-NEXT:    cvt.f32.f16 %r7, %rs3;
+-; CHECK-NOF16-NEXT:    cvt.f32.f16 %r8, %rs1;
+-; CHECK-NOF16-NEXT:    add.rn.f32 %r9, %r7, %r8;
++; CHECK-NOF16-NEXT:    cvt.f32.f16 %r7, %rs1;
++; CHECK-NOF16-NEXT:    cvt.f32.f16 %r8, %rs3;
++; CHECK-NOF16-NEXT:    add.rn.f32 %r9, %r8, %r7;
+ ; CHECK-NOF16-NEXT:    cvt.rn.f16.f32 %rs6, %r9;
+ ; CHECK-NOF16-NEXT:    mov.b32 %r10, {%rs6, %rs5};
+ ; CHECK-NOF16-NEXT:    st.param.b32 [func_retval0], %r10;
+@@ -1411,16 +1476,17 @@
+ ; CHECK-NOF16-EMPTY:
+ ; CHECK-NOF16-NEXT:  // %bb.0:
+ ; CHECK-NOF16-NEXT:    ld.param.v2.b32 {%r1, %r2}, [test_sitofp_2xi32_fadd_param_0];
++; CHECK-NOF16-NEXT:    ld.param.b32 %r3, [test_sitofp_2xi32_fadd_param_1];
+ ; CHECK-NOF16-NEXT:    cvt.rn.f16.s32 %rs1, %r1;
+ ; CHECK-NOF16-NEXT:    cvt.rn.f16.s32 %rs2, %r2;
+-; CHECK-NOF16-NEXT:    ld.param.v2.b16 {%rs3, %rs4}, [test_sitofp_2xi32_fadd_param_1];
+-; CHECK-NOF16-NEXT:    cvt.f32.f16 %r4, %rs4;
+-; CHECK-NOF16-NEXT:    cvt.f32.f16 %r5, %rs2;
+-; CHECK-NOF16-NEXT:    add.rn.f32 %r6, %r4, %r5;
++; CHECK-NOF16-NEXT:    cvt.f32.f16 %r4, %rs2;
++; CHECK-NOF16-NEXT:    mov.b32 {%rs3, %rs4}, %r3;
++; CHECK-NOF16-NEXT:    cvt.f32.f16 %r5, %rs4;
++; CHECK-NOF16-NEXT:    add.rn.f32 %r6, %r5, %r4;
+ ; CHECK-NOF16-NEXT:    cvt.rn.f16.f32 %rs5, %r6;
+-; CHECK-NOF16-NEXT:    cvt.f32.f16 %r7, %rs3;
+-; CHECK-NOF16-NEXT:    cvt.f32.f16 %r8, %rs1;
+-; CHECK-NOF16-NEXT:    add.rn.f32 %r9, %r7, %r8;
++; CHECK-NOF16-NEXT:    cvt.f32.f16 %r7, %rs1;
++; CHECK-NOF16-NEXT:    cvt.f32.f16 %r8, %rs3;
++; CHECK-NOF16-NEXT:    add.rn.f32 %r9, %r8, %r7;
+ ; CHECK-NOF16-NEXT:    cvt.rn.f16.f32 %rs6, %r9;
+ ; CHECK-NOF16-NEXT:    mov.b32 %r10, {%rs6, %rs5};
+ ; CHECK-NOF16-NEXT:    st.param.b32 [func_retval0], %r10;
+@@ -1433,11 +1499,16 @@
+ define <2 x half> @test_fptrunc_2xfloat(<2 x float> %a) #0 {
+ ; CHECK-LABEL: test_fptrunc_2xfloat(
+ ; CHECK:       {
++; CHECK-NEXT:    .reg .b16 %rs<3>;
++; CHECK-NEXT:    .reg .b32 %r<4>;
+ ; CHECK-NEXT:    .reg .b64 %rd<2>;
+ ; CHECK-EMPTY:
+ ; CHECK-NEXT:  // %bb.0:
+-; CHECK-NEXT:    ld.param.b64 %rd1, [test_fptrunc_2xfloat_param_0];
+-; CHECK-NEXT:    st.param.b32 [func_retval0], %rd1;
++; CHECK-NEXT:    ld.param.v2.b32 {%r1, %r2}, [test_fptrunc_2xfloat_param_0];
++; CHECK-NEXT:    cvt.rn.f16.f32 %rs1, %r2;
++; CHECK-NEXT:    cvt.rn.f16.f32 %rs2, %r1;
++; CHECK-NEXT:    mov.b32 %r3, {%rs2, %rs1};
++; CHECK-NEXT:    st.param.b32 [func_retval0], %r3;
+ ; CHECK-NEXT:    ret;
+   %r = fptrunc <2 x float> %a to <2 x half>
+   ret <2 x half> %r
+@@ -1468,7 +1539,8 @@
+ ; CHECK-NEXT:    .reg .b32 %r<4>;
+ ; CHECK-EMPTY:
+ ; CHECK-NEXT:  // %bb.0:
+-; CHECK-NEXT:    ld.param.v2.b16 {%rs1, %rs2}, [test_fpext_2xfloat_param_0];
++; CHECK-NEXT:    ld.param.b32 %r1, [test_fpext_2xfloat_param_0];
++; CHECK-NEXT:    mov.b32 {%rs1, %rs2}, %r1;
+ ; CHECK-NEXT:    cvt.f32.f16 %r2, %rs2;
+ ; CHECK-NEXT:    cvt.f32.f16 %r3, %rs1;
+ ; CHECK-NEXT:    st.param.v2.b32 [func_retval0], {%r3, %r2};
+@@ -1485,7 +1557,8 @@
+ ; CHECK-NEXT:    .reg .b64 %rd<3>;
+ ; CHECK-EMPTY:
+ ; CHECK-NEXT:  // %bb.0:
+-; CHECK-NEXT:    ld.param.v2.b16 {%rs1, %rs2}, [test_fpext_2xdouble_param_0];
++; CHECK-NEXT:    ld.param.b32 %r1, [test_fpext_2xdouble_param_0];
++; CHECK-NEXT:    mov.b32 {%rs1, %rs2}, %r1;
+ ; CHECK-NEXT:    cvt.f64.f16 %rd1, %rs2;
+ ; CHECK-NEXT:    cvt.f64.f16 %rd2, %rs1;
+ ; CHECK-NEXT:    st.param.v2.b64 [func_retval0], {%rd2, %rd1};
+@@ -1578,7 +1651,8 @@
+ ; CHECK-NEXT:    .reg .b32 %r<7>;
+ ; CHECK-EMPTY:
+ ; CHECK-NEXT:  // %bb.0:
+-; CHECK-NEXT:    ld.param.v2.b16 {%rs1, %rs2}, [test_sqrt_param_0];
++; CHECK-NEXT:    ld.param.b32 %r1, [test_sqrt_param_0];
++; CHECK-NEXT:    mov.b32 {%rs1, %rs2}, %r1;
+ ; CHECK-NEXT:    cvt.f32.f16 %r2, %rs2;
+ ; CHECK-NEXT:    sqrt.rn.f32 %r3, %r2;
+ ; CHECK-NEXT:    cvt.rn.f16.f32 %rs3, %r3;
+@@ -1606,7 +1680,8 @@
+ ; CHECK-NEXT:    .reg .b32 %r<7>;
+ ; CHECK-EMPTY:
+ ; CHECK-NEXT:  // %bb.0:
+-; CHECK-NEXT:    ld.param.v2.b16 {%rs1, %rs2}, [test_sin_param_0];
++; CHECK-NEXT:    ld.param.b32 %r1, [test_sin_param_0];
++; CHECK-NEXT:    mov.b32 {%rs1, %rs2}, %r1;
+ ; CHECK-NEXT:    cvt.f32.f16 %r2, %rs2;
+ ; CHECK-NEXT:    sin.approx.f32 %r3, %r2;
+ ; CHECK-NEXT:    cvt.rn.f16.f32 %rs3, %r3;
+@@ -1627,7 +1702,8 @@
+ ; CHECK-NEXT:    .reg .b32 %r<7>;
+ ; CHECK-EMPTY:
+ ; CHECK-NEXT:  // %bb.0:
+-; CHECK-NEXT:    ld.param.v2.b16 {%rs1, %rs2}, [test_cos_param_0];
++; CHECK-NEXT:    ld.param.b32 %r1, [test_cos_param_0];
++; CHECK-NEXT:    mov.b32 {%rs1, %rs2}, %r1;
+ ; CHECK-NEXT:    cvt.f32.f16 %r2, %rs2;
+ ; CHECK-NEXT:    cos.approx.f32 %r3, %r2;
+ ; CHECK-NEXT:    cvt.rn.f16.f32 %rs3, %r3;
+@@ -1703,17 +1779,20 @@
+ ; CHECK-NOF16-NEXT:    .reg .b32 %r<13>;
+ ; CHECK-NOF16-EMPTY:
+ ; CHECK-NOF16-NEXT:  // %bb.0:
+-; CHECK-NOF16-NEXT:    ld.param.v2.b16 {%rs1, %rs2}, [test_fma_param_0];
+-; CHECK-NOF16-NEXT:    ld.param.v2.b16 {%rs3, %rs4}, [test_fma_param_2];
+-; CHECK-NOF16-NEXT:    cvt.f32.f16 %r4, %rs4;
+-; CHECK-NOF16-NEXT:    ld.param.v2.b16 {%rs5, %rs6}, [test_fma_param_1];
+-; CHECK-NOF16-NEXT:    cvt.f32.f16 %r5, %rs6;
+-; CHECK-NOF16-NEXT:    cvt.f32.f16 %r6, %rs2;
++; CHECK-NOF16-NEXT:    ld.param.b32 %r3, [test_fma_param_2];
++; CHECK-NOF16-NEXT:    ld.param.b32 %r2, [test_fma_param_1];
++; CHECK-NOF16-NEXT:    ld.param.b32 %r1, [test_fma_param_0];
++; CHECK-NOF16-NEXT:    mov.b32 {%rs1, %rs2}, %r3;
++; CHECK-NOF16-NEXT:    cvt.f32.f16 %r4, %rs2;
++; CHECK-NOF16-NEXT:    mov.b32 {%rs3, %rs4}, %r2;
++; CHECK-NOF16-NEXT:    cvt.f32.f16 %r5, %rs4;
++; CHECK-NOF16-NEXT:    mov.b32 {%rs5, %rs6}, %r1;
++; CHECK-NOF16-NEXT:    cvt.f32.f16 %r6, %rs6;
+ ; CHECK-NOF16-NEXT:    fma.rn.f32 %r7, %r6, %r5, %r4;
+ ; CHECK-NOF16-NEXT:    cvt.rn.f16.f32 %rs7, %r7;
+-; CHECK-NOF16-NEXT:    cvt.f32.f16 %r8, %rs3;
+-; CHECK-NOF16-NEXT:    cvt.f32.f16 %r9, %rs5;
+-; CHECK-NOF16-NEXT:    cvt.f32.f16 %r10, %rs1;
++; CHECK-NOF16-NEXT:    cvt.f32.f16 %r8, %rs1;
++; CHECK-NOF16-NEXT:    cvt.f32.f16 %r9, %rs3;
++; CHECK-NOF16-NEXT:    cvt.f32.f16 %r10, %rs5;
+ ; CHECK-NOF16-NEXT:    fma.rn.f32 %r11, %r10, %r9, %r8;
+ ; CHECK-NOF16-NEXT:    cvt.rn.f16.f32 %rs8, %r11;
+ ; CHECK-NOF16-NEXT:    mov.b32 %r12, {%rs8, %rs7};
+@@ -1740,7 +1819,8 @@
+ ; CHECK-NOF16-NEXT:    .reg .b32 %r<7>;
+ ; CHECK-NOF16-EMPTY:
+ ; CHECK-NOF16-NEXT:  // %bb.0:
+-; CHECK-NOF16-NEXT:    ld.param.v2.b16 {%rs1, %rs2}, [test_fabs_param_0];
++; CHECK-NOF16-NEXT:    ld.param.b32 %r1, [test_fabs_param_0];
++; CHECK-NOF16-NEXT:    mov.b32 {%rs1, %rs2}, %r1;
+ ; CHECK-NOF16-NEXT:    cvt.f32.f16 %r2, %rs2;
+ ; CHECK-NOF16-NEXT:    abs.f32 %r3, %r2;
+ ; CHECK-NOF16-NEXT:    cvt.rn.f16.f32 %rs3, %r3;
+@@ -1761,14 +1841,16 @@
+ ; CHECK-NEXT:    .reg .b32 %r<10>;
+ ; CHECK-EMPTY:
+ ; CHECK-NEXT:  // %bb.0:
+-; CHECK-NEXT:    ld.param.v2.b16 {%rs1, %rs2}, [test_minnum_param_0];
+-; CHECK-NEXT:    ld.param.v2.b16 {%rs3, %rs4}, [test_minnum_param_1];
+-; CHECK-NEXT:    cvt.f32.f16 %r3, %rs4;
+-; CHECK-NEXT:    cvt.f32.f16 %r4, %rs2;
++; CHECK-NEXT:    ld.param.b32 %r2, [test_minnum_param_1];
++; CHECK-NEXT:    ld.param.b32 %r1, [test_minnum_param_0];
++; CHECK-NEXT:    mov.b32 {%rs1, %rs2}, %r2;
++; CHECK-NEXT:    cvt.f32.f16 %r3, %rs2;
++; CHECK-NEXT:    mov.b32 {%rs3, %rs4}, %r1;
++; CHECK-NEXT:    cvt.f32.f16 %r4, %rs4;
+ ; CHECK-NEXT:    min.f32 %r5, %r4, %r3;
+ ; CHECK-NEXT:    cvt.rn.f16.f32 %rs5, %r5;
+-; CHECK-NEXT:    cvt.f32.f16 %r6, %rs3;
+-; CHECK-NEXT:    cvt.f32.f16 %r7, %rs1;
++; CHECK-NEXT:    cvt.f32.f16 %r6, %rs1;
++; CHECK-NEXT:    cvt.f32.f16 %r7, %rs3;
+ ; CHECK-NEXT:    min.f32 %r8, %r7, %r6;
+ ; CHECK-NEXT:    cvt.rn.f16.f32 %rs6, %r8;
+ ; CHECK-NEXT:    mov.b32 %r9, {%rs6, %rs5};
+@@ -1785,14 +1867,16 @@
+ ; CHECK-NEXT:    .reg .b32 %r<10>;
+ ; CHECK-EMPTY:
+ ; CHECK-NEXT:  // %bb.0:
+-; CHECK-NEXT:    ld.param.v2.b16 {%rs1, %rs2}, [test_maxnum_param_0];
+-; CHECK-NEXT:    ld.param.v2.b16 {%rs3, %rs4}, [test_maxnum_param_1];
+-; CHECK-NEXT:    cvt.f32.f16 %r3, %rs4;
+-; CHECK-NEXT:    cvt.f32.f16 %r4, %rs2;
++; CHECK-NEXT:    ld.param.b32 %r2, [test_maxnum_param_1];
++; CHECK-NEXT:    ld.param.b32 %r1, [test_maxnum_param_0];
++; CHECK-NEXT:    mov.b32 {%rs1, %rs2}, %r2;
++; CHECK-NEXT:    cvt.f32.f16 %r3, %rs2;
++; CHECK-NEXT:    mov.b32 {%rs3, %rs4}, %r1;
++; CHECK-NEXT:    cvt.f32.f16 %r4, %rs4;
+ ; CHECK-NEXT:    max.f32 %r5, %r4, %r3;
+ ; CHECK-NEXT:    cvt.rn.f16.f32 %rs5, %r5;
+-; CHECK-NEXT:    cvt.f32.f16 %r6, %rs3;
+-; CHECK-NEXT:    cvt.f32.f16 %r7, %rs1;
++; CHECK-NEXT:    cvt.f32.f16 %r6, %rs1;
++; CHECK-NEXT:    cvt.f32.f16 %r7, %rs3;
+ ; CHECK-NEXT:    max.f32 %r8, %r7, %r6;
+ ; CHECK-NEXT:    cvt.rn.f16.f32 %rs6, %r8;
+ ; CHECK-NEXT:    mov.b32 %r9, {%rs6, %rs5};
+@@ -1822,13 +1906,15 @@
+ ; CHECK-NOF16-NEXT:    .reg .b32 %r<3>;
+ ; CHECK-NOF16-EMPTY:
+ ; CHECK-NOF16-NEXT:  // %bb.0:
+-; CHECK-NOF16-NEXT:    ld.param.v2.b16 {%rs1, %rs2}, [test_copysign_param_0];
+-; CHECK-NOF16-NEXT:    ld.param.v2.b16 {%rs3, %rs4}, [test_copysign_param_1];
+-; CHECK-NOF16-NEXT:    and.b16 %rs5, %rs4, -32768;
+-; CHECK-NOF16-NEXT:    and.b16 %rs6, %rs2, 32767;
+-; CHECK-NOF16-NEXT:    or.b16 %rs7, %rs6, %rs5;
+-; CHECK-NOF16-NEXT:    and.b16 %rs8, %rs3, -32768;
+-; CHECK-NOF16-NEXT:    and.b16 %rs9, %rs1, 32767;
++; CHECK-NOF16-NEXT:    ld.param.b32 %r2, [test_copysign_param_1];
++; CHECK-NOF16-NEXT:    ld.param.b32 %r1, [test_copysign_param_0];
++; CHECK-NOF16-NEXT:    mov.b32 {%rs1, %rs2}, %r2;
++; CHECK-NOF16-NEXT:    and.b16 %rs3, %rs2, -32768;
++; CHECK-NOF16-NEXT:    mov.b32 {%rs4, %rs5}, %r1;
++; CHECK-NOF16-NEXT:    and.b16 %rs6, %rs5, 32767;
++; CHECK-NOF16-NEXT:    or.b16 %rs7, %rs6, %rs3;
++; CHECK-NOF16-NEXT:    and.b16 %rs8, %rs1, -32768;
++; CHECK-NOF16-NEXT:    and.b16 %rs9, %rs4, 32767;
+ ; CHECK-NOF16-NEXT:    or.b16 %rs10, %rs9, %rs8;
+ ; CHECK-NOF16-NEXT:    st.param.v2.b16 [func_retval0], {%rs10, %rs7};
+ ; CHECK-NOF16-NEXT:    ret;
+@@ -1844,8 +1930,9 @@
+ ; CHECK-F16-NEXT:    .reg .b64 %rd<2>;
+ ; CHECK-F16-EMPTY:
+ ; CHECK-F16-NEXT:  // %bb.0:
++; CHECK-F16-NEXT:    ld.param.b64 %rd1, [test_copysign_f32_param_1];
+ ; CHECK-F16-NEXT:    ld.param.b32 %r1, [test_copysign_f32_param_0];
+-; CHECK-F16-NEXT:    ld.param.v2.b32 {%r2, %r3}, [test_copysign_f32_param_1];
++; CHECK-F16-NEXT:    mov.b64 {%r2, %r3}, %rd1;
+ ; CHECK-F16-NEXT:    cvt.rn.f16.f32 %rs1, %r3;
+ ; CHECK-F16-NEXT:    cvt.rn.f16.f32 %rs2, %r2;
+ ; CHECK-F16-NEXT:    mov.b32 %r4, {%rs2, %rs1};
+@@ -1862,8 +1949,10 @@
+ ; CHECK-NOF16-NEXT:    .reg .b64 %rd<2>;
+ ; CHECK-NOF16-EMPTY:
+ ; CHECK-NOF16-NEXT:  // %bb.0:
+-; CHECK-NOF16-NEXT:    ld.param.v2.b16 {%rs1, %rs2}, [test_copysign_f32_param_0];
+-; CHECK-NOF16-NEXT:    ld.param.v2.b32 {%r2, %r3}, [test_copysign_f32_param_1];
++; CHECK-NOF16-NEXT:    ld.param.b64 %rd1, [test_copysign_f32_param_1];
++; CHECK-NOF16-NEXT:    ld.param.b32 %r1, [test_copysign_f32_param_0];
++; CHECK-NOF16-NEXT:    mov.b64 {%r2, %r3}, %rd1;
++; CHECK-NOF16-NEXT:    mov.b32 {%rs1, %rs2}, %r1;
+ ; CHECK-NOF16-NEXT:    and.b16 %rs3, %rs2, 32767;
+ ; CHECK-NOF16-NEXT:    and.b32 %r4, %r3, -2147483648;
+ ; CHECK-NOF16-NEXT:    { .reg .b16 tmp; mov.b32 {tmp, %rs4}, %r4; }
+@@ -1906,7 +1995,8 @@
+ ; CHECK-NOF16-EMPTY:
+ ; CHECK-NOF16-NEXT:  // %bb.0:
+ ; CHECK-NOF16-NEXT:    ld.param.v2.b64 {%rd1, %rd2}, [test_copysign_f64_param_1];
+-; CHECK-NOF16-NEXT:    ld.param.v2.b16 {%rs1, %rs2}, [test_copysign_f64_param_0];
++; CHECK-NOF16-NEXT:    ld.param.b32 %r1, [test_copysign_f64_param_0];
++; CHECK-NOF16-NEXT:    mov.b32 {%rs1, %rs2}, %r1;
+ ; CHECK-NOF16-NEXT:    and.b16 %rs3, %rs2, 32767;
+ ; CHECK-NOF16-NEXT:    and.b64 %rd3, %rd2, -9223372036854775808;
+ ; CHECK-NOF16-NEXT:    shr.u64 %rd4, %rd3, 48;
+@@ -1948,13 +2038,15 @@
+ ; CHECK-NOF16-NEXT:    .reg .b32 %r<5>;
+ ; CHECK-NOF16-EMPTY:
+ ; CHECK-NOF16-NEXT:  // %bb.0:
+-; CHECK-NOF16-NEXT:    ld.param.v2.b16 {%rs1, %rs2}, [test_copysign_extended_param_0];
+-; CHECK-NOF16-NEXT:    ld.param.v2.b16 {%rs3, %rs4}, [test_copysign_extended_param_1];
+-; CHECK-NOF16-NEXT:    and.b16 %rs5, %rs3, -32768;
+-; CHECK-NOF16-NEXT:    and.b16 %rs6, %rs1, 32767;
+-; CHECK-NOF16-NEXT:    or.b16 %rs7, %rs6, %rs5;
+-; CHECK-NOF16-NEXT:    and.b16 %rs8, %rs4, -32768;
+-; CHECK-NOF16-NEXT:    and.b16 %rs9, %rs2, 32767;
++; CHECK-NOF16-NEXT:    ld.param.b32 %r2, [test_copysign_extended_param_1];
++; CHECK-NOF16-NEXT:    ld.param.b32 %r1, [test_copysign_extended_param_0];
++; CHECK-NOF16-NEXT:    mov.b32 {%rs1, %rs2}, %r2;
++; CHECK-NOF16-NEXT:    and.b16 %rs3, %rs1, -32768;
++; CHECK-NOF16-NEXT:    mov.b32 {%rs4, %rs5}, %r1;
++; CHECK-NOF16-NEXT:    and.b16 %rs6, %rs4, 32767;
++; CHECK-NOF16-NEXT:    or.b16 %rs7, %rs6, %rs3;
++; CHECK-NOF16-NEXT:    and.b16 %rs8, %rs2, -32768;
++; CHECK-NOF16-NEXT:    and.b16 %rs9, %rs5, 32767;
+ ; CHECK-NOF16-NEXT:    or.b16 %rs10, %rs9, %rs8;
+ ; CHECK-NOF16-NEXT:    cvt.f32.f16 %r3, %rs10;
+ ; CHECK-NOF16-NEXT:    cvt.f32.f16 %r4, %rs7;
+@@ -1972,7 +2064,8 @@
+ ; CHECK-NEXT:    .reg .b32 %r<2>;
+ ; CHECK-EMPTY:
+ ; CHECK-NEXT:  // %bb.0:
+-; CHECK-NEXT:    ld.param.v2.b16 {%rs1, %rs2}, [test_floor_param_0];
++; CHECK-NEXT:    ld.param.b32 %r1, [test_floor_param_0];
++; CHECK-NEXT:    mov.b32 {%rs1, %rs2}, %r1;
+ ; CHECK-NEXT:    cvt.rmi.f16.f16 %rs3, %rs2;
+ ; CHECK-NEXT:    cvt.rmi.f16.f16 %rs4, %rs1;
+ ; CHECK-NEXT:    st.param.v2.b16 [func_retval0], {%rs4, %rs3};
+@@ -1988,7 +2081,8 @@
+ ; CHECK-NEXT:    .reg .b32 %r<2>;
+ ; CHECK-EMPTY:
+ ; CHECK-NEXT:  // %bb.0:
+-; CHECK-NEXT:    ld.param.v2.b16 {%rs1, %rs2}, [test_ceil_param_0];
++; CHECK-NEXT:    ld.param.b32 %r1, [test_ceil_param_0];
++; CHECK-NEXT:    mov.b32 {%rs1, %rs2}, %r1;
+ ; CHECK-NEXT:    cvt.rpi.f16.f16 %rs3, %rs2;
+ ; CHECK-NEXT:    cvt.rpi.f16.f16 %rs4, %rs1;
+ ; CHECK-NEXT:    st.param.v2.b16 [func_retval0], {%rs4, %rs3};
+@@ -2004,7 +2098,8 @@
+ ; CHECK-NEXT:    .reg .b32 %r<2>;
+ ; CHECK-EMPTY:
+ ; CHECK-NEXT:  // %bb.0:
+-; CHECK-NEXT:    ld.param.v2.b16 {%rs1, %rs2}, [test_trunc_param_0];
++; CHECK-NEXT:    ld.param.b32 %r1, [test_trunc_param_0];
++; CHECK-NEXT:    mov.b32 {%rs1, %rs2}, %r1;
+ ; CHECK-NEXT:    cvt.rzi.f16.f16 %rs3, %rs2;
+ ; CHECK-NEXT:    cvt.rzi.f16.f16 %rs4, %rs1;
+ ; CHECK-NEXT:    st.param.v2.b16 [func_retval0], {%rs4, %rs3};
+@@ -2020,7 +2115,8 @@
+ ; CHECK-NEXT:    .reg .b32 %r<2>;
+ ; CHECK-EMPTY:
+ ; CHECK-NEXT:  // %bb.0:
+-; CHECK-NEXT:    ld.param.v2.b16 {%rs1, %rs2}, [test_rint_param_0];
++; CHECK-NEXT:    ld.param.b32 %r1, [test_rint_param_0];
++; CHECK-NEXT:    mov.b32 {%rs1, %rs2}, %r1;
+ ; CHECK-NEXT:    cvt.rni.f16.f16 %rs3, %rs2;
+ ; CHECK-NEXT:    cvt.rni.f16.f16 %rs4, %rs1;
+ ; CHECK-NEXT:    st.param.v2.b16 [func_retval0], {%rs4, %rs3};
+@@ -2036,7 +2132,8 @@
+ ; CHECK-NEXT:    .reg .b32 %r<2>;
+ ; CHECK-EMPTY:
+ ; CHECK-NEXT:  // %bb.0:
+-; CHECK-NEXT:    ld.param.v2.b16 {%rs1, %rs2}, [test_nearbyint_param_0];
++; CHECK-NEXT:    ld.param.b32 %r1, [test_nearbyint_param_0];
++; CHECK-NEXT:    mov.b32 {%rs1, %rs2}, %r1;
+ ; CHECK-NEXT:    cvt.rni.f16.f16 %rs3, %rs2;
+ ; CHECK-NEXT:    cvt.rni.f16.f16 %rs4, %rs1;
+ ; CHECK-NEXT:    st.param.v2.b16 [func_retval0], {%rs4, %rs3};
+@@ -2052,7 +2149,8 @@
+ ; CHECK-NEXT:    .reg .b32 %r<2>;
+ ; CHECK-EMPTY:
+ ; CHECK-NEXT:  // %bb.0:
+-; CHECK-NEXT:    ld.param.v2.b16 {%rs1, %rs2}, [test_roundeven_param_0];
++; CHECK-NEXT:    ld.param.b32 %r1, [test_roundeven_param_0];
++; CHECK-NEXT:    mov.b32 {%rs1, %rs2}, %r1;
+ ; CHECK-NEXT:    cvt.rni.f16.f16 %rs3, %rs2;
+ ; CHECK-NEXT:    cvt.rni.f16.f16 %rs4, %rs1;
+ ; CHECK-NEXT:    st.param.v2.b16 [func_retval0], {%rs4, %rs3};
+@@ -2070,7 +2168,8 @@
+ ; CHECK-NEXT:    .reg .b32 %r<21>;
+ ; CHECK-EMPTY:
+ ; CHECK-NEXT:  // %bb.0:
+-; CHECK-NEXT:    ld.param.v2.b16 {%rs1, %rs2}, [test_round_param_0];
++; CHECK-NEXT:    ld.param.b32 %r1, [test_round_param_0];
++; CHECK-NEXT:    mov.b32 {%rs1, %rs2}, %r1;
+ ; CHECK-NEXT:    cvt.f32.f16 %r2, %rs2;
+ ; CHECK-NEXT:    and.b32 %r3, %r2, -2147483648;
+ ; CHECK-NEXT:    or.b32 %r4, %r3, 1056964608;
+@@ -2121,17 +2220,20 @@
+ ; CHECK-NOF16-NEXT:    .reg .b32 %r<13>;
+ ; CHECK-NOF16-EMPTY:
+ ; CHECK-NOF16-NEXT:  // %bb.0:
+-; CHECK-NOF16-NEXT:    ld.param.v2.b16 {%rs1, %rs2}, [test_fmuladd_param_0];
+-; CHECK-NOF16-NEXT:    ld.param.v2.b16 {%rs3, %rs4}, [test_fmuladd_param_2];
+-; CHECK-NOF16-NEXT:    cvt.f32.f16 %r4, %rs4;
+-; CHECK-NOF16-NEXT:    ld.param.v2.b16 {%rs5, %rs6}, [test_fmuladd_param_1];
+-; CHECK-NOF16-NEXT:    cvt.f32.f16 %r5, %rs6;
+-; CHECK-NOF16-NEXT:    cvt.f32.f16 %r6, %rs2;
++; CHECK-NOF16-NEXT:    ld.param.b32 %r3, [test_fmuladd_param_2];
++; CHECK-NOF16-NEXT:    ld.param.b32 %r2, [test_fmuladd_param_1];
++; CHECK-NOF16-NEXT:    ld.param.b32 %r1, [test_fmuladd_param_0];
++; CHECK-NOF16-NEXT:    mov.b32 {%rs1, %rs2}, %r3;
++; CHECK-NOF16-NEXT:    cvt.f32.f16 %r4, %rs2;
++; CHECK-NOF16-NEXT:    mov.b32 {%rs3, %rs4}, %r2;
++; CHECK-NOF16-NEXT:    cvt.f32.f16 %r5, %rs4;
++; CHECK-NOF16-NEXT:    mov.b32 {%rs5, %rs6}, %r1;
++; CHECK-NOF16-NEXT:    cvt.f32.f16 %r6, %rs6;
+ ; CHECK-NOF16-NEXT:    fma.rn.f32 %r7, %r6, %r5, %r4;
+ ; CHECK-NOF16-NEXT:    cvt.rn.f16.f32 %rs7, %r7;
+-; CHECK-NOF16-NEXT:    cvt.f32.f16 %r8, %rs3;
+-; CHECK-NOF16-NEXT:    cvt.f32.f16 %r9, %rs5;
+-; CHECK-NOF16-NEXT:    cvt.f32.f16 %r10, %rs1;
++; CHECK-NOF16-NEXT:    cvt.f32.f16 %r8, %rs1;
++; CHECK-NOF16-NEXT:    cvt.f32.f16 %r9, %rs3;
++; CHECK-NOF16-NEXT:    cvt.f32.f16 %r10, %rs5;
+ ; CHECK-NOF16-NEXT:    fma.rn.f32 %r11, %r10, %r9, %r8;
+ ; CHECK-NOF16-NEXT:    cvt.rn.f16.f32 %rs8, %r11;
+ ; CHECK-NOF16-NEXT:    mov.b32 %r12, {%rs8, %rs7};
+@@ -2148,7 +2250,8 @@
+ ; CHECK-NEXT:    .reg .b32 %r<2>;
+ ; CHECK-EMPTY:
+ ; CHECK-NEXT:  // %bb.0:
+-; CHECK-NEXT:    ld.param.v2.b16 {%rs1, %rs2}, [test_shufflevector_param_0];
++; CHECK-NEXT:    ld.param.b32 %r1, [test_shufflevector_param_0];
++; CHECK-NEXT:    mov.b32 {%rs1, %rs2}, %r1;
+ ; CHECK-NEXT:    st.param.v2.b16 [func_retval0], {%rs2, %rs1};
+ ; CHECK-NEXT:    ret;
+   %s = shufflevector <2 x half> %a, <2 x half> undef, <2 x i32> <i32 1, i32 0>
+@@ -2158,12 +2261,13 @@
+ define <2 x half> @test_insertelement(<2 x half> %a, half %x) #0 {
+ ; CHECK-LABEL: test_insertelement(
+ ; CHECK:       {
+-; CHECK-NEXT:    .reg .b16 %rs<4>;
++; CHECK-NEXT:    .reg .b16 %rs<3>;
+ ; CHECK-NEXT:    .reg .b32 %r<2>;
+ ; CHECK-EMPTY:
+ ; CHECK-NEXT:  // %bb.0:
+ ; CHECK-NEXT:    ld.param.b16 %rs1, [test_insertelement_param_1];
+-; CHECK-NEXT:    ld.param.v2.b16 {%rs2, %rs3}, [test_insertelement_param_0];
++; CHECK-NEXT:    ld.param.b32 %r1, [test_insertelement_param_0];
++; CHECK-NEXT:    { .reg .b16 tmp; mov.b32 {%rs2, tmp}, %r1; }
+ ; CHECK-NEXT:    st.param.v2.b16 [func_retval0], {%rs2, %rs1};
+ ; CHECK-NEXT:    ret;
+   %i = insertelement <2 x half> %a, half %x, i64 1
+@@ -2177,7 +2281,8 @@
+ ; CHECK-NEXT:    .reg .b32 %r<2>;
+ ; CHECK-EMPTY:
+ ; CHECK-NEXT:  // %bb.0:
+-; CHECK-NEXT:    ld.param.v2.b16 {%rs1, %rs2}, [test_sitofp_2xi16_to_2xhalf_param_0];
++; CHECK-NEXT:    ld.param.b32 %r1, [test_sitofp_2xi16_to_2xhalf_param_0];
++; CHECK-NEXT:    mov.b32 {%rs1, %rs2}, %r1;
+ ; CHECK-NEXT:    cvt.rn.f16.s16 %rs3, %rs2;
+ ; CHECK-NEXT:    cvt.rn.f16.s16 %rs4, %rs1;
+ ; CHECK-NEXT:    st.param.v2.b16 [func_retval0], {%rs4, %rs3};
+@@ -2193,7 +2298,8 @@
+ ; CHECK-NEXT:    .reg .b32 %r<2>;
+ ; CHECK-EMPTY:
+ ; CHECK-NEXT:  // %bb.0:
+-; CHECK-NEXT:    ld.param.v2.b16 {%rs1, %rs2}, [test_uitofp_2xi16_to_2xhalf_param_0];
++; CHECK-NEXT:    ld.param.b32 %r1, [test_uitofp_2xi16_to_2xhalf_param_0];
++; CHECK-NEXT:    mov.b32 {%rs1, %rs2}, %r1;
+ ; CHECK-NEXT:    cvt.rn.f16.u16 %rs3, %rs2;
+ ; CHECK-NEXT:    cvt.rn.f16.u16 %rs4, %rs1;
+ ; CHECK-NEXT:    st.param.v2.b16 [func_retval0], {%rs4, %rs3};
+diff -ruN --strip-trailing-cr a/llvm/test/CodeGen/NVPTX/f32x2-instructions.ll b/llvm/test/CodeGen/NVPTX/f32x2-instructions.ll
+--- a/llvm/test/CodeGen/NVPTX/f32x2-instructions.ll
++++ b/llvm/test/CodeGen/NVPTX/f32x2-instructions.ll
+@@ -28,29 +28,53 @@
  }
  
- /// Print out the file/line/column information and include trace.
-diff -ruN --strip-trailing-cr a/clang/lib/Frontend/TextDiagnostic.cpp b/clang/lib/Frontend/TextDiagnostic.cpp
---- a/clang/lib/Frontend/TextDiagnostic.cpp
-+++ b/clang/lib/Frontend/TextDiagnostic.cpp
-@@ -738,7 +738,39 @@
+ define float @test_extract_0(<2 x float> %a) #0 {
+-; CHECK-LABEL: test_extract_0(
+-; CHECK:       {
+-; CHECK-NEXT:    .reg .b32 %r<3>;
+-; CHECK-NEXT:    .reg .b64 %rd<2>;
+-; CHECK-EMPTY:
+-; CHECK-NEXT:  // %bb.0:
+-; CHECK-NEXT:    ld.param.v2.b32 {%r1, %r2}, [test_extract_0_param_0];
+-; CHECK-NEXT:    st.param.b32 [func_retval0], %r1;
+-; CHECK-NEXT:    ret;
++; CHECK-NOF32X2-LABEL: test_extract_0(
++; CHECK-NOF32X2:       {
++; CHECK-NOF32X2-NEXT:    .reg .b32 %r<2>;
++; CHECK-NOF32X2-NEXT:    .reg .b64 %rd<2>;
++; CHECK-NOF32X2-EMPTY:
++; CHECK-NOF32X2-NEXT:  // %bb.0:
++; CHECK-NOF32X2-NEXT:    ld.param.b64 %rd1, [test_extract_0_param_0];
++; CHECK-NOF32X2-NEXT:    { .reg .b32 tmp; mov.b64 {%r1, tmp}, %rd1; }
++; CHECK-NOF32X2-NEXT:    st.param.b32 [func_retval0], %r1;
++; CHECK-NOF32X2-NEXT:    ret;
++;
++; CHECK-F32X2-LABEL: test_extract_0(
++; CHECK-F32X2:       {
++; CHECK-F32X2-NEXT:    .reg .b32 %r<2>;
++; CHECK-F32X2-NEXT:    .reg .b64 %rd<2>;
++; CHECK-F32X2-EMPTY:
++; CHECK-F32X2-NEXT:  // %bb.0:
++; CHECK-F32X2-NEXT:    ld.param.b64 %rd1, [test_extract_0_param_0];
++; CHECK-F32X2-NEXT:    mov.b64 {%r1, _}, %rd1;
++; CHECK-F32X2-NEXT:    st.param.b32 [func_retval0], %r1;
++; CHECK-F32X2-NEXT:    ret;
+   %e = extractelement <2 x float> %a, i32 0
+   ret float %e
  }
  
- void TextDiagnostic::emitFilename(StringRef Filename, const SourceManager &SM) {
--  OS << SM.getNameForDiagnostic(Filename, DiagOpts);
-+#ifdef _WIN32
-+  SmallString<4096> TmpFilename;
-+#endif
-+  if (DiagOpts.AbsolutePath) {
-+    auto File = SM.getFileManager().getOptionalFileRef(Filename);
-+    if (File) {
-+      // We want to print a simplified absolute path, i. e. without "dots".
-+      //
-+      // The hardest part here are the paths like "<part1>/<link>/../<part2>".
-+      // On Unix-like systems, we cannot just collapse "<link>/..", because
-+      // paths are resolved sequentially, and, thereby, the path
-+      // "<part1>/<part2>" may point to a different location. That is why
-+      // we use FileManager::getCanonicalName(), which expands all indirections
-+      // with llvm::sys::fs::real_path() and caches the result.
-+      //
-+      // On the other hand, it would be better to preserve as much of the
-+      // original path as possible, because that helps a user to recognize it.
-+      // real_path() expands all links, which sometimes too much. Luckily,
-+      // on Windows we can just use llvm::sys::path::remove_dots(), because,
-+      // on that system, both aforementioned paths point to the same place.
-+#ifdef _WIN32
-+      TmpFilename = File->getName();
-+      llvm::sys::fs::make_absolute(TmpFilename);
-+      llvm::sys::path::native(TmpFilename);
-+      llvm::sys::path::remove_dots(TmpFilename, /* remove_dot_dot */ true);
-+      Filename = StringRef(TmpFilename.data(), TmpFilename.size());
-+#else
-+      Filename = SM.getFileManager().getCanonicalName(*File);
-+#endif
-+    }
-+  }
-+
-+  OS << Filename;
+ define float @test_extract_1(<2 x float> %a) #0 {
+-; CHECK-LABEL: test_extract_1(
+-; CHECK:       {
+-; CHECK-NEXT:    .reg .b32 %r<3>;
+-; CHECK-NEXT:    .reg .b64 %rd<2>;
+-; CHECK-EMPTY:
+-; CHECK-NEXT:  // %bb.0:
+-; CHECK-NEXT:    ld.param.v2.b32 {%r1, %r2}, [test_extract_1_param_0];
+-; CHECK-NEXT:    st.param.b32 [func_retval0], %r2;
+-; CHECK-NEXT:    ret;
++; CHECK-NOF32X2-LABEL: test_extract_1(
++; CHECK-NOF32X2:       {
++; CHECK-NOF32X2-NEXT:    .reg .b32 %r<2>;
++; CHECK-NOF32X2-NEXT:    .reg .b64 %rd<2>;
++; CHECK-NOF32X2-EMPTY:
++; CHECK-NOF32X2-NEXT:  // %bb.0:
++; CHECK-NOF32X2-NEXT:    ld.param.b64 %rd1, [test_extract_1_param_0];
++; CHECK-NOF32X2-NEXT:    { .reg .b32 tmp; mov.b64 {tmp, %r1}, %rd1; }
++; CHECK-NOF32X2-NEXT:    st.param.b32 [func_retval0], %r1;
++; CHECK-NOF32X2-NEXT:    ret;
++;
++; CHECK-F32X2-LABEL: test_extract_1(
++; CHECK-F32X2:       {
++; CHECK-F32X2-NEXT:    .reg .b32 %r<2>;
++; CHECK-F32X2-NEXT:    .reg .b64 %rd<2>;
++; CHECK-F32X2-EMPTY:
++; CHECK-F32X2-NEXT:  // %bb.0:
++; CHECK-F32X2-NEXT:    ld.param.b64 %rd1, [test_extract_1_param_0];
++; CHECK-F32X2-NEXT:    mov.b64 {_, %r1}, %rd1;
++; CHECK-F32X2-NEXT:    st.param.b32 [func_retval0], %r1;
++; CHECK-F32X2-NEXT:    ret;
+   %e = extractelement <2 x float> %a, i32 1
+   ret float %e
+ }
+@@ -70,10 +94,12 @@
+ ; CHECK-NOF32X2-NEXT:    .reg .b64 %rd<3>;
+ ; CHECK-NOF32X2-EMPTY:
+ ; CHECK-NOF32X2-NEXT:  // %bb.0:
+-; CHECK-NOF32X2-NEXT:    ld.param.v2.b32 {%r1, %r2}, [test_fadd_param_0];
+-; CHECK-NOF32X2-NEXT:    ld.param.v2.b32 {%r3, %r4}, [test_fadd_param_1];
+-; CHECK-NOF32X2-NEXT:    add.rn.f32 %r5, %r2, %r4;
+-; CHECK-NOF32X2-NEXT:    add.rn.f32 %r6, %r1, %r3;
++; CHECK-NOF32X2-NEXT:    ld.param.b64 %rd2, [test_fadd_param_1];
++; CHECK-NOF32X2-NEXT:    ld.param.b64 %rd1, [test_fadd_param_0];
++; CHECK-NOF32X2-NEXT:    mov.b64 {%r1, %r2}, %rd2;
++; CHECK-NOF32X2-NEXT:    mov.b64 {%r3, %r4}, %rd1;
++; CHECK-NOF32X2-NEXT:    add.rn.f32 %r5, %r4, %r2;
++; CHECK-NOF32X2-NEXT:    add.rn.f32 %r6, %r3, %r1;
+ ; CHECK-NOF32X2-NEXT:    st.param.v2.b32 [func_retval0], {%r6, %r5};
+ ; CHECK-NOF32X2-NEXT:    ret;
+ ;
+@@ -98,7 +124,8 @@
+ ; CHECK-NOF32X2-NEXT:    .reg .b64 %rd<2>;
+ ; CHECK-NOF32X2-EMPTY:
+ ; CHECK-NOF32X2-NEXT:  // %bb.0:
+-; CHECK-NOF32X2-NEXT:    ld.param.v2.b32 {%r1, %r2}, [test_fadd_imm_0_param_0];
++; CHECK-NOF32X2-NEXT:    ld.param.b64 %rd1, [test_fadd_imm_0_param_0];
++; CHECK-NOF32X2-NEXT:    mov.b64 {%r1, %r2}, %rd1;
+ ; CHECK-NOF32X2-NEXT:    add.rn.f32 %r3, %r2, 0f40000000;
+ ; CHECK-NOF32X2-NEXT:    add.rn.f32 %r4, %r1, 0f3F800000;
+ ; CHECK-NOF32X2-NEXT:    st.param.v2.b32 [func_retval0], {%r4, %r3};
+@@ -128,7 +155,8 @@
+ ; CHECK-NOF32X2-NEXT:    .reg .b64 %rd<2>;
+ ; CHECK-NOF32X2-EMPTY:
+ ; CHECK-NOF32X2-NEXT:  // %bb.0:
+-; CHECK-NOF32X2-NEXT:    ld.param.v2.b32 {%r1, %r2}, [test_fadd_imm_1_param_0];
++; CHECK-NOF32X2-NEXT:    ld.param.b64 %rd1, [test_fadd_imm_1_param_0];
++; CHECK-NOF32X2-NEXT:    mov.b64 {%r1, %r2}, %rd1;
+ ; CHECK-NOF32X2-NEXT:    add.rn.f32 %r3, %r2, 0f40000000;
+ ; CHECK-NOF32X2-NEXT:    add.rn.f32 %r4, %r1, 0f3F800000;
+ ; CHECK-NOF32X2-NEXT:    st.param.v2.b32 [func_retval0], {%r4, %r3};
+@@ -158,13 +186,17 @@
+ ; CHECK-NOF32X2-NEXT:    .reg .b64 %rd<5>;
+ ; CHECK-NOF32X2-EMPTY:
+ ; CHECK-NOF32X2-NEXT:  // %bb.0:
+-; CHECK-NOF32X2-NEXT:    ld.param.v4.b32 {%r1, %r2, %r3, %r4}, [test_fadd_v4_param_0];
+-; CHECK-NOF32X2-NEXT:    ld.param.v4.b32 {%r5, %r6, %r7, %r8}, [test_fadd_v4_param_1];
+-; CHECK-NOF32X2-NEXT:    add.rn.f32 %r9, %r4, %r8;
+-; CHECK-NOF32X2-NEXT:    add.rn.f32 %r10, %r3, %r7;
+-; CHECK-NOF32X2-NEXT:    add.rn.f32 %r11, %r2, %r6;
+-; CHECK-NOF32X2-NEXT:    add.rn.f32 %r12, %r1, %r5;
+-; CHECK-NOF32X2-NEXT:    st.param.v4.b32 [func_retval0], {%r12, %r11, %r10, %r9};
++; CHECK-NOF32X2-NEXT:    ld.param.v2.b64 {%rd3, %rd4}, [test_fadd_v4_param_1];
++; CHECK-NOF32X2-NEXT:    ld.param.v2.b64 {%rd1, %rd2}, [test_fadd_v4_param_0];
++; CHECK-NOF32X2-NEXT:    mov.b64 {%r1, %r2}, %rd4;
++; CHECK-NOF32X2-NEXT:    mov.b64 {%r3, %r4}, %rd2;
++; CHECK-NOF32X2-NEXT:    add.rn.f32 %r5, %r4, %r2;
++; CHECK-NOF32X2-NEXT:    add.rn.f32 %r6, %r3, %r1;
++; CHECK-NOF32X2-NEXT:    mov.b64 {%r7, %r8}, %rd3;
++; CHECK-NOF32X2-NEXT:    mov.b64 {%r9, %r10}, %rd1;
++; CHECK-NOF32X2-NEXT:    add.rn.f32 %r11, %r10, %r8;
++; CHECK-NOF32X2-NEXT:    add.rn.f32 %r12, %r9, %r7;
++; CHECK-NOF32X2-NEXT:    st.param.v4.b32 [func_retval0], {%r12, %r11, %r6, %r5};
+ ; CHECK-NOF32X2-NEXT:    ret;
+ ;
+ ; CHECK-F32X2-LABEL: test_fadd_v4(
+@@ -189,12 +221,14 @@
+ ; CHECK-NOF32X2-NEXT:    .reg .b64 %rd<3>;
+ ; CHECK-NOF32X2-EMPTY:
+ ; CHECK-NOF32X2-NEXT:  // %bb.0:
+-; CHECK-NOF32X2-NEXT:    ld.param.v4.b32 {%r1, %r2, %r3, %r4}, [test_fadd_imm_0_v4_param_0];
+-; CHECK-NOF32X2-NEXT:    add.rn.f32 %r5, %r4, 0f40800000;
+-; CHECK-NOF32X2-NEXT:    add.rn.f32 %r6, %r3, 0f40400000;
+-; CHECK-NOF32X2-NEXT:    add.rn.f32 %r7, %r2, 0f40000000;
+-; CHECK-NOF32X2-NEXT:    add.rn.f32 %r8, %r1, 0f3F800000;
+-; CHECK-NOF32X2-NEXT:    st.param.v4.b32 [func_retval0], {%r8, %r7, %r6, %r5};
++; CHECK-NOF32X2-NEXT:    ld.param.v2.b64 {%rd1, %rd2}, [test_fadd_imm_0_v4_param_0];
++; CHECK-NOF32X2-NEXT:    mov.b64 {%r1, %r2}, %rd2;
++; CHECK-NOF32X2-NEXT:    add.rn.f32 %r3, %r2, 0f40800000;
++; CHECK-NOF32X2-NEXT:    add.rn.f32 %r4, %r1, 0f40400000;
++; CHECK-NOF32X2-NEXT:    mov.b64 {%r5, %r6}, %rd1;
++; CHECK-NOF32X2-NEXT:    add.rn.f32 %r7, %r6, 0f40000000;
++; CHECK-NOF32X2-NEXT:    add.rn.f32 %r8, %r5, 0f3F800000;
++; CHECK-NOF32X2-NEXT:    st.param.v4.b32 [func_retval0], {%r8, %r7, %r4, %r3};
+ ; CHECK-NOF32X2-NEXT:    ret;
+ ;
+ ; CHECK-F32X2-LABEL: test_fadd_imm_0_v4(
+@@ -225,12 +259,14 @@
+ ; CHECK-NOF32X2-NEXT:    .reg .b64 %rd<3>;
+ ; CHECK-NOF32X2-EMPTY:
+ ; CHECK-NOF32X2-NEXT:  // %bb.0:
+-; CHECK-NOF32X2-NEXT:    ld.param.v4.b32 {%r1, %r2, %r3, %r4}, [test_fadd_imm_1_v4_param_0];
+-; CHECK-NOF32X2-NEXT:    add.rn.f32 %r5, %r4, 0f40800000;
+-; CHECK-NOF32X2-NEXT:    add.rn.f32 %r6, %r3, 0f40400000;
+-; CHECK-NOF32X2-NEXT:    add.rn.f32 %r7, %r2, 0f40000000;
+-; CHECK-NOF32X2-NEXT:    add.rn.f32 %r8, %r1, 0f3F800000;
+-; CHECK-NOF32X2-NEXT:    st.param.v4.b32 [func_retval0], {%r8, %r7, %r6, %r5};
++; CHECK-NOF32X2-NEXT:    ld.param.v2.b64 {%rd1, %rd2}, [test_fadd_imm_1_v4_param_0];
++; CHECK-NOF32X2-NEXT:    mov.b64 {%r1, %r2}, %rd2;
++; CHECK-NOF32X2-NEXT:    add.rn.f32 %r3, %r2, 0f40800000;
++; CHECK-NOF32X2-NEXT:    add.rn.f32 %r4, %r1, 0f40400000;
++; CHECK-NOF32X2-NEXT:    mov.b64 {%r5, %r6}, %rd1;
++; CHECK-NOF32X2-NEXT:    add.rn.f32 %r7, %r6, 0f40000000;
++; CHECK-NOF32X2-NEXT:    add.rn.f32 %r8, %r5, 0f3F800000;
++; CHECK-NOF32X2-NEXT:    st.param.v4.b32 [func_retval0], {%r8, %r7, %r4, %r3};
+ ; CHECK-NOF32X2-NEXT:    ret;
+ ;
+ ; CHECK-F32X2-LABEL: test_fadd_imm_1_v4(
+@@ -261,10 +297,12 @@
+ ; CHECK-NOF32X2-NEXT:    .reg .b64 %rd<3>;
+ ; CHECK-NOF32X2-EMPTY:
+ ; CHECK-NOF32X2-NEXT:  // %bb.0:
+-; CHECK-NOF32X2-NEXT:    ld.param.v2.b32 {%r1, %r2}, [test_fsub_param_0];
+-; CHECK-NOF32X2-NEXT:    ld.param.v2.b32 {%r3, %r4}, [test_fsub_param_1];
+-; CHECK-NOF32X2-NEXT:    sub.rn.f32 %r5, %r2, %r4;
+-; CHECK-NOF32X2-NEXT:    sub.rn.f32 %r6, %r1, %r3;
++; CHECK-NOF32X2-NEXT:    ld.param.b64 %rd2, [test_fsub_param_1];
++; CHECK-NOF32X2-NEXT:    ld.param.b64 %rd1, [test_fsub_param_0];
++; CHECK-NOF32X2-NEXT:    mov.b64 {%r1, %r2}, %rd2;
++; CHECK-NOF32X2-NEXT:    mov.b64 {%r3, %r4}, %rd1;
++; CHECK-NOF32X2-NEXT:    sub.rn.f32 %r5, %r4, %r2;
++; CHECK-NOF32X2-NEXT:    sub.rn.f32 %r6, %r3, %r1;
+ ; CHECK-NOF32X2-NEXT:    st.param.v2.b32 [func_retval0], {%r6, %r5};
+ ; CHECK-NOF32X2-NEXT:    ret;
+ ;
+@@ -289,7 +327,8 @@
+ ; CHECK-NEXT:    .reg .b64 %rd<2>;
+ ; CHECK-EMPTY:
+ ; CHECK-NEXT:  // %bb.0:
+-; CHECK-NEXT:    ld.param.v2.b32 {%r1, %r2}, [test_fneg_param_0];
++; CHECK-NEXT:    ld.param.b64 %rd1, [test_fneg_param_0];
++; CHECK-NEXT:    mov.b64 {%r1, %r2}, %rd1;
+ ; CHECK-NEXT:    neg.f32 %r3, %r2;
+ ; CHECK-NEXT:    neg.f32 %r4, %r1;
+ ; CHECK-NEXT:    st.param.v2.b32 [func_retval0], {%r4, %r3};
+@@ -305,10 +344,12 @@
+ ; CHECK-NOF32X2-NEXT:    .reg .b64 %rd<3>;
+ ; CHECK-NOF32X2-EMPTY:
+ ; CHECK-NOF32X2-NEXT:  // %bb.0:
+-; CHECK-NOF32X2-NEXT:    ld.param.v2.b32 {%r1, %r2}, [test_fmul_param_0];
+-; CHECK-NOF32X2-NEXT:    ld.param.v2.b32 {%r3, %r4}, [test_fmul_param_1];
+-; CHECK-NOF32X2-NEXT:    mul.rn.f32 %r5, %r2, %r4;
+-; CHECK-NOF32X2-NEXT:    mul.rn.f32 %r6, %r1, %r3;
++; CHECK-NOF32X2-NEXT:    ld.param.b64 %rd2, [test_fmul_param_1];
++; CHECK-NOF32X2-NEXT:    ld.param.b64 %rd1, [test_fmul_param_0];
++; CHECK-NOF32X2-NEXT:    mov.b64 {%r1, %r2}, %rd2;
++; CHECK-NOF32X2-NEXT:    mov.b64 {%r3, %r4}, %rd1;
++; CHECK-NOF32X2-NEXT:    mul.rn.f32 %r5, %r4, %r2;
++; CHECK-NOF32X2-NEXT:    mul.rn.f32 %r6, %r3, %r1;
+ ; CHECK-NOF32X2-NEXT:    st.param.v2.b32 [func_retval0], {%r6, %r5};
+ ; CHECK-NOF32X2-NEXT:    ret;
+ ;
+@@ -333,10 +374,12 @@
+ ; CHECK-NEXT:    .reg .b64 %rd<3>;
+ ; CHECK-EMPTY:
+ ; CHECK-NEXT:  // %bb.0:
+-; CHECK-NEXT:    ld.param.v2.b32 {%r1, %r2}, [test_fdiv_param_0];
+-; CHECK-NEXT:    ld.param.v2.b32 {%r3, %r4}, [test_fdiv_param_1];
+-; CHECK-NEXT:    div.rn.f32 %r5, %r2, %r4;
+-; CHECK-NEXT:    div.rn.f32 %r6, %r1, %r3;
++; CHECK-NEXT:    ld.param.b64 %rd2, [test_fdiv_param_1];
++; CHECK-NEXT:    ld.param.b64 %rd1, [test_fdiv_param_0];
++; CHECK-NEXT:    mov.b64 {%r1, %r2}, %rd2;
++; CHECK-NEXT:    mov.b64 {%r3, %r4}, %rd1;
++; CHECK-NEXT:    div.rn.f32 %r5, %r4, %r2;
++; CHECK-NEXT:    div.rn.f32 %r6, %r3, %r1;
+ ; CHECK-NEXT:    st.param.v2.b32 [func_retval0], {%r6, %r5};
+ ; CHECK-NEXT:    ret;
+   %r = fdiv <2 x float> %a, %b
+@@ -351,20 +394,22 @@
+ ; CHECK-NEXT:    .reg .b64 %rd<3>;
+ ; CHECK-EMPTY:
+ ; CHECK-NEXT:  // %bb.0:
+-; CHECK-NEXT:    ld.param.v2.b32 {%r1, %r2}, [test_frem_param_0];
+-; CHECK-NEXT:    ld.param.v2.b32 {%r3, %r4}, [test_frem_param_1];
+-; CHECK-NEXT:    div.rn.f32 %r5, %r2, %r4;
++; CHECK-NEXT:    ld.param.b64 %rd2, [test_frem_param_1];
++; CHECK-NEXT:    ld.param.b64 %rd1, [test_frem_param_0];
++; CHECK-NEXT:    mov.b64 {%r1, %r2}, %rd2;
++; CHECK-NEXT:    mov.b64 {%r3, %r4}, %rd1;
++; CHECK-NEXT:    div.rn.f32 %r5, %r4, %r2;
+ ; CHECK-NEXT:    cvt.rzi.f32.f32 %r6, %r5;
+ ; CHECK-NEXT:    neg.f32 %r7, %r6;
+-; CHECK-NEXT:    fma.rn.f32 %r8, %r7, %r4, %r2;
+-; CHECK-NEXT:    testp.infinite.f32 %p1, %r4;
+-; CHECK-NEXT:    selp.f32 %r9, %r2, %r8, %p1;
+-; CHECK-NEXT:    div.rn.f32 %r10, %r1, %r3;
++; CHECK-NEXT:    fma.rn.f32 %r8, %r7, %r2, %r4;
++; CHECK-NEXT:    testp.infinite.f32 %p1, %r2;
++; CHECK-NEXT:    selp.f32 %r9, %r4, %r8, %p1;
++; CHECK-NEXT:    div.rn.f32 %r10, %r3, %r1;
+ ; CHECK-NEXT:    cvt.rzi.f32.f32 %r11, %r10;
+ ; CHECK-NEXT:    neg.f32 %r12, %r11;
+-; CHECK-NEXT:    fma.rn.f32 %r13, %r12, %r3, %r1;
+-; CHECK-NEXT:    testp.infinite.f32 %p2, %r3;
+-; CHECK-NEXT:    selp.f32 %r14, %r1, %r13, %p2;
++; CHECK-NEXT:    fma.rn.f32 %r13, %r12, %r1, %r3;
++; CHECK-NEXT:    testp.infinite.f32 %p2, %r1;
++; CHECK-NEXT:    selp.f32 %r14, %r3, %r13, %p2;
+ ; CHECK-NEXT:    st.param.v2.b32 [func_retval0], {%r14, %r9};
+ ; CHECK-NEXT:    ret;
+   %r = frem <2 x float> %a, %b
+@@ -378,10 +423,12 @@
+ ; CHECK-NOF32X2-NEXT:    .reg .b64 %rd<3>;
+ ; CHECK-NOF32X2-EMPTY:
+ ; CHECK-NOF32X2-NEXT:  // %bb.0:
+-; CHECK-NOF32X2-NEXT:    ld.param.v2.b32 {%r1, %r2}, [test_fadd_ftz_param_0];
+-; CHECK-NOF32X2-NEXT:    ld.param.v2.b32 {%r3, %r4}, [test_fadd_ftz_param_1];
+-; CHECK-NOF32X2-NEXT:    add.rn.ftz.f32 %r5, %r2, %r4;
+-; CHECK-NOF32X2-NEXT:    add.rn.ftz.f32 %r6, %r1, %r3;
++; CHECK-NOF32X2-NEXT:    ld.param.b64 %rd2, [test_fadd_ftz_param_1];
++; CHECK-NOF32X2-NEXT:    ld.param.b64 %rd1, [test_fadd_ftz_param_0];
++; CHECK-NOF32X2-NEXT:    mov.b64 {%r1, %r2}, %rd2;
++; CHECK-NOF32X2-NEXT:    mov.b64 {%r3, %r4}, %rd1;
++; CHECK-NOF32X2-NEXT:    add.rn.ftz.f32 %r5, %r4, %r2;
++; CHECK-NOF32X2-NEXT:    add.rn.ftz.f32 %r6, %r3, %r1;
+ ; CHECK-NOF32X2-NEXT:    st.param.v2.b32 [func_retval0], {%r6, %r5};
+ ; CHECK-NOF32X2-NEXT:    ret;
+ ;
+@@ -406,7 +453,8 @@
+ ; CHECK-NOF32X2-NEXT:    .reg .b64 %rd<2>;
+ ; CHECK-NOF32X2-EMPTY:
+ ; CHECK-NOF32X2-NEXT:  // %bb.0:
+-; CHECK-NOF32X2-NEXT:    ld.param.v2.b32 {%r1, %r2}, [test_fadd_imm_0_ftz_param_0];
++; CHECK-NOF32X2-NEXT:    ld.param.b64 %rd1, [test_fadd_imm_0_ftz_param_0];
++; CHECK-NOF32X2-NEXT:    mov.b64 {%r1, %r2}, %rd1;
+ ; CHECK-NOF32X2-NEXT:    add.rn.ftz.f32 %r3, %r2, 0f40000000;
+ ; CHECK-NOF32X2-NEXT:    add.rn.ftz.f32 %r4, %r1, 0f3F800000;
+ ; CHECK-NOF32X2-NEXT:    st.param.v2.b32 [func_retval0], {%r4, %r3};
+@@ -436,7 +484,8 @@
+ ; CHECK-NOF32X2-NEXT:    .reg .b64 %rd<2>;
+ ; CHECK-NOF32X2-EMPTY:
+ ; CHECK-NOF32X2-NEXT:  // %bb.0:
+-; CHECK-NOF32X2-NEXT:    ld.param.v2.b32 {%r1, %r2}, [test_fadd_imm_1_ftz_param_0];
++; CHECK-NOF32X2-NEXT:    ld.param.b64 %rd1, [test_fadd_imm_1_ftz_param_0];
++; CHECK-NOF32X2-NEXT:    mov.b64 {%r1, %r2}, %rd1;
+ ; CHECK-NOF32X2-NEXT:    add.rn.ftz.f32 %r3, %r2, 0f40000000;
+ ; CHECK-NOF32X2-NEXT:    add.rn.ftz.f32 %r4, %r1, 0f3F800000;
+ ; CHECK-NOF32X2-NEXT:    st.param.v2.b32 [func_retval0], {%r4, %r3};
+@@ -466,13 +515,17 @@
+ ; CHECK-NOF32X2-NEXT:    .reg .b64 %rd<5>;
+ ; CHECK-NOF32X2-EMPTY:
+ ; CHECK-NOF32X2-NEXT:  // %bb.0:
+-; CHECK-NOF32X2-NEXT:    ld.param.v4.b32 {%r1, %r2, %r3, %r4}, [test_fadd_v4_ftz_param_0];
+-; CHECK-NOF32X2-NEXT:    ld.param.v4.b32 {%r5, %r6, %r7, %r8}, [test_fadd_v4_ftz_param_1];
+-; CHECK-NOF32X2-NEXT:    add.rn.ftz.f32 %r9, %r4, %r8;
+-; CHECK-NOF32X2-NEXT:    add.rn.ftz.f32 %r10, %r3, %r7;
+-; CHECK-NOF32X2-NEXT:    add.rn.ftz.f32 %r11, %r2, %r6;
+-; CHECK-NOF32X2-NEXT:    add.rn.ftz.f32 %r12, %r1, %r5;
+-; CHECK-NOF32X2-NEXT:    st.param.v4.b32 [func_retval0], {%r12, %r11, %r10, %r9};
++; CHECK-NOF32X2-NEXT:    ld.param.v2.b64 {%rd3, %rd4}, [test_fadd_v4_ftz_param_1];
++; CHECK-NOF32X2-NEXT:    ld.param.v2.b64 {%rd1, %rd2}, [test_fadd_v4_ftz_param_0];
++; CHECK-NOF32X2-NEXT:    mov.b64 {%r1, %r2}, %rd4;
++; CHECK-NOF32X2-NEXT:    mov.b64 {%r3, %r4}, %rd2;
++; CHECK-NOF32X2-NEXT:    add.rn.ftz.f32 %r5, %r4, %r2;
++; CHECK-NOF32X2-NEXT:    add.rn.ftz.f32 %r6, %r3, %r1;
++; CHECK-NOF32X2-NEXT:    mov.b64 {%r7, %r8}, %rd3;
++; CHECK-NOF32X2-NEXT:    mov.b64 {%r9, %r10}, %rd1;
++; CHECK-NOF32X2-NEXT:    add.rn.ftz.f32 %r11, %r10, %r8;
++; CHECK-NOF32X2-NEXT:    add.rn.ftz.f32 %r12, %r9, %r7;
++; CHECK-NOF32X2-NEXT:    st.param.v4.b32 [func_retval0], {%r12, %r11, %r6, %r5};
+ ; CHECK-NOF32X2-NEXT:    ret;
+ ;
+ ; CHECK-F32X2-LABEL: test_fadd_v4_ftz(
+@@ -497,12 +550,14 @@
+ ; CHECK-NOF32X2-NEXT:    .reg .b64 %rd<3>;
+ ; CHECK-NOF32X2-EMPTY:
+ ; CHECK-NOF32X2-NEXT:  // %bb.0:
+-; CHECK-NOF32X2-NEXT:    ld.param.v4.b32 {%r1, %r2, %r3, %r4}, [test_fadd_imm_0_v4_ftz_param_0];
+-; CHECK-NOF32X2-NEXT:    add.rn.ftz.f32 %r5, %r4, 0f40800000;
+-; CHECK-NOF32X2-NEXT:    add.rn.ftz.f32 %r6, %r3, 0f40400000;
+-; CHECK-NOF32X2-NEXT:    add.rn.ftz.f32 %r7, %r2, 0f40000000;
+-; CHECK-NOF32X2-NEXT:    add.rn.ftz.f32 %r8, %r1, 0f3F800000;
+-; CHECK-NOF32X2-NEXT:    st.param.v4.b32 [func_retval0], {%r8, %r7, %r6, %r5};
++; CHECK-NOF32X2-NEXT:    ld.param.v2.b64 {%rd1, %rd2}, [test_fadd_imm_0_v4_ftz_param_0];
++; CHECK-NOF32X2-NEXT:    mov.b64 {%r1, %r2}, %rd2;
++; CHECK-NOF32X2-NEXT:    add.rn.ftz.f32 %r3, %r2, 0f40800000;
++; CHECK-NOF32X2-NEXT:    add.rn.ftz.f32 %r4, %r1, 0f40400000;
++; CHECK-NOF32X2-NEXT:    mov.b64 {%r5, %r6}, %rd1;
++; CHECK-NOF32X2-NEXT:    add.rn.ftz.f32 %r7, %r6, 0f40000000;
++; CHECK-NOF32X2-NEXT:    add.rn.ftz.f32 %r8, %r5, 0f3F800000;
++; CHECK-NOF32X2-NEXT:    st.param.v4.b32 [func_retval0], {%r8, %r7, %r4, %r3};
+ ; CHECK-NOF32X2-NEXT:    ret;
+ ;
+ ; CHECK-F32X2-LABEL: test_fadd_imm_0_v4_ftz(
+@@ -533,12 +588,14 @@
+ ; CHECK-NOF32X2-NEXT:    .reg .b64 %rd<3>;
+ ; CHECK-NOF32X2-EMPTY:
+ ; CHECK-NOF32X2-NEXT:  // %bb.0:
+-; CHECK-NOF32X2-NEXT:    ld.param.v4.b32 {%r1, %r2, %r3, %r4}, [test_fadd_imm_1_v4_ftz_param_0];
+-; CHECK-NOF32X2-NEXT:    add.rn.ftz.f32 %r5, %r4, 0f40800000;
+-; CHECK-NOF32X2-NEXT:    add.rn.ftz.f32 %r6, %r3, 0f40400000;
+-; CHECK-NOF32X2-NEXT:    add.rn.ftz.f32 %r7, %r2, 0f40000000;
+-; CHECK-NOF32X2-NEXT:    add.rn.ftz.f32 %r8, %r1, 0f3F800000;
+-; CHECK-NOF32X2-NEXT:    st.param.v4.b32 [func_retval0], {%r8, %r7, %r6, %r5};
++; CHECK-NOF32X2-NEXT:    ld.param.v2.b64 {%rd1, %rd2}, [test_fadd_imm_1_v4_ftz_param_0];
++; CHECK-NOF32X2-NEXT:    mov.b64 {%r1, %r2}, %rd2;
++; CHECK-NOF32X2-NEXT:    add.rn.ftz.f32 %r3, %r2, 0f40800000;
++; CHECK-NOF32X2-NEXT:    add.rn.ftz.f32 %r4, %r1, 0f40400000;
++; CHECK-NOF32X2-NEXT:    mov.b64 {%r5, %r6}, %rd1;
++; CHECK-NOF32X2-NEXT:    add.rn.ftz.f32 %r7, %r6, 0f40000000;
++; CHECK-NOF32X2-NEXT:    add.rn.ftz.f32 %r8, %r5, 0f3F800000;
++; CHECK-NOF32X2-NEXT:    st.param.v4.b32 [func_retval0], {%r8, %r7, %r4, %r3};
+ ; CHECK-NOF32X2-NEXT:    ret;
+ ;
+ ; CHECK-F32X2-LABEL: test_fadd_imm_1_v4_ftz(
+@@ -569,10 +626,12 @@
+ ; CHECK-NOF32X2-NEXT:    .reg .b64 %rd<3>;
+ ; CHECK-NOF32X2-EMPTY:
+ ; CHECK-NOF32X2-NEXT:  // %bb.0:
+-; CHECK-NOF32X2-NEXT:    ld.param.v2.b32 {%r1, %r2}, [test_fsub_ftz_param_0];
+-; CHECK-NOF32X2-NEXT:    ld.param.v2.b32 {%r3, %r4}, [test_fsub_ftz_param_1];
+-; CHECK-NOF32X2-NEXT:    sub.rn.ftz.f32 %r5, %r2, %r4;
+-; CHECK-NOF32X2-NEXT:    sub.rn.ftz.f32 %r6, %r1, %r3;
++; CHECK-NOF32X2-NEXT:    ld.param.b64 %rd2, [test_fsub_ftz_param_1];
++; CHECK-NOF32X2-NEXT:    ld.param.b64 %rd1, [test_fsub_ftz_param_0];
++; CHECK-NOF32X2-NEXT:    mov.b64 {%r1, %r2}, %rd2;
++; CHECK-NOF32X2-NEXT:    mov.b64 {%r3, %r4}, %rd1;
++; CHECK-NOF32X2-NEXT:    sub.rn.ftz.f32 %r5, %r4, %r2;
++; CHECK-NOF32X2-NEXT:    sub.rn.ftz.f32 %r6, %r3, %r1;
+ ; CHECK-NOF32X2-NEXT:    st.param.v2.b32 [func_retval0], {%r6, %r5};
+ ; CHECK-NOF32X2-NEXT:    ret;
+ ;
+@@ -597,7 +656,8 @@
+ ; CHECK-NEXT:    .reg .b64 %rd<2>;
+ ; CHECK-EMPTY:
+ ; CHECK-NEXT:  // %bb.0:
+-; CHECK-NEXT:    ld.param.v2.b32 {%r1, %r2}, [test_fneg_ftz_param_0];
++; CHECK-NEXT:    ld.param.b64 %rd1, [test_fneg_ftz_param_0];
++; CHECK-NEXT:    mov.b64 {%r1, %r2}, %rd1;
+ ; CHECK-NEXT:    neg.ftz.f32 %r3, %r2;
+ ; CHECK-NEXT:    neg.ftz.f32 %r4, %r1;
+ ; CHECK-NEXT:    st.param.v2.b32 [func_retval0], {%r4, %r3};
+@@ -613,10 +673,12 @@
+ ; CHECK-NOF32X2-NEXT:    .reg .b64 %rd<3>;
+ ; CHECK-NOF32X2-EMPTY:
+ ; CHECK-NOF32X2-NEXT:  // %bb.0:
+-; CHECK-NOF32X2-NEXT:    ld.param.v2.b32 {%r1, %r2}, [test_fmul_ftz_param_0];
+-; CHECK-NOF32X2-NEXT:    ld.param.v2.b32 {%r3, %r4}, [test_fmul_ftz_param_1];
+-; CHECK-NOF32X2-NEXT:    mul.rn.ftz.f32 %r5, %r2, %r4;
+-; CHECK-NOF32X2-NEXT:    mul.rn.ftz.f32 %r6, %r1, %r3;
++; CHECK-NOF32X2-NEXT:    ld.param.b64 %rd2, [test_fmul_ftz_param_1];
++; CHECK-NOF32X2-NEXT:    ld.param.b64 %rd1, [test_fmul_ftz_param_0];
++; CHECK-NOF32X2-NEXT:    mov.b64 {%r1, %r2}, %rd2;
++; CHECK-NOF32X2-NEXT:    mov.b64 {%r3, %r4}, %rd1;
++; CHECK-NOF32X2-NEXT:    mul.rn.ftz.f32 %r5, %r4, %r2;
++; CHECK-NOF32X2-NEXT:    mul.rn.ftz.f32 %r6, %r3, %r1;
+ ; CHECK-NOF32X2-NEXT:    st.param.v2.b32 [func_retval0], {%r6, %r5};
+ ; CHECK-NOF32X2-NEXT:    ret;
+ ;
+@@ -641,11 +703,14 @@
+ ; CHECK-NOF32X2-NEXT:    .reg .b64 %rd<4>;
+ ; CHECK-NOF32X2-EMPTY:
+ ; CHECK-NOF32X2-NEXT:  // %bb.0:
+-; CHECK-NOF32X2-NEXT:    ld.param.v2.b32 {%r1, %r2}, [test_fma_ftz_param_0];
+-; CHECK-NOF32X2-NEXT:    ld.param.v2.b32 {%r3, %r4}, [test_fma_ftz_param_1];
+-; CHECK-NOF32X2-NEXT:    ld.param.v2.b32 {%r5, %r6}, [test_fma_ftz_param_2];
+-; CHECK-NOF32X2-NEXT:    fma.rn.ftz.f32 %r7, %r2, %r4, %r6;
+-; CHECK-NOF32X2-NEXT:    fma.rn.ftz.f32 %r8, %r1, %r3, %r5;
++; CHECK-NOF32X2-NEXT:    ld.param.b64 %rd3, [test_fma_ftz_param_2];
++; CHECK-NOF32X2-NEXT:    ld.param.b64 %rd2, [test_fma_ftz_param_1];
++; CHECK-NOF32X2-NEXT:    ld.param.b64 %rd1, [test_fma_ftz_param_0];
++; CHECK-NOF32X2-NEXT:    mov.b64 {%r1, %r2}, %rd3;
++; CHECK-NOF32X2-NEXT:    mov.b64 {%r3, %r4}, %rd2;
++; CHECK-NOF32X2-NEXT:    mov.b64 {%r5, %r6}, %rd1;
++; CHECK-NOF32X2-NEXT:    fma.rn.ftz.f32 %r7, %r6, %r4, %r2;
++; CHECK-NOF32X2-NEXT:    fma.rn.ftz.f32 %r8, %r5, %r3, %r1;
+ ; CHECK-NOF32X2-NEXT:    st.param.v2.b32 [func_retval0], {%r8, %r7};
+ ; CHECK-NOF32X2-NEXT:    ret;
+ ;
+@@ -671,10 +736,12 @@
+ ; CHECK-NEXT:    .reg .b64 %rd<3>;
+ ; CHECK-EMPTY:
+ ; CHECK-NEXT:  // %bb.0:
+-; CHECK-NEXT:    ld.param.v2.b32 {%r1, %r2}, [test_fdiv_ftz_param_0];
+-; CHECK-NEXT:    ld.param.v2.b32 {%r3, %r4}, [test_fdiv_ftz_param_1];
+-; CHECK-NEXT:    div.rn.ftz.f32 %r5, %r2, %r4;
+-; CHECK-NEXT:    div.rn.ftz.f32 %r6, %r1, %r3;
++; CHECK-NEXT:    ld.param.b64 %rd2, [test_fdiv_ftz_param_1];
++; CHECK-NEXT:    ld.param.b64 %rd1, [test_fdiv_ftz_param_0];
++; CHECK-NEXT:    mov.b64 {%r1, %r2}, %rd2;
++; CHECK-NEXT:    mov.b64 {%r3, %r4}, %rd1;
++; CHECK-NEXT:    div.rn.ftz.f32 %r5, %r4, %r2;
++; CHECK-NEXT:    div.rn.ftz.f32 %r6, %r3, %r1;
+ ; CHECK-NEXT:    st.param.v2.b32 [func_retval0], {%r6, %r5};
+ ; CHECK-NEXT:    ret;
+   %r = fdiv <2 x float> %a, %b
+@@ -689,20 +756,22 @@
+ ; CHECK-NEXT:    .reg .b64 %rd<3>;
+ ; CHECK-EMPTY:
+ ; CHECK-NEXT:  // %bb.0:
+-; CHECK-NEXT:    ld.param.v2.b32 {%r1, %r2}, [test_frem_ftz_param_0];
+-; CHECK-NEXT:    ld.param.v2.b32 {%r3, %r4}, [test_frem_ftz_param_1];
+-; CHECK-NEXT:    div.rn.ftz.f32 %r5, %r2, %r4;
++; CHECK-NEXT:    ld.param.b64 %rd2, [test_frem_ftz_param_1];
++; CHECK-NEXT:    ld.param.b64 %rd1, [test_frem_ftz_param_0];
++; CHECK-NEXT:    mov.b64 {%r1, %r2}, %rd2;
++; CHECK-NEXT:    mov.b64 {%r3, %r4}, %rd1;
++; CHECK-NEXT:    div.rn.ftz.f32 %r5, %r4, %r2;
+ ; CHECK-NEXT:    cvt.rzi.ftz.f32.f32 %r6, %r5;
+ ; CHECK-NEXT:    neg.ftz.f32 %r7, %r6;
+-; CHECK-NEXT:    fma.rn.ftz.f32 %r8, %r7, %r4, %r2;
+-; CHECK-NEXT:    testp.infinite.f32 %p1, %r4;
+-; CHECK-NEXT:    selp.f32 %r9, %r2, %r8, %p1;
+-; CHECK-NEXT:    div.rn.ftz.f32 %r10, %r1, %r3;
++; CHECK-NEXT:    fma.rn.ftz.f32 %r8, %r7, %r2, %r4;
++; CHECK-NEXT:    testp.infinite.f32 %p1, %r2;
++; CHECK-NEXT:    selp.f32 %r9, %r4, %r8, %p1;
++; CHECK-NEXT:    div.rn.ftz.f32 %r10, %r3, %r1;
+ ; CHECK-NEXT:    cvt.rzi.ftz.f32.f32 %r11, %r10;
+ ; CHECK-NEXT:    neg.ftz.f32 %r12, %r11;
+-; CHECK-NEXT:    fma.rn.ftz.f32 %r13, %r12, %r3, %r1;
+-; CHECK-NEXT:    testp.infinite.f32 %p2, %r3;
+-; CHECK-NEXT:    selp.f32 %r14, %r1, %r13, %p2;
++; CHECK-NEXT:    fma.rn.ftz.f32 %r13, %r12, %r1, %r3;
++; CHECK-NEXT:    testp.infinite.f32 %p2, %r1;
++; CHECK-NEXT:    selp.f32 %r14, %r3, %r13, %p2;
+ ; CHECK-NEXT:    st.param.v2.b32 [func_retval0], {%r14, %r9};
+ ; CHECK-NEXT:    ret;
+   %r = frem <2 x float> %a, %b
+@@ -877,14 +946,18 @@
+ ; CHECK-NEXT:    .reg .b64 %rd<5>;
+ ; CHECK-EMPTY:
+ ; CHECK-NEXT:  // %bb.0:
+-; CHECK-NEXT:    ld.param.v2.b32 {%r1, %r2}, [test_select_cc_param_0];
+-; CHECK-NEXT:    ld.param.v2.b32 {%r3, %r4}, [test_select_cc_param_2];
+-; CHECK-NEXT:    ld.param.v2.b32 {%r5, %r6}, [test_select_cc_param_3];
+-; CHECK-NEXT:    setp.neu.f32 %p1, %r3, %r5;
+-; CHECK-NEXT:    setp.neu.f32 %p2, %r4, %r6;
+-; CHECK-NEXT:    ld.param.v2.b32 {%r7, %r8}, [test_select_cc_param_1];
+-; CHECK-NEXT:    selp.f32 %r9, %r2, %r8, %p2;
+-; CHECK-NEXT:    selp.f32 %r10, %r1, %r7, %p1;
++; CHECK-NEXT:    ld.param.b64 %rd4, [test_select_cc_param_3];
++; CHECK-NEXT:    ld.param.b64 %rd3, [test_select_cc_param_2];
++; CHECK-NEXT:    ld.param.b64 %rd2, [test_select_cc_param_1];
++; CHECK-NEXT:    ld.param.b64 %rd1, [test_select_cc_param_0];
++; CHECK-NEXT:    mov.b64 {%r1, %r2}, %rd4;
++; CHECK-NEXT:    mov.b64 {%r3, %r4}, %rd3;
++; CHECK-NEXT:    setp.neu.f32 %p1, %r3, %r1;
++; CHECK-NEXT:    setp.neu.f32 %p2, %r4, %r2;
++; CHECK-NEXT:    mov.b64 {%r5, %r6}, %rd2;
++; CHECK-NEXT:    mov.b64 {%r7, %r8}, %rd1;
++; CHECK-NEXT:    selp.f32 %r9, %r8, %r6, %p2;
++; CHECK-NEXT:    selp.f32 %r10, %r7, %r5, %p1;
+ ; CHECK-NEXT:    st.param.v2.b32 [func_retval0], {%r10, %r9};
+ ; CHECK-NEXT:    ret;
+   %cc = fcmp une <2 x float> %c, %d
+@@ -902,10 +975,12 @@
+ ; CHECK-NEXT:  // %bb.0:
+ ; CHECK-NEXT:    ld.param.v2.b64 {%rd3, %rd4}, [test_select_cc_f64_f32_param_1];
+ ; CHECK-NEXT:    ld.param.v2.b64 {%rd1, %rd2}, [test_select_cc_f64_f32_param_0];
+-; CHECK-NEXT:    ld.param.v2.b32 {%r1, %r2}, [test_select_cc_f64_f32_param_2];
+-; CHECK-NEXT:    ld.param.v2.b32 {%r3, %r4}, [test_select_cc_f64_f32_param_3];
+-; CHECK-NEXT:    setp.neu.f32 %p1, %r1, %r3;
+-; CHECK-NEXT:    setp.neu.f32 %p2, %r2, %r4;
++; CHECK-NEXT:    ld.param.b64 %rd6, [test_select_cc_f64_f32_param_3];
++; CHECK-NEXT:    ld.param.b64 %rd5, [test_select_cc_f64_f32_param_2];
++; CHECK-NEXT:    mov.b64 {%r1, %r2}, %rd6;
++; CHECK-NEXT:    mov.b64 {%r3, %r4}, %rd5;
++; CHECK-NEXT:    setp.neu.f32 %p1, %r3, %r1;
++; CHECK-NEXT:    setp.neu.f32 %p2, %r4, %r2;
+ ; CHECK-NEXT:    selp.f64 %rd7, %rd2, %rd4, %p2;
+ ; CHECK-NEXT:    selp.f64 %rd8, %rd1, %rd3, %p1;
+ ; CHECK-NEXT:    st.param.v2.b64 [func_retval0], {%rd8, %rd7};
+@@ -925,12 +1000,14 @@
+ ; CHECK-NEXT:  // %bb.0:
+ ; CHECK-NEXT:    ld.param.v2.b64 {%rd5, %rd6}, [test_select_cc_f32_f64_param_3];
+ ; CHECK-NEXT:    ld.param.v2.b64 {%rd3, %rd4}, [test_select_cc_f32_f64_param_2];
+-; CHECK-NEXT:    ld.param.v2.b32 {%r1, %r2}, [test_select_cc_f32_f64_param_0];
++; CHECK-NEXT:    ld.param.b64 %rd2, [test_select_cc_f32_f64_param_1];
++; CHECK-NEXT:    ld.param.b64 %rd1, [test_select_cc_f32_f64_param_0];
+ ; CHECK-NEXT:    setp.neu.f64 %p1, %rd3, %rd5;
+ ; CHECK-NEXT:    setp.neu.f64 %p2, %rd4, %rd6;
+-; CHECK-NEXT:    ld.param.v2.b32 {%r3, %r4}, [test_select_cc_f32_f64_param_1];
+-; CHECK-NEXT:    selp.f32 %r5, %r2, %r4, %p2;
+-; CHECK-NEXT:    selp.f32 %r6, %r1, %r3, %p1;
++; CHECK-NEXT:    mov.b64 {%r1, %r2}, %rd2;
++; CHECK-NEXT:    mov.b64 {%r3, %r4}, %rd1;
++; CHECK-NEXT:    selp.f32 %r5, %r4, %r2, %p2;
++; CHECK-NEXT:    selp.f32 %r6, %r3, %r1, %p1;
+ ; CHECK-NEXT:    st.param.v2.b32 [func_retval0], {%r6, %r5};
+ ; CHECK-NEXT:    ret;
+   %cc = fcmp une <2 x double> %c, %d
+@@ -947,10 +1024,12 @@
+ ; CHECK-NEXT:    .reg .b64 %rd<3>;
+ ; CHECK-EMPTY:
+ ; CHECK-NEXT:  // %bb.0:
+-; CHECK-NEXT:    ld.param.v2.b32 {%r1, %r2}, [test_fcmp_une_param_0];
+-; CHECK-NEXT:    ld.param.v2.b32 {%r3, %r4}, [test_fcmp_une_param_1];
+-; CHECK-NEXT:    setp.neu.f32 %p1, %r2, %r4;
+-; CHECK-NEXT:    setp.neu.f32 %p2, %r1, %r3;
++; CHECK-NEXT:    ld.param.b64 %rd2, [test_fcmp_une_param_1];
++; CHECK-NEXT:    ld.param.b64 %rd1, [test_fcmp_une_param_0];
++; CHECK-NEXT:    mov.b64 {%r1, %r2}, %rd2;
++; CHECK-NEXT:    mov.b64 {%r3, %r4}, %rd1;
++; CHECK-NEXT:    setp.neu.f32 %p1, %r4, %r2;
++; CHECK-NEXT:    setp.neu.f32 %p2, %r3, %r1;
+ ; CHECK-NEXT:    selp.b16 %rs1, -1, 0, %p2;
+ ; CHECK-NEXT:    st.param.b8 [func_retval0], %rs1;
+ ; CHECK-NEXT:    selp.b16 %rs2, -1, 0, %p1;
+@@ -969,10 +1048,12 @@
+ ; CHECK-NEXT:    .reg .b64 %rd<3>;
+ ; CHECK-EMPTY:
+ ; CHECK-NEXT:  // %bb.0:
+-; CHECK-NEXT:    ld.param.v2.b32 {%r1, %r2}, [test_fcmp_ueq_param_0];
+-; CHECK-NEXT:    ld.param.v2.b32 {%r3, %r4}, [test_fcmp_ueq_param_1];
+-; CHECK-NEXT:    setp.equ.f32 %p1, %r2, %r4;
+-; CHECK-NEXT:    setp.equ.f32 %p2, %r1, %r3;
++; CHECK-NEXT:    ld.param.b64 %rd2, [test_fcmp_ueq_param_1];
++; CHECK-NEXT:    ld.param.b64 %rd1, [test_fcmp_ueq_param_0];
++; CHECK-NEXT:    mov.b64 {%r1, %r2}, %rd2;
++; CHECK-NEXT:    mov.b64 {%r3, %r4}, %rd1;
++; CHECK-NEXT:    setp.equ.f32 %p1, %r4, %r2;
++; CHECK-NEXT:    setp.equ.f32 %p2, %r3, %r1;
+ ; CHECK-NEXT:    selp.b16 %rs1, -1, 0, %p2;
+ ; CHECK-NEXT:    st.param.b8 [func_retval0], %rs1;
+ ; CHECK-NEXT:    selp.b16 %rs2, -1, 0, %p1;
+@@ -991,10 +1072,12 @@
+ ; CHECK-NEXT:    .reg .b64 %rd<3>;
+ ; CHECK-EMPTY:
+ ; CHECK-NEXT:  // %bb.0:
+-; CHECK-NEXT:    ld.param.v2.b32 {%r1, %r2}, [test_fcmp_ugt_param_0];
+-; CHECK-NEXT:    ld.param.v2.b32 {%r3, %r4}, [test_fcmp_ugt_param_1];
+-; CHECK-NEXT:    setp.gtu.f32 %p1, %r2, %r4;
+-; CHECK-NEXT:    setp.gtu.f32 %p2, %r1, %r3;
++; CHECK-NEXT:    ld.param.b64 %rd2, [test_fcmp_ugt_param_1];
++; CHECK-NEXT:    ld.param.b64 %rd1, [test_fcmp_ugt_param_0];
++; CHECK-NEXT:    mov.b64 {%r1, %r2}, %rd2;
++; CHECK-NEXT:    mov.b64 {%r3, %r4}, %rd1;
++; CHECK-NEXT:    setp.gtu.f32 %p1, %r4, %r2;
++; CHECK-NEXT:    setp.gtu.f32 %p2, %r3, %r1;
+ ; CHECK-NEXT:    selp.b16 %rs1, -1, 0, %p2;
+ ; CHECK-NEXT:    st.param.b8 [func_retval0], %rs1;
+ ; CHECK-NEXT:    selp.b16 %rs2, -1, 0, %p1;
+@@ -1013,10 +1096,12 @@
+ ; CHECK-NEXT:    .reg .b64 %rd<3>;
+ ; CHECK-EMPTY:
+ ; CHECK-NEXT:  // %bb.0:
+-; CHECK-NEXT:    ld.param.v2.b32 {%r1, %r2}, [test_fcmp_uge_param_0];
+-; CHECK-NEXT:    ld.param.v2.b32 {%r3, %r4}, [test_fcmp_uge_param_1];
+-; CHECK-NEXT:    setp.geu.f32 %p1, %r2, %r4;
+-; CHECK-NEXT:    setp.geu.f32 %p2, %r1, %r3;
++; CHECK-NEXT:    ld.param.b64 %rd2, [test_fcmp_uge_param_1];
++; CHECK-NEXT:    ld.param.b64 %rd1, [test_fcmp_uge_param_0];
++; CHECK-NEXT:    mov.b64 {%r1, %r2}, %rd2;
++; CHECK-NEXT:    mov.b64 {%r3, %r4}, %rd1;
++; CHECK-NEXT:    setp.geu.f32 %p1, %r4, %r2;
++; CHECK-NEXT:    setp.geu.f32 %p2, %r3, %r1;
+ ; CHECK-NEXT:    selp.b16 %rs1, -1, 0, %p2;
+ ; CHECK-NEXT:    st.param.b8 [func_retval0], %rs1;
+ ; CHECK-NEXT:    selp.b16 %rs2, -1, 0, %p1;
+@@ -1035,10 +1120,12 @@
+ ; CHECK-NEXT:    .reg .b64 %rd<3>;
+ ; CHECK-EMPTY:
+ ; CHECK-NEXT:  // %bb.0:
+-; CHECK-NEXT:    ld.param.v2.b32 {%r1, %r2}, [test_fcmp_ult_param_0];
+-; CHECK-NEXT:    ld.param.v2.b32 {%r3, %r4}, [test_fcmp_ult_param_1];
+-; CHECK-NEXT:    setp.ltu.f32 %p1, %r2, %r4;
+-; CHECK-NEXT:    setp.ltu.f32 %p2, %r1, %r3;
++; CHECK-NEXT:    ld.param.b64 %rd2, [test_fcmp_ult_param_1];
++; CHECK-NEXT:    ld.param.b64 %rd1, [test_fcmp_ult_param_0];
++; CHECK-NEXT:    mov.b64 {%r1, %r2}, %rd2;
++; CHECK-NEXT:    mov.b64 {%r3, %r4}, %rd1;
++; CHECK-NEXT:    setp.ltu.f32 %p1, %r4, %r2;
++; CHECK-NEXT:    setp.ltu.f32 %p2, %r3, %r1;
+ ; CHECK-NEXT:    selp.b16 %rs1, -1, 0, %p2;
+ ; CHECK-NEXT:    st.param.b8 [func_retval0], %rs1;
+ ; CHECK-NEXT:    selp.b16 %rs2, -1, 0, %p1;
+@@ -1057,10 +1144,12 @@
+ ; CHECK-NEXT:    .reg .b64 %rd<3>;
+ ; CHECK-EMPTY:
+ ; CHECK-NEXT:  // %bb.0:
+-; CHECK-NEXT:    ld.param.v2.b32 {%r1, %r2}, [test_fcmp_ule_param_0];
+-; CHECK-NEXT:    ld.param.v2.b32 {%r3, %r4}, [test_fcmp_ule_param_1];
+-; CHECK-NEXT:    setp.leu.f32 %p1, %r2, %r4;
+-; CHECK-NEXT:    setp.leu.f32 %p2, %r1, %r3;
++; CHECK-NEXT:    ld.param.b64 %rd2, [test_fcmp_ule_param_1];
++; CHECK-NEXT:    ld.param.b64 %rd1, [test_fcmp_ule_param_0];
++; CHECK-NEXT:    mov.b64 {%r1, %r2}, %rd2;
++; CHECK-NEXT:    mov.b64 {%r3, %r4}, %rd1;
++; CHECK-NEXT:    setp.leu.f32 %p1, %r4, %r2;
++; CHECK-NEXT:    setp.leu.f32 %p2, %r3, %r1;
+ ; CHECK-NEXT:    selp.b16 %rs1, -1, 0, %p2;
+ ; CHECK-NEXT:    st.param.b8 [func_retval0], %rs1;
+ ; CHECK-NEXT:    selp.b16 %rs2, -1, 0, %p1;
+@@ -1079,10 +1168,12 @@
+ ; CHECK-NEXT:    .reg .b64 %rd<3>;
+ ; CHECK-EMPTY:
+ ; CHECK-NEXT:  // %bb.0:
+-; CHECK-NEXT:    ld.param.v2.b32 {%r1, %r2}, [test_fcmp_uno_param_0];
+-; CHECK-NEXT:    ld.param.v2.b32 {%r3, %r4}, [test_fcmp_uno_param_1];
+-; CHECK-NEXT:    setp.nan.f32 %p1, %r2, %r4;
+-; CHECK-NEXT:    setp.nan.f32 %p2, %r1, %r3;
++; CHECK-NEXT:    ld.param.b64 %rd2, [test_fcmp_uno_param_1];
++; CHECK-NEXT:    ld.param.b64 %rd1, [test_fcmp_uno_param_0];
++; CHECK-NEXT:    mov.b64 {%r1, %r2}, %rd2;
++; CHECK-NEXT:    mov.b64 {%r3, %r4}, %rd1;
++; CHECK-NEXT:    setp.nan.f32 %p1, %r4, %r2;
++; CHECK-NEXT:    setp.nan.f32 %p2, %r3, %r1;
+ ; CHECK-NEXT:    selp.b16 %rs1, -1, 0, %p2;
+ ; CHECK-NEXT:    st.param.b8 [func_retval0], %rs1;
+ ; CHECK-NEXT:    selp.b16 %rs2, -1, 0, %p1;
+@@ -1101,10 +1192,12 @@
+ ; CHECK-NEXT:    .reg .b64 %rd<3>;
+ ; CHECK-EMPTY:
+ ; CHECK-NEXT:  // %bb.0:
+-; CHECK-NEXT:    ld.param.v2.b32 {%r1, %r2}, [test_fcmp_one_param_0];
+-; CHECK-NEXT:    ld.param.v2.b32 {%r3, %r4}, [test_fcmp_one_param_1];
+-; CHECK-NEXT:    setp.ne.f32 %p1, %r2, %r4;
+-; CHECK-NEXT:    setp.ne.f32 %p2, %r1, %r3;
++; CHECK-NEXT:    ld.param.b64 %rd2, [test_fcmp_one_param_1];
++; CHECK-NEXT:    ld.param.b64 %rd1, [test_fcmp_one_param_0];
++; CHECK-NEXT:    mov.b64 {%r1, %r2}, %rd2;
++; CHECK-NEXT:    mov.b64 {%r3, %r4}, %rd1;
++; CHECK-NEXT:    setp.ne.f32 %p1, %r4, %r2;
++; CHECK-NEXT:    setp.ne.f32 %p2, %r3, %r1;
+ ; CHECK-NEXT:    selp.b16 %rs1, -1, 0, %p2;
+ ; CHECK-NEXT:    st.param.b8 [func_retval0], %rs1;
+ ; CHECK-NEXT:    selp.b16 %rs2, -1, 0, %p1;
+@@ -1123,10 +1216,12 @@
+ ; CHECK-NEXT:    .reg .b64 %rd<3>;
+ ; CHECK-EMPTY:
+ ; CHECK-NEXT:  // %bb.0:
+-; CHECK-NEXT:    ld.param.v2.b32 {%r1, %r2}, [test_fcmp_oeq_param_0];
+-; CHECK-NEXT:    ld.param.v2.b32 {%r3, %r4}, [test_fcmp_oeq_param_1];
+-; CHECK-NEXT:    setp.eq.f32 %p1, %r2, %r4;
+-; CHECK-NEXT:    setp.eq.f32 %p2, %r1, %r3;
++; CHECK-NEXT:    ld.param.b64 %rd2, [test_fcmp_oeq_param_1];
++; CHECK-NEXT:    ld.param.b64 %rd1, [test_fcmp_oeq_param_0];
++; CHECK-NEXT:    mov.b64 {%r1, %r2}, %rd2;
++; CHECK-NEXT:    mov.b64 {%r3, %r4}, %rd1;
++; CHECK-NEXT:    setp.eq.f32 %p1, %r4, %r2;
++; CHECK-NEXT:    setp.eq.f32 %p2, %r3, %r1;
+ ; CHECK-NEXT:    selp.b16 %rs1, -1, 0, %p2;
+ ; CHECK-NEXT:    st.param.b8 [func_retval0], %rs1;
+ ; CHECK-NEXT:    selp.b16 %rs2, -1, 0, %p1;
+@@ -1145,10 +1240,12 @@
+ ; CHECK-NEXT:    .reg .b64 %rd<3>;
+ ; CHECK-EMPTY:
+ ; CHECK-NEXT:  // %bb.0:
+-; CHECK-NEXT:    ld.param.v2.b32 {%r1, %r2}, [test_fcmp_ogt_param_0];
+-; CHECK-NEXT:    ld.param.v2.b32 {%r3, %r4}, [test_fcmp_ogt_param_1];
+-; CHECK-NEXT:    setp.gt.f32 %p1, %r2, %r4;
+-; CHECK-NEXT:    setp.gt.f32 %p2, %r1, %r3;
++; CHECK-NEXT:    ld.param.b64 %rd2, [test_fcmp_ogt_param_1];
++; CHECK-NEXT:    ld.param.b64 %rd1, [test_fcmp_ogt_param_0];
++; CHECK-NEXT:    mov.b64 {%r1, %r2}, %rd2;
++; CHECK-NEXT:    mov.b64 {%r3, %r4}, %rd1;
++; CHECK-NEXT:    setp.gt.f32 %p1, %r4, %r2;
++; CHECK-NEXT:    setp.gt.f32 %p2, %r3, %r1;
+ ; CHECK-NEXT:    selp.b16 %rs1, -1, 0, %p2;
+ ; CHECK-NEXT:    st.param.b8 [func_retval0], %rs1;
+ ; CHECK-NEXT:    selp.b16 %rs2, -1, 0, %p1;
+@@ -1167,10 +1264,12 @@
+ ; CHECK-NEXT:    .reg .b64 %rd<3>;
+ ; CHECK-EMPTY:
+ ; CHECK-NEXT:  // %bb.0:
+-; CHECK-NEXT:    ld.param.v2.b32 {%r1, %r2}, [test_fcmp_oge_param_0];
+-; CHECK-NEXT:    ld.param.v2.b32 {%r3, %r4}, [test_fcmp_oge_param_1];
+-; CHECK-NEXT:    setp.ge.f32 %p1, %r2, %r4;
+-; CHECK-NEXT:    setp.ge.f32 %p2, %r1, %r3;
++; CHECK-NEXT:    ld.param.b64 %rd2, [test_fcmp_oge_param_1];
++; CHECK-NEXT:    ld.param.b64 %rd1, [test_fcmp_oge_param_0];
++; CHECK-NEXT:    mov.b64 {%r1, %r2}, %rd2;
++; CHECK-NEXT:    mov.b64 {%r3, %r4}, %rd1;
++; CHECK-NEXT:    setp.ge.f32 %p1, %r4, %r2;
++; CHECK-NEXT:    setp.ge.f32 %p2, %r3, %r1;
+ ; CHECK-NEXT:    selp.b16 %rs1, -1, 0, %p2;
+ ; CHECK-NEXT:    st.param.b8 [func_retval0], %rs1;
+ ; CHECK-NEXT:    selp.b16 %rs2, -1, 0, %p1;
+@@ -1189,10 +1288,12 @@
+ ; CHECK-NEXT:    .reg .b64 %rd<3>;
+ ; CHECK-EMPTY:
+ ; CHECK-NEXT:  // %bb.0:
+-; CHECK-NEXT:    ld.param.v2.b32 {%r1, %r2}, [test_fcmp_olt_param_0];
+-; CHECK-NEXT:    ld.param.v2.b32 {%r3, %r4}, [test_fcmp_olt_param_1];
+-; CHECK-NEXT:    setp.lt.f32 %p1, %r2, %r4;
+-; CHECK-NEXT:    setp.lt.f32 %p2, %r1, %r3;
++; CHECK-NEXT:    ld.param.b64 %rd2, [test_fcmp_olt_param_1];
++; CHECK-NEXT:    ld.param.b64 %rd1, [test_fcmp_olt_param_0];
++; CHECK-NEXT:    mov.b64 {%r1, %r2}, %rd2;
++; CHECK-NEXT:    mov.b64 {%r3, %r4}, %rd1;
++; CHECK-NEXT:    setp.lt.f32 %p1, %r4, %r2;
++; CHECK-NEXT:    setp.lt.f32 %p2, %r3, %r1;
+ ; CHECK-NEXT:    selp.b16 %rs1, -1, 0, %p2;
+ ; CHECK-NEXT:    st.param.b8 [func_retval0], %rs1;
+ ; CHECK-NEXT:    selp.b16 %rs2, -1, 0, %p1;
+@@ -1211,10 +1312,12 @@
+ ; CHECK-NEXT:    .reg .b64 %rd<3>;
+ ; CHECK-EMPTY:
+ ; CHECK-NEXT:  // %bb.0:
+-; CHECK-NEXT:    ld.param.v2.b32 {%r1, %r2}, [test_fcmp_ole_param_0];
+-; CHECK-NEXT:    ld.param.v2.b32 {%r3, %r4}, [test_fcmp_ole_param_1];
+-; CHECK-NEXT:    setp.le.f32 %p1, %r2, %r4;
+-; CHECK-NEXT:    setp.le.f32 %p2, %r1, %r3;
++; CHECK-NEXT:    ld.param.b64 %rd2, [test_fcmp_ole_param_1];
++; CHECK-NEXT:    ld.param.b64 %rd1, [test_fcmp_ole_param_0];
++; CHECK-NEXT:    mov.b64 {%r1, %r2}, %rd2;
++; CHECK-NEXT:    mov.b64 {%r3, %r4}, %rd1;
++; CHECK-NEXT:    setp.le.f32 %p1, %r4, %r2;
++; CHECK-NEXT:    setp.le.f32 %p2, %r3, %r1;
+ ; CHECK-NEXT:    selp.b16 %rs1, -1, 0, %p2;
+ ; CHECK-NEXT:    st.param.b8 [func_retval0], %rs1;
+ ; CHECK-NEXT:    selp.b16 %rs2, -1, 0, %p1;
+@@ -1233,10 +1336,12 @@
+ ; CHECK-NEXT:    .reg .b64 %rd<3>;
+ ; CHECK-EMPTY:
+ ; CHECK-NEXT:  // %bb.0:
+-; CHECK-NEXT:    ld.param.v2.b32 {%r1, %r2}, [test_fcmp_ord_param_0];
+-; CHECK-NEXT:    ld.param.v2.b32 {%r3, %r4}, [test_fcmp_ord_param_1];
+-; CHECK-NEXT:    setp.num.f32 %p1, %r2, %r4;
+-; CHECK-NEXT:    setp.num.f32 %p2, %r1, %r3;
++; CHECK-NEXT:    ld.param.b64 %rd2, [test_fcmp_ord_param_1];
++; CHECK-NEXT:    ld.param.b64 %rd1, [test_fcmp_ord_param_0];
++; CHECK-NEXT:    mov.b64 {%r1, %r2}, %rd2;
++; CHECK-NEXT:    mov.b64 {%r3, %r4}, %rd1;
++; CHECK-NEXT:    setp.num.f32 %p1, %r4, %r2;
++; CHECK-NEXT:    setp.num.f32 %p2, %r3, %r1;
+ ; CHECK-NEXT:    selp.b16 %rs1, -1, 0, %p2;
+ ; CHECK-NEXT:    st.param.b8 [func_retval0], %rs1;
+ ; CHECK-NEXT:    selp.b16 %rs2, -1, 0, %p1;
+@@ -1253,7 +1358,8 @@
+ ; CHECK-NEXT:    .reg .b64 %rd<2>;
+ ; CHECK-EMPTY:
+ ; CHECK-NEXT:  // %bb.0:
+-; CHECK-NEXT:    ld.param.v2.b32 {%r1, %r2}, [test_fptosi_i32_param_0];
++; CHECK-NEXT:    ld.param.b64 %rd1, [test_fptosi_i32_param_0];
++; CHECK-NEXT:    mov.b64 {%r1, %r2}, %rd1;
+ ; CHECK-NEXT:    cvt.rzi.s32.f32 %r3, %r2;
+ ; CHECK-NEXT:    cvt.rzi.s32.f32 %r4, %r1;
+ ; CHECK-NEXT:    st.param.v2.b32 [func_retval0], {%r4, %r3};
+@@ -1269,7 +1375,8 @@
+ ; CHECK-NEXT:    .reg .b64 %rd<4>;
+ ; CHECK-EMPTY:
+ ; CHECK-NEXT:  // %bb.0:
+-; CHECK-NEXT:    ld.param.v2.b32 {%r1, %r2}, [test_fptosi_i64_param_0];
++; CHECK-NEXT:    ld.param.b64 %rd1, [test_fptosi_i64_param_0];
++; CHECK-NEXT:    mov.b64 {%r1, %r2}, %rd1;
+ ; CHECK-NEXT:    cvt.rzi.s64.f32 %rd2, %r2;
+ ; CHECK-NEXT:    cvt.rzi.s64.f32 %rd3, %r1;
+ ; CHECK-NEXT:    st.param.v2.b64 [func_retval0], {%rd3, %rd2};
+@@ -1285,7 +1392,8 @@
+ ; CHECK-NEXT:    .reg .b64 %rd<2>;
+ ; CHECK-EMPTY:
+ ; CHECK-NEXT:  // %bb.0:
+-; CHECK-NEXT:    ld.param.v2.b32 {%r1, %r2}, [test_fptoui_2xi32_param_0];
++; CHECK-NEXT:    ld.param.b64 %rd1, [test_fptoui_2xi32_param_0];
++; CHECK-NEXT:    mov.b64 {%r1, %r2}, %rd1;
+ ; CHECK-NEXT:    cvt.rzi.u32.f32 %r3, %r2;
+ ; CHECK-NEXT:    cvt.rzi.u32.f32 %r4, %r1;
+ ; CHECK-NEXT:    st.param.v2.b32 [func_retval0], {%r4, %r3};
+@@ -1301,7 +1409,8 @@
+ ; CHECK-NEXT:    .reg .b64 %rd<4>;
+ ; CHECK-EMPTY:
+ ; CHECK-NEXT:  // %bb.0:
+-; CHECK-NEXT:    ld.param.v2.b32 {%r1, %r2}, [test_fptoui_2xi64_param_0];
++; CHECK-NEXT:    ld.param.b64 %rd1, [test_fptoui_2xi64_param_0];
++; CHECK-NEXT:    mov.b64 {%r1, %r2}, %rd1;
+ ; CHECK-NEXT:    cvt.rzi.u64.f32 %rd2, %r2;
+ ; CHECK-NEXT:    cvt.rzi.u64.f32 %rd3, %r1;
+ ; CHECK-NEXT:    st.param.v2.b64 [func_retval0], {%rd3, %rd2};
+@@ -1380,9 +1489,10 @@
+ ; CHECK-NOF32X2-EMPTY:
+ ; CHECK-NOF32X2-NEXT:  // %bb.0:
+ ; CHECK-NOF32X2-NEXT:    ld.param.v2.b32 {%r1, %r2}, [test_uitofp_2xi32_fadd_param_0];
++; CHECK-NOF32X2-NEXT:    ld.param.b64 %rd1, [test_uitofp_2xi32_fadd_param_1];
+ ; CHECK-NOF32X2-NEXT:    cvt.rn.f32.u32 %r3, %r1;
+ ; CHECK-NOF32X2-NEXT:    cvt.rn.f32.u32 %r4, %r2;
+-; CHECK-NOF32X2-NEXT:    ld.param.v2.b32 {%r5, %r6}, [test_uitofp_2xi32_fadd_param_1];
++; CHECK-NOF32X2-NEXT:    mov.b64 {%r5, %r6}, %rd1;
+ ; CHECK-NOF32X2-NEXT:    add.rn.f32 %r7, %r6, %r4;
+ ; CHECK-NOF32X2-NEXT:    add.rn.f32 %r8, %r5, %r3;
+ ; CHECK-NOF32X2-NEXT:    st.param.v2.b32 [func_retval0], {%r8, %r7};
+@@ -1431,7 +1541,8 @@
+ ; CHECK-NEXT:    .reg .b64 %rd<4>;
+ ; CHECK-EMPTY:
+ ; CHECK-NEXT:  // %bb.0:
+-; CHECK-NEXT:    ld.param.v2.b32 {%r1, %r2}, [test_fpext_2xdouble_param_0];
++; CHECK-NEXT:    ld.param.b64 %rd1, [test_fpext_2xdouble_param_0];
++; CHECK-NEXT:    mov.b64 {%r1, %r2}, %rd1;
+ ; CHECK-NEXT:    cvt.f64.f32 %rd2, %r2;
+ ; CHECK-NEXT:    cvt.f64.f32 %rd3, %r1;
+ ; CHECK-NEXT:    st.param.v2.b64 [func_retval0], {%rd3, %rd2};
+@@ -1499,7 +1610,8 @@
+ ; CHECK-NEXT:    .reg .b64 %rd<2>;
+ ; CHECK-EMPTY:
+ ; CHECK-NEXT:  // %bb.0:
+-; CHECK-NEXT:    ld.param.v2.b32 {%r1, %r2}, [test_sqrt_param_0];
++; CHECK-NEXT:    ld.param.b64 %rd1, [test_sqrt_param_0];
++; CHECK-NEXT:    mov.b64 {%r1, %r2}, %rd1;
+ ; CHECK-NEXT:    sqrt.rn.f32 %r3, %r2;
+ ; CHECK-NEXT:    sqrt.rn.f32 %r4, %r1;
+ ; CHECK-NEXT:    st.param.v2.b32 [func_retval0], {%r4, %r3};
+@@ -1522,7 +1634,8 @@
+ ; CHECK-NEXT:    .reg .b64 %rd<2>;
+ ; CHECK-EMPTY:
+ ; CHECK-NEXT:  // %bb.0:
+-; CHECK-NEXT:    ld.param.v2.b32 {%r1, %r2}, [test_sin_param_0];
++; CHECK-NEXT:    ld.param.b64 %rd1, [test_sin_param_0];
++; CHECK-NEXT:    mov.b64 {%r1, %r2}, %rd1;
+ ; CHECK-NEXT:    sin.approx.f32 %r3, %r2;
+ ; CHECK-NEXT:    sin.approx.f32 %r4, %r1;
+ ; CHECK-NEXT:    st.param.v2.b32 [func_retval0], {%r4, %r3};
+@@ -1538,7 +1651,8 @@
+ ; CHECK-NEXT:    .reg .b64 %rd<2>;
+ ; CHECK-EMPTY:
+ ; CHECK-NEXT:  // %bb.0:
+-; CHECK-NEXT:    ld.param.v2.b32 {%r1, %r2}, [test_cos_param_0];
++; CHECK-NEXT:    ld.param.b64 %rd1, [test_cos_param_0];
++; CHECK-NEXT:    mov.b64 {%r1, %r2}, %rd1;
+ ; CHECK-NEXT:    cos.approx.f32 %r3, %r2;
+ ; CHECK-NEXT:    cos.approx.f32 %r4, %r1;
+ ; CHECK-NEXT:    st.param.v2.b32 [func_retval0], {%r4, %r3};
+@@ -1597,11 +1711,14 @@
+ ; CHECK-NOF32X2-NEXT:    .reg .b64 %rd<4>;
+ ; CHECK-NOF32X2-EMPTY:
+ ; CHECK-NOF32X2-NEXT:  // %bb.0:
+-; CHECK-NOF32X2-NEXT:    ld.param.v2.b32 {%r1, %r2}, [test_fma_param_0];
+-; CHECK-NOF32X2-NEXT:    ld.param.v2.b32 {%r3, %r4}, [test_fma_param_1];
+-; CHECK-NOF32X2-NEXT:    ld.param.v2.b32 {%r5, %r6}, [test_fma_param_2];
+-; CHECK-NOF32X2-NEXT:    fma.rn.f32 %r7, %r2, %r4, %r6;
+-; CHECK-NOF32X2-NEXT:    fma.rn.f32 %r8, %r1, %r3, %r5;
++; CHECK-NOF32X2-NEXT:    ld.param.b64 %rd3, [test_fma_param_2];
++; CHECK-NOF32X2-NEXT:    ld.param.b64 %rd2, [test_fma_param_1];
++; CHECK-NOF32X2-NEXT:    ld.param.b64 %rd1, [test_fma_param_0];
++; CHECK-NOF32X2-NEXT:    mov.b64 {%r1, %r2}, %rd3;
++; CHECK-NOF32X2-NEXT:    mov.b64 {%r3, %r4}, %rd2;
++; CHECK-NOF32X2-NEXT:    mov.b64 {%r5, %r6}, %rd1;
++; CHECK-NOF32X2-NEXT:    fma.rn.f32 %r7, %r6, %r4, %r2;
++; CHECK-NOF32X2-NEXT:    fma.rn.f32 %r8, %r5, %r3, %r1;
+ ; CHECK-NOF32X2-NEXT:    st.param.v2.b32 [func_retval0], {%r8, %r7};
+ ; CHECK-NOF32X2-NEXT:    ret;
+ ;
+@@ -1627,7 +1744,8 @@
+ ; CHECK-NEXT:    .reg .b64 %rd<2>;
+ ; CHECK-EMPTY:
+ ; CHECK-NEXT:  // %bb.0:
+-; CHECK-NEXT:    ld.param.v2.b32 {%r1, %r2}, [test_fabs_param_0];
++; CHECK-NEXT:    ld.param.b64 %rd1, [test_fabs_param_0];
++; CHECK-NEXT:    mov.b64 {%r1, %r2}, %rd1;
+ ; CHECK-NEXT:    abs.f32 %r3, %r2;
+ ; CHECK-NEXT:    abs.f32 %r4, %r1;
+ ; CHECK-NEXT:    st.param.v2.b32 [func_retval0], {%r4, %r3};
+@@ -1643,10 +1761,12 @@
+ ; CHECK-NEXT:    .reg .b64 %rd<3>;
+ ; CHECK-EMPTY:
+ ; CHECK-NEXT:  // %bb.0:
+-; CHECK-NEXT:    ld.param.v2.b32 {%r1, %r2}, [test_minnum_param_0];
+-; CHECK-NEXT:    ld.param.v2.b32 {%r3, %r4}, [test_minnum_param_1];
+-; CHECK-NEXT:    min.f32 %r5, %r2, %r4;
+-; CHECK-NEXT:    min.f32 %r6, %r1, %r3;
++; CHECK-NEXT:    ld.param.b64 %rd2, [test_minnum_param_1];
++; CHECK-NEXT:    ld.param.b64 %rd1, [test_minnum_param_0];
++; CHECK-NEXT:    mov.b64 {%r1, %r2}, %rd2;
++; CHECK-NEXT:    mov.b64 {%r3, %r4}, %rd1;
++; CHECK-NEXT:    min.f32 %r5, %r4, %r2;
++; CHECK-NEXT:    min.f32 %r6, %r3, %r1;
+ ; CHECK-NEXT:    st.param.v2.b32 [func_retval0], {%r6, %r5};
+ ; CHECK-NEXT:    ret;
+   %r = call <2 x float> @llvm.minnum(<2 x float> %a, <2 x float> %b)
+@@ -1660,10 +1780,12 @@
+ ; CHECK-NEXT:    .reg .b64 %rd<3>;
+ ; CHECK-EMPTY:
+ ; CHECK-NEXT:  // %bb.0:
+-; CHECK-NEXT:    ld.param.v2.b32 {%r1, %r2}, [test_maxnum_param_0];
+-; CHECK-NEXT:    ld.param.v2.b32 {%r3, %r4}, [test_maxnum_param_1];
+-; CHECK-NEXT:    max.f32 %r5, %r2, %r4;
+-; CHECK-NEXT:    max.f32 %r6, %r1, %r3;
++; CHECK-NEXT:    ld.param.b64 %rd2, [test_maxnum_param_1];
++; CHECK-NEXT:    ld.param.b64 %rd1, [test_maxnum_param_0];
++; CHECK-NEXT:    mov.b64 {%r1, %r2}, %rd2;
++; CHECK-NEXT:    mov.b64 {%r3, %r4}, %rd1;
++; CHECK-NEXT:    max.f32 %r5, %r4, %r2;
++; CHECK-NEXT:    max.f32 %r6, %r3, %r1;
+ ; CHECK-NEXT:    st.param.v2.b32 [func_retval0], {%r6, %r5};
+ ; CHECK-NEXT:    ret;
+   %r = call <2 x float> @llvm.maxnum(<2 x float> %a, <2 x float> %b)
+@@ -1677,8 +1799,10 @@
+ ; CHECK-NEXT:    .reg .b64 %rd<3>;
+ ; CHECK-EMPTY:
+ ; CHECK-NEXT:  // %bb.0:
+-; CHECK-NEXT:    ld.param.v2.b32 {%r1, %r2}, [test_copysign_param_0];
+-; CHECK-NEXT:    ld.param.v2.b32 {%r3, %r4}, [test_copysign_param_1];
++; CHECK-NEXT:    ld.param.b64 %rd2, [test_copysign_param_1];
++; CHECK-NEXT:    ld.param.b64 %rd1, [test_copysign_param_0];
++; CHECK-NEXT:    mov.b64 {%r1, %r2}, %rd1;
++; CHECK-NEXT:    mov.b64 {%r3, %r4}, %rd2;
+ ; CHECK-NEXT:    copysign.f32 %r5, %r4, %r2;
+ ; CHECK-NEXT:    copysign.f32 %r6, %r3, %r1;
+ ; CHECK-NEXT:    st.param.v2.b32 [func_retval0], {%r6, %r5};
+@@ -1696,18 +1820,19 @@
+ ; CHECK-EMPTY:
+ ; CHECK-NEXT:  // %bb.0:
+ ; CHECK-NEXT:    ld.param.v2.b64 {%rd2, %rd3}, [test_copysign_f64_param_1];
+-; CHECK-NEXT:    ld.param.v2.b32 {%r1, %r2}, [test_copysign_f64_param_0];
+-; CHECK-NEXT:    abs.f32 %r3, %r2;
+-; CHECK-NEXT:    neg.f32 %r4, %r3;
++; CHECK-NEXT:    ld.param.b64 %rd1, [test_copysign_f64_param_0];
+ ; CHECK-NEXT:    shr.u64 %rd4, %rd3, 63;
+ ; CHECK-NEXT:    and.b64 %rd5, %rd4, 1;
+ ; CHECK-NEXT:    setp.ne.b64 %p1, %rd5, 0;
++; CHECK-NEXT:    mov.b64 {%r1, %r2}, %rd1;
++; CHECK-NEXT:    abs.f32 %r3, %r2;
++; CHECK-NEXT:    neg.f32 %r4, %r3;
+ ; CHECK-NEXT:    selp.f32 %r5, %r4, %r3, %p1;
+-; CHECK-NEXT:    abs.f32 %r6, %r1;
+-; CHECK-NEXT:    neg.f32 %r7, %r6;
+ ; CHECK-NEXT:    shr.u64 %rd6, %rd2, 63;
+ ; CHECK-NEXT:    and.b64 %rd7, %rd6, 1;
+ ; CHECK-NEXT:    setp.ne.b64 %p2, %rd7, 0;
++; CHECK-NEXT:    abs.f32 %r6, %r1;
++; CHECK-NEXT:    neg.f32 %r7, %r6;
+ ; CHECK-NEXT:    selp.f32 %r8, %r7, %r6, %p2;
+ ; CHECK-NEXT:    st.param.v2.b32 [func_retval0], {%r8, %r5};
+ ; CHECK-NEXT:    ret;
+@@ -1723,8 +1848,10 @@
+ ; CHECK-NEXT:    .reg .b64 %rd<5>;
+ ; CHECK-EMPTY:
+ ; CHECK-NEXT:  // %bb.0:
+-; CHECK-NEXT:    ld.param.v2.b32 {%r1, %r2}, [test_copysign_extended_param_0];
+-; CHECK-NEXT:    ld.param.v2.b32 {%r3, %r4}, [test_copysign_extended_param_1];
++; CHECK-NEXT:    ld.param.b64 %rd2, [test_copysign_extended_param_1];
++; CHECK-NEXT:    ld.param.b64 %rd1, [test_copysign_extended_param_0];
++; CHECK-NEXT:    mov.b64 {%r1, %r2}, %rd1;
++; CHECK-NEXT:    mov.b64 {%r3, %r4}, %rd2;
+ ; CHECK-NEXT:    copysign.f32 %r5, %r3, %r1;
+ ; CHECK-NEXT:    copysign.f32 %r6, %r4, %r2;
+ ; CHECK-NEXT:    cvt.f64.f32 %rd3, %r6;
+@@ -1743,7 +1870,8 @@
+ ; CHECK-NEXT:    .reg .b64 %rd<2>;
+ ; CHECK-EMPTY:
+ ; CHECK-NEXT:  // %bb.0:
+-; CHECK-NEXT:    ld.param.v2.b32 {%r1, %r2}, [test_floor_param_0];
++; CHECK-NEXT:    ld.param.b64 %rd1, [test_floor_param_0];
++; CHECK-NEXT:    mov.b64 {%r1, %r2}, %rd1;
+ ; CHECK-NEXT:    cvt.rmi.f32.f32 %r3, %r2;
+ ; CHECK-NEXT:    cvt.rmi.f32.f32 %r4, %r1;
+ ; CHECK-NEXT:    st.param.v2.b32 [func_retval0], {%r4, %r3};
+@@ -1759,7 +1887,8 @@
+ ; CHECK-NEXT:    .reg .b64 %rd<2>;
+ ; CHECK-EMPTY:
+ ; CHECK-NEXT:  // %bb.0:
+-; CHECK-NEXT:    ld.param.v2.b32 {%r1, %r2}, [test_ceil_param_0];
++; CHECK-NEXT:    ld.param.b64 %rd1, [test_ceil_param_0];
++; CHECK-NEXT:    mov.b64 {%r1, %r2}, %rd1;
+ ; CHECK-NEXT:    cvt.rpi.f32.f32 %r3, %r2;
+ ; CHECK-NEXT:    cvt.rpi.f32.f32 %r4, %r1;
+ ; CHECK-NEXT:    st.param.v2.b32 [func_retval0], {%r4, %r3};
+@@ -1775,7 +1904,8 @@
+ ; CHECK-NEXT:    .reg .b64 %rd<2>;
+ ; CHECK-EMPTY:
+ ; CHECK-NEXT:  // %bb.0:
+-; CHECK-NEXT:    ld.param.v2.b32 {%r1, %r2}, [test_trunc_param_0];
++; CHECK-NEXT:    ld.param.b64 %rd1, [test_trunc_param_0];
++; CHECK-NEXT:    mov.b64 {%r1, %r2}, %rd1;
+ ; CHECK-NEXT:    cvt.rzi.f32.f32 %r3, %r2;
+ ; CHECK-NEXT:    cvt.rzi.f32.f32 %r4, %r1;
+ ; CHECK-NEXT:    st.param.v2.b32 [func_retval0], {%r4, %r3};
+@@ -1791,7 +1921,8 @@
+ ; CHECK-NEXT:    .reg .b64 %rd<2>;
+ ; CHECK-EMPTY:
+ ; CHECK-NEXT:  // %bb.0:
+-; CHECK-NEXT:    ld.param.v2.b32 {%r1, %r2}, [test_rint_param_0];
++; CHECK-NEXT:    ld.param.b64 %rd1, [test_rint_param_0];
++; CHECK-NEXT:    mov.b64 {%r1, %r2}, %rd1;
+ ; CHECK-NEXT:    cvt.rni.f32.f32 %r3, %r2;
+ ; CHECK-NEXT:    cvt.rni.f32.f32 %r4, %r1;
+ ; CHECK-NEXT:    st.param.v2.b32 [func_retval0], {%r4, %r3};
+@@ -1807,7 +1938,8 @@
+ ; CHECK-NEXT:    .reg .b64 %rd<2>;
+ ; CHECK-EMPTY:
+ ; CHECK-NEXT:  // %bb.0:
+-; CHECK-NEXT:    ld.param.v2.b32 {%r1, %r2}, [test_nearbyint_param_0];
++; CHECK-NEXT:    ld.param.b64 %rd1, [test_nearbyint_param_0];
++; CHECK-NEXT:    mov.b64 {%r1, %r2}, %rd1;
+ ; CHECK-NEXT:    cvt.rni.f32.f32 %r3, %r2;
+ ; CHECK-NEXT:    cvt.rni.f32.f32 %r4, %r1;
+ ; CHECK-NEXT:    st.param.v2.b32 [func_retval0], {%r4, %r3};
+@@ -1823,7 +1955,8 @@
+ ; CHECK-NEXT:    .reg .b64 %rd<2>;
+ ; CHECK-EMPTY:
+ ; CHECK-NEXT:  // %bb.0:
+-; CHECK-NEXT:    ld.param.v2.b32 {%r1, %r2}, [test_roundeven_param_0];
++; CHECK-NEXT:    ld.param.b64 %rd1, [test_roundeven_param_0];
++; CHECK-NEXT:    mov.b64 {%r1, %r2}, %rd1;
+ ; CHECK-NEXT:    cvt.rni.f32.f32 %r3, %r2;
+ ; CHECK-NEXT:    cvt.rni.f32.f32 %r4, %r1;
+ ; CHECK-NEXT:    st.param.v2.b32 [func_retval0], {%r4, %r3};
+@@ -1841,7 +1974,8 @@
+ ; CHECK-NEXT:    .reg .b64 %rd<2>;
+ ; CHECK-EMPTY:
+ ; CHECK-NEXT:  // %bb.0:
+-; CHECK-NEXT:    ld.param.v2.b32 {%r1, %r2}, [test_round_param_0];
++; CHECK-NEXT:    ld.param.b64 %rd1, [test_round_param_0];
++; CHECK-NEXT:    mov.b64 {%r1, %r2}, %rd1;
+ ; CHECK-NEXT:    and.b32 %r3, %r2, -2147483648;
+ ; CHECK-NEXT:    or.b32 %r4, %r3, 1056964608;
+ ; CHECK-NEXT:    add.rn.f32 %r5, %r2, %r4;
+@@ -1875,11 +2009,14 @@
+ ; CHECK-NOF32X2-NEXT:    .reg .b64 %rd<4>;
+ ; CHECK-NOF32X2-EMPTY:
+ ; CHECK-NOF32X2-NEXT:  // %bb.0:
+-; CHECK-NOF32X2-NEXT:    ld.param.v2.b32 {%r1, %r2}, [test_fmuladd_param_0];
+-; CHECK-NOF32X2-NEXT:    ld.param.v2.b32 {%r3, %r4}, [test_fmuladd_param_1];
+-; CHECK-NOF32X2-NEXT:    ld.param.v2.b32 {%r5, %r6}, [test_fmuladd_param_2];
+-; CHECK-NOF32X2-NEXT:    fma.rn.f32 %r7, %r2, %r4, %r6;
+-; CHECK-NOF32X2-NEXT:    fma.rn.f32 %r8, %r1, %r3, %r5;
++; CHECK-NOF32X2-NEXT:    ld.param.b64 %rd3, [test_fmuladd_param_2];
++; CHECK-NOF32X2-NEXT:    ld.param.b64 %rd2, [test_fmuladd_param_1];
++; CHECK-NOF32X2-NEXT:    ld.param.b64 %rd1, [test_fmuladd_param_0];
++; CHECK-NOF32X2-NEXT:    mov.b64 {%r1, %r2}, %rd3;
++; CHECK-NOF32X2-NEXT:    mov.b64 {%r3, %r4}, %rd2;
++; CHECK-NOF32X2-NEXT:    mov.b64 {%r5, %r6}, %rd1;
++; CHECK-NOF32X2-NEXT:    fma.rn.f32 %r7, %r6, %r4, %r2;
++; CHECK-NOF32X2-NEXT:    fma.rn.f32 %r8, %r5, %r3, %r1;
+ ; CHECK-NOF32X2-NEXT:    st.param.v2.b32 [func_retval0], {%r8, %r7};
+ ; CHECK-NOF32X2-NEXT:    ret;
+ ;
+@@ -1905,7 +2042,8 @@
+ ; CHECK-NEXT:    .reg .b64 %rd<2>;
+ ; CHECK-EMPTY:
+ ; CHECK-NEXT:  // %bb.0:
+-; CHECK-NEXT:    ld.param.v2.b32 {%r1, %r2}, [test_shufflevector_param_0];
++; CHECK-NEXT:    ld.param.b64 %rd1, [test_shufflevector_param_0];
++; CHECK-NEXT:    mov.b64 {%r1, %r2}, %rd1;
+ ; CHECK-NEXT:    st.param.v2.b32 [func_retval0], {%r2, %r1};
+ ; CHECK-NEXT:    ret;
+   %s = shufflevector <2 x float> %a, <2 x float> poison, <2 x i32> <i32 1, i32 0>
+@@ -1913,16 +2051,29 @@
  }
  
- /// Print out the file/line/column information and include trace.
-diff -ruN --strip-trailing-cr a/clang/lib/Headers/CMakeLists.txt b/clang/lib/Headers/CMakeLists.txt
---- a/clang/lib/Headers/CMakeLists.txt
-+++ b/clang/lib/Headers/CMakeLists.txt
-@@ -347,6 +347,10 @@
-   cuda_wrappers/bits/basic_string.tcc
- )
- 
-+set(cuda_wrapper_utility_files
-+  cuda_wrappers/__utility/declval.h
-+)
-+
- set(ppc_wrapper_files
-   ppc_wrappers/mmintrin.h
-   ppc_wrappers/xmmintrin.h
-@@ -443,8 +447,9 @@
- 
- # Copy header files from the source directory to the build directory
- foreach( f ${files} ${cuda_wrapper_files} ${cuda_wrapper_bits_files}
--           ${ppc_wrapper_files} ${openmp_wrapper_files} ${zos_wrapper_files} ${hlsl_files}
--	   ${llvm_libc_wrapper_files} ${llvm_offload_wrapper_files})
-+           ${cuda_wrapper_utility_files} ${ppc_wrapper_files} ${openmp_wrapper_files}
-+           ${zos_wrapper_files} ${hlsl_files} ${llvm_libc_wrapper_files}
-+           ${llvm_offload_wrapper_files})
-   copy_header_to_output_dir(${CMAKE_CURRENT_SOURCE_DIR} ${f})
- endforeach( f )
- 
-@@ -553,7 +558,7 @@
- # Architecture/platform specific targets
- add_header_target("arm-resource-headers" "${arm_only_files};${arm_only_generated_files}")
- add_header_target("aarch64-resource-headers" "${aarch64_only_files};${aarch64_only_generated_files}")
--add_header_target("cuda-resource-headers" "${cuda_files};${cuda_wrapper_files};${cuda_wrapper_bits_files}")
-+add_header_target("cuda-resource-headers" "${cuda_files};${cuda_wrapper_files};${cuda_wrapper_bits_files};${cuda_wrapper_utility_files}")
- add_header_target("hexagon-resource-headers" "${hexagon_files}")
- add_header_target("hip-resource-headers" "${hip_files}")
- add_header_target("loongarch-resource-headers" "${loongarch_files}")
-@@ -601,6 +606,11 @@
-   COMPONENT clang-resource-headers)
- 
- install(
-+  FILES ${cuda_wrapper_utility_files}
-+  DESTINATION ${header_install_dir}/cuda_wrappers/__utility
-+  COMPONENT clang-resource-headers)
-+
-+install(
-   FILES ${ppc_wrapper_files}
-   DESTINATION ${header_install_dir}/ppc_wrappers
-   COMPONENT clang-resource-headers)
-@@ -663,6 +673,12 @@
-   EXCLUDE_FROM_ALL
-   COMPONENT cuda-resource-headers)
+ define <2 x float> @test_insertelement(<2 x float> %a, float %x) #0 {
+-; CHECK-LABEL: test_insertelement(
+-; CHECK:       {
+-; CHECK-NEXT:    .reg .b32 %r<4>;
+-; CHECK-NEXT:    .reg .b64 %rd<2>;
+-; CHECK-EMPTY:
+-; CHECK-NEXT:  // %bb.0:
+-; CHECK-NEXT:    ld.param.b32 %r1, [test_insertelement_param_1];
+-; CHECK-NEXT:    ld.param.v2.b32 {%r2, %r3}, [test_insertelement_param_0];
+-; CHECK-NEXT:    st.param.v2.b32 [func_retval0], {%r2, %r1};
+-; CHECK-NEXT:    ret;
++; CHECK-NOF32X2-LABEL: test_insertelement(
++; CHECK-NOF32X2:       {
++; CHECK-NOF32X2-NEXT:    .reg .b32 %r<3>;
++; CHECK-NOF32X2-NEXT:    .reg .b64 %rd<2>;
++; CHECK-NOF32X2-EMPTY:
++; CHECK-NOF32X2-NEXT:  // %bb.0:
++; CHECK-NOF32X2-NEXT:    ld.param.b32 %r1, [test_insertelement_param_1];
++; CHECK-NOF32X2-NEXT:    ld.param.b64 %rd1, [test_insertelement_param_0];
++; CHECK-NOF32X2-NEXT:    { .reg .b32 tmp; mov.b64 {%r2, tmp}, %rd1; }
++; CHECK-NOF32X2-NEXT:    st.param.v2.b32 [func_retval0], {%r2, %r1};
++; CHECK-NOF32X2-NEXT:    ret;
++;
++; CHECK-F32X2-LABEL: test_insertelement(
++; CHECK-F32X2:       {
++; CHECK-F32X2-NEXT:    .reg .b32 %r<3>;
++; CHECK-F32X2-NEXT:    .reg .b64 %rd<2>;
++; CHECK-F32X2-EMPTY:
++; CHECK-F32X2-NEXT:  // %bb.0:
++; CHECK-F32X2-NEXT:    ld.param.b32 %r1, [test_insertelement_param_1];
++; CHECK-F32X2-NEXT:    ld.param.b64 %rd1, [test_insertelement_param_0];
++; CHECK-F32X2-NEXT:    mov.b64 {%r2, _}, %rd1;
++; CHECK-F32X2-NEXT:    st.param.v2.b32 [func_retval0], {%r2, %r1};
++; CHECK-F32X2-NEXT:    ret;
+   %i = insertelement <2 x float> %a, float %x, i64 1
+   ret <2 x float> %i
+ }
+@@ -1957,6 +2108,41 @@
+   ret <2 x float> %r
+ }
  
-+install(
-+  FILES ${cuda_wrapper_utility_files}
-+  DESTINATION ${header_install_dir}/cuda_wrappers/__utility
-+  EXCLUDE_FROM_ALL
-+  COMPONENT cuda-resource-headers)
-+
- install(
-   FILES ${cuda_files}
-   DESTINATION ${header_install_dir}
-diff -ruN --strip-trailing-cr a/clang/lib/Headers/cuda_wrappers/__utility/declval.h b/clang/lib/Headers/cuda_wrappers/__utility/declval.h
---- a/clang/lib/Headers/cuda_wrappers/__utility/declval.h
-+++ b/clang/lib/Headers/cuda_wrappers/__utility/declval.h
-@@ -0,0 +1,28 @@
-+#ifndef __CUDA_WRAPPERS_UTILITY_DECLVAL_H__
-+#define __CUDA_WRAPPERS_UTILITY_DECLVAL_H__
-+
-+#include_next <__utility/declval.h>
-+
-+// The stuff below is the exact copy of the <__utility/declval.h>,
-+// but with __device__ attribute applied to the functions, so it works on a GPU.
-+
-+_LIBCPP_BEGIN_NAMESPACE_STD
-+
-+// Suppress deprecation notice for volatile-qualified return type resulting
-+// from volatile-qualified types _Tp.
-+_LIBCPP_SUPPRESS_DEPRECATED_PUSH
-+template <class _Tp> __attribute__((device)) _Tp &&__declval(int);
-+template <class _Tp> __attribute__((device)) _Tp __declval(long);
-+_LIBCPP_SUPPRESS_DEPRECATED_POP
-+
-+template <class _Tp>
-+__attribute__((device)) _LIBCPP_HIDE_FROM_ABI decltype(std::__declval<_Tp>(0))
-+declval() _NOEXCEPT {
-+  static_assert(!__is_same(_Tp, _Tp),
-+                "std::declval can only be used in an unevaluated context. "
-+                "It's likely that your current usage is trying to extract a "
-+                "value from the function.");
++define void @test_trunc_to_v2bf16(<2 x float> %a, ptr %p) {
++; CHECK-LABEL: test_trunc_to_v2bf16(
++; CHECK:       {
++; CHECK-NEXT:    .reg .b32 %r<4>;
++; CHECK-NEXT:    .reg .b64 %rd<3>;
++; CHECK-EMPTY:
++; CHECK-NEXT:  // %bb.0:
++; CHECK-NEXT:    ld.param.b64 %rd2, [test_trunc_to_v2bf16_param_1];
++; CHECK-NEXT:    ld.param.v2.b32 {%r1, %r2}, [test_trunc_to_v2bf16_param_0];
++; CHECK-NEXT:    cvt.rn.bf16x2.f32 %r3, %r2, %r1;
++; CHECK-NEXT:    st.b32 [%rd2], %r3;
++; CHECK-NEXT:    ret;
++  %trunc = fptrunc <2 x float> %a to <2 x bfloat>
++  store <2 x bfloat> %trunc, ptr %p
++  ret void
 +}
 +
-+_LIBCPP_END_NAMESPACE_STD
-+#endif // __CUDA_WRAPPERS_UTILITY_DECLVAL_H__
-diff -ruN --strip-trailing-cr a/clang/lib/Sema/AnalysisBasedWarnings.cpp b/clang/lib/Sema/AnalysisBasedWarnings.cpp
---- a/clang/lib/Sema/AnalysisBasedWarnings.cpp
-+++ b/clang/lib/Sema/AnalysisBasedWarnings.cpp
-@@ -1969,11 +1969,26 @@
- 
-   void handleNoMutexHeld(const NamedDecl *D, ProtectedOperationKind POK,
-                          AccessKind AK, SourceLocation Loc) override {
--    assert((POK == POK_VarAccess || POK == POK_VarDereference) &&
--           "Only works for variables");
--    unsigned DiagID = POK == POK_VarAccess?
--                        diag::warn_variable_requires_any_lock:
--                        diag::warn_var_deref_requires_any_lock;
-+    unsigned DiagID = 0;
-+    switch (POK) {
-+    case POK_VarAccess:
-+    case POK_PassByRef:
-+    case POK_ReturnByRef:
-+    case POK_PassPointer:
-+    case POK_ReturnPointer:
-+      DiagID = diag::warn_variable_requires_any_lock;
-+      break;
-+    case POK_VarDereference:
-+    case POK_PtPassByRef:
-+    case POK_PtReturnByRef:
-+    case POK_PtPassPointer:
-+    case POK_PtReturnPointer:
-+      DiagID = diag::warn_var_deref_requires_any_lock;
-+      break;
-+    case POK_FunctionCall:
-+      llvm_unreachable("Only works for variables");
-+      break;
-+    }
-     PartialDiagnosticAt Warning(Loc, S.PDiag(DiagID)
-       << D << getLockKindFromAccessKind(AK));
-     Warnings.emplace_back(std::move(Warning), getNotes());
-diff -ruN --strip-trailing-cr a/clang/test/Frontend/absolute-paths.c b/clang/test/Frontend/absolute-paths.c
---- a/clang/test/Frontend/absolute-paths.c
-+++ b/clang/test/Frontend/absolute-paths.c
-@@ -8,9 +8,9 @@
- 
- #include "absolute-paths.h"
- 
--// Check that the bogus prefix we added is stripped out even if absolute paths
--// are disabled.
--// NORMAL-NOT: SystemHeaderPrefix
-+// Check whether the diagnostic from the header above includes the dummy
-+// directory in the path.
-+// NORMAL: SystemHeaderPrefix
- // ABSOLUTE-NOT: SystemHeaderPrefix
- // CHECK: warning: non-void function does not return a value
- 
-diff -ruN --strip-trailing-cr a/clang/test/Frontend/simplify-paths.c b/clang/test/Frontend/simplify-paths.c
---- a/clang/test/Frontend/simplify-paths.c
-+++ b/clang/test/Frontend/simplify-paths.c
-@@ -1,18 +0,0 @@
--// REQUIRES: shell
--
--// RUN: rm -rf %t
--// RUN: mkdir -p %t/a/b/
--// RUN: echo 'void x;' > %t/test.h
--// RUN: echo 'const void x;' > %t/header_with_a_really_long_name.h
--// RUN: ln -s %t/header_with_a_really_long_name.h %t/a/shorter_name.h
--//
--// RUN: %clang_cc1 -fsyntax-only -I %t %s 2> %t/output.txt || true
--// RUN: cat %t/output.txt | FileCheck %s
--
--// Check that we strip '..' by canonicalising the path...
--#include "a/b/../../test.h"
--// CHECK: simplify-paths.c.tmp/test.h:1:6: error: variable has incomplete type 'void'
--
--// ... but only if the resulting path is actually shorter.
--#include "a/b/../shorter_name.h"
--// CHECK: simplify-paths.c.tmp/a/b/../shorter_name.h:1:12: error: variable has incomplete type 'const void'
-diff -ruN --strip-trailing-cr a/clang/test/SemaCXX/warn-thread-safety-analysis.cpp b/clang/test/SemaCXX/warn-thread-safety-analysis.cpp
---- a/clang/test/SemaCXX/warn-thread-safety-analysis.cpp
-+++ b/clang/test/SemaCXX/warn-thread-safety-analysis.cpp
-@@ -6196,6 +6196,8 @@
-   Mutex mu;
-   Foo foo GUARDED_BY(mu);
-   Foo* foo_ptr PT_GUARDED_BY(mu);
-+  Foo foo_depr GUARDED_VAR;          // test deprecated attribute
-+  Foo* foo_ptr_depr PT_GUARDED_VAR;  // test deprecated attribute
- 
-   Foo returns_value_locked() {
-     MutexLock lock(&mu);
-@@ -6297,6 +6299,18 @@
-     return *foo_ptr;          // expected-warning {{returning the value that 'foo_ptr' points to by reference requires holding mutex 'mu' exclusively}}
-   }
- 
-+  Foo *returns_ptr_deprecated() {
-+    return &foo_depr;          // expected-warning {{writing variable 'foo_depr' requires holding any mutex exclusively}}
-+  }
-+
-+  Foo *returns_pt_ptr_deprecated() {
-+    return foo_ptr_depr;       // expected-warning {{writing the value pointed to by 'foo_ptr_depr' requires holding any mutex exclusively}}
-+  }
-+
-+  Foo &returns_ref_deprecated() {
-+    return *foo_ptr_depr;      // expected-warning {{writing the value pointed to by 'foo_ptr_depr' requires holding any mutex exclusively}}
-+  }
++define void @test_trunc_to_v2f16(<2 x float> %a, ptr %p) {
++; CHECK-LABEL: test_trunc_to_v2f16(
++; CHECK:       {
++; CHECK-NEXT:    .reg .b32 %r<4>;
++; CHECK-NEXT:    .reg .b64 %rd<3>;
++; CHECK-EMPTY:
++; CHECK-NEXT:  // %bb.0:
++; CHECK-NEXT:    ld.param.b64 %rd2, [test_trunc_to_v2f16_param_1];
++; CHECK-NEXT:    ld.param.v2.b32 {%r1, %r2}, [test_trunc_to_v2f16_param_0];
++; CHECK-NEXT:    cvt.rn.f16x2.f32 %r3, %r2, %r1;
++; CHECK-NEXT:    st.b32 [%rd2], %r3;
++; CHECK-NEXT:    ret;
++  %trunc = fptrunc <2 x float> %a to <2 x half>
++  store <2 x half> %trunc, ptr %p
++  ret void
++}
 +
-   // FIXME: Basic alias analysis would help catch cases like below.
-   Foo *returns_ptr_alias() {
-     mu.Lock();
-diff -ruN --strip-trailing-cr a/clang-tools-extra/test/clang-tidy/infrastructure/file-filter-symlinks.cpp b/clang-tools-extra/test/clang-tidy/infrastructure/file-filter-symlinks.cpp
---- a/clang-tools-extra/test/clang-tidy/infrastructure/file-filter-symlinks.cpp
-+++ b/clang-tools-extra/test/clang-tidy/infrastructure/file-filter-symlinks.cpp
-@@ -12,9 +12,8 @@
- // RUN: clang-tidy -checks='-*,google-explicit-constructor' -header-filter='header\.h' %s -- -I %t 2>&1 | FileCheck --check-prefix=CHECK_HEADER %s
- // RUN: clang-tidy -checks='-*,google-explicit-constructor' -header-filter='header\.h' -quiet %s -- -I %t 2>&1 | FileCheck --check-prefix=CHECK_HEADER %s
- 
--// `-header-filter` operates on the actual file path that the user provided in
--// the #include directive; however, Clang's path name simplification causes the
--// path to be printed in canonicalised form here.
-+// Check that `-header-filter` operates on the same file paths as paths in
-+// diagnostics printed by ClangTidy.
- #include "dir1/dir2/../header_alias.h"
--// CHECK_HEADER_ALIAS: dir1/header.h:1:11: warning: single-argument constructors
-+// CHECK_HEADER_ALIAS: dir1/dir2/../header_alias.h:1:11: warning: single-argument constructors
- // CHECK_HEADER-NOT: warning:
-diff -ruN --strip-trailing-cr a/libcxx/include/unordered_map b/libcxx/include/unordered_map
---- a/libcxx/include/unordered_map
-+++ b/libcxx/include/unordered_map
-@@ -967,9 +967,8 @@
-   typedef __hash_value_type<key_type, mapped_type> __value_type;
-   typedef __unordered_map_hasher<key_type, value_type, hasher, key_equal> __hasher;
-   typedef __unordered_map_equal<key_type, value_type, key_equal, hasher> __key_equal;
--  typedef __rebind_alloc<allocator_traits<allocator_type>, __value_type> __allocator_type;
- 
--  typedef __hash_table<__value_type, __hasher, __key_equal, __allocator_type> __table;
-+  typedef __hash_table<__value_type, __hasher, __key_equal, allocator_type> __table;
- 
-   __table __table_;
- 
-@@ -1777,9 +1776,8 @@
-   typedef __hash_value_type<key_type, mapped_type> __value_type;
-   typedef __unordered_map_hasher<key_type, value_type, hasher, key_equal> __hasher;
-   typedef __unordered_map_equal<key_type, value_type, key_equal, hasher> __key_equal;
--  typedef __rebind_alloc<allocator_traits<allocator_type>, __value_type> __allocator_type;
- 
--  typedef __hash_table<__value_type, __hasher, __key_equal, __allocator_type> __table;
-+  typedef __hash_table<__value_type, __hasher, __key_equal, allocator_type> __table;
- 
-   __table __table_;
- 
-diff -ruN --strip-trailing-cr a/libcxx/test/std/containers/associative/multimap/incomplete_type.pass.cpp b/libcxx/test/std/containers/associative/multimap/incomplete_type.pass.cpp
---- a/libcxx/test/std/containers/associative/multimap/incomplete_type.pass.cpp
-+++ b/libcxx/test/std/containers/associative/multimap/incomplete_type.pass.cpp
-@@ -13,6 +13,7 @@
- 
- #include <map>
- 
-+#include "min_allocator.h"
- #include "test_macros.h"
- 
- struct A {
-@@ -28,5 +29,8 @@
- int main(int, char**) {
-   A a;
- 
-+  // Make sure that the allocator isn't rebound to and incomplete type
-+  std::multimap<int, int, std::less<int>, complete_type_allocator<std::pair<const int, int> > > m;
 +
-   return 0;
+ attributes #0 = { nounwind }
+ attributes #1 = { "unsafe-fp-math" = "true" }
+ attributes #2 = { "denormal-fp-math"="preserve-sign" }
+diff -ruN --strip-trailing-cr a/llvm/test/CodeGen/NVPTX/i16x2-instructions.ll b/llvm/test/CodeGen/NVPTX/i16x2-instructions.ll
+--- a/llvm/test/CodeGen/NVPTX/i16x2-instructions.ll
++++ b/llvm/test/CodeGen/NVPTX/i16x2-instructions.ll
+@@ -32,31 +32,57 @@
  }
-diff -ruN --strip-trailing-cr a/libcxx/test/std/containers/unord/unord.map/incomplete_type.pass.cpp b/libcxx/test/std/containers/unord/unord.map/incomplete_type.pass.cpp
---- a/libcxx/test/std/containers/unord/unord.map/incomplete_type.pass.cpp
-+++ b/libcxx/test/std/containers/unord/unord.map/incomplete_type.pass.cpp
-@@ -14,6 +14,7 @@
- 
- #include <unordered_map>
- 
-+#include "min_allocator.h"
- #include "test_macros.h"
  
- template <class Tp>
-@@ -36,5 +37,9 @@
- int main(int, char**) {
-   A a;
- 
-+  // Make sure that the allocator isn't rebound to an incomplete type
-+  std::unordered_map<int, int, std::hash<int>, std::equal_to<int>, complete_type_allocator<std::pair<const int, int> > >
-+      m;
-+
-   return 0;
+ define i16 @test_extract_0(<2 x i16> %a) #0 {
+-; COMMON-LABEL: test_extract_0(
+-; COMMON:       {
+-; COMMON-NEXT:    .reg .b16 %rs<3>;
+-; COMMON-NEXT:    .reg .b32 %r<3>;
+-; COMMON-EMPTY:
+-; COMMON-NEXT:  // %bb.0:
+-; COMMON-NEXT:    ld.param.v2.b16 {%rs1, %rs2}, [test_extract_0_param_0];
+-; COMMON-NEXT:    cvt.u32.u16 %r2, %rs1;
+-; COMMON-NEXT:    st.param.b32 [func_retval0], %r2;
+-; COMMON-NEXT:    ret;
++; I16x2-LABEL: test_extract_0(
++; I16x2:       {
++; I16x2-NEXT:    .reg .b16 %rs<2>;
++; I16x2-NEXT:    .reg .b32 %r<3>;
++; I16x2-EMPTY:
++; I16x2-NEXT:  // %bb.0:
++; I16x2-NEXT:    ld.param.b32 %r1, [test_extract_0_param_0];
++; I16x2-NEXT:    mov.b32 {%rs1, _}, %r1;
++; I16x2-NEXT:    cvt.u32.u16 %r2, %rs1;
++; I16x2-NEXT:    st.param.b32 [func_retval0], %r2;
++; I16x2-NEXT:    ret;
++;
++; NO-I16x2-LABEL: test_extract_0(
++; NO-I16x2:       {
++; NO-I16x2-NEXT:    .reg .b16 %rs<2>;
++; NO-I16x2-NEXT:    .reg .b32 %r<3>;
++; NO-I16x2-EMPTY:
++; NO-I16x2-NEXT:  // %bb.0:
++; NO-I16x2-NEXT:    ld.param.b32 %r1, [test_extract_0_param_0];
++; NO-I16x2-NEXT:    { .reg .b16 tmp; mov.b32 {%rs1, tmp}, %r1; }
++; NO-I16x2-NEXT:    cvt.u32.u16 %r2, %rs1;
++; NO-I16x2-NEXT:    st.param.b32 [func_retval0], %r2;
++; NO-I16x2-NEXT:    ret;
+   %e = extractelement <2 x i16> %a, i32 0
+   ret i16 %e
  }
-diff -ruN --strip-trailing-cr a/libcxx/test/std/containers/unord/unord.multimap/incomplete.pass.cpp b/libcxx/test/std/containers/unord/unord.multimap/incomplete.pass.cpp
---- a/libcxx/test/std/containers/unord/unord.multimap/incomplete.pass.cpp
-+++ b/libcxx/test/std/containers/unord/unord.multimap/incomplete.pass.cpp
-@@ -14,6 +14,7 @@
- 
- #include <unordered_map>
  
-+#include "min_allocator.h"
- #include "test_macros.h"
- 
- template <class Tp>
-@@ -36,5 +37,13 @@
- int main(int, char**) {
-   A a;
- 
-+  // Make sure that the allocator isn't rebound to an incomplete type
-+  std::unordered_multimap<int,
-+                          int,
-+                          std::hash<int>,
-+                          std::equal_to<int>,
-+                          complete_type_allocator<std::pair<const int, int> > >
-+      m;
-+
-   return 0;
+ define i16 @test_extract_1(<2 x i16> %a) #0 {
+-; COMMON-LABEL: test_extract_1(
+-; COMMON:       {
+-; COMMON-NEXT:    .reg .b16 %rs<3>;
+-; COMMON-NEXT:    .reg .b32 %r<3>;
+-; COMMON-EMPTY:
+-; COMMON-NEXT:  // %bb.0:
+-; COMMON-NEXT:    ld.param.v2.b16 {%rs1, %rs2}, [test_extract_1_param_0];
+-; COMMON-NEXT:    cvt.u32.u16 %r2, %rs2;
+-; COMMON-NEXT:    st.param.b32 [func_retval0], %r2;
+-; COMMON-NEXT:    ret;
++; I16x2-LABEL: test_extract_1(
++; I16x2:       {
++; I16x2-NEXT:    .reg .b16 %rs<2>;
++; I16x2-NEXT:    .reg .b32 %r<3>;
++; I16x2-EMPTY:
++; I16x2-NEXT:  // %bb.0:
++; I16x2-NEXT:    ld.param.b32 %r1, [test_extract_1_param_0];
++; I16x2-NEXT:    mov.b32 {_, %rs1}, %r1;
++; I16x2-NEXT:    cvt.u32.u16 %r2, %rs1;
++; I16x2-NEXT:    st.param.b32 [func_retval0], %r2;
++; I16x2-NEXT:    ret;
++;
++; NO-I16x2-LABEL: test_extract_1(
++; NO-I16x2:       {
++; NO-I16x2-NEXT:    .reg .b16 %rs<2>;
++; NO-I16x2-NEXT:    .reg .b32 %r<3>;
++; NO-I16x2-EMPTY:
++; NO-I16x2-NEXT:  // %bb.0:
++; NO-I16x2-NEXT:    ld.param.b32 %r1, [test_extract_1_param_0];
++; NO-I16x2-NEXT:    { .reg .b16 tmp; mov.b32 {tmp, %rs1}, %r1; }
++; NO-I16x2-NEXT:    cvt.u32.u16 %r2, %rs1;
++; NO-I16x2-NEXT:    st.param.b32 [func_retval0], %r2;
++; NO-I16x2-NEXT:    ret;
+   %e = extractelement <2 x i16> %a, i32 1
+   ret i16 %e
+ }
+@@ -71,8 +97,9 @@
+ ; COMMON-EMPTY:
+ ; COMMON-NEXT:  // %bb.0:
+ ; COMMON-NEXT:    ld.param.b64 %rd1, [test_extract_i_param_1];
+-; COMMON-NEXT:    ld.param.v2.b16 {%rs1, %rs2}, [test_extract_i_param_0];
++; COMMON-NEXT:    ld.param.b32 %r1, [test_extract_i_param_0];
+ ; COMMON-NEXT:    setp.eq.b64 %p1, %rd1, 0;
++; COMMON-NEXT:    mov.b32 {%rs1, %rs2}, %r1;
+ ; COMMON-NEXT:    selp.b16 %rs3, %rs1, %rs2, %p1;
+ ; COMMON-NEXT:    cvt.u32.u16 %r2, %rs3;
+ ; COMMON-NEXT:    st.param.b32 [func_retval0], %r2;
+@@ -99,10 +126,12 @@
+ ; NO-I16x2-NEXT:    .reg .b32 %r<3>;
+ ; NO-I16x2-EMPTY:
+ ; NO-I16x2-NEXT:  // %bb.0:
+-; NO-I16x2-NEXT:    ld.param.v2.b16 {%rs1, %rs2}, [test_add_param_0];
+-; NO-I16x2-NEXT:    ld.param.v2.b16 {%rs3, %rs4}, [test_add_param_1];
+-; NO-I16x2-NEXT:    add.s16 %rs5, %rs2, %rs4;
+-; NO-I16x2-NEXT:    add.s16 %rs6, %rs1, %rs3;
++; NO-I16x2-NEXT:    ld.param.b32 %r2, [test_add_param_1];
++; NO-I16x2-NEXT:    ld.param.b32 %r1, [test_add_param_0];
++; NO-I16x2-NEXT:    mov.b32 {%rs1, %rs2}, %r2;
++; NO-I16x2-NEXT:    mov.b32 {%rs3, %rs4}, %r1;
++; NO-I16x2-NEXT:    add.s16 %rs5, %rs4, %rs2;
++; NO-I16x2-NEXT:    add.s16 %rs6, %rs3, %rs1;
+ ; NO-I16x2-NEXT:    st.param.v2.b16 [func_retval0], {%rs6, %rs5};
+ ; NO-I16x2-NEXT:    ret;
+   %r = add <2 x i16> %a, %b
+@@ -128,7 +157,8 @@
+ ; NO-I16x2-NEXT:    .reg .b32 %r<2>;
+ ; NO-I16x2-EMPTY:
+ ; NO-I16x2-NEXT:  // %bb.0:
+-; NO-I16x2-NEXT:    ld.param.v2.b16 {%rs1, %rs2}, [test_add_imm_0_param_0];
++; NO-I16x2-NEXT:    ld.param.b32 %r1, [test_add_imm_0_param_0];
++; NO-I16x2-NEXT:    mov.b32 {%rs1, %rs2}, %r1;
+ ; NO-I16x2-NEXT:    add.s16 %rs3, %rs2, 2;
+ ; NO-I16x2-NEXT:    add.s16 %rs4, %rs1, 1;
+ ; NO-I16x2-NEXT:    st.param.v2.b16 [func_retval0], {%rs4, %rs3};
+@@ -155,7 +185,8 @@
+ ; NO-I16x2-NEXT:    .reg .b32 %r<2>;
+ ; NO-I16x2-EMPTY:
+ ; NO-I16x2-NEXT:  // %bb.0:
+-; NO-I16x2-NEXT:    ld.param.v2.b16 {%rs1, %rs2}, [test_add_imm_1_param_0];
++; NO-I16x2-NEXT:    ld.param.b32 %r1, [test_add_imm_1_param_0];
++; NO-I16x2-NEXT:    mov.b32 {%rs1, %rs2}, %r1;
+ ; NO-I16x2-NEXT:    add.s16 %rs3, %rs2, 2;
+ ; NO-I16x2-NEXT:    add.s16 %rs4, %rs1, 1;
+ ; NO-I16x2-NEXT:    st.param.v2.b16 [func_retval0], {%rs4, %rs3};
+@@ -171,10 +202,12 @@
+ ; COMMON-NEXT:    .reg .b32 %r<3>;
+ ; COMMON-EMPTY:
+ ; COMMON-NEXT:  // %bb.0:
+-; COMMON-NEXT:    ld.param.v2.b16 {%rs1, %rs2}, [test_sub_param_0];
+-; COMMON-NEXT:    ld.param.v2.b16 {%rs3, %rs4}, [test_sub_param_1];
+-; COMMON-NEXT:    sub.s16 %rs5, %rs2, %rs4;
+-; COMMON-NEXT:    sub.s16 %rs6, %rs1, %rs3;
++; COMMON-NEXT:    ld.param.b32 %r2, [test_sub_param_1];
++; COMMON-NEXT:    ld.param.b32 %r1, [test_sub_param_0];
++; COMMON-NEXT:    mov.b32 {%rs1, %rs2}, %r2;
++; COMMON-NEXT:    mov.b32 {%rs3, %rs4}, %r1;
++; COMMON-NEXT:    sub.s16 %rs5, %rs4, %rs2;
++; COMMON-NEXT:    sub.s16 %rs6, %rs3, %rs1;
+ ; COMMON-NEXT:    st.param.v2.b16 [func_retval0], {%rs6, %rs5};
+ ; COMMON-NEXT:    ret;
+   %r = sub <2 x i16> %a, %b
+@@ -199,10 +232,12 @@
+ ; NO-I16x2-NEXT:    .reg .b32 %r<3>;
+ ; NO-I16x2-EMPTY:
+ ; NO-I16x2-NEXT:  // %bb.0:
+-; NO-I16x2-NEXT:    ld.param.v2.b16 {%rs1, %rs2}, [test_smax_param_0];
+-; NO-I16x2-NEXT:    ld.param.v2.b16 {%rs3, %rs4}, [test_smax_param_1];
+-; NO-I16x2-NEXT:    max.s16 %rs5, %rs2, %rs4;
+-; NO-I16x2-NEXT:    max.s16 %rs6, %rs1, %rs3;
++; NO-I16x2-NEXT:    ld.param.b32 %r2, [test_smax_param_1];
++; NO-I16x2-NEXT:    ld.param.b32 %r1, [test_smax_param_0];
++; NO-I16x2-NEXT:    mov.b32 {%rs1, %rs2}, %r2;
++; NO-I16x2-NEXT:    mov.b32 {%rs3, %rs4}, %r1;
++; NO-I16x2-NEXT:    max.s16 %rs5, %rs4, %rs2;
++; NO-I16x2-NEXT:    max.s16 %rs6, %rs3, %rs1;
+ ; NO-I16x2-NEXT:    st.param.v2.b16 [func_retval0], {%rs6, %rs5};
+ ; NO-I16x2-NEXT:    ret;
+   %cmp = icmp sgt <2 x i16> %a, %b
+@@ -228,10 +263,12 @@
+ ; NO-I16x2-NEXT:    .reg .b32 %r<3>;
+ ; NO-I16x2-EMPTY:
+ ; NO-I16x2-NEXT:  // %bb.0:
+-; NO-I16x2-NEXT:    ld.param.v2.b16 {%rs1, %rs2}, [test_umax_param_0];
+-; NO-I16x2-NEXT:    ld.param.v2.b16 {%rs3, %rs4}, [test_umax_param_1];
+-; NO-I16x2-NEXT:    max.u16 %rs5, %rs2, %rs4;
+-; NO-I16x2-NEXT:    max.u16 %rs6, %rs1, %rs3;
++; NO-I16x2-NEXT:    ld.param.b32 %r2, [test_umax_param_1];
++; NO-I16x2-NEXT:    ld.param.b32 %r1, [test_umax_param_0];
++; NO-I16x2-NEXT:    mov.b32 {%rs1, %rs2}, %r2;
++; NO-I16x2-NEXT:    mov.b32 {%rs3, %rs4}, %r1;
++; NO-I16x2-NEXT:    max.u16 %rs5, %rs4, %rs2;
++; NO-I16x2-NEXT:    max.u16 %rs6, %rs3, %rs1;
+ ; NO-I16x2-NEXT:    st.param.v2.b16 [func_retval0], {%rs6, %rs5};
+ ; NO-I16x2-NEXT:    ret;
+   %cmp = icmp ugt <2 x i16> %a, %b
+@@ -257,10 +294,12 @@
+ ; NO-I16x2-NEXT:    .reg .b32 %r<3>;
+ ; NO-I16x2-EMPTY:
+ ; NO-I16x2-NEXT:  // %bb.0:
+-; NO-I16x2-NEXT:    ld.param.v2.b16 {%rs1, %rs2}, [test_smin_param_0];
+-; NO-I16x2-NEXT:    ld.param.v2.b16 {%rs3, %rs4}, [test_smin_param_1];
+-; NO-I16x2-NEXT:    min.s16 %rs5, %rs2, %rs4;
+-; NO-I16x2-NEXT:    min.s16 %rs6, %rs1, %rs3;
++; NO-I16x2-NEXT:    ld.param.b32 %r2, [test_smin_param_1];
++; NO-I16x2-NEXT:    ld.param.b32 %r1, [test_smin_param_0];
++; NO-I16x2-NEXT:    mov.b32 {%rs1, %rs2}, %r2;
++; NO-I16x2-NEXT:    mov.b32 {%rs3, %rs4}, %r1;
++; NO-I16x2-NEXT:    min.s16 %rs5, %rs4, %rs2;
++; NO-I16x2-NEXT:    min.s16 %rs6, %rs3, %rs1;
+ ; NO-I16x2-NEXT:    st.param.v2.b16 [func_retval0], {%rs6, %rs5};
+ ; NO-I16x2-NEXT:    ret;
+   %cmp = icmp sle <2 x i16> %a, %b
+@@ -286,10 +325,12 @@
+ ; NO-I16x2-NEXT:    .reg .b32 %r<3>;
+ ; NO-I16x2-EMPTY:
+ ; NO-I16x2-NEXT:  // %bb.0:
+-; NO-I16x2-NEXT:    ld.param.v2.b16 {%rs1, %rs2}, [test_umin_param_0];
+-; NO-I16x2-NEXT:    ld.param.v2.b16 {%rs3, %rs4}, [test_umin_param_1];
+-; NO-I16x2-NEXT:    min.u16 %rs5, %rs2, %rs4;
+-; NO-I16x2-NEXT:    min.u16 %rs6, %rs1, %rs3;
++; NO-I16x2-NEXT:    ld.param.b32 %r2, [test_umin_param_1];
++; NO-I16x2-NEXT:    ld.param.b32 %r1, [test_umin_param_0];
++; NO-I16x2-NEXT:    mov.b32 {%rs1, %rs2}, %r2;
++; NO-I16x2-NEXT:    mov.b32 {%rs3, %rs4}, %r1;
++; NO-I16x2-NEXT:    min.u16 %rs5, %rs4, %rs2;
++; NO-I16x2-NEXT:    min.u16 %rs6, %rs3, %rs1;
+ ; NO-I16x2-NEXT:    st.param.v2.b16 [func_retval0], {%rs6, %rs5};
+ ; NO-I16x2-NEXT:    ret;
+   %cmp = icmp ule <2 x i16> %a, %b
+@@ -304,10 +345,12 @@
+ ; COMMON-NEXT:    .reg .b32 %r<3>;
+ ; COMMON-EMPTY:
+ ; COMMON-NEXT:  // %bb.0:
+-; COMMON-NEXT:    ld.param.v2.b16 {%rs1, %rs2}, [test_mul_param_0];
+-; COMMON-NEXT:    ld.param.v2.b16 {%rs3, %rs4}, [test_mul_param_1];
+-; COMMON-NEXT:    mul.lo.s16 %rs5, %rs2, %rs4;
+-; COMMON-NEXT:    mul.lo.s16 %rs6, %rs1, %rs3;
++; COMMON-NEXT:    ld.param.b32 %r2, [test_mul_param_1];
++; COMMON-NEXT:    ld.param.b32 %r1, [test_mul_param_0];
++; COMMON-NEXT:    mov.b32 {%rs1, %rs2}, %r2;
++; COMMON-NEXT:    mov.b32 {%rs3, %rs4}, %r1;
++; COMMON-NEXT:    mul.lo.s16 %rs5, %rs4, %rs2;
++; COMMON-NEXT:    mul.lo.s16 %rs6, %rs3, %rs1;
+ ; COMMON-NEXT:    st.param.v2.b16 [func_retval0], {%rs6, %rs5};
+ ; COMMON-NEXT:    ret;
+   %r = mul <2 x i16> %a, %b
+@@ -686,14 +729,18 @@
+ ; COMMON-NEXT:    .reg .b32 %r<5>;
+ ; COMMON-EMPTY:
+ ; COMMON-NEXT:  // %bb.0:
+-; COMMON-NEXT:    ld.param.v2.b16 {%rs1, %rs2}, [test_select_cc_param_0];
+-; COMMON-NEXT:    ld.param.v2.b16 {%rs3, %rs4}, [test_select_cc_param_2];
+-; COMMON-NEXT:    ld.param.v2.b16 {%rs5, %rs6}, [test_select_cc_param_3];
+-; COMMON-NEXT:    setp.ne.b16 %p1, %rs3, %rs5;
+-; COMMON-NEXT:    setp.ne.b16 %p2, %rs4, %rs6;
+-; COMMON-NEXT:    ld.param.v2.b16 {%rs7, %rs8}, [test_select_cc_param_1];
+-; COMMON-NEXT:    selp.b16 %rs9, %rs2, %rs8, %p2;
+-; COMMON-NEXT:    selp.b16 %rs10, %rs1, %rs7, %p1;
++; COMMON-NEXT:    ld.param.b32 %r4, [test_select_cc_param_3];
++; COMMON-NEXT:    ld.param.b32 %r3, [test_select_cc_param_2];
++; COMMON-NEXT:    ld.param.b32 %r2, [test_select_cc_param_1];
++; COMMON-NEXT:    ld.param.b32 %r1, [test_select_cc_param_0];
++; COMMON-NEXT:    mov.b32 {%rs1, %rs2}, %r4;
++; COMMON-NEXT:    mov.b32 {%rs3, %rs4}, %r3;
++; COMMON-NEXT:    setp.ne.b16 %p1, %rs3, %rs1;
++; COMMON-NEXT:    setp.ne.b16 %p2, %rs4, %rs2;
++; COMMON-NEXT:    mov.b32 {%rs5, %rs6}, %r2;
++; COMMON-NEXT:    mov.b32 {%rs7, %rs8}, %r1;
++; COMMON-NEXT:    selp.b16 %rs9, %rs8, %rs6, %p2;
++; COMMON-NEXT:    selp.b16 %rs10, %rs7, %rs5, %p1;
+ ; COMMON-NEXT:    st.param.v2.b16 [func_retval0], {%rs10, %rs9};
+ ; COMMON-NEXT:    ret;
+   %cc = icmp ne <2 x i16> %c, %d
+@@ -711,10 +758,12 @@
+ ; COMMON-NEXT:  // %bb.0:
+ ; COMMON-NEXT:    ld.param.v2.b32 {%r3, %r4}, [test_select_cc_i32_i16_param_1];
+ ; COMMON-NEXT:    ld.param.v2.b32 {%r1, %r2}, [test_select_cc_i32_i16_param_0];
+-; COMMON-NEXT:    ld.param.v2.b16 {%rs1, %rs2}, [test_select_cc_i32_i16_param_2];
+-; COMMON-NEXT:    ld.param.v2.b16 {%rs3, %rs4}, [test_select_cc_i32_i16_param_3];
+-; COMMON-NEXT:    setp.ne.b16 %p1, %rs1, %rs3;
+-; COMMON-NEXT:    setp.ne.b16 %p2, %rs2, %rs4;
++; COMMON-NEXT:    ld.param.b32 %r6, [test_select_cc_i32_i16_param_3];
++; COMMON-NEXT:    ld.param.b32 %r5, [test_select_cc_i32_i16_param_2];
++; COMMON-NEXT:    mov.b32 {%rs1, %rs2}, %r6;
++; COMMON-NEXT:    mov.b32 {%rs3, %rs4}, %r5;
++; COMMON-NEXT:    setp.ne.b16 %p1, %rs3, %rs1;
++; COMMON-NEXT:    setp.ne.b16 %p2, %rs4, %rs2;
+ ; COMMON-NEXT:    selp.b32 %r7, %r2, %r4, %p2;
+ ; COMMON-NEXT:    selp.b32 %r8, %r1, %r3, %p1;
+ ; COMMON-NEXT:    st.param.v2.b32 [func_retval0], {%r8, %r7};
+@@ -735,12 +784,14 @@
+ ; COMMON-NEXT:  // %bb.0:
+ ; COMMON-NEXT:    ld.param.v2.b32 {%r5, %r6}, [test_select_cc_i16_i32_param_3];
+ ; COMMON-NEXT:    ld.param.v2.b32 {%r3, %r4}, [test_select_cc_i16_i32_param_2];
+-; COMMON-NEXT:    ld.param.v2.b16 {%rs1, %rs2}, [test_select_cc_i16_i32_param_0];
++; COMMON-NEXT:    ld.param.b32 %r2, [test_select_cc_i16_i32_param_1];
++; COMMON-NEXT:    ld.param.b32 %r1, [test_select_cc_i16_i32_param_0];
+ ; COMMON-NEXT:    setp.ne.b32 %p1, %r3, %r5;
+ ; COMMON-NEXT:    setp.ne.b32 %p2, %r4, %r6;
+-; COMMON-NEXT:    ld.param.v2.b16 {%rs3, %rs4}, [test_select_cc_i16_i32_param_1];
+-; COMMON-NEXT:    selp.b16 %rs5, %rs2, %rs4, %p2;
+-; COMMON-NEXT:    selp.b16 %rs6, %rs1, %rs3, %p1;
++; COMMON-NEXT:    mov.b32 {%rs1, %rs2}, %r2;
++; COMMON-NEXT:    mov.b32 {%rs3, %rs4}, %r1;
++; COMMON-NEXT:    selp.b16 %rs5, %rs4, %rs2, %p2;
++; COMMON-NEXT:    selp.b16 %rs6, %rs3, %rs1, %p1;
+ ; COMMON-NEXT:    st.param.v2.b16 [func_retval0], {%rs6, %rs5};
+ ; COMMON-NEXT:    ret;
+                                           <2 x i32> %c, <2 x i32> %d) #0 {
+@@ -851,7 +902,8 @@
+ ; COMMON-NEXT:    .reg .b32 %r<4>;
+ ; COMMON-EMPTY:
+ ; COMMON-NEXT:  // %bb.0:
+-; COMMON-NEXT:    ld.param.v2.b16 {%rs1, %rs2}, [test_zext_2xi32_param_0];
++; COMMON-NEXT:    ld.param.b32 %r1, [test_zext_2xi32_param_0];
++; COMMON-NEXT:    mov.b32 {%rs1, %rs2}, %r1;
+ ; COMMON-NEXT:    cvt.u32.u16 %r2, %rs2;
+ ; COMMON-NEXT:    cvt.u32.u16 %r3, %rs1;
+ ; COMMON-NEXT:    st.param.v2.b32 [func_retval0], {%r3, %r2};
+@@ -868,7 +920,8 @@
+ ; COMMON-NEXT:    .reg .b64 %rd<3>;
+ ; COMMON-EMPTY:
+ ; COMMON-NEXT:  // %bb.0:
+-; COMMON-NEXT:    ld.param.v2.b16 {%rs1, %rs2}, [test_zext_2xi64_param_0];
++; COMMON-NEXT:    ld.param.b32 %r1, [test_zext_2xi64_param_0];
++; COMMON-NEXT:    mov.b32 {%rs1, %rs2}, %r1;
+ ; COMMON-NEXT:    cvt.u64.u16 %rd1, %rs2;
+ ; COMMON-NEXT:    cvt.u64.u16 %rd2, %rs1;
+ ; COMMON-NEXT:    st.param.v2.b64 [func_retval0], {%rd2, %rd1};
+@@ -926,7 +979,8 @@
+ ; COMMON-NEXT:    .reg .b32 %r<2>;
+ ; COMMON-EMPTY:
+ ; COMMON-NEXT:  // %bb.0:
+-; COMMON-NEXT:    ld.param.v2.b16 {%rs1, %rs2}, [test_shufflevector_param_0];
++; COMMON-NEXT:    ld.param.b32 %r1, [test_shufflevector_param_0];
++; COMMON-NEXT:    mov.b32 {%rs1, %rs2}, %r1;
+ ; COMMON-NEXT:    st.param.v2.b16 [func_retval0], {%rs2, %rs1};
+ ; COMMON-NEXT:    ret;
+   %s = shufflevector <2 x i16> %a, <2 x i16> undef, <2 x i32> <i32 1, i32 0>
+@@ -934,16 +988,29 @@
  }
-diff -ruN --strip-trailing-cr a/llvm/lib/Transforms/Coroutines/CoroSplit.cpp b/llvm/lib/Transforms/Coroutines/CoroSplit.cpp
---- a/llvm/lib/Transforms/Coroutines/CoroSplit.cpp
-+++ b/llvm/lib/Transforms/Coroutines/CoroSplit.cpp
-@@ -1484,12 +1484,9 @@
-     // If there is no DISubprogram for F, it implies the function is compiled
-     // without debug info. So we also don't generate debug info for the
-     // suspension points.
--    bool AddDebugLabels =
--        (DIS && DIS->getUnit() &&
--         (DIS->getUnit()->getEmissionKind() ==
--              DICompileUnit::DebugEmissionKind::FullDebug ||
--          DIS->getUnit()->getEmissionKind() ==
--              DICompileUnit::DebugEmissionKind::LineTablesOnly));
-+    bool AddDebugLabels = DIS && DIS->getUnit() &&
-+                          (DIS->getUnit()->getEmissionKind() ==
-+                           DICompileUnit::DebugEmissionKind::FullDebug);
  
-     // resume.entry:
-     //  %index.addr = getelementptr inbounds %f.Frame, %f.Frame* %FramePtr, i32
-diff -ruN --strip-trailing-cr a/llvm/lib/Transforms/Vectorize/LoopVectorize.cpp b/llvm/lib/Transforms/Vectorize/LoopVectorize.cpp
---- a/llvm/lib/Transforms/Vectorize/LoopVectorize.cpp
-+++ b/llvm/lib/Transforms/Vectorize/LoopVectorize.cpp
-@@ -10061,8 +10061,7 @@
-   // Get user vectorization factor and interleave count.
-   ElementCount UserVF = Hints.getWidth();
-   unsigned UserIC = Hints.getInterleave();
--  if (LVL.hasUncountableEarlyExit() && UserIC != 1 &&
--      !VectorizerParams::isInterleaveForced()) {
-+  if (LVL.hasUncountableEarlyExit() && UserIC != 1) {
-     UserIC = 1;
-     reportVectorizationInfo("Interleaving not supported for loops "
-                             "with uncountable early exits",
-diff -ruN --strip-trailing-cr a/llvm/test/Transforms/Coroutines/coro-split-dbg-labels.ll b/llvm/test/Transforms/Coroutines/coro-split-dbg-labels.ll
---- a/llvm/test/Transforms/Coroutines/coro-split-dbg-labels.ll
-+++ b/llvm/test/Transforms/Coroutines/coro-split-dbg-labels.ll
-@@ -1,14 +1,19 @@
- ; Tests that we add DILabels for the suspend points.
- ;
--; We check both the generated LLVM:
-+; Check the generated LLVM:
- ; RUN: opt < %s -passes='cgscc(coro-split)' -S | FileCheck %s
- ;
--; And the debug info:
-+; Check the generated DWARF debug info:
- ; REQUIRES: object-emission
- ; RUN: opt < %s -passes='cgscc(coro-split),coro-cleanup' \
- ; RUN:   | %llc_dwarf -O0 -filetype=obj -o - \
- ; RUN:   | llvm-dwarfdump - \
- ; RUN:   | FileCheck %s -check-prefix=DWARF
+ define <2 x i16> @test_insertelement(<2 x i16> %a, i16 %x) #0 {
+-; COMMON-LABEL: test_insertelement(
+-; COMMON:       {
+-; COMMON-NEXT:    .reg .b16 %rs<4>;
+-; COMMON-NEXT:    .reg .b32 %r<2>;
+-; COMMON-EMPTY:
+-; COMMON-NEXT:  // %bb.0:
+-; COMMON-NEXT:    ld.param.b16 %rs1, [test_insertelement_param_1];
+-; COMMON-NEXT:    ld.param.v2.b16 {%rs2, %rs3}, [test_insertelement_param_0];
+-; COMMON-NEXT:    st.param.v2.b16 [func_retval0], {%rs2, %rs1};
+-; COMMON-NEXT:    ret;
++; I16x2-LABEL: test_insertelement(
++; I16x2:       {
++; I16x2-NEXT:    .reg .b16 %rs<3>;
++; I16x2-NEXT:    .reg .b32 %r<2>;
++; I16x2-EMPTY:
++; I16x2-NEXT:  // %bb.0:
++; I16x2-NEXT:    ld.param.b16 %rs1, [test_insertelement_param_1];
++; I16x2-NEXT:    ld.param.b32 %r1, [test_insertelement_param_0];
++; I16x2-NEXT:    mov.b32 {%rs2, _}, %r1;
++; I16x2-NEXT:    st.param.v2.b16 [func_retval0], {%rs2, %rs1};
++; I16x2-NEXT:    ret;
 +;
-+; Check that we don't emit any DILabel if in `LineTablesOnly` mode
-+; RUN: sed -e 's/emissionKind: FullDebug/emissionKind: LineTablesOnly/' %s \
-+; RUN:   | opt -passes='cgscc(coro-split)' -S \
-+; RUN:   | FileCheck %s -check-prefix=LINE-TABLE
- 
- source_filename = "coro.c"
- 
-@@ -83,6 +88,12 @@
- ; CHECK: ![[DESTROY_0]] = !DILabel(scope: !{{[0-9]+}}, name: "__coro_resume_0", file: !{{[0-9]*}}, line: 12, column: 6, isArtificial: true, coroSuspendIdx: 0)
- ; CHECK: ![[DESTROY_1]] = !DILabel(scope: !{{[0-9]+}}, name: "__coro_resume_1", file: !{{[0-9]*}}, line: 14, column: 6, isArtificial: true, coroSuspendIdx: 1)
- 
-+; Check the we do not emit any DILabels in LineTablesOnly mode.
-+; The DWARF emitter cannot handle this and would run into an assertion.
-+; LINE-TABLE: !DICompileUnit{{.*}}LineTablesOnly
-+; LINE-TABLE-NOT: DILabel
++; NO-I16x2-LABEL: test_insertelement(
++; NO-I16x2:       {
++; NO-I16x2-NEXT:    .reg .b16 %rs<3>;
++; NO-I16x2-NEXT:    .reg .b32 %r<2>;
++; NO-I16x2-EMPTY:
++; NO-I16x2-NEXT:  // %bb.0:
++; NO-I16x2-NEXT:    ld.param.b16 %rs1, [test_insertelement_param_1];
++; NO-I16x2-NEXT:    ld.param.b32 %r1, [test_insertelement_param_0];
++; NO-I16x2-NEXT:    { .reg .b16 tmp; mov.b32 {%rs2, tmp}, %r1; }
++; NO-I16x2-NEXT:    st.param.v2.b16 [func_retval0], {%rs2, %rs1};
++; NO-I16x2-NEXT:    ret;
+   %i = insertelement <2 x i16> %a, i16 %x, i64 1
+   ret <2 x i16> %i
+ }
+@@ -955,7 +1022,8 @@
+ ; COMMON-NEXT:    .reg .b32 %r<2>;
+ ; COMMON-EMPTY:
+ ; COMMON-NEXT:  // %bb.0:
+-; COMMON-NEXT:    ld.param.v2.b16 {%rs1, %rs2}, [test_fptosi_2xhalf_to_2xi16_param_0];
++; COMMON-NEXT:    ld.param.b32 %r1, [test_fptosi_2xhalf_to_2xi16_param_0];
++; COMMON-NEXT:    mov.b32 {%rs1, %rs2}, %r1;
+ ; COMMON-NEXT:    cvt.rzi.s16.f16 %rs3, %rs2;
+ ; COMMON-NEXT:    cvt.rzi.s16.f16 %rs4, %rs1;
+ ; COMMON-NEXT:    st.param.v2.b16 [func_retval0], {%rs4, %rs3};
+@@ -971,7 +1039,8 @@
+ ; COMMON-NEXT:    .reg .b32 %r<2>;
+ ; COMMON-EMPTY:
+ ; COMMON-NEXT:  // %bb.0:
+-; COMMON-NEXT:    ld.param.v2.b16 {%rs1, %rs2}, [test_fptoui_2xhalf_to_2xi16_param_0];
++; COMMON-NEXT:    ld.param.b32 %r1, [test_fptoui_2xhalf_to_2xi16_param_0];
++; COMMON-NEXT:    mov.b32 {%rs1, %rs2}, %r1;
+ ; COMMON-NEXT:    cvt.rzi.u16.f16 %rs3, %rs2;
+ ; COMMON-NEXT:    cvt.rzi.u16.f16 %rs4, %rs1;
+ ; COMMON-NEXT:    st.param.v2.b16 [func_retval0], {%rs4, %rs3};
+diff -ruN --strip-trailing-cr a/llvm/test/CodeGen/NVPTX/i8x4-instructions.ll b/llvm/test/CodeGen/NVPTX/i8x4-instructions.ll
+--- a/llvm/test/CodeGen/NVPTX/i8x4-instructions.ll
++++ b/llvm/test/CodeGen/NVPTX/i8x4-instructions.ll
+@@ -1935,16 +1935,18 @@
+ ; O0-NEXT:    .reg .b32 %r<12>;
+ ; O0-EMPTY:
+ ; O0-NEXT:  // %bb.0:
+-; O0-NEXT:    ld.param.v4.b16 {%rs1, %rs2, %rs3, %rs4}, [test_fptosi_4xhalf_to_4xi8_param_0];
+-; O0-NEXT:    cvt.rzi.s16.f16 %rs5, %rs4;
+-; O0-NEXT:    cvt.rzi.s16.f16 %rs6, %rs3;
+-; O0-NEXT:    mov.b32 %r3, {%rs6, %rs5};
+-; O0-NEXT:    mov.b32 {%rs7, %rs8}, %r3;
+-; O0-NEXT:    cvt.u32.u16 %r4, %rs8;
+-; O0-NEXT:    cvt.u32.u16 %r5, %rs7;
++; O0-NEXT:    ld.param.v2.b32 {%r1, %r2}, [test_fptosi_4xhalf_to_4xi8_param_0];
++; O0-NEXT:    mov.b32 {%rs1, %rs2}, %r2;
++; O0-NEXT:    cvt.rzi.s16.f16 %rs3, %rs2;
++; O0-NEXT:    cvt.rzi.s16.f16 %rs4, %rs1;
++; O0-NEXT:    mov.b32 %r3, {%rs4, %rs3};
++; O0-NEXT:    mov.b32 {%rs5, %rs6}, %r3;
++; O0-NEXT:    cvt.u32.u16 %r4, %rs6;
++; O0-NEXT:    cvt.u32.u16 %r5, %rs5;
+ ; O0-NEXT:    prmt.b32 %r6, %r5, %r4, 0x3340U;
+-; O0-NEXT:    cvt.rzi.s16.f16 %rs9, %rs2;
+-; O0-NEXT:    cvt.rzi.s16.f16 %rs10, %rs1;
++; O0-NEXT:    mov.b32 {%rs7, %rs8}, %r1;
++; O0-NEXT:    cvt.rzi.s16.f16 %rs9, %rs8;
++; O0-NEXT:    cvt.rzi.s16.f16 %rs10, %rs7;
+ ; O0-NEXT:    mov.b32 %r7, {%rs10, %rs9};
+ ; O0-NEXT:    mov.b32 {%rs11, %rs12}, %r7;
+ ; O0-NEXT:    cvt.u32.u16 %r8, %rs12;
+@@ -1989,16 +1991,18 @@
+ ; O0-NEXT:    .reg .b32 %r<12>;
+ ; O0-EMPTY:
+ ; O0-NEXT:  // %bb.0:
+-; O0-NEXT:    ld.param.v4.b16 {%rs1, %rs2, %rs3, %rs4}, [test_fptoui_4xhalf_to_4xi8_param_0];
+-; O0-NEXT:    cvt.rzi.u16.f16 %rs5, %rs4;
+-; O0-NEXT:    cvt.rzi.u16.f16 %rs6, %rs3;
+-; O0-NEXT:    mov.b32 %r3, {%rs6, %rs5};
+-; O0-NEXT:    mov.b32 {%rs7, %rs8}, %r3;
+-; O0-NEXT:    cvt.u32.u16 %r4, %rs8;
+-; O0-NEXT:    cvt.u32.u16 %r5, %rs7;
++; O0-NEXT:    ld.param.v2.b32 {%r1, %r2}, [test_fptoui_4xhalf_to_4xi8_param_0];
++; O0-NEXT:    mov.b32 {%rs1, %rs2}, %r2;
++; O0-NEXT:    cvt.rzi.u16.f16 %rs3, %rs2;
++; O0-NEXT:    cvt.rzi.u16.f16 %rs4, %rs1;
++; O0-NEXT:    mov.b32 %r3, {%rs4, %rs3};
++; O0-NEXT:    mov.b32 {%rs5, %rs6}, %r3;
++; O0-NEXT:    cvt.u32.u16 %r4, %rs6;
++; O0-NEXT:    cvt.u32.u16 %r5, %rs5;
+ ; O0-NEXT:    prmt.b32 %r6, %r5, %r4, 0x3340U;
+-; O0-NEXT:    cvt.rzi.u16.f16 %rs9, %rs2;
+-; O0-NEXT:    cvt.rzi.u16.f16 %rs10, %rs1;
++; O0-NEXT:    mov.b32 {%rs7, %rs8}, %r1;
++; O0-NEXT:    cvt.rzi.u16.f16 %rs9, %rs8;
++; O0-NEXT:    cvt.rzi.u16.f16 %rs10, %rs7;
+ ; O0-NEXT:    mov.b32 %r7, {%rs10, %rs9};
+ ; O0-NEXT:    mov.b32 {%rs11, %rs12}, %r7;
+ ; O0-NEXT:    cvt.u32.u16 %r8, %rs12;
+diff -ruN --strip-trailing-cr a/llvm/test/CodeGen/NVPTX/pr126337.ll b/llvm/test/CodeGen/NVPTX/pr126337.ll
+--- a/llvm/test/CodeGen/NVPTX/pr126337.ll
++++ b/llvm/test/CodeGen/NVPTX/pr126337.ll
+@@ -0,0 +1,41 @@
++; NOTE: Assertions have been autogenerated by utils/update_llc_test_checks.py UTC_ARGS: --version 5
++; RUN: llc < %s -mtriple=nvptx64 -mcpu=sm_70 | FileCheck %s
++; RUN: %if ptxas %{ llc < %s -mtriple=nvptx64 -mcpu=sm_70 | %ptxas-verify %}
 +
++; This IR should compile without triggering assertions in LICM
++; when the CopyToReg from %0 in the first BB gets eliminated
++; but we still use its result in the second BB.
++; Technically the problem happens in MIR, but there are multiple
++; passes involved, so testing with the IR reproducer is more convenient.
++; https://github.com/llvm/llvm-project/pull/126337#issuecomment-3081431594
 +
- ; DWARF:        {{.*}}DW_TAG_label
- ; DWARF-NEXT:    DW_AT_name ("__coro_resume_0")
- ; DWARF-NEXT:    DW_AT_decl_file
-diff -ruN --strip-trailing-cr a/llvm/test/Transforms/LoopVectorize/AArch64/single-early-exit-interleave.ll b/llvm/test/Transforms/LoopVectorize/AArch64/single-early-exit-interleave.ll
---- a/llvm/test/Transforms/LoopVectorize/AArch64/single-early-exit-interleave.ll
-+++ b/llvm/test/Transforms/LoopVectorize/AArch64/single-early-exit-interleave.ll
-@@ -14,16 +14,15 @@
- ; CHECK-NEXT:    call void @init_mem(ptr [[P1]], i64 1024)
- ; CHECK-NEXT:    call void @init_mem(ptr [[P2]], i64 1024)
- ; CHECK-NEXT:    [[TMP0:%.*]] = call i64 @llvm.vscale.i64()
--; CHECK-NEXT:    [[TMP1:%.*]] = mul nuw i64 [[TMP0]], 64
--; CHECK-NEXT:    [[MIN_ITERS_CHECK:%.*]] = icmp ult i64 510, [[TMP1]]
--; CHECK-NEXT:    br i1 [[MIN_ITERS_CHECK]], label [[SCALAR_PH:%.*]], label [[VECTOR_PH:%.*]]
-+; CHECK-NEXT:    [[TMP1:%.*]] = mul nuw i64 [[TMP0]], 16
-+; CHECK-NEXT:    br i1 false, label [[SCALAR_PH:%.*]], label [[VECTOR_PH:%.*]]
- ; CHECK:       vector.ph:
- ; CHECK-NEXT:    [[TMP2:%.*]] = call i64 @llvm.vscale.i64()
--; CHECK-NEXT:    [[TMP3:%.*]] = mul nuw i64 [[TMP2]], 64
-+; CHECK-NEXT:    [[TMP3:%.*]] = mul nuw i64 [[TMP2]], 16
- ; CHECK-NEXT:    [[N_MOD_VF:%.*]] = urem i64 510, [[TMP3]]
- ; CHECK-NEXT:    [[N_VEC:%.*]] = sub i64 510, [[N_MOD_VF]]
- ; CHECK-NEXT:    [[TMP4:%.*]] = call i64 @llvm.vscale.i64()
--; CHECK-NEXT:    [[TMP5:%.*]] = mul nuw i64 [[TMP4]], 64
-+; CHECK-NEXT:    [[TMP5:%.*]] = mul nuw i64 [[TMP4]], 16
- ; CHECK-NEXT:    [[INDEX_NEXT:%.*]] = add i64 3, [[N_VEC]]
- ; CHECK-NEXT:    br label [[LOOP:%.*]]
- ; CHECK:       vector.body:
-@@ -31,43 +30,13 @@
- ; CHECK-NEXT:    [[OFFSET_IDX:%.*]] = add i64 3, [[INDEX1]]
- ; CHECK-NEXT:    [[TMP7:%.*]] = getelementptr inbounds i8, ptr [[P1]], i64 [[OFFSET_IDX]]
- ; CHECK-NEXT:    [[TMP8:%.*]] = getelementptr inbounds i8, ptr [[TMP7]], i32 0
--; CHECK-NEXT:    [[TMP18:%.*]] = call i64 @llvm.vscale.i64()
--; CHECK-NEXT:    [[TMP19:%.*]] = mul nuw i64 [[TMP18]], 16
--; CHECK-NEXT:    [[TMP29:%.*]] = getelementptr inbounds i8, ptr [[TMP7]], i64 [[TMP19]]
--; CHECK-NEXT:    [[TMP36:%.*]] = call i64 @llvm.vscale.i64()
--; CHECK-NEXT:    [[TMP37:%.*]] = mul nuw i64 [[TMP36]], 32
--; CHECK-NEXT:    [[TMP38:%.*]] = getelementptr inbounds i8, ptr [[TMP7]], i64 [[TMP37]]
--; CHECK-NEXT:    [[TMP39:%.*]] = call i64 @llvm.vscale.i64()
--; CHECK-NEXT:    [[TMP40:%.*]] = mul nuw i64 [[TMP39]], 48
--; CHECK-NEXT:    [[TMP41:%.*]] = getelementptr inbounds i8, ptr [[TMP7]], i64 [[TMP40]]
--; CHECK-NEXT:    [[WIDE_LOAD:%.*]] = load <vscale x 16 x i8>, ptr [[TMP8]], align 1
--; CHECK-NEXT:    [[WIDE_LOAD5:%.*]] = load <vscale x 16 x i8>, ptr [[TMP29]], align 1
--; CHECK-NEXT:    [[WIDE_LOAD3:%.*]] = load <vscale x 16 x i8>, ptr [[TMP38]], align 1
--; CHECK-NEXT:    [[WIDE_LOAD4:%.*]] = load <vscale x 16 x i8>, ptr [[TMP41]], align 1
-+; CHECK-NEXT:    [[WIDE_LOAD4:%.*]] = load <vscale x 16 x i8>, ptr [[TMP8]], align 1
- ; CHECK-NEXT:    [[TMP9:%.*]] = getelementptr inbounds i8, ptr [[P2]], i64 [[OFFSET_IDX]]
- ; CHECK-NEXT:    [[TMP10:%.*]] = getelementptr inbounds i8, ptr [[TMP9]], i32 0
--; CHECK-NEXT:    [[TMP20:%.*]] = call i64 @llvm.vscale.i64()
--; CHECK-NEXT:    [[TMP21:%.*]] = mul nuw i64 [[TMP20]], 16
--; CHECK-NEXT:    [[TMP22:%.*]] = getelementptr inbounds i8, ptr [[TMP9]], i64 [[TMP21]]
--; CHECK-NEXT:    [[TMP23:%.*]] = call i64 @llvm.vscale.i64()
--; CHECK-NEXT:    [[TMP24:%.*]] = mul nuw i64 [[TMP23]], 32
--; CHECK-NEXT:    [[TMP25:%.*]] = getelementptr inbounds i8, ptr [[TMP9]], i64 [[TMP24]]
--; CHECK-NEXT:    [[TMP26:%.*]] = call i64 @llvm.vscale.i64()
--; CHECK-NEXT:    [[TMP27:%.*]] = mul nuw i64 [[TMP26]], 48
--; CHECK-NEXT:    [[TMP28:%.*]] = getelementptr inbounds i8, ptr [[TMP9]], i64 [[TMP27]]
--; CHECK-NEXT:    [[WIDE_LOAD2:%.*]] = load <vscale x 16 x i8>, ptr [[TMP10]], align 1
--; CHECK-NEXT:    [[WIDE_LOAD6:%.*]] = load <vscale x 16 x i8>, ptr [[TMP22]], align 1
--; CHECK-NEXT:    [[WIDE_LOAD7:%.*]] = load <vscale x 16 x i8>, ptr [[TMP25]], align 1
--; CHECK-NEXT:    [[WIDE_LOAD8:%.*]] = load <vscale x 16 x i8>, ptr [[TMP28]], align 1
--; CHECK-NEXT:    [[TMP11:%.*]] = icmp ne <vscale x 16 x i8> [[WIDE_LOAD]], [[WIDE_LOAD2]]
--; CHECK-NEXT:    [[TMP30:%.*]] = icmp ne <vscale x 16 x i8> [[WIDE_LOAD5]], [[WIDE_LOAD6]]
--; CHECK-NEXT:    [[TMP31:%.*]] = icmp ne <vscale x 16 x i8> [[WIDE_LOAD3]], [[WIDE_LOAD7]]
-+; CHECK-NEXT:    [[WIDE_LOAD8:%.*]] = load <vscale x 16 x i8>, ptr [[TMP10]], align 1
- ; CHECK-NEXT:    [[TMP32:%.*]] = icmp ne <vscale x 16 x i8> [[WIDE_LOAD4]], [[WIDE_LOAD8]]
- ; CHECK-NEXT:    [[INDEX_NEXT3]] = add nuw i64 [[INDEX1]], [[TMP5]]
--; CHECK-NEXT:    [[TMP33:%.*]] = or <vscale x 16 x i1> [[TMP11]], [[TMP30]]
--; CHECK-NEXT:    [[TMP34:%.*]] = or <vscale x 16 x i1> [[TMP33]], [[TMP31]]
--; CHECK-NEXT:    [[TMP35:%.*]] = or <vscale x 16 x i1> [[TMP34]], [[TMP32]]
--; CHECK-NEXT:    [[TMP12:%.*]] = call i1 @llvm.vector.reduce.or.nxv16i1(<vscale x 16 x i1> [[TMP35]])
-+; CHECK-NEXT:    [[TMP12:%.*]] = call i1 @llvm.vector.reduce.or.nxv16i1(<vscale x 16 x i1> [[TMP32]])
- ; CHECK-NEXT:    [[TMP13:%.*]] = icmp eq i64 [[INDEX_NEXT3]], [[N_VEC]]
- ; CHECK-NEXT:    [[TMP14:%.*]] = or i1 [[TMP12]], [[TMP13]]
- ; CHECK-NEXT:    br i1 [[TMP14]], label [[MIDDLE_SPLIT:%.*]], label [[LOOP]], !llvm.loop [[LOOP0:![0-9]+]]
-@@ -77,26 +46,7 @@
- ; CHECK-NEXT:    [[CMP_N:%.*]] = icmp eq i64 510, [[N_VEC]]
- ; CHECK-NEXT:    br i1 [[CMP_N]], label [[LOOP_END:%.*]], label [[SCALAR_PH]]
- ; CHECK:       vector.early.exit:
--; CHECK-NEXT:    [[TMP63:%.*]] = call i64 @llvm.vscale.i64()
--; CHECK-NEXT:    [[TMP42:%.*]] = mul nuw i64 [[TMP63]], 16
--; CHECK-NEXT:    [[TMP44:%.*]] = call i64 @llvm.experimental.cttz.elts.i64.nxv16i1(<vscale x 16 x i1> [[TMP32]], i1 true)
--; CHECK-NEXT:    [[TMP62:%.*]] = mul i64 [[TMP42]], 3
--; CHECK-NEXT:    [[TMP45:%.*]] = add i64 [[TMP62]], [[TMP44]]
--; CHECK-NEXT:    [[TMP46:%.*]] = call i64 @llvm.experimental.cttz.elts.i64.nxv16i1(<vscale x 16 x i1> [[TMP31]], i1 true)
--; CHECK-NEXT:    [[TMP58:%.*]] = mul i64 [[TMP42]], 2
--; CHECK-NEXT:    [[TMP50:%.*]] = add i64 [[TMP58]], [[TMP46]]
--; CHECK-NEXT:    [[TMP47:%.*]] = icmp ne i64 [[TMP46]], [[TMP42]]
--; CHECK-NEXT:    [[TMP51:%.*]] = select i1 [[TMP47]], i64 [[TMP50]], i64 [[TMP45]]
--; CHECK-NEXT:    [[TMP52:%.*]] = call i64 @llvm.experimental.cttz.elts.i64.nxv16i1(<vscale x 16 x i1> [[TMP30]], i1 true)
--; CHECK-NEXT:    [[TMP64:%.*]] = mul i64 [[TMP42]], 1
--; CHECK-NEXT:    [[TMP56:%.*]] = add i64 [[TMP64]], [[TMP52]]
--; CHECK-NEXT:    [[TMP53:%.*]] = icmp ne i64 [[TMP52]], [[TMP42]]
--; CHECK-NEXT:    [[TMP57:%.*]] = select i1 [[TMP53]], i64 [[TMP56]], i64 [[TMP51]]
--; CHECK-NEXT:    [[TMP15:%.*]] = call i64 @llvm.experimental.cttz.elts.i64.nxv16i1(<vscale x 16 x i1> [[TMP11]], i1 true)
--; CHECK-NEXT:    [[TMP65:%.*]] = mul i64 [[TMP42]], 0
--; CHECK-NEXT:    [[TMP60:%.*]] = add i64 [[TMP65]], [[TMP15]]
--; CHECK-NEXT:    [[TMP59:%.*]] = icmp ne i64 [[TMP15]], [[TMP42]]
--; CHECK-NEXT:    [[TMP61:%.*]] = select i1 [[TMP59]], i64 [[TMP60]], i64 [[TMP57]]
-+; CHECK-NEXT:    [[TMP61:%.*]] = call i64 @llvm.experimental.cttz.elts.i64.nxv16i1(<vscale x 16 x i1> [[TMP32]], i1 true)
- ; CHECK-NEXT:    [[TMP16:%.*]] = add i64 [[INDEX1]], [[TMP61]]
- ; CHECK-NEXT:    [[TMP17:%.*]] = add i64 3, [[TMP16]]
- ; CHECK-NEXT:    br label [[LOOP_END]]
-diff -ruN --strip-trailing-cr a/llvm/test/Transforms/LoopVectorize/single-early-exit-interleave.ll b/llvm/test/Transforms/LoopVectorize/single-early-exit-interleave.ll
---- a/llvm/test/Transforms/LoopVectorize/single-early-exit-interleave.ll
-+++ b/llvm/test/Transforms/LoopVectorize/single-early-exit-interleave.ll
-@@ -15,22 +15,10 @@
- ; VF4IC4-NEXT:    [[INDEX:%.*]] = phi i64 [ 0, [[VECTOR_PH]] ], [ [[INDEX_NEXT:%.*]], [[VECTOR_BODY]] ]
- ; VF4IC4-NEXT:    [[TMP0:%.*]] = getelementptr inbounds i32, ptr [[SRC]], i64 [[INDEX]]
- ; VF4IC4-NEXT:    [[TMP1:%.*]] = getelementptr inbounds i32, ptr [[TMP0]], i32 0
--; VF4IC4-NEXT:    [[TMP12:%.*]] = getelementptr inbounds i32, ptr [[TMP0]], i32 4
--; VF4IC4-NEXT:    [[TMP13:%.*]] = getelementptr inbounds i32, ptr [[TMP0]], i32 8
--; VF4IC4-NEXT:    [[TMP14:%.*]] = getelementptr inbounds i32, ptr [[TMP0]], i32 12
--; VF4IC4-NEXT:    [[WIDE_LOAD:%.*]] = load <4 x i32>, ptr [[TMP1]], align 4
--; VF4IC4-NEXT:    [[WIDE_LOAD1:%.*]] = load <4 x i32>, ptr [[TMP12]], align 4
--; VF4IC4-NEXT:    [[WIDE_LOAD2:%.*]] = load <4 x i32>, ptr [[TMP13]], align 4
--; VF4IC4-NEXT:    [[WIDE_LOAD3:%.*]] = load <4 x i32>, ptr [[TMP14]], align 4
--; VF4IC4-NEXT:    [[TMP2:%.*]] = icmp eq <4 x i32> [[WIDE_LOAD]], splat (i32 10)
--; VF4IC4-NEXT:    [[TMP6:%.*]] = icmp eq <4 x i32> [[WIDE_LOAD1]], splat (i32 10)
--; VF4IC4-NEXT:    [[TMP7:%.*]] = icmp eq <4 x i32> [[WIDE_LOAD2]], splat (i32 10)
-+; VF4IC4-NEXT:    [[WIDE_LOAD3:%.*]] = load <4 x i32>, ptr [[TMP1]], align 4
- ; VF4IC4-NEXT:    [[TMP8:%.*]] = icmp eq <4 x i32> [[WIDE_LOAD3]], splat (i32 10)
--; VF4IC4-NEXT:    [[INDEX_NEXT]] = add nuw i64 [[INDEX]], 16
--; VF4IC4-NEXT:    [[TMP9:%.*]] = or <4 x i1> [[TMP2]], [[TMP6]]
--; VF4IC4-NEXT:    [[TMP10:%.*]] = or <4 x i1> [[TMP9]], [[TMP7]]
--; VF4IC4-NEXT:    [[TMP11:%.*]] = or <4 x i1> [[TMP10]], [[TMP8]]
--; VF4IC4-NEXT:    [[TMP3:%.*]] = call i1 @llvm.vector.reduce.or.v4i1(<4 x i1> [[TMP11]])
-+; VF4IC4-NEXT:    [[INDEX_NEXT]] = add nuw i64 [[INDEX]], 4
-+; VF4IC4-NEXT:    [[TMP3:%.*]] = call i1 @llvm.vector.reduce.or.v4i1(<4 x i1> [[TMP8]])
- ; VF4IC4-NEXT:    [[TMP4:%.*]] = icmp eq i64 [[INDEX_NEXT]], 128
- ; VF4IC4-NEXT:    [[TMP5:%.*]] = or i1 [[TMP3]], [[TMP4]]
- ; VF4IC4-NEXT:    br i1 [[TMP5]], label [[MIDDLE_SPLIT:%.*]], label [[VECTOR_BODY]], !llvm.loop [[LOOP0:![0-9]+]]
-@@ -101,31 +89,13 @@
- ; VF4IC4-NEXT:    [[OFFSET_IDX:%.*]] = add i64 3, [[INDEX]]
- ; VF4IC4-NEXT:    [[TMP0:%.*]] = getelementptr inbounds i8, ptr [[P1]], i64 [[OFFSET_IDX]]
- ; VF4IC4-NEXT:    [[TMP1:%.*]] = getelementptr inbounds i8, ptr [[TMP0]], i32 0
--; VF4IC4-NEXT:    [[TMP2:%.*]] = getelementptr inbounds i8, ptr [[TMP0]], i32 4
--; VF4IC4-NEXT:    [[TMP3:%.*]] = getelementptr inbounds i8, ptr [[TMP0]], i32 8
--; VF4IC4-NEXT:    [[TMP17:%.*]] = getelementptr inbounds i8, ptr [[TMP0]], i32 12
--; VF4IC4-NEXT:    [[WIDE_LOAD:%.*]] = load <4 x i8>, ptr [[TMP1]], align 1
--; VF4IC4-NEXT:    [[WIDE_LOAD4:%.*]] = load <4 x i8>, ptr [[TMP2]], align 1
--; VF4IC4-NEXT:    [[WIDE_LOAD2:%.*]] = load <4 x i8>, ptr [[TMP3]], align 1
--; VF4IC4-NEXT:    [[WIDE_LOAD3:%.*]] = load <4 x i8>, ptr [[TMP17]], align 1
-+; VF4IC4-NEXT:    [[WIDE_LOAD3:%.*]] = load <4 x i8>, ptr [[TMP1]], align 1
- ; VF4IC4-NEXT:    [[TMP18:%.*]] = getelementptr inbounds i8, ptr [[P2]], i64 [[OFFSET_IDX]]
- ; VF4IC4-NEXT:    [[TMP19:%.*]] = getelementptr inbounds i8, ptr [[TMP18]], i32 0
--; VF4IC4-NEXT:    [[TMP20:%.*]] = getelementptr inbounds i8, ptr [[TMP18]], i32 4
--; VF4IC4-NEXT:    [[TMP21:%.*]] = getelementptr inbounds i8, ptr [[TMP18]], i32 8
--; VF4IC4-NEXT:    [[TMP22:%.*]] = getelementptr inbounds i8, ptr [[TMP18]], i32 12
--; VF4IC4-NEXT:    [[WIDE_LOAD1:%.*]] = load <4 x i8>, ptr [[TMP19]], align 1
--; VF4IC4-NEXT:    [[WIDE_LOAD5:%.*]] = load <4 x i8>, ptr [[TMP20]], align 1
--; VF4IC4-NEXT:    [[WIDE_LOAD6:%.*]] = load <4 x i8>, ptr [[TMP21]], align 1
--; VF4IC4-NEXT:    [[WIDE_LOAD7:%.*]] = load <4 x i8>, ptr [[TMP22]], align 1
--; VF4IC4-NEXT:    [[TMP4:%.*]] = icmp ne <4 x i8> [[WIDE_LOAD]], [[WIDE_LOAD1]]
--; VF4IC4-NEXT:    [[TMP11:%.*]] = icmp ne <4 x i8> [[WIDE_LOAD4]], [[WIDE_LOAD5]]
--; VF4IC4-NEXT:    [[TMP12:%.*]] = icmp ne <4 x i8> [[WIDE_LOAD2]], [[WIDE_LOAD6]]
-+; VF4IC4-NEXT:    [[WIDE_LOAD7:%.*]] = load <4 x i8>, ptr [[TMP19]], align 1
- ; VF4IC4-NEXT:    [[TMP13:%.*]] = icmp ne <4 x i8> [[WIDE_LOAD3]], [[WIDE_LOAD7]]
--; VF4IC4-NEXT:    [[INDEX_NEXT]] = add nuw i64 [[INDEX]], 16
--; VF4IC4-NEXT:    [[TMP14:%.*]] = or <4 x i1> [[TMP4]], [[TMP11]]
--; VF4IC4-NEXT:    [[TMP15:%.*]] = or <4 x i1> [[TMP14]], [[TMP12]]
--; VF4IC4-NEXT:    [[TMP16:%.*]] = or <4 x i1> [[TMP15]], [[TMP13]]
--; VF4IC4-NEXT:    [[TMP5:%.*]] = call i1 @llvm.vector.reduce.or.v4i1(<4 x i1> [[TMP16]])
-+; VF4IC4-NEXT:    [[INDEX_NEXT]] = add nuw i64 [[INDEX]], 4
-+; VF4IC4-NEXT:    [[TMP5:%.*]] = call i1 @llvm.vector.reduce.or.v4i1(<4 x i1> [[TMP13]])
- ; VF4IC4-NEXT:    [[TMP6:%.*]] = icmp eq i64 [[INDEX_NEXT]], 64
- ; VF4IC4-NEXT:    [[TMP7:%.*]] = or i1 [[TMP5]], [[TMP6]]
- ; VF4IC4-NEXT:    br i1 [[TMP7]], label [[MIDDLE_SPLIT:%.*]], label [[VECTOR_BODY]], !llvm.loop [[LOOP4:![0-9]+]]
-@@ -134,20 +104,7 @@
- ; VF4IC4:       middle.block:
- ; VF4IC4-NEXT:    br i1 true, label [[LOOP_END:%.*]], label [[SCALAR_PH]]
- ; VF4IC4:       vector.early.exit:
--; VF4IC4-NEXT:    [[TMP33:%.*]] = call i64 @llvm.experimental.cttz.elts.i64.v4i1(<4 x i1> [[TMP13]], i1 true)
--; VF4IC4-NEXT:    [[TMP34:%.*]] = add i64 12, [[TMP33]]
--; VF4IC4-NEXT:    [[TMP35:%.*]] = call i64 @llvm.experimental.cttz.elts.i64.v4i1(<4 x i1> [[TMP12]], i1 true)
--; VF4IC4-NEXT:    [[TMP24:%.*]] = add i64 8, [[TMP35]]
--; VF4IC4-NEXT:    [[TMP23:%.*]] = icmp ne i64 [[TMP35]], 4
--; VF4IC4-NEXT:    [[TMP25:%.*]] = select i1 [[TMP23]], i64 [[TMP24]], i64 [[TMP34]]
--; VF4IC4-NEXT:    [[TMP26:%.*]] = call i64 @llvm.experimental.cttz.elts.i64.v4i1(<4 x i1> [[TMP11]], i1 true)
--; VF4IC4-NEXT:    [[TMP28:%.*]] = add i64 4, [[TMP26]]
--; VF4IC4-NEXT:    [[TMP27:%.*]] = icmp ne i64 [[TMP26]], 4
--; VF4IC4-NEXT:    [[TMP29:%.*]] = select i1 [[TMP27]], i64 [[TMP28]], i64 [[TMP25]]
--; VF4IC4-NEXT:    [[TMP30:%.*]] = call i64 @llvm.experimental.cttz.elts.i64.v4i1(<4 x i1> [[TMP4]], i1 true)
--; VF4IC4-NEXT:    [[TMP32:%.*]] = add i64 0, [[TMP30]]
--; VF4IC4-NEXT:    [[TMP31:%.*]] = icmp ne i64 [[TMP30]], 4
--; VF4IC4-NEXT:    [[TMP8:%.*]] = select i1 [[TMP31]], i64 [[TMP32]], i64 [[TMP29]]
-+; VF4IC4-NEXT:    [[TMP8:%.*]] = call i64 @llvm.experimental.cttz.elts.i64.v4i1(<4 x i1> [[TMP13]], i1 true)
- ; VF4IC4-NEXT:    [[TMP9:%.*]] = add i64 [[INDEX]], [[TMP8]]
- ; VF4IC4-NEXT:    [[TMP10:%.*]] = add i64 3, [[TMP9]]
- ; VF4IC4-NEXT:    br label [[LOOP_END]]
-@@ -210,22 +167,10 @@
- ; VF4IC4-NEXT:    [[INDEX:%.*]] = phi i64 [ 0, [[VECTOR_PH]] ], [ [[INDEX_NEXT:%.*]], [[VECTOR_BODY]] ]
- ; VF4IC4-NEXT:    [[NEXT_GEP:%.*]] = getelementptr i8, ptr [[P1]], i64 [[INDEX]]
- ; VF4IC4-NEXT:    [[TMP1:%.*]] = getelementptr i8, ptr [[NEXT_GEP]], i32 0
--; VF4IC4-NEXT:    [[TMP12:%.*]] = getelementptr i8, ptr [[NEXT_GEP]], i32 4
--; VF4IC4-NEXT:    [[TMP13:%.*]] = getelementptr i8, ptr [[NEXT_GEP]], i32 8
--; VF4IC4-NEXT:    [[TMP14:%.*]] = getelementptr i8, ptr [[NEXT_GEP]], i32 12
--; VF4IC4-NEXT:    [[WIDE_LOAD:%.*]] = load <4 x i8>, ptr [[TMP1]], align 1
--; VF4IC4-NEXT:    [[WIDE_LOAD1:%.*]] = load <4 x i8>, ptr [[TMP12]], align 1
--; VF4IC4-NEXT:    [[WIDE_LOAD2:%.*]] = load <4 x i8>, ptr [[TMP13]], align 1
--; VF4IC4-NEXT:    [[WIDE_LOAD3:%.*]] = load <4 x i8>, ptr [[TMP14]], align 1
--; VF4IC4-NEXT:    [[TMP2:%.*]] = icmp ne <4 x i8> [[WIDE_LOAD]], splat (i8 72)
--; VF4IC4-NEXT:    [[TMP15:%.*]] = icmp ne <4 x i8> [[WIDE_LOAD1]], splat (i8 72)
--; VF4IC4-NEXT:    [[TMP16:%.*]] = icmp ne <4 x i8> [[WIDE_LOAD2]], splat (i8 72)
-+; VF4IC4-NEXT:    [[WIDE_LOAD3:%.*]] = load <4 x i8>, ptr [[TMP1]], align 1
- ; VF4IC4-NEXT:    [[TMP17:%.*]] = icmp ne <4 x i8> [[WIDE_LOAD3]], splat (i8 72)
--; VF4IC4-NEXT:    [[INDEX_NEXT]] = add nuw i64 [[INDEX]], 16
--; VF4IC4-NEXT:    [[TMP9:%.*]] = or <4 x i1> [[TMP2]], [[TMP15]]
--; VF4IC4-NEXT:    [[TMP10:%.*]] = or <4 x i1> [[TMP9]], [[TMP16]]
--; VF4IC4-NEXT:    [[TMP11:%.*]] = or <4 x i1> [[TMP10]], [[TMP17]]
--; VF4IC4-NEXT:    [[TMP3:%.*]] = call i1 @llvm.vector.reduce.or.v4i1(<4 x i1> [[TMP11]])
-+; VF4IC4-NEXT:    [[INDEX_NEXT]] = add nuw i64 [[INDEX]], 4
-+; VF4IC4-NEXT:    [[TMP3:%.*]] = call i1 @llvm.vector.reduce.or.v4i1(<4 x i1> [[TMP17]])
- ; VF4IC4-NEXT:    [[TMP4:%.*]] = icmp eq i64 [[INDEX_NEXT]], 1024
- ; VF4IC4-NEXT:    [[TMP5:%.*]] = or i1 [[TMP3]], [[TMP4]]
- ; VF4IC4-NEXT:    br i1 [[TMP5]], label [[MIDDLE_SPLIT:%.*]], label [[VECTOR_BODY]], !llvm.loop [[LOOP6:![0-9]+]]
-@@ -234,20 +179,7 @@
- ; VF4IC4:       middle.block:
- ; VF4IC4-NEXT:    br i1 true, label [[LOOP_END:%.*]], label [[SCALAR_PH]]
- ; VF4IC4:       vector.early.exit:
--; VF4IC4-NEXT:    [[TMP28:%.*]] = call i64 @llvm.experimental.cttz.elts.i64.v4i1(<4 x i1> [[TMP17]], i1 true)
--; VF4IC4-NEXT:    [[TMP29:%.*]] = add i64 12, [[TMP28]]
--; VF4IC4-NEXT:    [[TMP30:%.*]] = call i64 @llvm.experimental.cttz.elts.i64.v4i1(<4 x i1> [[TMP16]], i1 true)
--; VF4IC4-NEXT:    [[TMP19:%.*]] = add i64 8, [[TMP30]]
--; VF4IC4-NEXT:    [[TMP18:%.*]] = icmp ne i64 [[TMP30]], 4
--; VF4IC4-NEXT:    [[TMP20:%.*]] = select i1 [[TMP18]], i64 [[TMP19]], i64 [[TMP29]]
--; VF4IC4-NEXT:    [[TMP21:%.*]] = call i64 @llvm.experimental.cttz.elts.i64.v4i1(<4 x i1> [[TMP15]], i1 true)
--; VF4IC4-NEXT:    [[TMP23:%.*]] = add i64 4, [[TMP21]]
--; VF4IC4-NEXT:    [[TMP22:%.*]] = icmp ne i64 [[TMP21]], 4
--; VF4IC4-NEXT:    [[TMP24:%.*]] = select i1 [[TMP22]], i64 [[TMP23]], i64 [[TMP20]]
--; VF4IC4-NEXT:    [[TMP25:%.*]] = call i64 @llvm.experimental.cttz.elts.i64.v4i1(<4 x i1> [[TMP2]], i1 true)
--; VF4IC4-NEXT:    [[TMP27:%.*]] = add i64 0, [[TMP25]]
--; VF4IC4-NEXT:    [[TMP26:%.*]] = icmp ne i64 [[TMP25]], 4
--; VF4IC4-NEXT:    [[TMP6:%.*]] = select i1 [[TMP26]], i64 [[TMP27]], i64 [[TMP24]]
-+; VF4IC4-NEXT:    [[TMP6:%.*]] = call i64 @llvm.experimental.cttz.elts.i64.v4i1(<4 x i1> [[TMP17]], i1 true)
- ; VF4IC4-NEXT:    [[TMP7:%.*]] = add i64 [[INDEX]], [[TMP6]]
- ; VF4IC4-NEXT:    [[TMP8:%.*]] = getelementptr i8, ptr [[P1]], i64 [[TMP7]]
- ; VF4IC4-NEXT:    br label [[LOOP_END]]
-@@ -304,31 +236,13 @@
- ; VF4IC4-NEXT:    [[OFFSET_IDX:%.*]] = add i64 3, [[INDEX]]
- ; VF4IC4-NEXT:    [[TMP0:%.*]] = getelementptr inbounds i8, ptr [[P1]], i64 [[OFFSET_IDX]]
- ; VF4IC4-NEXT:    [[TMP1:%.*]] = getelementptr inbounds i8, ptr [[TMP0]], i32 0
--; VF4IC4-NEXT:    [[TMP2:%.*]] = getelementptr inbounds i8, ptr [[TMP0]], i32 4
--; VF4IC4-NEXT:    [[TMP3:%.*]] = getelementptr inbounds i8, ptr [[TMP0]], i32 8
--; VF4IC4-NEXT:    [[TMP17:%.*]] = getelementptr inbounds i8, ptr [[TMP0]], i32 12
--; VF4IC4-NEXT:    [[WIDE_LOAD:%.*]] = load <4 x i8>, ptr [[TMP1]], align 1
--; VF4IC4-NEXT:    [[WIDE_LOAD4:%.*]] = load <4 x i8>, ptr [[TMP2]], align 1
--; VF4IC4-NEXT:    [[WIDE_LOAD2:%.*]] = load <4 x i8>, ptr [[TMP3]], align 1
--; VF4IC4-NEXT:    [[WIDE_LOAD3:%.*]] = load <4 x i8>, ptr [[TMP17]], align 1
-+; VF4IC4-NEXT:    [[WIDE_LOAD3:%.*]] = load <4 x i8>, ptr [[TMP1]], align 1
- ; VF4IC4-NEXT:    [[TMP18:%.*]] = getelementptr inbounds i8, ptr [[P2]], i64 [[OFFSET_IDX]]
- ; VF4IC4-NEXT:    [[TMP19:%.*]] = getelementptr inbounds i8, ptr [[TMP18]], i32 0
--; VF4IC4-NEXT:    [[TMP20:%.*]] = getelementptr inbounds i8, ptr [[TMP18]], i32 4
--; VF4IC4-NEXT:    [[TMP21:%.*]] = getelementptr inbounds i8, ptr [[TMP18]], i32 8
--; VF4IC4-NEXT:    [[TMP22:%.*]] = getelementptr inbounds i8, ptr [[TMP18]], i32 12
--; VF4IC4-NEXT:    [[WIDE_LOAD1:%.*]] = load <4 x i8>, ptr [[TMP19]], align 1
--; VF4IC4-NEXT:    [[WIDE_LOAD5:%.*]] = load <4 x i8>, ptr [[TMP20]], align 1
--; VF4IC4-NEXT:    [[WIDE_LOAD6:%.*]] = load <4 x i8>, ptr [[TMP21]], align 1
--; VF4IC4-NEXT:    [[WIDE_LOAD7:%.*]] = load <4 x i8>, ptr [[TMP22]], align 1
--; VF4IC4-NEXT:    [[TMP4:%.*]] = icmp ne <4 x i8> [[WIDE_LOAD]], [[WIDE_LOAD1]]
--; VF4IC4-NEXT:    [[TMP11:%.*]] = icmp ne <4 x i8> [[WIDE_LOAD4]], [[WIDE_LOAD5]]
--; VF4IC4-NEXT:    [[TMP12:%.*]] = icmp ne <4 x i8> [[WIDE_LOAD2]], [[WIDE_LOAD6]]
-+; VF4IC4-NEXT:    [[WIDE_LOAD7:%.*]] = load <4 x i8>, ptr [[TMP19]], align 1
- ; VF4IC4-NEXT:    [[TMP13:%.*]] = icmp ne <4 x i8> [[WIDE_LOAD3]], [[WIDE_LOAD7]]
--; VF4IC4-NEXT:    [[INDEX_NEXT]] = add nuw i64 [[INDEX]], 16
--; VF4IC4-NEXT:    [[TMP14:%.*]] = or <4 x i1> [[TMP4]], [[TMP11]]
--; VF4IC4-NEXT:    [[TMP15:%.*]] = or <4 x i1> [[TMP14]], [[TMP12]]
--; VF4IC4-NEXT:    [[TMP16:%.*]] = or <4 x i1> [[TMP15]], [[TMP13]]
--; VF4IC4-NEXT:    [[TMP5:%.*]] = call i1 @llvm.vector.reduce.or.v4i1(<4 x i1> [[TMP16]])
-+; VF4IC4-NEXT:    [[INDEX_NEXT]] = add nuw i64 [[INDEX]], 4
-+; VF4IC4-NEXT:    [[TMP5:%.*]] = call i1 @llvm.vector.reduce.or.v4i1(<4 x i1> [[TMP13]])
- ; VF4IC4-NEXT:    [[TMP6:%.*]] = icmp eq i64 [[INDEX_NEXT]], 64
- ; VF4IC4-NEXT:    [[TMP7:%.*]] = or i1 [[TMP5]], [[TMP6]]
- ; VF4IC4-NEXT:    br i1 [[TMP7]], label [[MIDDLE_SPLIT:%.*]], label [[VECTOR_BODY]], !llvm.loop [[LOOP8:![0-9]+]]
-@@ -337,20 +251,7 @@
- ; VF4IC4:       middle.block:
- ; VF4IC4-NEXT:    br i1 true, label [[LOOP_END:%.*]], label [[SCALAR_PH]]
- ; VF4IC4:       vector.early.exit:
--; VF4IC4-NEXT:    [[TMP33:%.*]] = call i64 @llvm.experimental.cttz.elts.i64.v4i1(<4 x i1> [[TMP13]], i1 true)
--; VF4IC4-NEXT:    [[TMP34:%.*]] = add i64 12, [[TMP33]]
--; VF4IC4-NEXT:    [[TMP35:%.*]] = call i64 @llvm.experimental.cttz.elts.i64.v4i1(<4 x i1> [[TMP12]], i1 true)
--; VF4IC4-NEXT:    [[TMP24:%.*]] = add i64 8, [[TMP35]]
--; VF4IC4-NEXT:    [[TMP23:%.*]] = icmp ne i64 [[TMP35]], 4
--; VF4IC4-NEXT:    [[TMP25:%.*]] = select i1 [[TMP23]], i64 [[TMP24]], i64 [[TMP34]]
--; VF4IC4-NEXT:    [[TMP26:%.*]] = call i64 @llvm.experimental.cttz.elts.i64.v4i1(<4 x i1> [[TMP11]], i1 true)
--; VF4IC4-NEXT:    [[TMP28:%.*]] = add i64 4, [[TMP26]]
--; VF4IC4-NEXT:    [[TMP27:%.*]] = icmp ne i64 [[TMP26]], 4
--; VF4IC4-NEXT:    [[TMP29:%.*]] = select i1 [[TMP27]], i64 [[TMP28]], i64 [[TMP25]]
--; VF4IC4-NEXT:    [[TMP30:%.*]] = call i64 @llvm.experimental.cttz.elts.i64.v4i1(<4 x i1> [[TMP4]], i1 true)
--; VF4IC4-NEXT:    [[TMP32:%.*]] = add i64 0, [[TMP30]]
--; VF4IC4-NEXT:    [[TMP31:%.*]] = icmp ne i64 [[TMP30]], 4
--; VF4IC4-NEXT:    [[TMP8:%.*]] = select i1 [[TMP31]], i64 [[TMP32]], i64 [[TMP29]]
-+; VF4IC4-NEXT:    [[TMP8:%.*]] = call i64 @llvm.experimental.cttz.elts.i64.v4i1(<4 x i1> [[TMP13]], i1 true)
- ; VF4IC4-NEXT:    [[TMP9:%.*]] = add i64 [[INDEX]], [[TMP8]]
- ; VF4IC4-NEXT:    [[TMP10:%.*]] = add i64 3, [[TMP9]]
- ; VF4IC4-NEXT:    br label [[LOOP_END]]
-@@ -414,31 +315,13 @@
- ; VF4IC4-NEXT:    [[OFFSET_IDX:%.*]] = add i64 3, [[INDEX]]
- ; VF4IC4-NEXT:    [[TMP0:%.*]] = getelementptr inbounds i8, ptr [[P1]], i64 [[OFFSET_IDX]]
- ; VF4IC4-NEXT:    [[TMP1:%.*]] = getelementptr inbounds i8, ptr [[TMP0]], i32 0
--; VF4IC4-NEXT:    [[TMP2:%.*]] = getelementptr inbounds i8, ptr [[TMP0]], i32 4
--; VF4IC4-NEXT:    [[TMP3:%.*]] = getelementptr inbounds i8, ptr [[TMP0]], i32 8
--; VF4IC4-NEXT:    [[TMP17:%.*]] = getelementptr inbounds i8, ptr [[TMP0]], i32 12
--; VF4IC4-NEXT:    [[WIDE_LOAD:%.*]] = load <4 x i8>, ptr [[TMP1]], align 1
--; VF4IC4-NEXT:    [[WIDE_LOAD4:%.*]] = load <4 x i8>, ptr [[TMP2]], align 1
--; VF4IC4-NEXT:    [[WIDE_LOAD2:%.*]] = load <4 x i8>, ptr [[TMP3]], align 1
--; VF4IC4-NEXT:    [[WIDE_LOAD3:%.*]] = load <4 x i8>, ptr [[TMP17]], align 1
-+; VF4IC4-NEXT:    [[WIDE_LOAD3:%.*]] = load <4 x i8>, ptr [[TMP1]], align 1
- ; VF4IC4-NEXT:    [[TMP18:%.*]] = getelementptr inbounds i8, ptr [[P2]], i64 [[OFFSET_IDX]]
- ; VF4IC4-NEXT:    [[TMP19:%.*]] = getelementptr inbounds i8, ptr [[TMP18]], i32 0
--; VF4IC4-NEXT:    [[TMP20:%.*]] = getelementptr inbounds i8, ptr [[TMP18]], i32 4
--; VF4IC4-NEXT:    [[TMP21:%.*]] = getelementptr inbounds i8, ptr [[TMP18]], i32 8
--; VF4IC4-NEXT:    [[TMP22:%.*]] = getelementptr inbounds i8, ptr [[TMP18]], i32 12
--; VF4IC4-NEXT:    [[WIDE_LOAD1:%.*]] = load <4 x i8>, ptr [[TMP19]], align 1
--; VF4IC4-NEXT:    [[WIDE_LOAD5:%.*]] = load <4 x i8>, ptr [[TMP20]], align 1
--; VF4IC4-NEXT:    [[WIDE_LOAD6:%.*]] = load <4 x i8>, ptr [[TMP21]], align 1
--; VF4IC4-NEXT:    [[WIDE_LOAD7:%.*]] = load <4 x i8>, ptr [[TMP22]], align 1
--; VF4IC4-NEXT:    [[TMP4:%.*]] = icmp ne <4 x i8> [[WIDE_LOAD]], [[WIDE_LOAD1]]
--; VF4IC4-NEXT:    [[TMP11:%.*]] = icmp ne <4 x i8> [[WIDE_LOAD4]], [[WIDE_LOAD5]]
--; VF4IC4-NEXT:    [[TMP12:%.*]] = icmp ne <4 x i8> [[WIDE_LOAD2]], [[WIDE_LOAD6]]
-+; VF4IC4-NEXT:    [[WIDE_LOAD7:%.*]] = load <4 x i8>, ptr [[TMP19]], align 1
- ; VF4IC4-NEXT:    [[TMP13:%.*]] = icmp ne <4 x i8> [[WIDE_LOAD3]], [[WIDE_LOAD7]]
--; VF4IC4-NEXT:    [[INDEX_NEXT]] = add nuw i64 [[INDEX]], 16
--; VF4IC4-NEXT:    [[TMP14:%.*]] = or <4 x i1> [[TMP4]], [[TMP11]]
--; VF4IC4-NEXT:    [[TMP15:%.*]] = or <4 x i1> [[TMP14]], [[TMP12]]
--; VF4IC4-NEXT:    [[TMP16:%.*]] = or <4 x i1> [[TMP15]], [[TMP13]]
--; VF4IC4-NEXT:    [[TMP5:%.*]] = call i1 @llvm.vector.reduce.or.v4i1(<4 x i1> [[TMP16]])
-+; VF4IC4-NEXT:    [[INDEX_NEXT]] = add nuw i64 [[INDEX]], 4
-+; VF4IC4-NEXT:    [[TMP5:%.*]] = call i1 @llvm.vector.reduce.or.v4i1(<4 x i1> [[TMP13]])
- ; VF4IC4-NEXT:    [[TMP6:%.*]] = icmp eq i64 [[INDEX_NEXT]], 64
- ; VF4IC4-NEXT:    [[TMP7:%.*]] = or i1 [[TMP5]], [[TMP6]]
- ; VF4IC4-NEXT:    br i1 [[TMP7]], label [[MIDDLE_SPLIT:%.*]], label [[VECTOR_BODY]], !llvm.loop [[LOOP10:![0-9]+]]
-@@ -447,20 +330,7 @@
- ; VF4IC4:       middle.block:
- ; VF4IC4-NEXT:    br i1 true, label [[LOOP_END:%.*]], label [[SCALAR_PH]]
- ; VF4IC4:       vector.early.exit:
--; VF4IC4-NEXT:    [[TMP33:%.*]] = call i64 @llvm.experimental.cttz.elts.i64.v4i1(<4 x i1> [[TMP13]], i1 true)
--; VF4IC4-NEXT:    [[TMP34:%.*]] = add i64 12, [[TMP33]]
--; VF4IC4-NEXT:    [[TMP35:%.*]] = call i64 @llvm.experimental.cttz.elts.i64.v4i1(<4 x i1> [[TMP12]], i1 true)
--; VF4IC4-NEXT:    [[TMP24:%.*]] = add i64 8, [[TMP35]]
--; VF4IC4-NEXT:    [[TMP23:%.*]] = icmp ne i64 [[TMP35]], 4
--; VF4IC4-NEXT:    [[TMP25:%.*]] = select i1 [[TMP23]], i64 [[TMP24]], i64 [[TMP34]]
--; VF4IC4-NEXT:    [[TMP26:%.*]] = call i64 @llvm.experimental.cttz.elts.i64.v4i1(<4 x i1> [[TMP11]], i1 true)
--; VF4IC4-NEXT:    [[TMP28:%.*]] = add i64 4, [[TMP26]]
--; VF4IC4-NEXT:    [[TMP27:%.*]] = icmp ne i64 [[TMP26]], 4
--; VF4IC4-NEXT:    [[TMP29:%.*]] = select i1 [[TMP27]], i64 [[TMP28]], i64 [[TMP25]]
--; VF4IC4-NEXT:    [[TMP30:%.*]] = call i64 @llvm.experimental.cttz.elts.i64.v4i1(<4 x i1> [[TMP4]], i1 true)
--; VF4IC4-NEXT:    [[TMP32:%.*]] = add i64 0, [[TMP30]]
--; VF4IC4-NEXT:    [[TMP31:%.*]] = icmp ne i64 [[TMP30]], 4
--; VF4IC4-NEXT:    [[TMP8:%.*]] = select i1 [[TMP31]], i64 [[TMP32]], i64 [[TMP29]]
-+; VF4IC4-NEXT:    [[TMP8:%.*]] = call i64 @llvm.experimental.cttz.elts.i64.v4i1(<4 x i1> [[TMP13]], i1 true)
- ; VF4IC4-NEXT:    [[TMP9:%.*]] = add i64 [[INDEX]], [[TMP8]]
- ; VF4IC4-NEXT:    [[TMP10:%.*]] = add i64 3, [[TMP9]]
- ; VF4IC4-NEXT:    br label [[LOOP_EARLY_EXIT:%.*]]
-@@ -531,31 +401,13 @@
- ; VF4IC4-NEXT:    [[OFFSET_IDX:%.*]] = add i64 3, [[INDEX]]
- ; VF4IC4-NEXT:    [[TMP0:%.*]] = getelementptr inbounds i8, ptr [[P1]], i64 [[OFFSET_IDX]]
- ; VF4IC4-NEXT:    [[TMP1:%.*]] = getelementptr inbounds i8, ptr [[TMP0]], i32 0
--; VF4IC4-NEXT:    [[TMP2:%.*]] = getelementptr inbounds i8, ptr [[TMP0]], i32 4
--; VF4IC4-NEXT:    [[TMP3:%.*]] = getelementptr inbounds i8, ptr [[TMP0]], i32 8
--; VF4IC4-NEXT:    [[TMP17:%.*]] = getelementptr inbounds i8, ptr [[TMP0]], i32 12
--; VF4IC4-NEXT:    [[WIDE_LOAD:%.*]] = load <4 x i8>, ptr [[TMP1]], align 1
--; VF4IC4-NEXT:    [[WIDE_LOAD4:%.*]] = load <4 x i8>, ptr [[TMP2]], align 1
--; VF4IC4-NEXT:    [[WIDE_LOAD2:%.*]] = load <4 x i8>, ptr [[TMP3]], align 1
--; VF4IC4-NEXT:    [[WIDE_LOAD3:%.*]] = load <4 x i8>, ptr [[TMP17]], align 1
-+; VF4IC4-NEXT:    [[WIDE_LOAD3:%.*]] = load <4 x i8>, ptr [[TMP1]], align 1
- ; VF4IC4-NEXT:    [[TMP18:%.*]] = getelementptr inbounds i8, ptr [[P2]], i64 [[OFFSET_IDX]]
- ; VF4IC4-NEXT:    [[TMP19:%.*]] = getelementptr inbounds i8, ptr [[TMP18]], i32 0
--; VF4IC4-NEXT:    [[TMP20:%.*]] = getelementptr inbounds i8, ptr [[TMP18]], i32 4
--; VF4IC4-NEXT:    [[TMP21:%.*]] = getelementptr inbounds i8, ptr [[TMP18]], i32 8
--; VF4IC4-NEXT:    [[TMP22:%.*]] = getelementptr inbounds i8, ptr [[TMP18]], i32 12
--; VF4IC4-NEXT:    [[WIDE_LOAD1:%.*]] = load <4 x i8>, ptr [[TMP19]], align 1
--; VF4IC4-NEXT:    [[WIDE_LOAD5:%.*]] = load <4 x i8>, ptr [[TMP20]], align 1
--; VF4IC4-NEXT:    [[WIDE_LOAD6:%.*]] = load <4 x i8>, ptr [[TMP21]], align 1
--; VF4IC4-NEXT:    [[WIDE_LOAD7:%.*]] = load <4 x i8>, ptr [[TMP22]], align 1
--; VF4IC4-NEXT:    [[TMP4:%.*]] = icmp ne <4 x i8> [[WIDE_LOAD]], [[WIDE_LOAD1]]
--; VF4IC4-NEXT:    [[TMP11:%.*]] = icmp ne <4 x i8> [[WIDE_LOAD4]], [[WIDE_LOAD5]]
--; VF4IC4-NEXT:    [[TMP12:%.*]] = icmp ne <4 x i8> [[WIDE_LOAD2]], [[WIDE_LOAD6]]
-+; VF4IC4-NEXT:    [[WIDE_LOAD7:%.*]] = load <4 x i8>, ptr [[TMP19]], align 1
- ; VF4IC4-NEXT:    [[TMP13:%.*]] = icmp ne <4 x i8> [[WIDE_LOAD3]], [[WIDE_LOAD7]]
--; VF4IC4-NEXT:    [[INDEX_NEXT]] = add nuw i64 [[INDEX]], 16
--; VF4IC4-NEXT:    [[TMP14:%.*]] = or <4 x i1> [[TMP4]], [[TMP11]]
--; VF4IC4-NEXT:    [[TMP15:%.*]] = or <4 x i1> [[TMP14]], [[TMP12]]
--; VF4IC4-NEXT:    [[TMP16:%.*]] = or <4 x i1> [[TMP15]], [[TMP13]]
--; VF4IC4-NEXT:    [[TMP5:%.*]] = call i1 @llvm.vector.reduce.or.v4i1(<4 x i1> [[TMP16]])
-+; VF4IC4-NEXT:    [[INDEX_NEXT]] = add nuw i64 [[INDEX]], 4
-+; VF4IC4-NEXT:    [[TMP5:%.*]] = call i1 @llvm.vector.reduce.or.v4i1(<4 x i1> [[TMP13]])
- ; VF4IC4-NEXT:    [[TMP6:%.*]] = icmp eq i64 [[INDEX_NEXT]], 64
- ; VF4IC4-NEXT:    [[TMP7:%.*]] = or i1 [[TMP5]], [[TMP6]]
- ; VF4IC4-NEXT:    br i1 [[TMP7]], label [[MIDDLE_SPLIT:%.*]], label [[VECTOR_BODY]], !llvm.loop [[LOOP12:![0-9]+]]
-@@ -564,20 +416,7 @@
- ; VF4IC4:       middle.block:
- ; VF4IC4-NEXT:    br i1 true, label [[LOOP_END:%.*]], label [[SCALAR_PH]]
- ; VF4IC4:       vector.early.exit:
--; VF4IC4-NEXT:    [[TMP33:%.*]] = call i64 @llvm.experimental.cttz.elts.i64.v4i1(<4 x i1> [[TMP13]], i1 true)
--; VF4IC4-NEXT:    [[TMP34:%.*]] = add i64 12, [[TMP33]]
--; VF4IC4-NEXT:    [[TMP35:%.*]] = call i64 @llvm.experimental.cttz.elts.i64.v4i1(<4 x i1> [[TMP12]], i1 true)
--; VF4IC4-NEXT:    [[TMP24:%.*]] = add i64 8, [[TMP35]]
--; VF4IC4-NEXT:    [[TMP23:%.*]] = icmp ne i64 [[TMP35]], 4
--; VF4IC4-NEXT:    [[TMP25:%.*]] = select i1 [[TMP23]], i64 [[TMP24]], i64 [[TMP34]]
--; VF4IC4-NEXT:    [[TMP26:%.*]] = call i64 @llvm.experimental.cttz.elts.i64.v4i1(<4 x i1> [[TMP11]], i1 true)
--; VF4IC4-NEXT:    [[TMP28:%.*]] = add i64 4, [[TMP26]]
--; VF4IC4-NEXT:    [[TMP27:%.*]] = icmp ne i64 [[TMP26]], 4
--; VF4IC4-NEXT:    [[TMP29:%.*]] = select i1 [[TMP27]], i64 [[TMP28]], i64 [[TMP25]]
--; VF4IC4-NEXT:    [[TMP30:%.*]] = call i64 @llvm.experimental.cttz.elts.i64.v4i1(<4 x i1> [[TMP4]], i1 true)
--; VF4IC4-NEXT:    [[TMP32:%.*]] = add i64 0, [[TMP30]]
--; VF4IC4-NEXT:    [[TMP31:%.*]] = icmp ne i64 [[TMP30]], 4
--; VF4IC4-NEXT:    [[TMP8:%.*]] = select i1 [[TMP31]], i64 [[TMP32]], i64 [[TMP29]]
-+; VF4IC4-NEXT:    [[TMP8:%.*]] = call i64 @llvm.experimental.cttz.elts.i64.v4i1(<4 x i1> [[TMP13]], i1 true)
- ; VF4IC4-NEXT:    [[TMP9:%.*]] = add i64 [[INDEX]], [[TMP8]]
- ; VF4IC4-NEXT:    [[TMP10:%.*]] = add i64 3, [[TMP9]]
- ; VF4IC4-NEXT:    br label [[LOOP_EARLY_EXIT:%.*]]
-@@ -648,48 +487,18 @@
- ; VF4IC4-NEXT:    [[OFFSET_IDX:%.*]] = sub i64 1023, [[INDEX]]
- ; VF4IC4-NEXT:    [[TMP0:%.*]] = getelementptr inbounds i8, ptr [[P1]], i64 [[OFFSET_IDX]]
- ; VF4IC4-NEXT:    [[TMP1:%.*]] = getelementptr inbounds i8, ptr [[TMP0]], i32 0
--; VF4IC4-NEXT:    [[TMP2:%.*]] = getelementptr inbounds i8, ptr [[TMP1]], i32 -3
--; VF4IC4-NEXT:    [[TMP18:%.*]] = getelementptr inbounds i8, ptr [[TMP0]], i32 -4
--; VF4IC4-NEXT:    [[TMP13:%.*]] = getelementptr inbounds i8, ptr [[TMP18]], i32 -3
--; VF4IC4-NEXT:    [[TMP14:%.*]] = getelementptr inbounds i8, ptr [[TMP0]], i32 -8
--; VF4IC4-NEXT:    [[TMP15:%.*]] = getelementptr inbounds i8, ptr [[TMP14]], i32 -3
--; VF4IC4-NEXT:    [[TMP16:%.*]] = getelementptr inbounds i8, ptr [[TMP0]], i32 -12
--; VF4IC4-NEXT:    [[TMP17:%.*]] = getelementptr inbounds i8, ptr [[TMP16]], i32 -3
--; VF4IC4-NEXT:    [[WIDE_LOAD1:%.*]] = load <4 x i8>, ptr [[TMP2]], align 1
--; VF4IC4-NEXT:    [[REVERSE2:%.*]] = shufflevector <4 x i8> [[WIDE_LOAD1]], <4 x i8> poison, <4 x i32> <i32 3, i32 2, i32 1, i32 0>
--; VF4IC4-NEXT:    [[WIDE_LOAD9:%.*]] = load <4 x i8>, ptr [[TMP13]], align 1
--; VF4IC4-NEXT:    [[REVERSE10:%.*]] = shufflevector <4 x i8> [[WIDE_LOAD9]], <4 x i8> poison, <4 x i32> <i32 3, i32 2, i32 1, i32 0>
--; VF4IC4-NEXT:    [[WIDE_LOAD11:%.*]] = load <4 x i8>, ptr [[TMP15]], align 1
--; VF4IC4-NEXT:    [[REVERSE12:%.*]] = shufflevector <4 x i8> [[WIDE_LOAD11]], <4 x i8> poison, <4 x i32> <i32 3, i32 2, i32 1, i32 0>
-+; VF4IC4-NEXT:    [[TMP17:%.*]] = getelementptr inbounds i8, ptr [[TMP1]], i32 -3
- ; VF4IC4-NEXT:    [[WIDE_LOAD13:%.*]] = load <4 x i8>, ptr [[TMP17]], align 1
- ; VF4IC4-NEXT:    [[REVERSE14:%.*]] = shufflevector <4 x i8> [[WIDE_LOAD13]], <4 x i8> poison, <4 x i32> <i32 3, i32 2, i32 1, i32 0>
- ; VF4IC4-NEXT:    [[TMP25:%.*]] = getelementptr inbounds i8, ptr [[P2]], i64 [[OFFSET_IDX]]
- ; VF4IC4-NEXT:    [[TMP26:%.*]] = getelementptr inbounds i8, ptr [[TMP25]], i32 0
--; VF4IC4-NEXT:    [[TMP27:%.*]] = getelementptr inbounds i8, ptr [[TMP26]], i32 -3
--; VF4IC4-NEXT:    [[TMP28:%.*]] = getelementptr inbounds i8, ptr [[TMP25]], i32 -4
--; VF4IC4-NEXT:    [[TMP29:%.*]] = getelementptr inbounds i8, ptr [[TMP28]], i32 -3
--; VF4IC4-NEXT:    [[TMP30:%.*]] = getelementptr inbounds i8, ptr [[TMP25]], i32 -8
--; VF4IC4-NEXT:    [[TMP44:%.*]] = getelementptr inbounds i8, ptr [[TMP30]], i32 -3
--; VF4IC4-NEXT:    [[TMP45:%.*]] = getelementptr inbounds i8, ptr [[TMP25]], i32 -12
--; VF4IC4-NEXT:    [[TMP46:%.*]] = getelementptr inbounds i8, ptr [[TMP45]], i32 -3
--; VF4IC4-NEXT:    [[WIDE_LOAD7:%.*]] = load <4 x i8>, ptr [[TMP27]], align 1
--; VF4IC4-NEXT:    [[REVERSE8:%.*]] = shufflevector <4 x i8> [[WIDE_LOAD7]], <4 x i8> poison, <4 x i32> <i32 3, i32 2, i32 1, i32 0>
--; VF4IC4-NEXT:    [[WIDE_LOAD10:%.*]] = load <4 x i8>, ptr [[TMP29]], align 1
--; VF4IC4-NEXT:    [[REVERSE11:%.*]] = shufflevector <4 x i8> [[WIDE_LOAD10]], <4 x i8> poison, <4 x i32> <i32 3, i32 2, i32 1, i32 0>
--; VF4IC4-NEXT:    [[WIDE_LOAD12:%.*]] = load <4 x i8>, ptr [[TMP44]], align 1
--; VF4IC4-NEXT:    [[REVERSE13:%.*]] = shufflevector <4 x i8> [[WIDE_LOAD12]], <4 x i8> poison, <4 x i32> <i32 3, i32 2, i32 1, i32 0>
-+; VF4IC4-NEXT:    [[TMP46:%.*]] = getelementptr inbounds i8, ptr [[TMP26]], i32 -3
- ; VF4IC4-NEXT:    [[WIDE_LOAD14:%.*]] = load <4 x i8>, ptr [[TMP46]], align 1
- ; VF4IC4-NEXT:    [[REVERSE15:%.*]] = shufflevector <4 x i8> [[WIDE_LOAD14]], <4 x i8> poison, <4 x i32> <i32 3, i32 2, i32 1, i32 0>
--; VF4IC4-NEXT:    [[TMP6:%.*]] = icmp ne <4 x i8> [[REVERSE2]], [[REVERSE8]]
--; VF4IC4-NEXT:    [[TMP19:%.*]] = icmp ne <4 x i8> [[REVERSE10]], [[REVERSE11]]
--; VF4IC4-NEXT:    [[TMP20:%.*]] = icmp ne <4 x i8> [[REVERSE12]], [[REVERSE13]]
- ; VF4IC4-NEXT:    [[TMP21:%.*]] = icmp ne <4 x i8> [[REVERSE14]], [[REVERSE15]]
--; VF4IC4-NEXT:    [[INDEX_NEXT]] = add nuw i64 [[INDEX]], 16
--; VF4IC4-NEXT:    [[TMP22:%.*]] = or <4 x i1> [[TMP6]], [[TMP19]]
--; VF4IC4-NEXT:    [[TMP23:%.*]] = or <4 x i1> [[TMP22]], [[TMP20]]
--; VF4IC4-NEXT:    [[TMP24:%.*]] = or <4 x i1> [[TMP23]], [[TMP21]]
--; VF4IC4-NEXT:    [[TMP7:%.*]] = call i1 @llvm.vector.reduce.or.v4i1(<4 x i1> [[TMP24]])
--; VF4IC4-NEXT:    [[TMP8:%.*]] = icmp eq i64 [[INDEX_NEXT]], 1008
-+; VF4IC4-NEXT:    [[INDEX_NEXT]] = add nuw i64 [[INDEX]], 4
-+; VF4IC4-NEXT:    [[TMP7:%.*]] = call i1 @llvm.vector.reduce.or.v4i1(<4 x i1> [[TMP21]])
-+; VF4IC4-NEXT:    [[TMP8:%.*]] = icmp eq i64 [[INDEX_NEXT]], 1020
- ; VF4IC4-NEXT:    [[TMP9:%.*]] = or i1 [[TMP7]], [[TMP8]]
- ; VF4IC4-NEXT:    br i1 [[TMP9]], label [[MIDDLE_SPLIT:%.*]], label [[VECTOR_BODY]], !llvm.loop [[LOOP14:![0-9]+]]
- ; VF4IC4:       middle.split:
-@@ -697,25 +506,12 @@
- ; VF4IC4:       middle.block:
- ; VF4IC4-NEXT:    br i1 false, label [[LOOP_END:%.*]], label [[SCALAR_PH]]
- ; VF4IC4:       vector.early.exit:
--; VF4IC4-NEXT:    [[TMP41:%.*]] = call i64 @llvm.experimental.cttz.elts.i64.v4i1(<4 x i1> [[TMP21]], i1 true)
--; VF4IC4-NEXT:    [[TMP42:%.*]] = add i64 12, [[TMP41]]
--; VF4IC4-NEXT:    [[TMP43:%.*]] = call i64 @llvm.experimental.cttz.elts.i64.v4i1(<4 x i1> [[TMP20]], i1 true)
--; VF4IC4-NEXT:    [[TMP32:%.*]] = add i64 8, [[TMP43]]
--; VF4IC4-NEXT:    [[TMP31:%.*]] = icmp ne i64 [[TMP43]], 4
--; VF4IC4-NEXT:    [[TMP33:%.*]] = select i1 [[TMP31]], i64 [[TMP32]], i64 [[TMP42]]
--; VF4IC4-NEXT:    [[TMP34:%.*]] = call i64 @llvm.experimental.cttz.elts.i64.v4i1(<4 x i1> [[TMP19]], i1 true)
--; VF4IC4-NEXT:    [[TMP36:%.*]] = add i64 4, [[TMP34]]
--; VF4IC4-NEXT:    [[TMP35:%.*]] = icmp ne i64 [[TMP34]], 4
--; VF4IC4-NEXT:    [[TMP37:%.*]] = select i1 [[TMP35]], i64 [[TMP36]], i64 [[TMP33]]
--; VF4IC4-NEXT:    [[TMP38:%.*]] = call i64 @llvm.experimental.cttz.elts.i64.v4i1(<4 x i1> [[TMP6]], i1 true)
--; VF4IC4-NEXT:    [[TMP40:%.*]] = add i64 0, [[TMP38]]
--; VF4IC4-NEXT:    [[TMP39:%.*]] = icmp ne i64 [[TMP38]], 4
--; VF4IC4-NEXT:    [[TMP10:%.*]] = select i1 [[TMP39]], i64 [[TMP40]], i64 [[TMP37]]
-+; VF4IC4-NEXT:    [[TMP10:%.*]] = call i64 @llvm.experimental.cttz.elts.i64.v4i1(<4 x i1> [[TMP21]], i1 true)
- ; VF4IC4-NEXT:    [[TMP11:%.*]] = add i64 [[INDEX]], [[TMP10]]
- ; VF4IC4-NEXT:    [[TMP12:%.*]] = sub i64 1023, [[TMP11]]
- ; VF4IC4-NEXT:    br label [[LOOP_END]]
- ; VF4IC4:       scalar.ph:
--; VF4IC4-NEXT:    [[BC_RESUME_VAL:%.*]] = phi i64 [ 15, [[MIDDLE_BLOCK]] ], [ 1023, [[ENTRY:%.*]] ]
-+; VF4IC4-NEXT:    [[BC_RESUME_VAL:%.*]] = phi i64 [ 3, [[MIDDLE_BLOCK]] ], [ 1023, [[ENTRY:%.*]] ]
- ; VF4IC4-NEXT:    br label [[LOOP:%.*]]
- ; VF4IC4:       loop:
- ; VF4IC4-NEXT:    [[IV:%.*]] = phi i64 [ [[IV_NEXT:%.*]], [[LOOP_INC:%.*]] ], [ [[BC_RESUME_VAL]], [[SCALAR_PH]] ]
-@@ -774,31 +570,13 @@
- ; VF4IC4-NEXT:    [[INDEX:%.*]] = phi i64 [ 0, [[VECTOR_PH]] ], [ [[INDEX_NEXT:%.*]], [[VECTOR_BODY]] ]
- ; VF4IC4-NEXT:    [[TMP0:%.*]] = getelementptr inbounds i8, ptr [[P1]], i64 [[INDEX]]
- ; VF4IC4-NEXT:    [[TMP1:%.*]] = getelementptr inbounds i8, ptr [[TMP0]], i32 0
--; VF4IC4-NEXT:    [[TMP10:%.*]] = getelementptr inbounds i8, ptr [[TMP0]], i32 4
--; VF4IC4-NEXT:    [[TMP3:%.*]] = getelementptr inbounds i8, ptr [[TMP0]], i32 8
--; VF4IC4-NEXT:    [[TMP17:%.*]] = getelementptr inbounds i8, ptr [[TMP0]], i32 12
--; VF4IC4-NEXT:    [[WIDE_LOAD:%.*]] = load <4 x i8>, ptr [[TMP1]], align 1
--; VF4IC4-NEXT:    [[WIDE_LOAD1:%.*]] = load <4 x i8>, ptr [[TMP10]], align 1
--; VF4IC4-NEXT:    [[WIDE_LOAD2:%.*]] = load <4 x i8>, ptr [[TMP3]], align 1
--; VF4IC4-NEXT:    [[WIDE_LOAD3:%.*]] = load <4 x i8>, ptr [[TMP17]], align 1
-+; VF4IC4-NEXT:    [[WIDE_LOAD3:%.*]] = load <4 x i8>, ptr [[TMP1]], align 1
- ; VF4IC4-NEXT:    [[TMP18:%.*]] = getelementptr inbounds i8, ptr [[P2]], i64 [[INDEX]]
- ; VF4IC4-NEXT:    [[TMP19:%.*]] = getelementptr inbounds i8, ptr [[TMP18]], i32 0
--; VF4IC4-NEXT:    [[TMP29:%.*]] = getelementptr inbounds i8, ptr [[TMP18]], i32 4
--; VF4IC4-NEXT:    [[TMP8:%.*]] = getelementptr inbounds i8, ptr [[TMP18]], i32 8
--; VF4IC4-NEXT:    [[TMP9:%.*]] = getelementptr inbounds i8, ptr [[TMP18]], i32 12
--; VF4IC4-NEXT:    [[WIDE_LOAD4:%.*]] = load <4 x i8>, ptr [[TMP19]], align 1
--; VF4IC4-NEXT:    [[WIDE_LOAD5:%.*]] = load <4 x i8>, ptr [[TMP29]], align 1
--; VF4IC4-NEXT:    [[WIDE_LOAD6:%.*]] = load <4 x i8>, ptr [[TMP8]], align 1
--; VF4IC4-NEXT:    [[WIDE_LOAD7:%.*]] = load <4 x i8>, ptr [[TMP9]], align 1
--; VF4IC4-NEXT:    [[TMP4:%.*]] = icmp ne <4 x i8> [[WIDE_LOAD]], [[WIDE_LOAD4]]
--; VF4IC4-NEXT:    [[TMP11:%.*]] = icmp ne <4 x i8> [[WIDE_LOAD1]], [[WIDE_LOAD5]]
--; VF4IC4-NEXT:    [[TMP12:%.*]] = icmp ne <4 x i8> [[WIDE_LOAD2]], [[WIDE_LOAD6]]
-+; VF4IC4-NEXT:    [[WIDE_LOAD7:%.*]] = load <4 x i8>, ptr [[TMP19]], align 1
- ; VF4IC4-NEXT:    [[TMP13:%.*]] = icmp ne <4 x i8> [[WIDE_LOAD3]], [[WIDE_LOAD7]]
--; VF4IC4-NEXT:    [[INDEX_NEXT]] = add nuw i64 [[INDEX]], 16
--; VF4IC4-NEXT:    [[TMP14:%.*]] = or <4 x i1> [[TMP4]], [[TMP11]]
--; VF4IC4-NEXT:    [[TMP15:%.*]] = or <4 x i1> [[TMP14]], [[TMP12]]
--; VF4IC4-NEXT:    [[TMP16:%.*]] = or <4 x i1> [[TMP15]], [[TMP13]]
--; VF4IC4-NEXT:    [[TMP5:%.*]] = call i1 @llvm.vector.reduce.or.v4i1(<4 x i1> [[TMP16]])
-+; VF4IC4-NEXT:    [[INDEX_NEXT]] = add nuw i64 [[INDEX]], 4
-+; VF4IC4-NEXT:    [[TMP5:%.*]] = call i1 @llvm.vector.reduce.or.v4i1(<4 x i1> [[TMP13]])
- ; VF4IC4-NEXT:    [[TMP6:%.*]] = icmp eq i64 [[INDEX_NEXT]], 1024
- ; VF4IC4-NEXT:    [[TMP7:%.*]] = or i1 [[TMP5]], [[TMP6]]
- ; VF4IC4-NEXT:    br i1 [[TMP7]], label [[MIDDLE_SPLIT:%.*]], label [[VECTOR_BODY]], !llvm.loop [[LOOP16:![0-9]+]]
-@@ -808,20 +586,7 @@
- ; VF4IC4-NEXT:    br i1 true, label [[LOOP_END:%.*]], label [[SCALAR_PH]]
- ; VF4IC4:       vector.early.exit:
- ; VF4IC4-NEXT:    [[FIRST_ACTIVE_LANE1:%.*]] = call i64 @llvm.experimental.cttz.elts.i64.v4i1(<4 x i1> [[TMP13]], i1 true)
--; VF4IC4-NEXT:    [[TMP20:%.*]] = add i64 12, [[FIRST_ACTIVE_LANE1]]
--; VF4IC4-NEXT:    [[FIRST_ACTIVE_LANE8:%.*]] = call i64 @llvm.experimental.cttz.elts.i64.v4i1(<4 x i1> [[TMP12]], i1 true)
--; VF4IC4-NEXT:    [[TMP22:%.*]] = add i64 8, [[FIRST_ACTIVE_LANE8]]
--; VF4IC4-NEXT:    [[TMP21:%.*]] = icmp ne i64 [[FIRST_ACTIVE_LANE8]], 4
--; VF4IC4-NEXT:    [[TMP23:%.*]] = select i1 [[TMP21]], i64 [[TMP22]], i64 [[TMP20]]
--; VF4IC4-NEXT:    [[FIRST_ACTIVE_LANE9:%.*]] = call i64 @llvm.experimental.cttz.elts.i64.v4i1(<4 x i1> [[TMP11]], i1 true)
--; VF4IC4-NEXT:    [[TMP25:%.*]] = add i64 4, [[FIRST_ACTIVE_LANE9]]
--; VF4IC4-NEXT:    [[TMP24:%.*]] = icmp ne i64 [[FIRST_ACTIVE_LANE9]], 4
--; VF4IC4-NEXT:    [[TMP26:%.*]] = select i1 [[TMP24]], i64 [[TMP25]], i64 [[TMP23]]
--; VF4IC4-NEXT:    [[FIRST_ACTIVE_LANE10:%.*]] = call i64 @llvm.experimental.cttz.elts.i64.v4i1(<4 x i1> [[TMP4]], i1 true)
--; VF4IC4-NEXT:    [[TMP28:%.*]] = add i64 0, [[FIRST_ACTIVE_LANE10]]
--; VF4IC4-NEXT:    [[TMP27:%.*]] = icmp ne i64 [[FIRST_ACTIVE_LANE10]], 4
--; VF4IC4-NEXT:    [[FIRST_ACTIVE_LANE:%.*]] = select i1 [[TMP27]], i64 [[TMP28]], i64 [[TMP26]]
--; VF4IC4-NEXT:    [[EARLY_EXIT_VALUE:%.*]] = extractelement <4 x i8> [[WIDE_LOAD]], i64 [[FIRST_ACTIVE_LANE]]
-+; VF4IC4-NEXT:    [[EARLY_EXIT_VALUE:%.*]] = extractelement <4 x i8> [[WIDE_LOAD3]], i64 [[FIRST_ACTIVE_LANE1]]
- ; VF4IC4-NEXT:    br label [[LOOP_END]]
- ; VF4IC4:       scalar.ph:
- ; VF4IC4-NEXT:    [[BC_RESUME_VAL:%.*]] = phi i64 [ 1024, [[MIDDLE_BLOCK]] ], [ 0, [[ENTRY:%.*]] ]
-@@ -884,48 +649,18 @@
- ; VF4IC4-NEXT:    [[OFFSET_IDX:%.*]] = sub i64 1023, [[INDEX]]
- ; VF4IC4-NEXT:    [[TMP0:%.*]] = getelementptr inbounds i8, ptr [[P1]], i64 [[OFFSET_IDX]]
- ; VF4IC4-NEXT:    [[TMP1:%.*]] = getelementptr inbounds i8, ptr [[TMP0]], i32 0
--; VF4IC4-NEXT:    [[TMP2:%.*]] = getelementptr inbounds i8, ptr [[TMP1]], i32 -3
--; VF4IC4-NEXT:    [[TMP10:%.*]] = getelementptr inbounds i8, ptr [[TMP0]], i32 -4
--; VF4IC4-NEXT:    [[TMP11:%.*]] = getelementptr inbounds i8, ptr [[TMP10]], i32 -3
--; VF4IC4-NEXT:    [[TMP18:%.*]] = getelementptr inbounds i8, ptr [[TMP0]], i32 -8
--; VF4IC4-NEXT:    [[TMP37:%.*]] = getelementptr inbounds i8, ptr [[TMP18]], i32 -3
--; VF4IC4-NEXT:    [[TMP7:%.*]] = getelementptr inbounds i8, ptr [[TMP0]], i32 -12
--; VF4IC4-NEXT:    [[TMP8:%.*]] = getelementptr inbounds i8, ptr [[TMP7]], i32 -3
--; VF4IC4-NEXT:    [[WIDE_LOAD:%.*]] = load <4 x i8>, ptr [[TMP2]], align 1
--; VF4IC4-NEXT:    [[REVERSE:%.*]] = shufflevector <4 x i8> [[WIDE_LOAD]], <4 x i8> poison, <4 x i32> <i32 3, i32 2, i32 1, i32 0>
--; VF4IC4-NEXT:    [[WIDE_LOAD1:%.*]] = load <4 x i8>, ptr [[TMP11]], align 1
--; VF4IC4-NEXT:    [[REVERSE2:%.*]] = shufflevector <4 x i8> [[WIDE_LOAD1]], <4 x i8> poison, <4 x i32> <i32 3, i32 2, i32 1, i32 0>
--; VF4IC4-NEXT:    [[WIDE_LOAD3:%.*]] = load <4 x i8>, ptr [[TMP37]], align 1
--; VF4IC4-NEXT:    [[REVERSE4:%.*]] = shufflevector <4 x i8> [[WIDE_LOAD3]], <4 x i8> poison, <4 x i32> <i32 3, i32 2, i32 1, i32 0>
-+; VF4IC4-NEXT:    [[TMP8:%.*]] = getelementptr inbounds i8, ptr [[TMP1]], i32 -3
- ; VF4IC4-NEXT:    [[WIDE_LOAD5:%.*]] = load <4 x i8>, ptr [[TMP8]], align 1
- ; VF4IC4-NEXT:    [[REVERSE6:%.*]] = shufflevector <4 x i8> [[WIDE_LOAD5]], <4 x i8> poison, <4 x i32> <i32 3, i32 2, i32 1, i32 0>
- ; VF4IC4-NEXT:    [[TMP9:%.*]] = getelementptr inbounds i8, ptr [[P2]], i64 [[OFFSET_IDX]]
- ; VF4IC4-NEXT:    [[TMP38:%.*]] = getelementptr inbounds i8, ptr [[TMP9]], i32 0
--; VF4IC4-NEXT:    [[TMP39:%.*]] = getelementptr inbounds i8, ptr [[TMP38]], i32 -3
--; VF4IC4-NEXT:    [[TMP12:%.*]] = getelementptr inbounds i8, ptr [[TMP9]], i32 -4
--; VF4IC4-NEXT:    [[TMP13:%.*]] = getelementptr inbounds i8, ptr [[TMP12]], i32 -3
--; VF4IC4-NEXT:    [[TMP14:%.*]] = getelementptr inbounds i8, ptr [[TMP9]], i32 -8
--; VF4IC4-NEXT:    [[TMP15:%.*]] = getelementptr inbounds i8, ptr [[TMP14]], i32 -3
--; VF4IC4-NEXT:    [[TMP16:%.*]] = getelementptr inbounds i8, ptr [[TMP9]], i32 -12
--; VF4IC4-NEXT:    [[TMP17:%.*]] = getelementptr inbounds i8, ptr [[TMP16]], i32 -3
--; VF4IC4-NEXT:    [[WIDE_LOAD7:%.*]] = load <4 x i8>, ptr [[TMP39]], align 1
--; VF4IC4-NEXT:    [[REVERSE8:%.*]] = shufflevector <4 x i8> [[WIDE_LOAD7]], <4 x i8> poison, <4 x i32> <i32 3, i32 2, i32 1, i32 0>
--; VF4IC4-NEXT:    [[WIDE_LOAD9:%.*]] = load <4 x i8>, ptr [[TMP13]], align 1
--; VF4IC4-NEXT:    [[REVERSE10:%.*]] = shufflevector <4 x i8> [[WIDE_LOAD9]], <4 x i8> poison, <4 x i32> <i32 3, i32 2, i32 1, i32 0>
--; VF4IC4-NEXT:    [[WIDE_LOAD11:%.*]] = load <4 x i8>, ptr [[TMP15]], align 1
--; VF4IC4-NEXT:    [[REVERSE12:%.*]] = shufflevector <4 x i8> [[WIDE_LOAD11]], <4 x i8> poison, <4 x i32> <i32 3, i32 2, i32 1, i32 0>
-+; VF4IC4-NEXT:    [[TMP17:%.*]] = getelementptr inbounds i8, ptr [[TMP38]], i32 -3
- ; VF4IC4-NEXT:    [[WIDE_LOAD13:%.*]] = load <4 x i8>, ptr [[TMP17]], align 1
- ; VF4IC4-NEXT:    [[REVERSE14:%.*]] = shufflevector <4 x i8> [[WIDE_LOAD13]], <4 x i8> poison, <4 x i32> <i32 3, i32 2, i32 1, i32 0>
--; VF4IC4-NEXT:    [[TMP6:%.*]] = icmp ne <4 x i8> [[REVERSE]], [[REVERSE8]]
--; VF4IC4-NEXT:    [[TMP19:%.*]] = icmp ne <4 x i8> [[REVERSE2]], [[REVERSE10]]
--; VF4IC4-NEXT:    [[TMP20:%.*]] = icmp ne <4 x i8> [[REVERSE4]], [[REVERSE12]]
- ; VF4IC4-NEXT:    [[TMP21:%.*]] = icmp ne <4 x i8> [[REVERSE6]], [[REVERSE14]]
--; VF4IC4-NEXT:    [[INDEX_NEXT]] = add nuw i64 [[INDEX]], 16
--; VF4IC4-NEXT:    [[TMP22:%.*]] = or <4 x i1> [[TMP6]], [[TMP19]]
--; VF4IC4-NEXT:    [[TMP23:%.*]] = or <4 x i1> [[TMP22]], [[TMP20]]
--; VF4IC4-NEXT:    [[TMP24:%.*]] = or <4 x i1> [[TMP23]], [[TMP21]]
--; VF4IC4-NEXT:    [[TMP25:%.*]] = call i1 @llvm.vector.reduce.or.v4i1(<4 x i1> [[TMP24]])
--; VF4IC4-NEXT:    [[TMP26:%.*]] = icmp eq i64 [[INDEX_NEXT]], 1008
-+; VF4IC4-NEXT:    [[INDEX_NEXT]] = add nuw i64 [[INDEX]], 4
-+; VF4IC4-NEXT:    [[TMP25:%.*]] = call i1 @llvm.vector.reduce.or.v4i1(<4 x i1> [[TMP21]])
-+; VF4IC4-NEXT:    [[TMP26:%.*]] = icmp eq i64 [[INDEX_NEXT]], 1020
- ; VF4IC4-NEXT:    [[TMP27:%.*]] = or i1 [[TMP25]], [[TMP26]]
- ; VF4IC4-NEXT:    br i1 [[TMP27]], label [[MIDDLE_SPLIT:%.*]], label [[VECTOR_BODY]], !llvm.loop [[LOOP18:![0-9]+]]
- ; VF4IC4:       middle.split:
-@@ -934,23 +669,10 @@
- ; VF4IC4-NEXT:    br i1 false, label [[LOOP_END:%.*]], label [[SCALAR_PH]]
- ; VF4IC4:       vector.early.exit:
- ; VF4IC4-NEXT:    [[FIRST_ACTIVE_LANE1:%.*]] = call i64 @llvm.experimental.cttz.elts.i64.v4i1(<4 x i1> [[TMP21]], i1 true)
--; VF4IC4-NEXT:    [[TMP28:%.*]] = add i64 12, [[FIRST_ACTIVE_LANE1]]
--; VF4IC4-NEXT:    [[FIRST_ACTIVE_LANE15:%.*]] = call i64 @llvm.experimental.cttz.elts.i64.v4i1(<4 x i1> [[TMP20]], i1 true)
--; VF4IC4-NEXT:    [[TMP30:%.*]] = add i64 8, [[FIRST_ACTIVE_LANE15]]
--; VF4IC4-NEXT:    [[TMP29:%.*]] = icmp ne i64 [[FIRST_ACTIVE_LANE15]], 4
--; VF4IC4-NEXT:    [[TMP31:%.*]] = select i1 [[TMP29]], i64 [[TMP30]], i64 [[TMP28]]
--; VF4IC4-NEXT:    [[FIRST_ACTIVE_LANE16:%.*]] = call i64 @llvm.experimental.cttz.elts.i64.v4i1(<4 x i1> [[TMP19]], i1 true)
--; VF4IC4-NEXT:    [[TMP33:%.*]] = add i64 4, [[FIRST_ACTIVE_LANE16]]
--; VF4IC4-NEXT:    [[TMP32:%.*]] = icmp ne i64 [[FIRST_ACTIVE_LANE16]], 4
--; VF4IC4-NEXT:    [[TMP34:%.*]] = select i1 [[TMP32]], i64 [[TMP33]], i64 [[TMP31]]
--; VF4IC4-NEXT:    [[FIRST_ACTIVE_LANE17:%.*]] = call i64 @llvm.experimental.cttz.elts.i64.v4i1(<4 x i1> [[TMP6]], i1 true)
--; VF4IC4-NEXT:    [[TMP36:%.*]] = add i64 0, [[FIRST_ACTIVE_LANE17]]
--; VF4IC4-NEXT:    [[TMP35:%.*]] = icmp ne i64 [[FIRST_ACTIVE_LANE17]], 4
--; VF4IC4-NEXT:    [[FIRST_ACTIVE_LANE:%.*]] = select i1 [[TMP35]], i64 [[TMP36]], i64 [[TMP34]]
--; VF4IC4-NEXT:    [[EARLY_EXIT_VALUE:%.*]] = extractelement <4 x i8> [[REVERSE]], i64 [[FIRST_ACTIVE_LANE]]
-+; VF4IC4-NEXT:    [[EARLY_EXIT_VALUE:%.*]] = extractelement <4 x i8> [[REVERSE6]], i64 [[FIRST_ACTIVE_LANE1]]
- ; VF4IC4-NEXT:    br label [[LOOP_END]]
- ; VF4IC4:       scalar.ph:
--; VF4IC4-NEXT:    [[BC_RESUME_VAL:%.*]] = phi i64 [ 15, [[MIDDLE_BLOCK]] ], [ 1023, [[ENTRY:%.*]] ]
-+; VF4IC4-NEXT:    [[BC_RESUME_VAL:%.*]] = phi i64 [ 3, [[MIDDLE_BLOCK]] ], [ 1023, [[ENTRY:%.*]] ]
- ; VF4IC4-NEXT:    br label [[LOOP:%.*]]
- ; VF4IC4:       loop:
- ; VF4IC4-NEXT:    [[IV:%.*]] = phi i64 [ [[IV_NEXT:%.*]], [[LOOP_INC:%.*]] ], [ [[BC_RESUME_VAL]], [[SCALAR_PH]] ]
-diff -ruN --strip-trailing-cr a/llvm/test/Transforms/LoopVectorize/vector-loop-backedge-elimination-early-exit.ll b/llvm/test/Transforms/LoopVectorize/vector-loop-backedge-elimination-early-exit.ll
---- a/llvm/test/Transforms/LoopVectorize/vector-loop-backedge-elimination-early-exit.ll
-+++ b/llvm/test/Transforms/LoopVectorize/vector-loop-backedge-elimination-early-exit.ll
-@@ -55,17 +55,18 @@
- ; VF8UF2:       [[VECTOR_PH]]:
- ; VF8UF2-NEXT:    br label %[[VECTOR_BODY:.*]]
- ; VF8UF2:       [[VECTOR_BODY]]:
--; VF8UF2-NEXT:    [[TMP2:%.*]] = getelementptr inbounds i8, ptr [[A]], i32 0
--; VF8UF2-NEXT:    [[TMP1:%.*]] = getelementptr inbounds i8, ptr [[A]], i32 8
--; VF8UF2-NEXT:    [[WIDE_LOAD:%.*]] = load <8 x i8>, ptr [[TMP2]], align 1
-+; VF8UF2-NEXT:    [[INDEX:%.*]] = phi i64 [ 0, %[[VECTOR_PH]] ], [ [[INDEX_NEXT:%.*]], %[[VECTOR_BODY]] ]
-+; VF8UF2-NEXT:    [[TMP0:%.*]] = getelementptr inbounds i8, ptr [[A]], i64 [[INDEX]]
-+; VF8UF2-NEXT:    [[TMP1:%.*]] = getelementptr inbounds i8, ptr [[TMP0]], i32 0
- ; VF8UF2-NEXT:    [[WIDE_LOAD1:%.*]] = load <8 x i8>, ptr [[TMP1]], align 1
--; VF8UF2-NEXT:    [[TMP3:%.*]] = icmp eq <8 x i8> [[WIDE_LOAD]], zeroinitializer
- ; VF8UF2-NEXT:    [[TMP6:%.*]] = icmp eq <8 x i8> [[WIDE_LOAD1]], zeroinitializer
--; VF8UF2-NEXT:    [[TMP4:%.*]] = or <8 x i1> [[TMP3]], [[TMP6]]
--; VF8UF2-NEXT:    [[TMP5:%.*]] = call i1 @llvm.vector.reduce.or.v8i1(<8 x i1> [[TMP4]])
--; VF8UF2-NEXT:    br label %[[MIDDLE_SPLIT:.*]]
-+; VF8UF2-NEXT:    [[INDEX_NEXT]] = add nuw i64 [[INDEX]], 8
-+; VF8UF2-NEXT:    [[TMP3:%.*]] = call i1 @llvm.vector.reduce.or.v8i1(<8 x i1> [[TMP6]])
-+; VF8UF2-NEXT:    [[TMP4:%.*]] = icmp eq i64 [[INDEX_NEXT]], 16
-+; VF8UF2-NEXT:    [[TMP5:%.*]] = or i1 [[TMP3]], [[TMP4]]
-+; VF8UF2-NEXT:    br i1 [[TMP5]], label %[[MIDDLE_SPLIT:.*]], label %[[VECTOR_BODY]], !llvm.loop [[LOOP0:![0-9]+]]
- ; VF8UF2:       [[MIDDLE_SPLIT]]:
--; VF8UF2-NEXT:    br i1 [[TMP5]], label %[[VECTOR_EARLY_EXIT:.*]], label %[[MIDDLE_BLOCK:.*]]
-+; VF8UF2-NEXT:    br i1 [[TMP3]], label %[[VECTOR_EARLY_EXIT:.*]], label %[[MIDDLE_BLOCK:.*]]
- ; VF8UF2:       [[MIDDLE_BLOCK]]:
- ; VF8UF2-NEXT:    br i1 true, label %[[EXIT:.*]], label %[[SCALAR_PH]]
- ; VF8UF2:       [[VECTOR_EARLY_EXIT]]:
-@@ -82,7 +83,7 @@
- ; VF8UF2:       [[LOOP_LATCH]]:
- ; VF8UF2-NEXT:    [[IV_NEXT]] = add nsw i64 [[IV1]], 1
- ; VF8UF2-NEXT:    [[CMP:%.*]] = icmp eq i64 [[IV_NEXT]], 16
--; VF8UF2-NEXT:    br i1 [[CMP]], label %[[EXIT]], label %[[LOOP_HEADER]], !llvm.loop [[LOOP0:![0-9]+]]
-+; VF8UF2-NEXT:    br i1 [[CMP]], label %[[EXIT]], label %[[LOOP_HEADER]], !llvm.loop [[LOOP3:![0-9]+]]
- ; VF8UF2:       [[EXIT]]:
- ; VF8UF2-NEXT:    [[RES:%.*]] = phi i8 [ 0, %[[LOOP_HEADER]] ], [ 1, %[[LOOP_LATCH]] ], [ 1, %[[MIDDLE_BLOCK]] ], [ 0, %[[VECTOR_EARLY_EXIT]] ]
- ; VF8UF2-NEXT:    ret i8 [[RES]]
-@@ -192,27 +193,23 @@
- ; VF8UF2:       [[VECTOR_PH]]:
- ; VF8UF2-NEXT:    br label %[[VECTOR_BODY:.*]]
- ; VF8UF2:       [[VECTOR_BODY]]:
--; VF8UF2-NEXT:    [[TMP2:%.*]] = getelementptr inbounds i8, ptr [[A]], i32 0
--; VF8UF2-NEXT:    [[TMP1:%.*]] = getelementptr inbounds i8, ptr [[A]], i32 8
--; VF8UF2-NEXT:    [[WIDE_LOAD:%.*]] = load <8 x i8>, ptr [[TMP2]], align 1
-+; VF8UF2-NEXT:    [[INDEX:%.*]] = phi i64 [ 0, %[[VECTOR_PH]] ], [ [[INDEX_NEXT:%.*]], %[[VECTOR_BODY]] ]
-+; VF8UF2-NEXT:    [[TMP0:%.*]] = getelementptr inbounds i8, ptr [[A]], i64 [[INDEX]]
-+; VF8UF2-NEXT:    [[TMP1:%.*]] = getelementptr inbounds i8, ptr [[TMP0]], i32 0
- ; VF8UF2-NEXT:    [[WIDE_LOAD1:%.*]] = load <8 x i8>, ptr [[TMP1]], align 1
--; VF8UF2-NEXT:    [[TMP3:%.*]] = icmp eq <8 x i8> [[WIDE_LOAD]], zeroinitializer
- ; VF8UF2-NEXT:    [[TMP6:%.*]] = icmp eq <8 x i8> [[WIDE_LOAD1]], zeroinitializer
--; VF8UF2-NEXT:    [[TMP4:%.*]] = or <8 x i1> [[TMP3]], [[TMP6]]
--; VF8UF2-NEXT:    [[TMP7:%.*]] = call i1 @llvm.vector.reduce.or.v8i1(<8 x i1> [[TMP4]])
--; VF8UF2-NEXT:    br label %[[MIDDLE_SPLIT:.*]]
-+; VF8UF2-NEXT:    [[INDEX_NEXT]] = add nuw i64 [[INDEX]], 8
-+; VF8UF2-NEXT:    [[TMP3:%.*]] = call i1 @llvm.vector.reduce.or.v8i1(<8 x i1> [[TMP6]])
-+; VF8UF2-NEXT:    [[TMP4:%.*]] = icmp eq i64 [[INDEX_NEXT]], 16
-+; VF8UF2-NEXT:    [[TMP5:%.*]] = or i1 [[TMP3]], [[TMP4]]
-+; VF8UF2-NEXT:    br i1 [[TMP5]], label %[[MIDDLE_SPLIT:.*]], label %[[VECTOR_BODY]], !llvm.loop [[LOOP4:![0-9]+]]
- ; VF8UF2:       [[MIDDLE_SPLIT]]:
--; VF8UF2-NEXT:    br i1 [[TMP7]], label %[[VECTOR_EARLY_EXIT:.*]], label %[[MIDDLE_BLOCK:.*]]
-+; VF8UF2-NEXT:    br i1 [[TMP3]], label %[[VECTOR_EARLY_EXIT:.*]], label %[[MIDDLE_BLOCK:.*]]
- ; VF8UF2:       [[MIDDLE_BLOCK]]:
- ; VF8UF2-NEXT:    br i1 true, label %[[EXIT:.*]], label %[[SCALAR_PH]]
- ; VF8UF2:       [[VECTOR_EARLY_EXIT]]:
- ; VF8UF2-NEXT:    [[TMP8:%.*]] = call i64 @llvm.experimental.cttz.elts.i64.v8i1(<8 x i1> [[TMP6]], i1 true)
--; VF8UF2-NEXT:    [[TMP10:%.*]] = add i64 8, [[TMP8]]
--; VF8UF2-NEXT:    [[FIRST_ACTIVE_LANE:%.*]] = call i64 @llvm.experimental.cttz.elts.i64.v8i1(<8 x i1> [[TMP3]], i1 true)
--; VF8UF2-NEXT:    [[TMP5:%.*]] = add i64 0, [[FIRST_ACTIVE_LANE]]
--; VF8UF2-NEXT:    [[TMP9:%.*]] = icmp ne i64 [[FIRST_ACTIVE_LANE]], 8
--; VF8UF2-NEXT:    [[TMP11:%.*]] = select i1 [[TMP9]], i64 [[TMP5]], i64 [[TMP10]]
--; VF8UF2-NEXT:    [[TMP12:%.*]] = add i64 0, [[TMP11]]
-+; VF8UF2-NEXT:    [[TMP7:%.*]] = add i64 [[INDEX]], [[TMP8]]
- ; VF8UF2-NEXT:    br label %[[EXIT]]
- ; VF8UF2:       [[SCALAR_PH]]:
- ; VF8UF2-NEXT:    [[BC_RESUME_VAL:%.*]] = phi i64 [ 16, %[[MIDDLE_BLOCK]] ], [ 0, %[[ENTRY]] ]
-@@ -226,9 +223,9 @@
- ; VF8UF2:       [[LOOP_LATCH]]:
- ; VF8UF2-NEXT:    [[IV_NEXT]] = add nsw i64 [[IV1]], 1
- ; VF8UF2-NEXT:    [[CMP:%.*]] = icmp eq i64 [[IV_NEXT]], 16
--; VF8UF2-NEXT:    br i1 [[CMP]], label %[[EXIT]], label %[[LOOP_HEADER]], !llvm.loop [[LOOP3:![0-9]+]]
-+; VF8UF2-NEXT:    br i1 [[CMP]], label %[[EXIT]], label %[[LOOP_HEADER]], !llvm.loop [[LOOP5:![0-9]+]]
- ; VF8UF2:       [[EXIT]]:
--; VF8UF2-NEXT:    [[RES:%.*]] = phi i64 [ [[IV1]], %[[LOOP_HEADER]] ], [ 1, %[[LOOP_LATCH]] ], [ 1, %[[MIDDLE_BLOCK]] ], [ [[TMP12]], %[[VECTOR_EARLY_EXIT]] ]
-+; VF8UF2-NEXT:    [[RES:%.*]] = phi i64 [ [[IV1]], %[[LOOP_HEADER]] ], [ 1, %[[LOOP_LATCH]] ], [ 1, %[[MIDDLE_BLOCK]] ], [ [[TMP7]], %[[VECTOR_EARLY_EXIT]] ]
- ; VF8UF2-NEXT:    ret i64 [[RES]]
- ;
- ; VF16UF1-LABEL: define i64 @test_early_exit_max_tc_less_than_16_with_iv_used_outside(
-diff -ruN --strip-trailing-cr a/mlir/python/mlir/dialects/TransformTuneExtensionOps.td b/mlir/python/mlir/dialects/TransformTuneExtensionOps.td
---- a/mlir/python/mlir/dialects/TransformTuneExtensionOps.td
-+++ b/mlir/python/mlir/dialects/TransformTuneExtensionOps.td
-@@ -11,9 +11,9 @@
- //
- //===----------------------------------------------------------------------===//
- 
--#ifndef PYTHON_BINDINGS_TRANSFORM_DEBUG_EXTENSION_OPS
--#define PYTHON_BINDINGS_TRANSFORM_DEBUG_EXTENSION_OPS
-+#ifndef PYTHON_BINDINGS_TRANSFORM_TUNE_EXTENSION_OPS
-+#define PYTHON_BINDINGS_TRANSFORM_TUNE_EXTENSION_OPS
- 
- include "mlir/Dialect/Transform/TuneExtension/TuneExtensionOps.td"
- 
--#endif // PYTHON_BINDINGS_TRANSFORM_DEBUG_EXTENSION_OPS
-+#endif // PYTHON_BINDINGS_TRANSFORM_TUNE_EXTENSION_OPS
-diff -ruN --strip-trailing-cr a/utils/bazel/llvm-project-overlay/libc/BUILD.bazel b/utils/bazel/llvm-project-overlay/libc/BUILD.bazel
---- a/utils/bazel/llvm-project-overlay/libc/BUILD.bazel
-+++ b/utils/bazel/llvm-project-overlay/libc/BUILD.bazel
-@@ -492,6 +492,7 @@
-     name = "__support_macros_properties_types",
-     hdrs = ["src/__support/macros/properties/types.h"],
-     deps = [
-+        ":__support_macros_config",
-         ":__support_macros_properties_architectures",
-         ":__support_macros_properties_compiler",
-         ":__support_macros_properties_cpu_features",
-@@ -1078,6 +1079,24 @@
- )
- 
- libc_support_library(
-+    name = "__support_fputil_bfloat16",
-+    hdrs = ["src/__support/FPUtil/bfloat16.h"],
-+    deps = [
-+        ":__support_cpp_bit",
-+        ":__support_cpp_type_traits",
-+        ":__support_fputil_cast",
-+        ":__support_fputil_dyadic_float",
-+        ":__support_macros_config",
-+        ":__support_macros_properties_types",
-+    ],
-+)
++target datalayout = "e-p6:32:32-i64:64-i128:128-v16:16-v32:32-n16:32:64"
++target triple = "nvptx64-nvidia-cuda"
 +
-+alias(
-+    name = "bfloat16",  # Alias for test/src/math:bfloat16_test.
-+    actual = ":__support_fputil_bfloat16",
-+)
++define ptx_kernel void @Equal_GPU_DT_COMPLEX64_DT_BOOL_kernel(<2 x float> %0) {
++; CHECK-LABEL: Equal_GPU_DT_COMPLEX64_DT_BOOL_kernel(
++; CHECK:       {
++; CHECK-NEXT:    .reg .pred %p<2>;
++; CHECK-NEXT:    .reg .b16 %rs<2>;
++; CHECK-NEXT:    .reg .b32 %r<2>;
++; CHECK-NEXT:    .reg .b64 %rd<3>;
++; CHECK-EMPTY:
++; CHECK-NEXT:  // %bb.0: // %.preheader15
++; CHECK-NEXT:    ld.param.b64 %rd1, [Equal_GPU_DT_COMPLEX64_DT_BOOL_kernel_param_0];
++; CHECK-NEXT:    { .reg .b32 tmp; mov.b64 {%r1, tmp}, %rd1; }
++; CHECK-NEXT:    setp.eq.f32 %p1, %r1, 0f00000000;
++; CHECK-NEXT:    selp.b16 %rs1, 1, 0, %p1;
++; CHECK-NEXT:  $L__BB0_1: // =>This Inner Loop Header: Depth=1
++; CHECK-NEXT:    mov.b64 %rd2, 0;
++; CHECK-NEXT:    st.b8 [%rd2], %rs1;
++; CHECK-NEXT:    bra.uni $L__BB0_1;
++.preheader15:
++  br label %1
 +
-+libc_support_library(
-     name = "__support_fputil_cast",
-     hdrs = ["src/__support/FPUtil/cast.h"],
-     deps = [
-diff -ruN --strip-trailing-cr a/utils/bazel/llvm-project-overlay/libc/test/src/__support/FPUtil/BUILD.bazel b/utils/bazel/llvm-project-overlay/libc/test/src/__support/FPUtil/BUILD.bazel
---- a/utils/bazel/llvm-project-overlay/libc/test/src/__support/FPUtil/BUILD.bazel
-+++ b/utils/bazel/llvm-project-overlay/libc/test/src/__support/FPUtil/BUILD.bazel
-@@ -24,6 +24,17 @@
- )
- 
- libc_test(
-+    name = "bfloat16_test",
-+    srcs = ["bfloat16_test.cpp"],
-+    deps = [
-+        "//libc:__support_fputil_bfloat16",
-+        "//libc/test/UnitTest:fp_test_helpers",
-+        "//libc/utils/MPFRWrapper:mp_common",
-+        "//libc/utils/MPFRWrapper:mpfr_wrapper",
-+    ],
-+)
++1:                                                ; preds = %1, %.preheader15
++  %2 = fcmp oeq <2 x float> %0, zeroinitializer
++  %3 = extractelement <2 x i1> %2, i64 0
++  store i1 %3, ptr null, align 4
++  br label %1
++}
 +
-+libc_test(
-     name = "dyadic_float_test",
-     srcs = ["dyadic_float_test.cpp"],
-     copts = ["-frounding-math"],
-diff -ruN --strip-trailing-cr a/utils/bazel/llvm-project-overlay/libc/utils/MPFRWrapper/BUILD.bazel b/utils/bazel/llvm-project-overlay/libc/utils/MPFRWrapper/BUILD.bazel
---- a/utils/bazel/llvm-project-overlay/libc/utils/MPFRWrapper/BUILD.bazel
-+++ b/utils/bazel/llvm-project-overlay/libc/utils/MPFRWrapper/BUILD.bazel
-@@ -42,6 +42,7 @@
-         "//libc:__support_cpp_string",
-         "//libc:__support_cpp_string_view",
-         "//libc:__support_cpp_type_traits",
-+        "//libc:__support_fputil_bfloat16",
-         "//libc:__support_fputil_cast",
-         "//libc:__support_fputil_fp_bits",
-         "//libc:__support_macros_config",
-diff -ruN --strip-trailing-cr a/utils/bazel/llvm-project-overlay/mlir/python/BUILD.bazel b/utils/bazel/llvm-project-overlay/mlir/python/BUILD.bazel
---- a/utils/bazel/llvm-project-overlay/mlir/python/BUILD.bazel
-+++ b/utils/bazel/llvm-project-overlay/mlir/python/BUILD.bazel
-@@ -701,6 +701,32 @@
- )
+diff -ruN --strip-trailing-cr a/llvm/test/CodeGen/NVPTX/reduction-intrinsics.ll b/llvm/test/CodeGen/NVPTX/reduction-intrinsics.ll
+--- a/llvm/test/CodeGen/NVPTX/reduction-intrinsics.ll
++++ b/llvm/test/CodeGen/NVPTX/reduction-intrinsics.ll
+@@ -117,16 +117,20 @@
+ ; CHECK-NEXT:    .reg .b64 %rd<5>;
+ ; CHECK-EMPTY:
+ ; CHECK-NEXT:  // %bb.0:
+-; CHECK-NEXT:    ld.param.v4.b32 {%r1, %r2, %r3, %r4}, [reduce_fadd_float_param_0+16];
+-; CHECK-NEXT:    ld.param.v4.b32 {%r5, %r6, %r7, %r8}, [reduce_fadd_float_param_0];
+-; CHECK-NEXT:    add.rn.f32 %r9, %r5, 0f00000000;
+-; CHECK-NEXT:    add.rn.f32 %r10, %r9, %r6;
+-; CHECK-NEXT:    add.rn.f32 %r11, %r10, %r7;
+-; CHECK-NEXT:    add.rn.f32 %r12, %r11, %r8;
+-; CHECK-NEXT:    add.rn.f32 %r13, %r12, %r1;
+-; CHECK-NEXT:    add.rn.f32 %r14, %r13, %r2;
+-; CHECK-NEXT:    add.rn.f32 %r15, %r14, %r3;
+-; CHECK-NEXT:    add.rn.f32 %r16, %r15, %r4;
++; CHECK-NEXT:    ld.param.v2.b64 {%rd3, %rd4}, [reduce_fadd_float_param_0+16];
++; CHECK-NEXT:    mov.b64 {%r1, %r2}, %rd4;
++; CHECK-NEXT:    mov.b64 {%r3, %r4}, %rd3;
++; CHECK-NEXT:    ld.param.v2.b64 {%rd1, %rd2}, [reduce_fadd_float_param_0];
++; CHECK-NEXT:    mov.b64 {%r5, %r6}, %rd2;
++; CHECK-NEXT:    mov.b64 {%r7, %r8}, %rd1;
++; CHECK-NEXT:    add.rn.f32 %r9, %r7, 0f00000000;
++; CHECK-NEXT:    add.rn.f32 %r10, %r9, %r8;
++; CHECK-NEXT:    add.rn.f32 %r11, %r10, %r5;
++; CHECK-NEXT:    add.rn.f32 %r12, %r11, %r6;
++; CHECK-NEXT:    add.rn.f32 %r13, %r12, %r3;
++; CHECK-NEXT:    add.rn.f32 %r14, %r13, %r4;
++; CHECK-NEXT:    add.rn.f32 %r15, %r14, %r1;
++; CHECK-NEXT:    add.rn.f32 %r16, %r15, %r2;
+ ; CHECK-NEXT:    st.param.b32 [func_retval0], %r16;
+ ; CHECK-NEXT:    ret;
+   %res = call float @llvm.vector.reduce.fadd(float 0.0, <8 x float> %in)
+@@ -140,14 +144,18 @@
+ ; CHECK-SM80-NEXT:    .reg .b64 %rd<5>;
+ ; CHECK-SM80-EMPTY:
+ ; CHECK-SM80-NEXT:  // %bb.0:
+-; CHECK-SM80-NEXT:    ld.param.v4.b32 {%r1, %r2, %r3, %r4}, [reduce_fadd_float_reassoc_param_0+16];
+-; CHECK-SM80-NEXT:    ld.param.v4.b32 {%r5, %r6, %r7, %r8}, [reduce_fadd_float_reassoc_param_0];
+-; CHECK-SM80-NEXT:    add.rn.f32 %r9, %r7, %r3;
+-; CHECK-SM80-NEXT:    add.rn.f32 %r10, %r5, %r1;
+-; CHECK-SM80-NEXT:    add.rn.f32 %r11, %r8, %r4;
+-; CHECK-SM80-NEXT:    add.rn.f32 %r12, %r6, %r2;
++; CHECK-SM80-NEXT:    ld.param.v2.b64 {%rd3, %rd4}, [reduce_fadd_float_reassoc_param_0+16];
++; CHECK-SM80-NEXT:    ld.param.v2.b64 {%rd1, %rd2}, [reduce_fadd_float_reassoc_param_0];
++; CHECK-SM80-NEXT:    mov.b64 {%r1, %r2}, %rd4;
++; CHECK-SM80-NEXT:    mov.b64 {%r3, %r4}, %rd2;
++; CHECK-SM80-NEXT:    add.rn.f32 %r5, %r3, %r1;
++; CHECK-SM80-NEXT:    mov.b64 {%r6, %r7}, %rd3;
++; CHECK-SM80-NEXT:    mov.b64 {%r8, %r9}, %rd1;
++; CHECK-SM80-NEXT:    add.rn.f32 %r10, %r8, %r6;
++; CHECK-SM80-NEXT:    add.rn.f32 %r11, %r4, %r2;
++; CHECK-SM80-NEXT:    add.rn.f32 %r12, %r9, %r7;
+ ; CHECK-SM80-NEXT:    add.rn.f32 %r13, %r12, %r11;
+-; CHECK-SM80-NEXT:    add.rn.f32 %r14, %r10, %r9;
++; CHECK-SM80-NEXT:    add.rn.f32 %r14, %r10, %r5;
+ ; CHECK-SM80-NEXT:    add.rn.f32 %r15, %r14, %r13;
+ ; CHECK-SM80-NEXT:    add.rn.f32 %r16, %r15, 0f00000000;
+ ; CHECK-SM80-NEXT:    st.param.b32 [func_retval0], %r16;
+@@ -321,15 +329,19 @@
+ ; CHECK-NEXT:    .reg .b64 %rd<5>;
+ ; CHECK-EMPTY:
+ ; CHECK-NEXT:  // %bb.0:
+-; CHECK-NEXT:    ld.param.v4.b32 {%r1, %r2, %r3, %r4}, [reduce_fmul_float_param_0+16];
+-; CHECK-NEXT:    ld.param.v4.b32 {%r5, %r6, %r7, %r8}, [reduce_fmul_float_param_0];
+-; CHECK-NEXT:    mul.rn.f32 %r9, %r5, %r6;
+-; CHECK-NEXT:    mul.rn.f32 %r10, %r9, %r7;
+-; CHECK-NEXT:    mul.rn.f32 %r11, %r10, %r8;
+-; CHECK-NEXT:    mul.rn.f32 %r12, %r11, %r1;
+-; CHECK-NEXT:    mul.rn.f32 %r13, %r12, %r2;
+-; CHECK-NEXT:    mul.rn.f32 %r14, %r13, %r3;
+-; CHECK-NEXT:    mul.rn.f32 %r15, %r14, %r4;
++; CHECK-NEXT:    ld.param.v2.b64 {%rd3, %rd4}, [reduce_fmul_float_param_0+16];
++; CHECK-NEXT:    mov.b64 {%r1, %r2}, %rd4;
++; CHECK-NEXT:    mov.b64 {%r3, %r4}, %rd3;
++; CHECK-NEXT:    ld.param.v2.b64 {%rd1, %rd2}, [reduce_fmul_float_param_0];
++; CHECK-NEXT:    mov.b64 {%r5, %r6}, %rd2;
++; CHECK-NEXT:    mov.b64 {%r7, %r8}, %rd1;
++; CHECK-NEXT:    mul.rn.f32 %r9, %r7, %r8;
++; CHECK-NEXT:    mul.rn.f32 %r10, %r9, %r5;
++; CHECK-NEXT:    mul.rn.f32 %r11, %r10, %r6;
++; CHECK-NEXT:    mul.rn.f32 %r12, %r11, %r3;
++; CHECK-NEXT:    mul.rn.f32 %r13, %r12, %r4;
++; CHECK-NEXT:    mul.rn.f32 %r14, %r13, %r1;
++; CHECK-NEXT:    mul.rn.f32 %r15, %r14, %r2;
+ ; CHECK-NEXT:    st.param.b32 [func_retval0], %r15;
+ ; CHECK-NEXT:    ret;
+   %res = call float @llvm.vector.reduce.fmul(float 1.0, <8 x float> %in)
+@@ -343,14 +355,18 @@
+ ; CHECK-SM80-NEXT:    .reg .b64 %rd<5>;
+ ; CHECK-SM80-EMPTY:
+ ; CHECK-SM80-NEXT:  // %bb.0:
+-; CHECK-SM80-NEXT:    ld.param.v4.b32 {%r1, %r2, %r3, %r4}, [reduce_fmul_float_reassoc_param_0+16];
+-; CHECK-SM80-NEXT:    ld.param.v4.b32 {%r5, %r6, %r7, %r8}, [reduce_fmul_float_reassoc_param_0];
+-; CHECK-SM80-NEXT:    mul.rn.f32 %r9, %r7, %r3;
+-; CHECK-SM80-NEXT:    mul.rn.f32 %r10, %r5, %r1;
+-; CHECK-SM80-NEXT:    mul.rn.f32 %r11, %r8, %r4;
+-; CHECK-SM80-NEXT:    mul.rn.f32 %r12, %r6, %r2;
++; CHECK-SM80-NEXT:    ld.param.v2.b64 {%rd3, %rd4}, [reduce_fmul_float_reassoc_param_0+16];
++; CHECK-SM80-NEXT:    ld.param.v2.b64 {%rd1, %rd2}, [reduce_fmul_float_reassoc_param_0];
++; CHECK-SM80-NEXT:    mov.b64 {%r1, %r2}, %rd4;
++; CHECK-SM80-NEXT:    mov.b64 {%r3, %r4}, %rd2;
++; CHECK-SM80-NEXT:    mul.rn.f32 %r5, %r3, %r1;
++; CHECK-SM80-NEXT:    mov.b64 {%r6, %r7}, %rd3;
++; CHECK-SM80-NEXT:    mov.b64 {%r8, %r9}, %rd1;
++; CHECK-SM80-NEXT:    mul.rn.f32 %r10, %r8, %r6;
++; CHECK-SM80-NEXT:    mul.rn.f32 %r11, %r4, %r2;
++; CHECK-SM80-NEXT:    mul.rn.f32 %r12, %r9, %r7;
+ ; CHECK-SM80-NEXT:    mul.rn.f32 %r13, %r12, %r11;
+-; CHECK-SM80-NEXT:    mul.rn.f32 %r14, %r10, %r9;
++; CHECK-SM80-NEXT:    mul.rn.f32 %r14, %r10, %r5;
+ ; CHECK-SM80-NEXT:    mul.rn.f32 %r15, %r14, %r13;
+ ; CHECK-SM80-NEXT:    st.param.b32 [func_retval0], %r15;
+ ; CHECK-SM80-NEXT:    ret;
+@@ -494,13 +510,17 @@
+ ; CHECK-NEXT:    .reg .b64 %rd<5>;
+ ; CHECK-EMPTY:
+ ; CHECK-NEXT:  // %bb.0:
+-; CHECK-NEXT:    ld.param.v4.b32 {%r1, %r2, %r3, %r4}, [reduce_fmax_float_param_0+16];
+-; CHECK-NEXT:    ld.param.v4.b32 {%r5, %r6, %r7, %r8}, [reduce_fmax_float_param_0];
+-; CHECK-NEXT:    max.f32 %r9, %r8, %r4;
+-; CHECK-NEXT:    max.f32 %r10, %r6, %r2;
+-; CHECK-NEXT:    max.f32 %r11, %r10, %r9;
+-; CHECK-NEXT:    max.f32 %r12, %r7, %r3;
+-; CHECK-NEXT:    max.f32 %r13, %r5, %r1;
++; CHECK-NEXT:    ld.param.v2.b64 {%rd3, %rd4}, [reduce_fmax_float_param_0+16];
++; CHECK-NEXT:    ld.param.v2.b64 {%rd1, %rd2}, [reduce_fmax_float_param_0];
++; CHECK-NEXT:    mov.b64 {%r1, %r2}, %rd4;
++; CHECK-NEXT:    mov.b64 {%r3, %r4}, %rd2;
++; CHECK-NEXT:    max.f32 %r5, %r4, %r2;
++; CHECK-NEXT:    mov.b64 {%r6, %r7}, %rd3;
++; CHECK-NEXT:    mov.b64 {%r8, %r9}, %rd1;
++; CHECK-NEXT:    max.f32 %r10, %r9, %r7;
++; CHECK-NEXT:    max.f32 %r11, %r10, %r5;
++; CHECK-NEXT:    max.f32 %r12, %r3, %r1;
++; CHECK-NEXT:    max.f32 %r13, %r8, %r6;
+ ; CHECK-NEXT:    max.f32 %r14, %r13, %r12;
+ ; CHECK-NEXT:    max.f32 %r15, %r14, %r11;
+ ; CHECK-NEXT:    st.param.b32 [func_retval0], %r15;
+@@ -517,13 +537,17 @@
+ ; CHECK-NEXT:    .reg .b64 %rd<5>;
+ ; CHECK-EMPTY:
+ ; CHECK-NEXT:  // %bb.0:
+-; CHECK-NEXT:    ld.param.v4.b32 {%r1, %r2, %r3, %r4}, [reduce_fmax_float_reassoc_param_0+16];
+-; CHECK-NEXT:    ld.param.v4.b32 {%r5, %r6, %r7, %r8}, [reduce_fmax_float_reassoc_param_0];
+-; CHECK-NEXT:    max.f32 %r9, %r8, %r4;
+-; CHECK-NEXT:    max.f32 %r10, %r6, %r2;
+-; CHECK-NEXT:    max.f32 %r11, %r10, %r9;
+-; CHECK-NEXT:    max.f32 %r12, %r7, %r3;
+-; CHECK-NEXT:    max.f32 %r13, %r5, %r1;
++; CHECK-NEXT:    ld.param.v2.b64 {%rd3, %rd4}, [reduce_fmax_float_reassoc_param_0+16];
++; CHECK-NEXT:    ld.param.v2.b64 {%rd1, %rd2}, [reduce_fmax_float_reassoc_param_0];
++; CHECK-NEXT:    mov.b64 {%r1, %r2}, %rd4;
++; CHECK-NEXT:    mov.b64 {%r3, %r4}, %rd2;
++; CHECK-NEXT:    max.f32 %r5, %r4, %r2;
++; CHECK-NEXT:    mov.b64 {%r6, %r7}, %rd3;
++; CHECK-NEXT:    mov.b64 {%r8, %r9}, %rd1;
++; CHECK-NEXT:    max.f32 %r10, %r9, %r7;
++; CHECK-NEXT:    max.f32 %r11, %r10, %r5;
++; CHECK-NEXT:    max.f32 %r12, %r3, %r1;
++; CHECK-NEXT:    max.f32 %r13, %r8, %r6;
+ ; CHECK-NEXT:    max.f32 %r14, %r13, %r12;
+ ; CHECK-NEXT:    max.f32 %r15, %r14, %r11;
+ ; CHECK-NEXT:    st.param.b32 [func_retval0], %r15;
+@@ -628,13 +652,17 @@
+ ; CHECK-NEXT:    .reg .b64 %rd<5>;
+ ; CHECK-EMPTY:
+ ; CHECK-NEXT:  // %bb.0:
+-; CHECK-NEXT:    ld.param.v4.b32 {%r1, %r2, %r3, %r4}, [reduce_fmin_float_param_0+16];
+-; CHECK-NEXT:    ld.param.v4.b32 {%r5, %r6, %r7, %r8}, [reduce_fmin_float_param_0];
+-; CHECK-NEXT:    min.f32 %r9, %r8, %r4;
+-; CHECK-NEXT:    min.f32 %r10, %r6, %r2;
+-; CHECK-NEXT:    min.f32 %r11, %r10, %r9;
+-; CHECK-NEXT:    min.f32 %r12, %r7, %r3;
+-; CHECK-NEXT:    min.f32 %r13, %r5, %r1;
++; CHECK-NEXT:    ld.param.v2.b64 {%rd3, %rd4}, [reduce_fmin_float_param_0+16];
++; CHECK-NEXT:    ld.param.v2.b64 {%rd1, %rd2}, [reduce_fmin_float_param_0];
++; CHECK-NEXT:    mov.b64 {%r1, %r2}, %rd4;
++; CHECK-NEXT:    mov.b64 {%r3, %r4}, %rd2;
++; CHECK-NEXT:    min.f32 %r5, %r4, %r2;
++; CHECK-NEXT:    mov.b64 {%r6, %r7}, %rd3;
++; CHECK-NEXT:    mov.b64 {%r8, %r9}, %rd1;
++; CHECK-NEXT:    min.f32 %r10, %r9, %r7;
++; CHECK-NEXT:    min.f32 %r11, %r10, %r5;
++; CHECK-NEXT:    min.f32 %r12, %r3, %r1;
++; CHECK-NEXT:    min.f32 %r13, %r8, %r6;
+ ; CHECK-NEXT:    min.f32 %r14, %r13, %r12;
+ ; CHECK-NEXT:    min.f32 %r15, %r14, %r11;
+ ; CHECK-NEXT:    st.param.b32 [func_retval0], %r15;
+@@ -651,13 +679,17 @@
+ ; CHECK-NEXT:    .reg .b64 %rd<5>;
+ ; CHECK-EMPTY:
+ ; CHECK-NEXT:  // %bb.0:
+-; CHECK-NEXT:    ld.param.v4.b32 {%r1, %r2, %r3, %r4}, [reduce_fmin_float_reassoc_param_0+16];
+-; CHECK-NEXT:    ld.param.v4.b32 {%r5, %r6, %r7, %r8}, [reduce_fmin_float_reassoc_param_0];
+-; CHECK-NEXT:    min.f32 %r9, %r8, %r4;
+-; CHECK-NEXT:    min.f32 %r10, %r6, %r2;
+-; CHECK-NEXT:    min.f32 %r11, %r10, %r9;
+-; CHECK-NEXT:    min.f32 %r12, %r7, %r3;
+-; CHECK-NEXT:    min.f32 %r13, %r5, %r1;
++; CHECK-NEXT:    ld.param.v2.b64 {%rd3, %rd4}, [reduce_fmin_float_reassoc_param_0+16];
++; CHECK-NEXT:    ld.param.v2.b64 {%rd1, %rd2}, [reduce_fmin_float_reassoc_param_0];
++; CHECK-NEXT:    mov.b64 {%r1, %r2}, %rd4;
++; CHECK-NEXT:    mov.b64 {%r3, %r4}, %rd2;
++; CHECK-NEXT:    min.f32 %r5, %r4, %r2;
++; CHECK-NEXT:    mov.b64 {%r6, %r7}, %rd3;
++; CHECK-NEXT:    mov.b64 {%r8, %r9}, %rd1;
++; CHECK-NEXT:    min.f32 %r10, %r9, %r7;
++; CHECK-NEXT:    min.f32 %r11, %r10, %r5;
++; CHECK-NEXT:    min.f32 %r12, %r3, %r1;
++; CHECK-NEXT:    min.f32 %r13, %r8, %r6;
+ ; CHECK-NEXT:    min.f32 %r14, %r13, %r12;
+ ; CHECK-NEXT:    min.f32 %r15, %r14, %r11;
+ ; CHECK-NEXT:    st.param.b32 [func_retval0], %r15;
+@@ -762,13 +794,17 @@
+ ; CHECK-NEXT:    .reg .b64 %rd<5>;
+ ; CHECK-EMPTY:
+ ; CHECK-NEXT:  // %bb.0:
+-; CHECK-NEXT:    ld.param.v4.b32 {%r1, %r2, %r3, %r4}, [reduce_fmaximum_float_param_0+16];
+-; CHECK-NEXT:    ld.param.v4.b32 {%r5, %r6, %r7, %r8}, [reduce_fmaximum_float_param_0];
+-; CHECK-NEXT:    max.NaN.f32 %r9, %r8, %r4;
+-; CHECK-NEXT:    max.NaN.f32 %r10, %r6, %r2;
+-; CHECK-NEXT:    max.NaN.f32 %r11, %r10, %r9;
+-; CHECK-NEXT:    max.NaN.f32 %r12, %r7, %r3;
+-; CHECK-NEXT:    max.NaN.f32 %r13, %r5, %r1;
++; CHECK-NEXT:    ld.param.v2.b64 {%rd3, %rd4}, [reduce_fmaximum_float_param_0+16];
++; CHECK-NEXT:    ld.param.v2.b64 {%rd1, %rd2}, [reduce_fmaximum_float_param_0];
++; CHECK-NEXT:    mov.b64 {%r1, %r2}, %rd4;
++; CHECK-NEXT:    mov.b64 {%r3, %r4}, %rd2;
++; CHECK-NEXT:    max.NaN.f32 %r5, %r4, %r2;
++; CHECK-NEXT:    mov.b64 {%r6, %r7}, %rd3;
++; CHECK-NEXT:    mov.b64 {%r8, %r9}, %rd1;
++; CHECK-NEXT:    max.NaN.f32 %r10, %r9, %r7;
++; CHECK-NEXT:    max.NaN.f32 %r11, %r10, %r5;
++; CHECK-NEXT:    max.NaN.f32 %r12, %r3, %r1;
++; CHECK-NEXT:    max.NaN.f32 %r13, %r8, %r6;
+ ; CHECK-NEXT:    max.NaN.f32 %r14, %r13, %r12;
+ ; CHECK-NEXT:    max.NaN.f32 %r15, %r14, %r11;
+ ; CHECK-NEXT:    st.param.b32 [func_retval0], %r15;
+@@ -785,13 +821,17 @@
+ ; CHECK-NEXT:    .reg .b64 %rd<5>;
+ ; CHECK-EMPTY:
+ ; CHECK-NEXT:  // %bb.0:
+-; CHECK-NEXT:    ld.param.v4.b32 {%r1, %r2, %r3, %r4}, [reduce_fmaximum_float_reassoc_param_0+16];
+-; CHECK-NEXT:    ld.param.v4.b32 {%r5, %r6, %r7, %r8}, [reduce_fmaximum_float_reassoc_param_0];
+-; CHECK-NEXT:    max.NaN.f32 %r9, %r8, %r4;
+-; CHECK-NEXT:    max.NaN.f32 %r10, %r6, %r2;
+-; CHECK-NEXT:    max.NaN.f32 %r11, %r10, %r9;
+-; CHECK-NEXT:    max.NaN.f32 %r12, %r7, %r3;
+-; CHECK-NEXT:    max.NaN.f32 %r13, %r5, %r1;
++; CHECK-NEXT:    ld.param.v2.b64 {%rd3, %rd4}, [reduce_fmaximum_float_reassoc_param_0+16];
++; CHECK-NEXT:    ld.param.v2.b64 {%rd1, %rd2}, [reduce_fmaximum_float_reassoc_param_0];
++; CHECK-NEXT:    mov.b64 {%r1, %r2}, %rd4;
++; CHECK-NEXT:    mov.b64 {%r3, %r4}, %rd2;
++; CHECK-NEXT:    max.NaN.f32 %r5, %r4, %r2;
++; CHECK-NEXT:    mov.b64 {%r6, %r7}, %rd3;
++; CHECK-NEXT:    mov.b64 {%r8, %r9}, %rd1;
++; CHECK-NEXT:    max.NaN.f32 %r10, %r9, %r7;
++; CHECK-NEXT:    max.NaN.f32 %r11, %r10, %r5;
++; CHECK-NEXT:    max.NaN.f32 %r12, %r3, %r1;
++; CHECK-NEXT:    max.NaN.f32 %r13, %r8, %r6;
+ ; CHECK-NEXT:    max.NaN.f32 %r14, %r13, %r12;
+ ; CHECK-NEXT:    max.NaN.f32 %r15, %r14, %r11;
+ ; CHECK-NEXT:    st.param.b32 [func_retval0], %r15;
+@@ -896,13 +936,17 @@
+ ; CHECK-NEXT:    .reg .b64 %rd<5>;
+ ; CHECK-EMPTY:
+ ; CHECK-NEXT:  // %bb.0:
+-; CHECK-NEXT:    ld.param.v4.b32 {%r1, %r2, %r3, %r4}, [reduce_fminimum_float_param_0+16];
+-; CHECK-NEXT:    ld.param.v4.b32 {%r5, %r6, %r7, %r8}, [reduce_fminimum_float_param_0];
+-; CHECK-NEXT:    min.NaN.f32 %r9, %r8, %r4;
+-; CHECK-NEXT:    min.NaN.f32 %r10, %r6, %r2;
+-; CHECK-NEXT:    min.NaN.f32 %r11, %r10, %r9;
+-; CHECK-NEXT:    min.NaN.f32 %r12, %r7, %r3;
+-; CHECK-NEXT:    min.NaN.f32 %r13, %r5, %r1;
++; CHECK-NEXT:    ld.param.v2.b64 {%rd3, %rd4}, [reduce_fminimum_float_param_0+16];
++; CHECK-NEXT:    ld.param.v2.b64 {%rd1, %rd2}, [reduce_fminimum_float_param_0];
++; CHECK-NEXT:    mov.b64 {%r1, %r2}, %rd4;
++; CHECK-NEXT:    mov.b64 {%r3, %r4}, %rd2;
++; CHECK-NEXT:    min.NaN.f32 %r5, %r4, %r2;
++; CHECK-NEXT:    mov.b64 {%r6, %r7}, %rd3;
++; CHECK-NEXT:    mov.b64 {%r8, %r9}, %rd1;
++; CHECK-NEXT:    min.NaN.f32 %r10, %r9, %r7;
++; CHECK-NEXT:    min.NaN.f32 %r11, %r10, %r5;
++; CHECK-NEXT:    min.NaN.f32 %r12, %r3, %r1;
++; CHECK-NEXT:    min.NaN.f32 %r13, %r8, %r6;
+ ; CHECK-NEXT:    min.NaN.f32 %r14, %r13, %r12;
+ ; CHECK-NEXT:    min.NaN.f32 %r15, %r14, %r11;
+ ; CHECK-NEXT:    st.param.b32 [func_retval0], %r15;
+@@ -919,13 +963,17 @@
+ ; CHECK-NEXT:    .reg .b64 %rd<5>;
+ ; CHECK-EMPTY:
+ ; CHECK-NEXT:  // %bb.0:
+-; CHECK-NEXT:    ld.param.v4.b32 {%r1, %r2, %r3, %r4}, [reduce_fminimum_float_reassoc_param_0+16];
+-; CHECK-NEXT:    ld.param.v4.b32 {%r5, %r6, %r7, %r8}, [reduce_fminimum_float_reassoc_param_0];
+-; CHECK-NEXT:    min.NaN.f32 %r9, %r8, %r4;
+-; CHECK-NEXT:    min.NaN.f32 %r10, %r6, %r2;
+-; CHECK-NEXT:    min.NaN.f32 %r11, %r10, %r9;
+-; CHECK-NEXT:    min.NaN.f32 %r12, %r7, %r3;
+-; CHECK-NEXT:    min.NaN.f32 %r13, %r5, %r1;
++; CHECK-NEXT:    ld.param.v2.b64 {%rd3, %rd4}, [reduce_fminimum_float_reassoc_param_0+16];
++; CHECK-NEXT:    ld.param.v2.b64 {%rd1, %rd2}, [reduce_fminimum_float_reassoc_param_0];
++; CHECK-NEXT:    mov.b64 {%r1, %r2}, %rd4;
++; CHECK-NEXT:    mov.b64 {%r3, %r4}, %rd2;
++; CHECK-NEXT:    min.NaN.f32 %r5, %r4, %r2;
++; CHECK-NEXT:    mov.b64 {%r6, %r7}, %rd3;
++; CHECK-NEXT:    mov.b64 {%r8, %r9}, %rd1;
++; CHECK-NEXT:    min.NaN.f32 %r10, %r9, %r7;
++; CHECK-NEXT:    min.NaN.f32 %r11, %r10, %r5;
++; CHECK-NEXT:    min.NaN.f32 %r12, %r3, %r1;
++; CHECK-NEXT:    min.NaN.f32 %r13, %r8, %r6;
+ ; CHECK-NEXT:    min.NaN.f32 %r14, %r13, %r12;
+ ; CHECK-NEXT:    min.NaN.f32 %r15, %r14, %r11;
+ ; CHECK-NEXT:    st.param.b32 [func_retval0], %r15;
+diff -ruN --strip-trailing-cr a/mlir/lib/Target/IRDLToCpp/TemplatingUtils.h b/mlir/lib/Target/IRDLToCpp/TemplatingUtils.h
+--- a/mlir/lib/Target/IRDLToCpp/TemplatingUtils.h
++++ b/mlir/lib/Target/IRDLToCpp/TemplatingUtils.h
+@@ -15,6 +15,7 @@
+ #include "llvm/Support/ErrorHandling.h"
+ #include "llvm/Support/raw_ostream.h"
+ #include <variant>
++#include <vector>
  
- ##---------------------------------------------------------------------------##
-+# Tune dialect.
-+##---------------------------------------------------------------------------##
-+
-+gentbl_filegroup(
-+    name = "TuneTransformOpsPyGen",
-+    tbl_outs = {"mlir/dialects/_transform_tune_extension_ops_gen.py": [
-+        "-gen-python-op-bindings",
-+        "-bind-dialect=transform",
-+        "-dialect-extension=transform_tune_extension",
-+    ]},
-+    tblgen = "//mlir:mlir-tblgen",
-+    td_file = "mlir/dialects/TransformTuneExtensionOps.td",
-+    deps = [
-+        "//mlir:TransformTuneExtensionTdFiles",
-+    ],
-+)
-+
-+filegroup(
-+    name = "TunePyFiles",
-+    srcs = [
-+        "mlir/dialects/transform/tune.py",
-+        ":TuneTransformOpsPyGen",
-+    ],
-+)
-+
-+##---------------------------------------------------------------------------##
- # PythonTest dialect.
- ##---------------------------------------------------------------------------##
+ namespace mlir::irdl::detail {
+ 
+diff -ruN --strip-trailing-cr a/mlir/test/IR/test-pattern-logging-listener.mlir b/mlir/test/IR/test-pattern-logging-listener.mlir
+--- a/mlir/test/IR/test-pattern-logging-listener.mlir
++++ b/mlir/test/IR/test-pattern-logging-listener.mlir
+@@ -1,3 +1,4 @@
++// REQUIRES: asserts
+ // RUN: mlir-opt %s --test-walk-pattern-rewrite-driver \
+ // RUN:   --allow-unregistered-dialect --debug-only=pattern-logging-listener 2>&1 | FileCheck %s
  
diff --git a/third_party/llvm/memcpy.patch b/third_party/llvm/memcpy.patch
deleted file mode 100644
index c6cc824..0000000
--- a/third_party/llvm/memcpy.patch
+++ /dev/null
@@ -1,62 +0,0 @@
-diff --git a/llvm/include/llvm/ADT/Hashing.h b/llvm/include/llvm/ADT/Hashing.h
-index 0093c281aac8..ad131015a7d9 100644
---- a/llvm/include/llvm/ADT/Hashing.h
-+++ b/llvm/include/llvm/ADT/Hashing.h
-@@ -136,7 +136,7 @@ namespace detail {
- 
- inline uint64_t fetch64(const char *p) {
-   uint64_t result;
--  memcpy(&result, p, sizeof(result));
-+  std::memcpy(&result, p, sizeof(result));
-   if (sys::IsBigEndianHost)
-     sys::swapByteOrder(result);
-   return result;
-@@ -144,7 +144,7 @@ inline uint64_t fetch64(const char *p) {
- 
- inline uint32_t fetch32(const char *p) {
-   uint32_t result;
--  memcpy(&result, p, sizeof(result));
-+  std::memcpy(&result, p, sizeof(result));
-   if (sys::IsBigEndianHost)
-     sys::swapByteOrder(result);
-   return result;
-@@ -379,7 +379,7 @@ bool store_and_advance(char *&buffer_ptr, char *buffer_end, const T& value,
-   if (buffer_ptr + store_size > buffer_end)
-     return false;
-   const char *value_data = reinterpret_cast<const char *>(&value);
--  memcpy(buffer_ptr, value_data + offset, store_size);
-+  std::memcpy(buffer_ptr, value_data + offset, store_size);
-   buffer_ptr += store_size;
-   return true;
- }
-@@ -513,7 +513,7 @@ public:
-       // with the variadic combine because that formation can have varying
-       // argument types.
-       size_t partial_store_size = buffer_end - buffer_ptr;
--      memcpy(buffer_ptr, &data, partial_store_size);
-+      std::memcpy(buffer_ptr, &data, partial_store_size);
- 
-       // If the store fails, our buffer is full and ready to hash. We have to
-       // either initialize the hash state (on the first full buffer) or mix
-diff --git a/llvm/include/llvm/ADT/SmallVector.h b/llvm/include/llvm/ADT/SmallVector.h
-index 0b8bb48b8fe5..80f7734b8690 100644
---- a/llvm/include/llvm/ADT/SmallVector.h
-+++ b/llvm/include/llvm/ADT/SmallVector.h
-@@ -518,7 +518,7 @@ protected:
-     // use memcpy here. Note that I and E are iterators and thus might be
-     // invalid for memcpy if they are equal.
-     if (I != E)
--      memcpy(reinterpret_cast<void *>(Dest), I, (E - I) * sizeof(T));
-+      std::memcpy(reinterpret_cast<void *>(Dest), I, (E - I) * sizeof(T));
-   }
- 
-   /// Double the size of the allocated memory, guaranteeing space for at
-@@ -561,7 +561,7 @@ protected:
- public:
-   void push_back(ValueParamT Elt) {
-     const T *EltPtr = reserveForParamAndGetAddress(Elt);
--    memcpy(reinterpret_cast<void *>(this->end()), EltPtr, sizeof(T));
-+    std::memcpy(reinterpret_cast<void *>(this->end()), EltPtr, sizeof(T));
-     this->set_size(this->size() + 1);
-   }
- 
diff --git a/third_party/llvm/workspace.bzl b/third_party/llvm/workspace.bzl
index 530f6da..79fbbfa 100644
--- a/third_party/llvm/workspace.bzl
+++ b/third_party/llvm/workspace.bzl
@@ -4,8 +4,8 @@ load("//third_party:repo.bzl", "tf_http_archive")
 
 def repo(name):
     """Imports LLVM."""
-    LLVM_COMMIT = "06ae0c2a10864e8029ea52b83c46c1839ddb0c1b"
-    LLVM_SHA256 = "1abf0e914ee6cd6755dcc11b684197a5f72d362838096101f3c81692a67ed40a"
+    LLVM_COMMIT = "13f7786f72d13a84dfc3d49d87a70e6a05f21fd4"
+    LLVM_SHA256 = "444620f561a7ab1ccaa310b7ba5cdc82c61ff534b6e60b00cb58e779a24cb3bd"
 
     tf_http_archive(
         name = name,
@@ -20,7 +20,6 @@ def repo(name):
             "//third_party/llvm:generated.patch",  # Autogenerated, don't remove.
             "//third_party/llvm:build.patch",
             "//third_party/llvm:mathextras.patch",
-            "//third_party/llvm:memcpy.patch",
             "//third_party/llvm:toolchains.patch",
             "//third_party/llvm:zstd.patch",
         ],
diff --git a/third_party/stablehlo/temporary.patch b/third_party/stablehlo/temporary.patch
index f5895df..0580a1c 100755
--- a/third_party/stablehlo/temporary.patch
+++ b/third_party/stablehlo/temporary.patch
@@ -102,6 +102,33 @@ diff --ruN a/stablehlo/stablehlo/dialect/AssemblyFormat.cpp b/stablehlo/stablehl
    p.printRegion(cond, /*printEntryBlockArgs=*/false);
    p << " do ";
    p.printRegion(body, /*printEntryBlockArgs=*/false);
+diff --ruN a/stablehlo/stablehlo/dialect/StablehloOps.td b/stablehlo/stablehlo/dialect/StablehloOps.td
+--- stablehlo/stablehlo/dialect/StablehloOps.td
++++ stablehlo/stablehlo/dialect/StablehloOps.td
+@@ -1245,11 +1245,6 @@
+   );
+ 
+   let results = (outs HLO_Token);
+-  let builders = [
+-    OpBuilder<(ins
+-      "::mlir::Type":$result_type, "::mlir::Value":$operand,
+-      "::mlir::DenseIntElementsAttr":$source_target_pairs,
+-      "::mlir::stablehlo::ChannelHandleAttr":$channel_handle)>];
+ }
+ 
+ def StableHLO_RecvOp : StableHLO_Op<"recv", [
+@@ -1279,11 +1274,6 @@
+     DefaultValuedOptionalAttr<BoolAttr, "false">:$is_host_transfer, /*recv_i4*/
+     OptionalAttr<I64ElementsAttr>:$source_target_pairs /*recv_i5*/
+   );
+-  let builders = [
+-    OpBuilder<(ins
+-      "::mlir::Type":$result_type, "::mlir::Value":$operand,
+-      "::mlir::DenseIntElementsAttr":$source_target_pairs,
+-      "::mlir::stablehlo::ChannelHandleAttr":$channel_handle)>];
+ 
+   let results = (outs Variadic<HLO_StaticShapeTensorOrPerAxisQuantizedTensorOrToken>);
+   let hasVerifier = 1;
 diff --ruN a/stablehlo/stablehlo/dialect/TypeInference.cpp b/stablehlo/stablehlo/dialect/TypeInference.cpp
 --- stablehlo/stablehlo/dialect/TypeInference.cpp
 +++ stablehlo/stablehlo/dialect/TypeInference.cpp
