diff --git a/third_party/llvm/generated.patch b/third_party/llvm/generated.patch
index d52ea5c..3744c10 100644
--- a/third_party/llvm/generated.patch
+++ b/third_party/llvm/generated.patch
@@ -1,2910 +1,3207 @@
 Auto generated patch. Do not edit or delete it, even if empty.
-diff -ruN --strip-trailing-cr a/clang/include/clang/Basic/SourceManager.h b/clang/include/clang/Basic/SourceManager.h
---- a/clang/include/clang/Basic/SourceManager.h
-+++ b/clang/include/clang/Basic/SourceManager.h
-@@ -824,12 +824,6 @@
+diff -ruN --strip-trailing-cr a/llvm/lib/Target/NVPTX/NVPTXISelLowering.cpp b/llvm/lib/Target/NVPTX/NVPTXISelLowering.cpp
+--- a/llvm/lib/Target/NVPTX/NVPTXISelLowering.cpp
++++ b/llvm/lib/Target/NVPTX/NVPTXISelLowering.cpp
+@@ -731,6 +731,8 @@
+   setTruncStoreAction(MVT::f32, MVT::bf16, Expand);
+   setTruncStoreAction(MVT::f64, MVT::bf16, Expand);
+   setTruncStoreAction(MVT::f64, MVT::f32, Expand);
++  setTruncStoreAction(MVT::v2f32, MVT::v2f16, Expand);
++  setTruncStoreAction(MVT::v2f32, MVT::v2bf16, Expand);
  
-   mutable std::unique_ptr<SrcMgr::SLocEntry> FakeSLocEntryForRecovery;
+   // PTX does not support load / store predicate registers
+   setOperationAction(ISD::LOAD, MVT::i1, Custom);
+@@ -5060,12 +5062,6 @@
+           return !U.getUser()->use_empty();
+         }
  
--  /// Cache for filenames used in diagnostics. See 'getNameForDiagnostic()'.
--  mutable llvm::StringMap<StringRef> DiagNames;
+-        // Handle CopyToReg nodes that will become dead after our replacement
+-        if (U.getUser()->getOpcode() == ISD::CopyToReg) {
+-          DeadCopyToRegs.push_back(U.getUser());
+-          return true;
+-        }
 -
--  /// Allocator for absolute/short names.
--  mutable llvm::BumpPtrAllocator DiagNameAlloc;
--
-   /// Lazily computed map of macro argument chunks to their expanded
-   /// source location.
-   using MacroArgsMap = std::map<unsigned, SourceLocation>;
-@@ -1854,16 +1848,6 @@
-   /// \return Location of the top-level macro caller.
-   SourceLocation getTopMacroCallerLoc(SourceLocation Loc) const;
+         // Otherwise, this use prevents us from splitting a value.
+         return false;
+       }))
+@@ -5132,10 +5128,6 @@
+   for (unsigned I : seq(NewLoad->getNumValues() - NewNumOutputs))
+     Results.push_back(NewLoad.getValue(NewNumOutputs + I));
  
--  /// Retrieve the name of a file suitable for diagnostics.
--  // FIXME: Passing in the DiagnosticOptions here is a workaround for the
--  // fact that installapi does some weird things with DiagnosticsEngines,
--  // which causes the 'Diag' member of SourceManager (or at least the
--  // DiagnosticsOptions member thereof) to be a dangling reference
--  // sometimes. We should probably fix that or decouple the two classes
--  // to avoid this issue entirely.
--  StringRef getNameForDiagnostic(StringRef Filename,
--                                 const DiagnosticOptions &Opts) const;
+-  // Remove dead CopyToReg nodes by folding them into the chain they reference
+-  for (SDNode *CTR : DeadCopyToRegs)
+-    DCI.CombineTo(CTR, CTR->getOperand(0));
 -
- private:
-   friend class ASTReader;
-   friend class ASTWriter;
-diff -ruN --strip-trailing-cr a/clang/lib/Basic/SourceManager.cpp b/clang/lib/Basic/SourceManager.cpp
---- a/clang/lib/Basic/SourceManager.cpp
-+++ b/clang/lib/Basic/SourceManager.cpp
-@@ -2390,75 +2390,3 @@
-   assert(ID.isValid());
-   SourceMgr->setMainFileID(ID);
+   return DCI.DAG.getMergeValues(Results, DL);
  }
--
--StringRef
--SourceManager::getNameForDiagnostic(StringRef Filename,
--                                    const DiagnosticOptions &Opts) const {
--  OptionalFileEntryRef File = getFileManager().getOptionalFileRef(Filename);
--  if (!File)
--    return Filename;
--
--  bool SimplifyPath = [&] {
--    if (Opts.AbsolutePath)
--      return true;
--
--    // Try to simplify paths that contain '..' in any case since paths to
--    // standard library headers especially tend to get quite long otherwise.
--    // Only do that for local filesystems though to avoid slowing down
--    // compilation too much.
--    if (!File->getName().contains(".."))
--      return false;
--
--    // If we're not on Windows, check if we're on a network file system and
--    // avoid simplifying the path in that case since that can be slow. On
--    // Windows, the check for a local filesystem is already slow, so skip it.
--#ifndef _WIN32
--    if (!llvm::sys::fs::is_local(File->getName()))
--      return false;
--#endif
--
--    return true;
--  }();
--
--  if (!SimplifyPath)
--    return Filename;
--
--  // This may involve computing canonical names, so cache the result.
--  StringRef &CacheEntry = DiagNames[Filename];
--  if (!CacheEntry.empty())
--    return CacheEntry;
--
--  // We want to print a simplified absolute path, i. e. without "dots".
--  //
--  // The hardest part here are the paths like "<part1>/<link>/../<part2>".
--  // On Unix-like systems, we cannot just collapse "<link>/..", because
--  // paths are resolved sequentially, and, thereby, the path
--  // "<part1>/<part2>" may point to a different location. That is why
--  // we use FileManager::getCanonicalName(), which expands all indirections
--  // with llvm::sys::fs::real_path() and caches the result.
--  //
--  // On the other hand, it would be better to preserve as much of the
--  // original path as possible, because that helps a user to recognize it.
--  // real_path() expands all links, which sometimes too much. Luckily,
--  // on Windows we can just use llvm::sys::path::remove_dots(), because,
--  // on that system, both aforementioned paths point to the same place.
--  SmallString<256> TempBuf;
--#ifdef _WIN32
--  TempBuf = File->getName();
--  llvm::sys::fs::make_absolute(TempBuf);
--  llvm::sys::path::native(TempBuf);
--  llvm::sys::path::remove_dots(TempBuf, /* remove_dot_dot */ true);
--#else
--  TempBuf = getFileManager().getCanonicalName(*File);
--#endif
--
--  // In some cases, the resolved path may actually end up being longer (e.g.
--  // if it was originally a relative path), so just retain whichever one
--  // ends up being shorter.
--  if (!Opts.AbsolutePath && TempBuf.size() > Filename.size())
--    CacheEntry = Filename;
--  else
--    CacheEntry = TempBuf.str().copy(DiagNameAlloc);
--
--  return CacheEntry;
+ 
+@@ -6544,4 +6536,4 @@
+   default:
+     break;
+   }
 -}
-diff -ruN --strip-trailing-cr a/clang/lib/Frontend/SARIFDiagnostic.cpp b/clang/lib/Frontend/SARIFDiagnostic.cpp
---- a/clang/lib/Frontend/SARIFDiagnostic.cpp
-+++ b/clang/lib/Frontend/SARIFDiagnostic.cpp
-@@ -163,7 +163,36 @@
++}
+diff -ruN --strip-trailing-cr a/llvm/lib/Target/X86/X86ISelLowering.cpp b/llvm/lib/Target/X86/X86ISelLowering.cpp
+--- a/llvm/lib/Target/X86/X86ISelLowering.cpp
++++ b/llvm/lib/Target/X86/X86ISelLowering.cpp
+@@ -45059,6 +45059,10 @@
+   unsigned NumElts = DemandedElts.getBitWidth();
  
- llvm::StringRef SARIFDiagnostic::emitFilename(StringRef Filename,
-                                               const SourceManager &SM) {
--  return SM.getNameForDiagnostic(Filename, DiagOpts);
-+  if (DiagOpts.AbsolutePath) {
-+    auto File = SM.getFileManager().getOptionalFileRef(Filename);
-+    if (File) {
-+      // We want to print a simplified absolute path, i. e. without "dots".
-+      //
-+      // The hardest part here are the paths like "<part1>/<link>/../<part2>".
-+      // On Unix-like systems, we cannot just collapse "<link>/..", because
-+      // paths are resolved sequentially, and, thereby, the path
-+      // "<part1>/<part2>" may point to a different location. That is why
-+      // we use FileManager::getCanonicalName(), which expands all indirections
-+      // with llvm::sys::fs::real_path() and caches the result.
-+      //
-+      // On the other hand, it would be better to preserve as much of the
-+      // original path as possible, because that helps a user to recognize it.
-+      // real_path() expands all links, which is sometimes too much. Luckily,
-+      // on Windows we can just use llvm::sys::path::remove_dots(), because,
-+      // on that system, both aforementioned paths point to the same place.
-+#ifdef _WIN32
-+      SmallString<256> TmpFilename = File->getName();
-+      llvm::sys::fs::make_absolute(TmpFilename);
-+      llvm::sys::path::native(TmpFilename);
-+      llvm::sys::path::remove_dots(TmpFilename, /* remove_dot_dot */ true);
-+      Filename = StringRef(TmpFilename.data(), TmpFilename.size());
-+#else
-+      Filename = SM.getFileManager().getCanonicalName(*File);
-+#endif
-+    }
-+  }
-+
-+  return Filename;
+   switch (Op.getOpcode()) {
++  case X86ISD::GlobalBaseReg:
++  case X86ISD::Wrapper:
++  case X86ISD::WrapperRIP:
++    return true;
+   case X86ISD::BLENDI:
+   case X86ISD::PSHUFD:
+   case X86ISD::UNPCKL:
+diff -ruN --strip-trailing-cr a/llvm/test/CodeGen/NVPTX/bf16x2-instructions.ll b/llvm/test/CodeGen/NVPTX/bf16x2-instructions.ll
+--- a/llvm/test/CodeGen/NVPTX/bf16x2-instructions.ll
++++ b/llvm/test/CodeGen/NVPTX/bf16x2-instructions.ll
+@@ -359,11 +359,12 @@
+ define <2 x bfloat> @test_fptrunc_2xfloat(<2 x float> %a) #0 {
+ ; CHECK-LABEL: test_fptrunc_2xfloat(
+ ; CHECK:       {
+-; CHECK-NEXT:    .reg .b64 %rd<2>;
++; CHECK-NEXT:    .reg .b32 %r<4>;
+ ; CHECK-EMPTY:
+ ; CHECK-NEXT:  // %bb.0:
+-; CHECK-NEXT:    ld.param.b64 %rd1, [test_fptrunc_2xfloat_param_0];
+-; CHECK-NEXT:    st.param.b32 [func_retval0], %rd1;
++; CHECK-NEXT:    ld.param.v2.b32 {%r1, %r2}, [test_fptrunc_2xfloat_param_0];
++; CHECK-NEXT:    cvt.rn.bf16x2.f32 %r3, %r2, %r1;
++; CHECK-NEXT:    st.param.b32 [func_retval0], %r3;
+ ; CHECK-NEXT:    ret;
+   %r = fptrunc <2 x float> %a to <2 x bfloat>
+   ret <2 x bfloat> %r
+diff -ruN --strip-trailing-cr a/llvm/test/CodeGen/NVPTX/f16x2-instructions.ll b/llvm/test/CodeGen/NVPTX/f16x2-instructions.ll
+--- a/llvm/test/CodeGen/NVPTX/f16x2-instructions.ll
++++ b/llvm/test/CodeGen/NVPTX/f16x2-instructions.ll
+@@ -45,11 +45,12 @@
+ define half @test_extract_0(<2 x half> %a) #0 {
+ ; CHECK-LABEL: test_extract_0(
+ ; CHECK:       {
+-; CHECK-NEXT:    .reg .b16 %rs<3>;
++; CHECK-NEXT:    .reg .b16 %rs<2>;
+ ; CHECK-NEXT:    .reg .b32 %r<2>;
+ ; CHECK-EMPTY:
+ ; CHECK-NEXT:  // %bb.0:
+-; CHECK-NEXT:    ld.param.v2.b16 {%rs1, %rs2}, [test_extract_0_param_0];
++; CHECK-NEXT:    ld.param.b32 %r1, [test_extract_0_param_0];
++; CHECK-NEXT:    { .reg .b16 tmp; mov.b32 {%rs1, tmp}, %r1; }
+ ; CHECK-NEXT:    st.param.b16 [func_retval0], %rs1;
+ ; CHECK-NEXT:    ret;
+   %e = extractelement <2 x half> %a, i32 0
+@@ -59,12 +60,13 @@
+ define half @test_extract_1(<2 x half> %a) #0 {
+ ; CHECK-LABEL: test_extract_1(
+ ; CHECK:       {
+-; CHECK-NEXT:    .reg .b16 %rs<3>;
++; CHECK-NEXT:    .reg .b16 %rs<2>;
+ ; CHECK-NEXT:    .reg .b32 %r<2>;
+ ; CHECK-EMPTY:
+ ; CHECK-NEXT:  // %bb.0:
+-; CHECK-NEXT:    ld.param.v2.b16 {%rs1, %rs2}, [test_extract_1_param_0];
+-; CHECK-NEXT:    st.param.b16 [func_retval0], %rs2;
++; CHECK-NEXT:    ld.param.b32 %r1, [test_extract_1_param_0];
++; CHECK-NEXT:    { .reg .b16 tmp; mov.b32 {tmp, %rs1}, %r1; }
++; CHECK-NEXT:    st.param.b16 [func_retval0], %rs1;
+ ; CHECK-NEXT:    ret;
+   %e = extractelement <2 x half> %a, i32 1
+   ret half %e
+@@ -80,8 +82,9 @@
+ ; CHECK-EMPTY:
+ ; CHECK-NEXT:  // %bb.0:
+ ; CHECK-NEXT:    ld.param.b64 %rd1, [test_extract_i_param_1];
+-; CHECK-NEXT:    ld.param.v2.b16 {%rs1, %rs2}, [test_extract_i_param_0];
++; CHECK-NEXT:    ld.param.b32 %r1, [test_extract_i_param_0];
+ ; CHECK-NEXT:    setp.eq.b64 %p1, %rd1, 0;
++; CHECK-NEXT:    mov.b32 {%rs1, %rs2}, %r1;
+ ; CHECK-NEXT:    selp.b16 %rs3, %rs1, %rs2, %p1;
+ ; CHECK-NEXT:    st.param.b16 [func_retval0], %rs3;
+ ; CHECK-NEXT:    ret;
+@@ -107,14 +110,16 @@
+ ; CHECK-NOF16-NEXT:    .reg .b32 %r<10>;
+ ; CHECK-NOF16-EMPTY:
+ ; CHECK-NOF16-NEXT:  // %bb.0:
+-; CHECK-NOF16-NEXT:    ld.param.v2.b16 {%rs1, %rs2}, [test_fadd_param_0];
+-; CHECK-NOF16-NEXT:    ld.param.v2.b16 {%rs3, %rs4}, [test_fadd_param_1];
+-; CHECK-NOF16-NEXT:    cvt.f32.f16 %r3, %rs4;
+-; CHECK-NOF16-NEXT:    cvt.f32.f16 %r4, %rs2;
++; CHECK-NOF16-NEXT:    ld.param.b32 %r2, [test_fadd_param_1];
++; CHECK-NOF16-NEXT:    ld.param.b32 %r1, [test_fadd_param_0];
++; CHECK-NOF16-NEXT:    mov.b32 {%rs1, %rs2}, %r2;
++; CHECK-NOF16-NEXT:    cvt.f32.f16 %r3, %rs2;
++; CHECK-NOF16-NEXT:    mov.b32 {%rs3, %rs4}, %r1;
++; CHECK-NOF16-NEXT:    cvt.f32.f16 %r4, %rs4;
+ ; CHECK-NOF16-NEXT:    add.rn.f32 %r5, %r4, %r3;
+ ; CHECK-NOF16-NEXT:    cvt.rn.f16.f32 %rs5, %r5;
+-; CHECK-NOF16-NEXT:    cvt.f32.f16 %r6, %rs3;
+-; CHECK-NOF16-NEXT:    cvt.f32.f16 %r7, %rs1;
++; CHECK-NOF16-NEXT:    cvt.f32.f16 %r6, %rs1;
++; CHECK-NOF16-NEXT:    cvt.f32.f16 %r7, %rs3;
+ ; CHECK-NOF16-NEXT:    add.rn.f32 %r8, %r7, %r6;
+ ; CHECK-NOF16-NEXT:    cvt.rn.f16.f32 %rs6, %r8;
+ ; CHECK-NOF16-NEXT:    mov.b32 %r9, {%rs6, %rs5};
+@@ -143,7 +148,8 @@
+ ; CHECK-NOF16-NEXT:    .reg .b32 %r<7>;
+ ; CHECK-NOF16-EMPTY:
+ ; CHECK-NOF16-NEXT:  // %bb.0:
+-; CHECK-NOF16-NEXT:    ld.param.v2.b16 {%rs1, %rs2}, [test_fadd_imm_0_param_0];
++; CHECK-NOF16-NEXT:    ld.param.b32 %r1, [test_fadd_imm_0_param_0];
++; CHECK-NOF16-NEXT:    mov.b32 {%rs1, %rs2}, %r1;
+ ; CHECK-NOF16-NEXT:    cvt.f32.f16 %r2, %rs2;
+ ; CHECK-NOF16-NEXT:    add.rn.f32 %r3, %r2, 0f40000000;
+ ; CHECK-NOF16-NEXT:    cvt.rn.f16.f32 %rs3, %r3;
+@@ -175,7 +181,8 @@
+ ; CHECK-NOF16-NEXT:    .reg .b32 %r<7>;
+ ; CHECK-NOF16-EMPTY:
+ ; CHECK-NOF16-NEXT:  // %bb.0:
+-; CHECK-NOF16-NEXT:    ld.param.v2.b16 {%rs1, %rs2}, [test_fadd_imm_1_param_0];
++; CHECK-NOF16-NEXT:    ld.param.b32 %r1, [test_fadd_imm_1_param_0];
++; CHECK-NOF16-NEXT:    mov.b32 {%rs1, %rs2}, %r1;
+ ; CHECK-NOF16-NEXT:    cvt.f32.f16 %r2, %rs2;
+ ; CHECK-NOF16-NEXT:    add.rn.f32 %r3, %r2, 0f40000000;
+ ; CHECK-NOF16-NEXT:    cvt.rn.f16.f32 %rs3, %r3;
+@@ -207,14 +214,16 @@
+ ; CHECK-NOF16-NEXT:    .reg .b32 %r<10>;
+ ; CHECK-NOF16-EMPTY:
+ ; CHECK-NOF16-NEXT:  // %bb.0:
+-; CHECK-NOF16-NEXT:    ld.param.v2.b16 {%rs1, %rs2}, [test_fsub_param_0];
+-; CHECK-NOF16-NEXT:    ld.param.v2.b16 {%rs3, %rs4}, [test_fsub_param_1];
+-; CHECK-NOF16-NEXT:    cvt.f32.f16 %r3, %rs4;
+-; CHECK-NOF16-NEXT:    cvt.f32.f16 %r4, %rs2;
++; CHECK-NOF16-NEXT:    ld.param.b32 %r2, [test_fsub_param_1];
++; CHECK-NOF16-NEXT:    ld.param.b32 %r1, [test_fsub_param_0];
++; CHECK-NOF16-NEXT:    mov.b32 {%rs1, %rs2}, %r2;
++; CHECK-NOF16-NEXT:    cvt.f32.f16 %r3, %rs2;
++; CHECK-NOF16-NEXT:    mov.b32 {%rs3, %rs4}, %r1;
++; CHECK-NOF16-NEXT:    cvt.f32.f16 %r4, %rs4;
+ ; CHECK-NOF16-NEXT:    sub.rn.f32 %r5, %r4, %r3;
+ ; CHECK-NOF16-NEXT:    cvt.rn.f16.f32 %rs5, %r5;
+-; CHECK-NOF16-NEXT:    cvt.f32.f16 %r6, %rs3;
+-; CHECK-NOF16-NEXT:    cvt.f32.f16 %r7, %rs1;
++; CHECK-NOF16-NEXT:    cvt.f32.f16 %r6, %rs1;
++; CHECK-NOF16-NEXT:    cvt.f32.f16 %r7, %rs3;
+ ; CHECK-NOF16-NEXT:    sub.rn.f32 %r8, %r7, %r6;
+ ; CHECK-NOF16-NEXT:    cvt.rn.f16.f32 %rs6, %r8;
+ ; CHECK-NOF16-NEXT:    mov.b32 %r9, {%rs6, %rs5};
+@@ -242,7 +251,8 @@
+ ; CHECK-NOF16-NEXT:    .reg .b32 %r<8>;
+ ; CHECK-NOF16-EMPTY:
+ ; CHECK-NOF16-NEXT:  // %bb.0:
+-; CHECK-NOF16-NEXT:    ld.param.v2.b16 {%rs1, %rs2}, [test_fneg_param_0];
++; CHECK-NOF16-NEXT:    ld.param.b32 %r1, [test_fneg_param_0];
++; CHECK-NOF16-NEXT:    mov.b32 {%rs1, %rs2}, %r1;
+ ; CHECK-NOF16-NEXT:    cvt.f32.f16 %r2, %rs2;
+ ; CHECK-NOF16-NEXT:    mov.b32 %r3, 0f00000000;
+ ; CHECK-NOF16-NEXT:    sub.rn.f32 %r4, %r3, %r2;
+@@ -275,14 +285,16 @@
+ ; CHECK-NOF16-NEXT:    .reg .b32 %r<10>;
+ ; CHECK-NOF16-EMPTY:
+ ; CHECK-NOF16-NEXT:  // %bb.0:
+-; CHECK-NOF16-NEXT:    ld.param.v2.b16 {%rs1, %rs2}, [test_fmul_param_0];
+-; CHECK-NOF16-NEXT:    ld.param.v2.b16 {%rs3, %rs4}, [test_fmul_param_1];
+-; CHECK-NOF16-NEXT:    cvt.f32.f16 %r3, %rs4;
+-; CHECK-NOF16-NEXT:    cvt.f32.f16 %r4, %rs2;
++; CHECK-NOF16-NEXT:    ld.param.b32 %r2, [test_fmul_param_1];
++; CHECK-NOF16-NEXT:    ld.param.b32 %r1, [test_fmul_param_0];
++; CHECK-NOF16-NEXT:    mov.b32 {%rs1, %rs2}, %r2;
++; CHECK-NOF16-NEXT:    cvt.f32.f16 %r3, %rs2;
++; CHECK-NOF16-NEXT:    mov.b32 {%rs3, %rs4}, %r1;
++; CHECK-NOF16-NEXT:    cvt.f32.f16 %r4, %rs4;
+ ; CHECK-NOF16-NEXT:    mul.rn.f32 %r5, %r4, %r3;
+ ; CHECK-NOF16-NEXT:    cvt.rn.f16.f32 %rs5, %r5;
+-; CHECK-NOF16-NEXT:    cvt.f32.f16 %r6, %rs3;
+-; CHECK-NOF16-NEXT:    cvt.f32.f16 %r7, %rs1;
++; CHECK-NOF16-NEXT:    cvt.f32.f16 %r6, %rs1;
++; CHECK-NOF16-NEXT:    cvt.f32.f16 %r7, %rs3;
+ ; CHECK-NOF16-NEXT:    mul.rn.f32 %r8, %r7, %r6;
+ ; CHECK-NOF16-NEXT:    cvt.rn.f16.f32 %rs6, %r8;
+ ; CHECK-NOF16-NEXT:    mov.b32 %r9, {%rs6, %rs5};
+@@ -299,14 +311,16 @@
+ ; CHECK-NEXT:    .reg .b32 %r<10>;
+ ; CHECK-EMPTY:
+ ; CHECK-NEXT:  // %bb.0:
+-; CHECK-NEXT:    ld.param.v2.b16 {%rs1, %rs2}, [test_fdiv_param_0];
+-; CHECK-NEXT:    ld.param.v2.b16 {%rs3, %rs4}, [test_fdiv_param_1];
+-; CHECK-NEXT:    cvt.f32.f16 %r3, %rs4;
+-; CHECK-NEXT:    cvt.f32.f16 %r4, %rs2;
++; CHECK-NEXT:    ld.param.b32 %r2, [test_fdiv_param_1];
++; CHECK-NEXT:    ld.param.b32 %r1, [test_fdiv_param_0];
++; CHECK-NEXT:    mov.b32 {%rs1, %rs2}, %r2;
++; CHECK-NEXT:    cvt.f32.f16 %r3, %rs2;
++; CHECK-NEXT:    mov.b32 {%rs3, %rs4}, %r1;
++; CHECK-NEXT:    cvt.f32.f16 %r4, %rs4;
+ ; CHECK-NEXT:    div.rn.f32 %r5, %r4, %r3;
+ ; CHECK-NEXT:    cvt.rn.f16.f32 %rs5, %r5;
+-; CHECK-NEXT:    cvt.f32.f16 %r6, %rs3;
+-; CHECK-NEXT:    cvt.f32.f16 %r7, %rs1;
++; CHECK-NEXT:    cvt.f32.f16 %r6, %rs1;
++; CHECK-NEXT:    cvt.f32.f16 %r7, %rs3;
+ ; CHECK-NEXT:    div.rn.f32 %r8, %r7, %r6;
+ ; CHECK-NEXT:    cvt.rn.f16.f32 %rs6, %r8;
+ ; CHECK-NEXT:    mov.b32 %r9, {%rs6, %rs5};
+@@ -331,10 +345,12 @@
+ ; CHECK-NEXT:    .reg .b32 %r<18>;
+ ; CHECK-EMPTY:
+ ; CHECK-NEXT:  // %bb.0:
+-; CHECK-NEXT:    ld.param.v2.b16 {%rs1, %rs2}, [test_frem_param_0];
+-; CHECK-NEXT:    ld.param.v2.b16 {%rs3, %rs4}, [test_frem_param_1];
+-; CHECK-NEXT:    cvt.f32.f16 %r3, %rs4;
+-; CHECK-NEXT:    cvt.f32.f16 %r4, %rs2;
++; CHECK-NEXT:    ld.param.b32 %r2, [test_frem_param_1];
++; CHECK-NEXT:    ld.param.b32 %r1, [test_frem_param_0];
++; CHECK-NEXT:    mov.b32 {%rs1, %rs2}, %r2;
++; CHECK-NEXT:    cvt.f32.f16 %r3, %rs2;
++; CHECK-NEXT:    mov.b32 {%rs3, %rs4}, %r1;
++; CHECK-NEXT:    cvt.f32.f16 %r4, %rs4;
+ ; CHECK-NEXT:    div.rn.f32 %r5, %r4, %r3;
+ ; CHECK-NEXT:    cvt.rzi.f32.f32 %r6, %r5;
+ ; CHECK-NEXT:    neg.f32 %r7, %r6;
+@@ -342,8 +358,8 @@
+ ; CHECK-NEXT:    testp.infinite.f32 %p1, %r3;
+ ; CHECK-NEXT:    selp.f32 %r9, %r4, %r8, %p1;
+ ; CHECK-NEXT:    cvt.rn.f16.f32 %rs5, %r9;
+-; CHECK-NEXT:    cvt.f32.f16 %r10, %rs3;
+-; CHECK-NEXT:    cvt.f32.f16 %r11, %rs1;
++; CHECK-NEXT:    cvt.f32.f16 %r10, %rs1;
++; CHECK-NEXT:    cvt.f32.f16 %r11, %rs3;
+ ; CHECK-NEXT:    div.rn.f32 %r12, %r11, %r10;
+ ; CHECK-NEXT:    cvt.rzi.f32.f32 %r13, %r12;
+ ; CHECK-NEXT:    neg.f32 %r14, %r13;
+@@ -535,11 +551,13 @@
+ ; CHECK-F16-NEXT:  // %bb.0:
+ ; CHECK-F16-NEXT:    ld.param.b32 %r4, [test_select_cc_param_3];
+ ; CHECK-F16-NEXT:    ld.param.b32 %r3, [test_select_cc_param_2];
+-; CHECK-F16-NEXT:    ld.param.v2.b16 {%rs1, %rs2}, [test_select_cc_param_0];
++; CHECK-F16-NEXT:    ld.param.b32 %r2, [test_select_cc_param_1];
++; CHECK-F16-NEXT:    ld.param.b32 %r1, [test_select_cc_param_0];
+ ; CHECK-F16-NEXT:    setp.neu.f16x2 %p1|%p2, %r3, %r4;
+-; CHECK-F16-NEXT:    ld.param.v2.b16 {%rs3, %rs4}, [test_select_cc_param_1];
+-; CHECK-F16-NEXT:    selp.b16 %rs5, %rs2, %rs4, %p2;
+-; CHECK-F16-NEXT:    selp.b16 %rs6, %rs1, %rs3, %p1;
++; CHECK-F16-NEXT:    mov.b32 {%rs1, %rs2}, %r2;
++; CHECK-F16-NEXT:    mov.b32 {%rs3, %rs4}, %r1;
++; CHECK-F16-NEXT:    selp.b16 %rs5, %rs4, %rs2, %p2;
++; CHECK-F16-NEXT:    selp.b16 %rs6, %rs3, %rs1, %p1;
+ ; CHECK-F16-NEXT:    st.param.v2.b16 [func_retval0], {%rs6, %rs5};
+ ; CHECK-F16-NEXT:    ret;
+ ;
+@@ -550,18 +568,22 @@
+ ; CHECK-NOF16-NEXT:    .reg .b32 %r<9>;
+ ; CHECK-NOF16-EMPTY:
+ ; CHECK-NOF16-NEXT:  // %bb.0:
+-; CHECK-NOF16-NEXT:    ld.param.v2.b16 {%rs1, %rs2}, [test_select_cc_param_0];
+-; CHECK-NOF16-NEXT:    ld.param.v2.b16 {%rs3, %rs4}, [test_select_cc_param_3];
+-; CHECK-NOF16-NEXT:    cvt.f32.f16 %r5, %rs3;
+-; CHECK-NOF16-NEXT:    ld.param.v2.b16 {%rs5, %rs6}, [test_select_cc_param_2];
+-; CHECK-NOF16-NEXT:    cvt.f32.f16 %r6, %rs5;
++; CHECK-NOF16-NEXT:    ld.param.b32 %r4, [test_select_cc_param_3];
++; CHECK-NOF16-NEXT:    ld.param.b32 %r3, [test_select_cc_param_2];
++; CHECK-NOF16-NEXT:    ld.param.b32 %r2, [test_select_cc_param_1];
++; CHECK-NOF16-NEXT:    ld.param.b32 %r1, [test_select_cc_param_0];
++; CHECK-NOF16-NEXT:    mov.b32 {%rs1, %rs2}, %r4;
++; CHECK-NOF16-NEXT:    cvt.f32.f16 %r5, %rs1;
++; CHECK-NOF16-NEXT:    mov.b32 {%rs3, %rs4}, %r3;
++; CHECK-NOF16-NEXT:    cvt.f32.f16 %r6, %rs3;
+ ; CHECK-NOF16-NEXT:    setp.neu.f32 %p1, %r6, %r5;
+-; CHECK-NOF16-NEXT:    cvt.f32.f16 %r7, %rs4;
+-; CHECK-NOF16-NEXT:    cvt.f32.f16 %r8, %rs6;
++; CHECK-NOF16-NEXT:    cvt.f32.f16 %r7, %rs2;
++; CHECK-NOF16-NEXT:    cvt.f32.f16 %r8, %rs4;
+ ; CHECK-NOF16-NEXT:    setp.neu.f32 %p2, %r8, %r7;
+-; CHECK-NOF16-NEXT:    ld.param.v2.b16 {%rs7, %rs8}, [test_select_cc_param_1];
+-; CHECK-NOF16-NEXT:    selp.b16 %rs9, %rs2, %rs8, %p2;
+-; CHECK-NOF16-NEXT:    selp.b16 %rs10, %rs1, %rs7, %p1;
++; CHECK-NOF16-NEXT:    mov.b32 {%rs5, %rs6}, %r2;
++; CHECK-NOF16-NEXT:    mov.b32 {%rs7, %rs8}, %r1;
++; CHECK-NOF16-NEXT:    selp.b16 %rs9, %rs8, %rs6, %p2;
++; CHECK-NOF16-NEXT:    selp.b16 %rs10, %rs7, %rs5, %p1;
+ ; CHECK-NOF16-NEXT:    st.param.v2.b16 [func_retval0], {%rs10, %rs9};
+ ; CHECK-NOF16-NEXT:    ret;
+   %cc = fcmp une <2 x half> %c, %d
+@@ -579,11 +601,13 @@
+ ; CHECK-F16-NEXT:  // %bb.0:
+ ; CHECK-F16-NEXT:    ld.param.b32 %r2, [test_select_cc_f32_f16_param_3];
+ ; CHECK-F16-NEXT:    ld.param.b32 %r1, [test_select_cc_f32_f16_param_2];
+-; CHECK-F16-NEXT:    ld.param.v2.b32 {%r3, %r4}, [test_select_cc_f32_f16_param_0];
++; CHECK-F16-NEXT:    ld.param.b64 %rd2, [test_select_cc_f32_f16_param_1];
++; CHECK-F16-NEXT:    ld.param.b64 %rd1, [test_select_cc_f32_f16_param_0];
+ ; CHECK-F16-NEXT:    setp.neu.f16x2 %p1|%p2, %r1, %r2;
+-; CHECK-F16-NEXT:    ld.param.v2.b32 {%r5, %r6}, [test_select_cc_f32_f16_param_1];
+-; CHECK-F16-NEXT:    selp.f32 %r7, %r4, %r6, %p2;
+-; CHECK-F16-NEXT:    selp.f32 %r8, %r3, %r5, %p1;
++; CHECK-F16-NEXT:    mov.b64 {%r3, %r4}, %rd2;
++; CHECK-F16-NEXT:    mov.b64 {%r5, %r6}, %rd1;
++; CHECK-F16-NEXT:    selp.f32 %r7, %r6, %r4, %p2;
++; CHECK-F16-NEXT:    selp.f32 %r8, %r5, %r3, %p1;
+ ; CHECK-F16-NEXT:    st.param.v2.b32 [func_retval0], {%r8, %r7};
+ ; CHECK-F16-NEXT:    ret;
+ ;
+@@ -595,18 +619,22 @@
+ ; CHECK-NOF16-NEXT:    .reg .b64 %rd<3>;
+ ; CHECK-NOF16-EMPTY:
+ ; CHECK-NOF16-NEXT:  // %bb.0:
+-; CHECK-NOF16-NEXT:    ld.param.v2.b32 {%r3, %r4}, [test_select_cc_f32_f16_param_0];
+-; CHECK-NOF16-NEXT:    ld.param.v2.b16 {%rs1, %rs2}, [test_select_cc_f32_f16_param_3];
+-; CHECK-NOF16-NEXT:    cvt.f32.f16 %r5, %rs1;
+-; CHECK-NOF16-NEXT:    ld.param.v2.b16 {%rs3, %rs4}, [test_select_cc_f32_f16_param_2];
+-; CHECK-NOF16-NEXT:    cvt.f32.f16 %r6, %rs3;
+-; CHECK-NOF16-NEXT:    setp.neu.f32 %p1, %r6, %r5;
+-; CHECK-NOF16-NEXT:    cvt.f32.f16 %r7, %rs2;
+-; CHECK-NOF16-NEXT:    cvt.f32.f16 %r8, %rs4;
+-; CHECK-NOF16-NEXT:    setp.neu.f32 %p2, %r8, %r7;
+-; CHECK-NOF16-NEXT:    ld.param.v2.b32 {%r9, %r10}, [test_select_cc_f32_f16_param_1];
+-; CHECK-NOF16-NEXT:    selp.f32 %r11, %r4, %r10, %p2;
+-; CHECK-NOF16-NEXT:    selp.f32 %r12, %r3, %r9, %p1;
++; CHECK-NOF16-NEXT:    ld.param.b32 %r2, [test_select_cc_f32_f16_param_3];
++; CHECK-NOF16-NEXT:    ld.param.b32 %r1, [test_select_cc_f32_f16_param_2];
++; CHECK-NOF16-NEXT:    ld.param.b64 %rd2, [test_select_cc_f32_f16_param_1];
++; CHECK-NOF16-NEXT:    ld.param.b64 %rd1, [test_select_cc_f32_f16_param_0];
++; CHECK-NOF16-NEXT:    mov.b32 {%rs1, %rs2}, %r2;
++; CHECK-NOF16-NEXT:    cvt.f32.f16 %r3, %rs1;
++; CHECK-NOF16-NEXT:    mov.b32 {%rs3, %rs4}, %r1;
++; CHECK-NOF16-NEXT:    cvt.f32.f16 %r4, %rs3;
++; CHECK-NOF16-NEXT:    setp.neu.f32 %p1, %r4, %r3;
++; CHECK-NOF16-NEXT:    cvt.f32.f16 %r5, %rs2;
++; CHECK-NOF16-NEXT:    cvt.f32.f16 %r6, %rs4;
++; CHECK-NOF16-NEXT:    setp.neu.f32 %p2, %r6, %r5;
++; CHECK-NOF16-NEXT:    mov.b64 {%r7, %r8}, %rd2;
++; CHECK-NOF16-NEXT:    mov.b64 {%r9, %r10}, %rd1;
++; CHECK-NOF16-NEXT:    selp.f32 %r11, %r10, %r8, %p2;
++; CHECK-NOF16-NEXT:    selp.f32 %r12, %r9, %r7, %p1;
+ ; CHECK-NOF16-NEXT:    st.param.v2.b32 [func_retval0], {%r12, %r11};
+ ; CHECK-NOF16-NEXT:    ret;
+                                            <2 x half> %c, <2 x half> %d) #0 {
+@@ -624,14 +652,18 @@
+ ; CHECK-NEXT:    .reg .b64 %rd<3>;
+ ; CHECK-EMPTY:
+ ; CHECK-NEXT:  // %bb.0:
+-; CHECK-NEXT:    ld.param.v2.b16 {%rs1, %rs2}, [test_select_cc_f16_f32_param_0];
+-; CHECK-NEXT:    ld.param.v2.b32 {%r3, %r4}, [test_select_cc_f16_f32_param_2];
+-; CHECK-NEXT:    ld.param.v2.b32 {%r5, %r6}, [test_select_cc_f16_f32_param_3];
+-; CHECK-NEXT:    setp.neu.f32 %p1, %r3, %r5;
+-; CHECK-NEXT:    setp.neu.f32 %p2, %r4, %r6;
+-; CHECK-NEXT:    ld.param.v2.b16 {%rs3, %rs4}, [test_select_cc_f16_f32_param_1];
+-; CHECK-NEXT:    selp.b16 %rs5, %rs2, %rs4, %p2;
+-; CHECK-NEXT:    selp.b16 %rs6, %rs1, %rs3, %p1;
++; CHECK-NEXT:    ld.param.b64 %rd2, [test_select_cc_f16_f32_param_3];
++; CHECK-NEXT:    ld.param.b64 %rd1, [test_select_cc_f16_f32_param_2];
++; CHECK-NEXT:    ld.param.b32 %r2, [test_select_cc_f16_f32_param_1];
++; CHECK-NEXT:    ld.param.b32 %r1, [test_select_cc_f16_f32_param_0];
++; CHECK-NEXT:    mov.b64 {%r3, %r4}, %rd2;
++; CHECK-NEXT:    mov.b64 {%r5, %r6}, %rd1;
++; CHECK-NEXT:    setp.neu.f32 %p1, %r5, %r3;
++; CHECK-NEXT:    setp.neu.f32 %p2, %r6, %r4;
++; CHECK-NEXT:    mov.b32 {%rs1, %rs2}, %r2;
++; CHECK-NEXT:    mov.b32 {%rs3, %rs4}, %r1;
++; CHECK-NEXT:    selp.b16 %rs5, %rs4, %rs2, %p2;
++; CHECK-NEXT:    selp.b16 %rs6, %rs3, %rs1, %p1;
+ ; CHECK-NEXT:    st.param.v2.b16 [func_retval0], {%rs6, %rs5};
+ ; CHECK-NEXT:    ret;
+                                           <2 x float> %c, <2 x float> %d) #0 {
+@@ -664,13 +696,15 @@
+ ; CHECK-NOF16-NEXT:    .reg .b32 %r<7>;
+ ; CHECK-NOF16-EMPTY:
+ ; CHECK-NOF16-NEXT:  // %bb.0:
+-; CHECK-NOF16-NEXT:    ld.param.v2.b16 {%rs1, %rs2}, [test_fcmp_une_param_0];
+-; CHECK-NOF16-NEXT:    ld.param.v2.b16 {%rs3, %rs4}, [test_fcmp_une_param_1];
+-; CHECK-NOF16-NEXT:    cvt.f32.f16 %r3, %rs4;
+-; CHECK-NOF16-NEXT:    cvt.f32.f16 %r4, %rs2;
++; CHECK-NOF16-NEXT:    ld.param.b32 %r2, [test_fcmp_une_param_1];
++; CHECK-NOF16-NEXT:    ld.param.b32 %r1, [test_fcmp_une_param_0];
++; CHECK-NOF16-NEXT:    mov.b32 {%rs1, %rs2}, %r2;
++; CHECK-NOF16-NEXT:    cvt.f32.f16 %r3, %rs2;
++; CHECK-NOF16-NEXT:    mov.b32 {%rs3, %rs4}, %r1;
++; CHECK-NOF16-NEXT:    cvt.f32.f16 %r4, %rs4;
+ ; CHECK-NOF16-NEXT:    setp.neu.f32 %p1, %r4, %r3;
+-; CHECK-NOF16-NEXT:    cvt.f32.f16 %r5, %rs3;
+-; CHECK-NOF16-NEXT:    cvt.f32.f16 %r6, %rs1;
++; CHECK-NOF16-NEXT:    cvt.f32.f16 %r5, %rs1;
++; CHECK-NOF16-NEXT:    cvt.f32.f16 %r6, %rs3;
+ ; CHECK-NOF16-NEXT:    setp.neu.f32 %p2, %r6, %r5;
+ ; CHECK-NOF16-NEXT:    selp.b16 %rs5, -1, 0, %p2;
+ ; CHECK-NOF16-NEXT:    st.param.b8 [func_retval0], %rs5;
+@@ -705,13 +739,15 @@
+ ; CHECK-NOF16-NEXT:    .reg .b32 %r<7>;
+ ; CHECK-NOF16-EMPTY:
+ ; CHECK-NOF16-NEXT:  // %bb.0:
+-; CHECK-NOF16-NEXT:    ld.param.v2.b16 {%rs1, %rs2}, [test_fcmp_ueq_param_0];
+-; CHECK-NOF16-NEXT:    ld.param.v2.b16 {%rs3, %rs4}, [test_fcmp_ueq_param_1];
+-; CHECK-NOF16-NEXT:    cvt.f32.f16 %r3, %rs4;
+-; CHECK-NOF16-NEXT:    cvt.f32.f16 %r4, %rs2;
++; CHECK-NOF16-NEXT:    ld.param.b32 %r2, [test_fcmp_ueq_param_1];
++; CHECK-NOF16-NEXT:    ld.param.b32 %r1, [test_fcmp_ueq_param_0];
++; CHECK-NOF16-NEXT:    mov.b32 {%rs1, %rs2}, %r2;
++; CHECK-NOF16-NEXT:    cvt.f32.f16 %r3, %rs2;
++; CHECK-NOF16-NEXT:    mov.b32 {%rs3, %rs4}, %r1;
++; CHECK-NOF16-NEXT:    cvt.f32.f16 %r4, %rs4;
+ ; CHECK-NOF16-NEXT:    setp.equ.f32 %p1, %r4, %r3;
+-; CHECK-NOF16-NEXT:    cvt.f32.f16 %r5, %rs3;
+-; CHECK-NOF16-NEXT:    cvt.f32.f16 %r6, %rs1;
++; CHECK-NOF16-NEXT:    cvt.f32.f16 %r5, %rs1;
++; CHECK-NOF16-NEXT:    cvt.f32.f16 %r6, %rs3;
+ ; CHECK-NOF16-NEXT:    setp.equ.f32 %p2, %r6, %r5;
+ ; CHECK-NOF16-NEXT:    selp.b16 %rs5, -1, 0, %p2;
+ ; CHECK-NOF16-NEXT:    st.param.b8 [func_retval0], %rs5;
+@@ -746,13 +782,15 @@
+ ; CHECK-NOF16-NEXT:    .reg .b32 %r<7>;
+ ; CHECK-NOF16-EMPTY:
+ ; CHECK-NOF16-NEXT:  // %bb.0:
+-; CHECK-NOF16-NEXT:    ld.param.v2.b16 {%rs1, %rs2}, [test_fcmp_ugt_param_0];
+-; CHECK-NOF16-NEXT:    ld.param.v2.b16 {%rs3, %rs4}, [test_fcmp_ugt_param_1];
+-; CHECK-NOF16-NEXT:    cvt.f32.f16 %r3, %rs4;
+-; CHECK-NOF16-NEXT:    cvt.f32.f16 %r4, %rs2;
++; CHECK-NOF16-NEXT:    ld.param.b32 %r2, [test_fcmp_ugt_param_1];
++; CHECK-NOF16-NEXT:    ld.param.b32 %r1, [test_fcmp_ugt_param_0];
++; CHECK-NOF16-NEXT:    mov.b32 {%rs1, %rs2}, %r2;
++; CHECK-NOF16-NEXT:    cvt.f32.f16 %r3, %rs2;
++; CHECK-NOF16-NEXT:    mov.b32 {%rs3, %rs4}, %r1;
++; CHECK-NOF16-NEXT:    cvt.f32.f16 %r4, %rs4;
+ ; CHECK-NOF16-NEXT:    setp.gtu.f32 %p1, %r4, %r3;
+-; CHECK-NOF16-NEXT:    cvt.f32.f16 %r5, %rs3;
+-; CHECK-NOF16-NEXT:    cvt.f32.f16 %r6, %rs1;
++; CHECK-NOF16-NEXT:    cvt.f32.f16 %r5, %rs1;
++; CHECK-NOF16-NEXT:    cvt.f32.f16 %r6, %rs3;
+ ; CHECK-NOF16-NEXT:    setp.gtu.f32 %p2, %r6, %r5;
+ ; CHECK-NOF16-NEXT:    selp.b16 %rs5, -1, 0, %p2;
+ ; CHECK-NOF16-NEXT:    st.param.b8 [func_retval0], %rs5;
+@@ -787,13 +825,15 @@
+ ; CHECK-NOF16-NEXT:    .reg .b32 %r<7>;
+ ; CHECK-NOF16-EMPTY:
+ ; CHECK-NOF16-NEXT:  // %bb.0:
+-; CHECK-NOF16-NEXT:    ld.param.v2.b16 {%rs1, %rs2}, [test_fcmp_uge_param_0];
+-; CHECK-NOF16-NEXT:    ld.param.v2.b16 {%rs3, %rs4}, [test_fcmp_uge_param_1];
+-; CHECK-NOF16-NEXT:    cvt.f32.f16 %r3, %rs4;
+-; CHECK-NOF16-NEXT:    cvt.f32.f16 %r4, %rs2;
++; CHECK-NOF16-NEXT:    ld.param.b32 %r2, [test_fcmp_uge_param_1];
++; CHECK-NOF16-NEXT:    ld.param.b32 %r1, [test_fcmp_uge_param_0];
++; CHECK-NOF16-NEXT:    mov.b32 {%rs1, %rs2}, %r2;
++; CHECK-NOF16-NEXT:    cvt.f32.f16 %r3, %rs2;
++; CHECK-NOF16-NEXT:    mov.b32 {%rs3, %rs4}, %r1;
++; CHECK-NOF16-NEXT:    cvt.f32.f16 %r4, %rs4;
+ ; CHECK-NOF16-NEXT:    setp.geu.f32 %p1, %r4, %r3;
+-; CHECK-NOF16-NEXT:    cvt.f32.f16 %r5, %rs3;
+-; CHECK-NOF16-NEXT:    cvt.f32.f16 %r6, %rs1;
++; CHECK-NOF16-NEXT:    cvt.f32.f16 %r5, %rs1;
++; CHECK-NOF16-NEXT:    cvt.f32.f16 %r6, %rs3;
+ ; CHECK-NOF16-NEXT:    setp.geu.f32 %p2, %r6, %r5;
+ ; CHECK-NOF16-NEXT:    selp.b16 %rs5, -1, 0, %p2;
+ ; CHECK-NOF16-NEXT:    st.param.b8 [func_retval0], %rs5;
+@@ -828,13 +868,15 @@
+ ; CHECK-NOF16-NEXT:    .reg .b32 %r<7>;
+ ; CHECK-NOF16-EMPTY:
+ ; CHECK-NOF16-NEXT:  // %bb.0:
+-; CHECK-NOF16-NEXT:    ld.param.v2.b16 {%rs1, %rs2}, [test_fcmp_ult_param_0];
+-; CHECK-NOF16-NEXT:    ld.param.v2.b16 {%rs3, %rs4}, [test_fcmp_ult_param_1];
+-; CHECK-NOF16-NEXT:    cvt.f32.f16 %r3, %rs4;
+-; CHECK-NOF16-NEXT:    cvt.f32.f16 %r4, %rs2;
++; CHECK-NOF16-NEXT:    ld.param.b32 %r2, [test_fcmp_ult_param_1];
++; CHECK-NOF16-NEXT:    ld.param.b32 %r1, [test_fcmp_ult_param_0];
++; CHECK-NOF16-NEXT:    mov.b32 {%rs1, %rs2}, %r2;
++; CHECK-NOF16-NEXT:    cvt.f32.f16 %r3, %rs2;
++; CHECK-NOF16-NEXT:    mov.b32 {%rs3, %rs4}, %r1;
++; CHECK-NOF16-NEXT:    cvt.f32.f16 %r4, %rs4;
+ ; CHECK-NOF16-NEXT:    setp.ltu.f32 %p1, %r4, %r3;
+-; CHECK-NOF16-NEXT:    cvt.f32.f16 %r5, %rs3;
+-; CHECK-NOF16-NEXT:    cvt.f32.f16 %r6, %rs1;
++; CHECK-NOF16-NEXT:    cvt.f32.f16 %r5, %rs1;
++; CHECK-NOF16-NEXT:    cvt.f32.f16 %r6, %rs3;
+ ; CHECK-NOF16-NEXT:    setp.ltu.f32 %p2, %r6, %r5;
+ ; CHECK-NOF16-NEXT:    selp.b16 %rs5, -1, 0, %p2;
+ ; CHECK-NOF16-NEXT:    st.param.b8 [func_retval0], %rs5;
+@@ -869,13 +911,15 @@
+ ; CHECK-NOF16-NEXT:    .reg .b32 %r<7>;
+ ; CHECK-NOF16-EMPTY:
+ ; CHECK-NOF16-NEXT:  // %bb.0:
+-; CHECK-NOF16-NEXT:    ld.param.v2.b16 {%rs1, %rs2}, [test_fcmp_ule_param_0];
+-; CHECK-NOF16-NEXT:    ld.param.v2.b16 {%rs3, %rs4}, [test_fcmp_ule_param_1];
+-; CHECK-NOF16-NEXT:    cvt.f32.f16 %r3, %rs4;
+-; CHECK-NOF16-NEXT:    cvt.f32.f16 %r4, %rs2;
++; CHECK-NOF16-NEXT:    ld.param.b32 %r2, [test_fcmp_ule_param_1];
++; CHECK-NOF16-NEXT:    ld.param.b32 %r1, [test_fcmp_ule_param_0];
++; CHECK-NOF16-NEXT:    mov.b32 {%rs1, %rs2}, %r2;
++; CHECK-NOF16-NEXT:    cvt.f32.f16 %r3, %rs2;
++; CHECK-NOF16-NEXT:    mov.b32 {%rs3, %rs4}, %r1;
++; CHECK-NOF16-NEXT:    cvt.f32.f16 %r4, %rs4;
+ ; CHECK-NOF16-NEXT:    setp.leu.f32 %p1, %r4, %r3;
+-; CHECK-NOF16-NEXT:    cvt.f32.f16 %r5, %rs3;
+-; CHECK-NOF16-NEXT:    cvt.f32.f16 %r6, %rs1;
++; CHECK-NOF16-NEXT:    cvt.f32.f16 %r5, %rs1;
++; CHECK-NOF16-NEXT:    cvt.f32.f16 %r6, %rs3;
+ ; CHECK-NOF16-NEXT:    setp.leu.f32 %p2, %r6, %r5;
+ ; CHECK-NOF16-NEXT:    selp.b16 %rs5, -1, 0, %p2;
+ ; CHECK-NOF16-NEXT:    st.param.b8 [func_retval0], %rs5;
+@@ -911,13 +955,15 @@
+ ; CHECK-NOF16-NEXT:    .reg .b32 %r<7>;
+ ; CHECK-NOF16-EMPTY:
+ ; CHECK-NOF16-NEXT:  // %bb.0:
+-; CHECK-NOF16-NEXT:    ld.param.v2.b16 {%rs1, %rs2}, [test_fcmp_uno_param_0];
+-; CHECK-NOF16-NEXT:    ld.param.v2.b16 {%rs3, %rs4}, [test_fcmp_uno_param_1];
+-; CHECK-NOF16-NEXT:    cvt.f32.f16 %r3, %rs4;
+-; CHECK-NOF16-NEXT:    cvt.f32.f16 %r4, %rs2;
++; CHECK-NOF16-NEXT:    ld.param.b32 %r2, [test_fcmp_uno_param_1];
++; CHECK-NOF16-NEXT:    ld.param.b32 %r1, [test_fcmp_uno_param_0];
++; CHECK-NOF16-NEXT:    mov.b32 {%rs1, %rs2}, %r2;
++; CHECK-NOF16-NEXT:    cvt.f32.f16 %r3, %rs2;
++; CHECK-NOF16-NEXT:    mov.b32 {%rs3, %rs4}, %r1;
++; CHECK-NOF16-NEXT:    cvt.f32.f16 %r4, %rs4;
+ ; CHECK-NOF16-NEXT:    setp.nan.f32 %p1, %r4, %r3;
+-; CHECK-NOF16-NEXT:    cvt.f32.f16 %r5, %rs3;
+-; CHECK-NOF16-NEXT:    cvt.f32.f16 %r6, %rs1;
++; CHECK-NOF16-NEXT:    cvt.f32.f16 %r5, %rs1;
++; CHECK-NOF16-NEXT:    cvt.f32.f16 %r6, %rs3;
+ ; CHECK-NOF16-NEXT:    setp.nan.f32 %p2, %r6, %r5;
+ ; CHECK-NOF16-NEXT:    selp.b16 %rs5, -1, 0, %p2;
+ ; CHECK-NOF16-NEXT:    st.param.b8 [func_retval0], %rs5;
+@@ -952,13 +998,15 @@
+ ; CHECK-NOF16-NEXT:    .reg .b32 %r<7>;
+ ; CHECK-NOF16-EMPTY:
+ ; CHECK-NOF16-NEXT:  // %bb.0:
+-; CHECK-NOF16-NEXT:    ld.param.v2.b16 {%rs1, %rs2}, [test_fcmp_one_param_0];
+-; CHECK-NOF16-NEXT:    ld.param.v2.b16 {%rs3, %rs4}, [test_fcmp_one_param_1];
+-; CHECK-NOF16-NEXT:    cvt.f32.f16 %r3, %rs4;
+-; CHECK-NOF16-NEXT:    cvt.f32.f16 %r4, %rs2;
++; CHECK-NOF16-NEXT:    ld.param.b32 %r2, [test_fcmp_one_param_1];
++; CHECK-NOF16-NEXT:    ld.param.b32 %r1, [test_fcmp_one_param_0];
++; CHECK-NOF16-NEXT:    mov.b32 {%rs1, %rs2}, %r2;
++; CHECK-NOF16-NEXT:    cvt.f32.f16 %r3, %rs2;
++; CHECK-NOF16-NEXT:    mov.b32 {%rs3, %rs4}, %r1;
++; CHECK-NOF16-NEXT:    cvt.f32.f16 %r4, %rs4;
+ ; CHECK-NOF16-NEXT:    setp.ne.f32 %p1, %r4, %r3;
+-; CHECK-NOF16-NEXT:    cvt.f32.f16 %r5, %rs3;
+-; CHECK-NOF16-NEXT:    cvt.f32.f16 %r6, %rs1;
++; CHECK-NOF16-NEXT:    cvt.f32.f16 %r5, %rs1;
++; CHECK-NOF16-NEXT:    cvt.f32.f16 %r6, %rs3;
+ ; CHECK-NOF16-NEXT:    setp.ne.f32 %p2, %r6, %r5;
+ ; CHECK-NOF16-NEXT:    selp.b16 %rs5, -1, 0, %p2;
+ ; CHECK-NOF16-NEXT:    st.param.b8 [func_retval0], %rs5;
+@@ -993,13 +1041,15 @@
+ ; CHECK-NOF16-NEXT:    .reg .b32 %r<7>;
+ ; CHECK-NOF16-EMPTY:
+ ; CHECK-NOF16-NEXT:  // %bb.0:
+-; CHECK-NOF16-NEXT:    ld.param.v2.b16 {%rs1, %rs2}, [test_fcmp_oeq_param_0];
+-; CHECK-NOF16-NEXT:    ld.param.v2.b16 {%rs3, %rs4}, [test_fcmp_oeq_param_1];
+-; CHECK-NOF16-NEXT:    cvt.f32.f16 %r3, %rs4;
+-; CHECK-NOF16-NEXT:    cvt.f32.f16 %r4, %rs2;
++; CHECK-NOF16-NEXT:    ld.param.b32 %r2, [test_fcmp_oeq_param_1];
++; CHECK-NOF16-NEXT:    ld.param.b32 %r1, [test_fcmp_oeq_param_0];
++; CHECK-NOF16-NEXT:    mov.b32 {%rs1, %rs2}, %r2;
++; CHECK-NOF16-NEXT:    cvt.f32.f16 %r3, %rs2;
++; CHECK-NOF16-NEXT:    mov.b32 {%rs3, %rs4}, %r1;
++; CHECK-NOF16-NEXT:    cvt.f32.f16 %r4, %rs4;
+ ; CHECK-NOF16-NEXT:    setp.eq.f32 %p1, %r4, %r3;
+-; CHECK-NOF16-NEXT:    cvt.f32.f16 %r5, %rs3;
+-; CHECK-NOF16-NEXT:    cvt.f32.f16 %r6, %rs1;
++; CHECK-NOF16-NEXT:    cvt.f32.f16 %r5, %rs1;
++; CHECK-NOF16-NEXT:    cvt.f32.f16 %r6, %rs3;
+ ; CHECK-NOF16-NEXT:    setp.eq.f32 %p2, %r6, %r5;
+ ; CHECK-NOF16-NEXT:    selp.b16 %rs5, -1, 0, %p2;
+ ; CHECK-NOF16-NEXT:    st.param.b8 [func_retval0], %rs5;
+@@ -1034,13 +1084,15 @@
+ ; CHECK-NOF16-NEXT:    .reg .b32 %r<7>;
+ ; CHECK-NOF16-EMPTY:
+ ; CHECK-NOF16-NEXT:  // %bb.0:
+-; CHECK-NOF16-NEXT:    ld.param.v2.b16 {%rs1, %rs2}, [test_fcmp_ogt_param_0];
+-; CHECK-NOF16-NEXT:    ld.param.v2.b16 {%rs3, %rs4}, [test_fcmp_ogt_param_1];
+-; CHECK-NOF16-NEXT:    cvt.f32.f16 %r3, %rs4;
+-; CHECK-NOF16-NEXT:    cvt.f32.f16 %r4, %rs2;
++; CHECK-NOF16-NEXT:    ld.param.b32 %r2, [test_fcmp_ogt_param_1];
++; CHECK-NOF16-NEXT:    ld.param.b32 %r1, [test_fcmp_ogt_param_0];
++; CHECK-NOF16-NEXT:    mov.b32 {%rs1, %rs2}, %r2;
++; CHECK-NOF16-NEXT:    cvt.f32.f16 %r3, %rs2;
++; CHECK-NOF16-NEXT:    mov.b32 {%rs3, %rs4}, %r1;
++; CHECK-NOF16-NEXT:    cvt.f32.f16 %r4, %rs4;
+ ; CHECK-NOF16-NEXT:    setp.gt.f32 %p1, %r4, %r3;
+-; CHECK-NOF16-NEXT:    cvt.f32.f16 %r5, %rs3;
+-; CHECK-NOF16-NEXT:    cvt.f32.f16 %r6, %rs1;
++; CHECK-NOF16-NEXT:    cvt.f32.f16 %r5, %rs1;
++; CHECK-NOF16-NEXT:    cvt.f32.f16 %r6, %rs3;
+ ; CHECK-NOF16-NEXT:    setp.gt.f32 %p2, %r6, %r5;
+ ; CHECK-NOF16-NEXT:    selp.b16 %rs5, -1, 0, %p2;
+ ; CHECK-NOF16-NEXT:    st.param.b8 [func_retval0], %rs5;
+@@ -1075,13 +1127,15 @@
+ ; CHECK-NOF16-NEXT:    .reg .b32 %r<7>;
+ ; CHECK-NOF16-EMPTY:
+ ; CHECK-NOF16-NEXT:  // %bb.0:
+-; CHECK-NOF16-NEXT:    ld.param.v2.b16 {%rs1, %rs2}, [test_fcmp_oge_param_0];
+-; CHECK-NOF16-NEXT:    ld.param.v2.b16 {%rs3, %rs4}, [test_fcmp_oge_param_1];
+-; CHECK-NOF16-NEXT:    cvt.f32.f16 %r3, %rs4;
+-; CHECK-NOF16-NEXT:    cvt.f32.f16 %r4, %rs2;
++; CHECK-NOF16-NEXT:    ld.param.b32 %r2, [test_fcmp_oge_param_1];
++; CHECK-NOF16-NEXT:    ld.param.b32 %r1, [test_fcmp_oge_param_0];
++; CHECK-NOF16-NEXT:    mov.b32 {%rs1, %rs2}, %r2;
++; CHECK-NOF16-NEXT:    cvt.f32.f16 %r3, %rs2;
++; CHECK-NOF16-NEXT:    mov.b32 {%rs3, %rs4}, %r1;
++; CHECK-NOF16-NEXT:    cvt.f32.f16 %r4, %rs4;
+ ; CHECK-NOF16-NEXT:    setp.ge.f32 %p1, %r4, %r3;
+-; CHECK-NOF16-NEXT:    cvt.f32.f16 %r5, %rs3;
+-; CHECK-NOF16-NEXT:    cvt.f32.f16 %r6, %rs1;
++; CHECK-NOF16-NEXT:    cvt.f32.f16 %r5, %rs1;
++; CHECK-NOF16-NEXT:    cvt.f32.f16 %r6, %rs3;
+ ; CHECK-NOF16-NEXT:    setp.ge.f32 %p2, %r6, %r5;
+ ; CHECK-NOF16-NEXT:    selp.b16 %rs5, -1, 0, %p2;
+ ; CHECK-NOF16-NEXT:    st.param.b8 [func_retval0], %rs5;
+@@ -1116,13 +1170,15 @@
+ ; CHECK-NOF16-NEXT:    .reg .b32 %r<7>;
+ ; CHECK-NOF16-EMPTY:
+ ; CHECK-NOF16-NEXT:  // %bb.0:
+-; CHECK-NOF16-NEXT:    ld.param.v2.b16 {%rs1, %rs2}, [test_fcmp_olt_param_0];
+-; CHECK-NOF16-NEXT:    ld.param.v2.b16 {%rs3, %rs4}, [test_fcmp_olt_param_1];
+-; CHECK-NOF16-NEXT:    cvt.f32.f16 %r3, %rs4;
+-; CHECK-NOF16-NEXT:    cvt.f32.f16 %r4, %rs2;
++; CHECK-NOF16-NEXT:    ld.param.b32 %r2, [test_fcmp_olt_param_1];
++; CHECK-NOF16-NEXT:    ld.param.b32 %r1, [test_fcmp_olt_param_0];
++; CHECK-NOF16-NEXT:    mov.b32 {%rs1, %rs2}, %r2;
++; CHECK-NOF16-NEXT:    cvt.f32.f16 %r3, %rs2;
++; CHECK-NOF16-NEXT:    mov.b32 {%rs3, %rs4}, %r1;
++; CHECK-NOF16-NEXT:    cvt.f32.f16 %r4, %rs4;
+ ; CHECK-NOF16-NEXT:    setp.lt.f32 %p1, %r4, %r3;
+-; CHECK-NOF16-NEXT:    cvt.f32.f16 %r5, %rs3;
+-; CHECK-NOF16-NEXT:    cvt.f32.f16 %r6, %rs1;
++; CHECK-NOF16-NEXT:    cvt.f32.f16 %r5, %rs1;
++; CHECK-NOF16-NEXT:    cvt.f32.f16 %r6, %rs3;
+ ; CHECK-NOF16-NEXT:    setp.lt.f32 %p2, %r6, %r5;
+ ; CHECK-NOF16-NEXT:    selp.b16 %rs5, -1, 0, %p2;
+ ; CHECK-NOF16-NEXT:    st.param.b8 [func_retval0], %rs5;
+@@ -1157,13 +1213,15 @@
+ ; CHECK-NOF16-NEXT:    .reg .b32 %r<7>;
+ ; CHECK-NOF16-EMPTY:
+ ; CHECK-NOF16-NEXT:  // %bb.0:
+-; CHECK-NOF16-NEXT:    ld.param.v2.b16 {%rs1, %rs2}, [test_fcmp_ole_param_0];
+-; CHECK-NOF16-NEXT:    ld.param.v2.b16 {%rs3, %rs4}, [test_fcmp_ole_param_1];
+-; CHECK-NOF16-NEXT:    cvt.f32.f16 %r3, %rs4;
+-; CHECK-NOF16-NEXT:    cvt.f32.f16 %r4, %rs2;
++; CHECK-NOF16-NEXT:    ld.param.b32 %r2, [test_fcmp_ole_param_1];
++; CHECK-NOF16-NEXT:    ld.param.b32 %r1, [test_fcmp_ole_param_0];
++; CHECK-NOF16-NEXT:    mov.b32 {%rs1, %rs2}, %r2;
++; CHECK-NOF16-NEXT:    cvt.f32.f16 %r3, %rs2;
++; CHECK-NOF16-NEXT:    mov.b32 {%rs3, %rs4}, %r1;
++; CHECK-NOF16-NEXT:    cvt.f32.f16 %r4, %rs4;
+ ; CHECK-NOF16-NEXT:    setp.le.f32 %p1, %r4, %r3;
+-; CHECK-NOF16-NEXT:    cvt.f32.f16 %r5, %rs3;
+-; CHECK-NOF16-NEXT:    cvt.f32.f16 %r6, %rs1;
++; CHECK-NOF16-NEXT:    cvt.f32.f16 %r5, %rs1;
++; CHECK-NOF16-NEXT:    cvt.f32.f16 %r6, %rs3;
+ ; CHECK-NOF16-NEXT:    setp.le.f32 %p2, %r6, %r5;
+ ; CHECK-NOF16-NEXT:    selp.b16 %rs5, -1, 0, %p2;
+ ; CHECK-NOF16-NEXT:    st.param.b8 [func_retval0], %rs5;
+@@ -1198,13 +1256,15 @@
+ ; CHECK-NOF16-NEXT:    .reg .b32 %r<7>;
+ ; CHECK-NOF16-EMPTY:
+ ; CHECK-NOF16-NEXT:  // %bb.0:
+-; CHECK-NOF16-NEXT:    ld.param.v2.b16 {%rs1, %rs2}, [test_fcmp_ord_param_0];
+-; CHECK-NOF16-NEXT:    ld.param.v2.b16 {%rs3, %rs4}, [test_fcmp_ord_param_1];
+-; CHECK-NOF16-NEXT:    cvt.f32.f16 %r3, %rs4;
+-; CHECK-NOF16-NEXT:    cvt.f32.f16 %r4, %rs2;
++; CHECK-NOF16-NEXT:    ld.param.b32 %r2, [test_fcmp_ord_param_1];
++; CHECK-NOF16-NEXT:    ld.param.b32 %r1, [test_fcmp_ord_param_0];
++; CHECK-NOF16-NEXT:    mov.b32 {%rs1, %rs2}, %r2;
++; CHECK-NOF16-NEXT:    cvt.f32.f16 %r3, %rs2;
++; CHECK-NOF16-NEXT:    mov.b32 {%rs3, %rs4}, %r1;
++; CHECK-NOF16-NEXT:    cvt.f32.f16 %r4, %rs4;
+ ; CHECK-NOF16-NEXT:    setp.num.f32 %p1, %r4, %r3;
+-; CHECK-NOF16-NEXT:    cvt.f32.f16 %r5, %rs3;
+-; CHECK-NOF16-NEXT:    cvt.f32.f16 %r6, %rs1;
++; CHECK-NOF16-NEXT:    cvt.f32.f16 %r5, %rs1;
++; CHECK-NOF16-NEXT:    cvt.f32.f16 %r6, %rs3;
+ ; CHECK-NOF16-NEXT:    setp.num.f32 %p2, %r6, %r5;
+ ; CHECK-NOF16-NEXT:    selp.b16 %rs5, -1, 0, %p2;
+ ; CHECK-NOF16-NEXT:    st.param.b8 [func_retval0], %rs5;
+@@ -1222,7 +1282,8 @@
+ ; CHECK-NEXT:    .reg .b32 %r<4>;
+ ; CHECK-EMPTY:
+ ; CHECK-NEXT:  // %bb.0:
+-; CHECK-NEXT:    ld.param.v2.b16 {%rs1, %rs2}, [test_fptosi_i32_param_0];
++; CHECK-NEXT:    ld.param.b32 %r1, [test_fptosi_i32_param_0];
++; CHECK-NEXT:    mov.b32 {%rs1, %rs2}, %r1;
+ ; CHECK-NEXT:    cvt.rzi.s32.f16 %r2, %rs2;
+ ; CHECK-NEXT:    cvt.rzi.s32.f16 %r3, %rs1;
+ ; CHECK-NEXT:    st.param.v2.b32 [func_retval0], {%r3, %r2};
+@@ -1239,7 +1300,8 @@
+ ; CHECK-NEXT:    .reg .b64 %rd<3>;
+ ; CHECK-EMPTY:
+ ; CHECK-NEXT:  // %bb.0:
+-; CHECK-NEXT:    ld.param.v2.b16 {%rs1, %rs2}, [test_fptosi_i64_param_0];
++; CHECK-NEXT:    ld.param.b32 %r1, [test_fptosi_i64_param_0];
++; CHECK-NEXT:    mov.b32 {%rs1, %rs2}, %r1;
+ ; CHECK-NEXT:    cvt.rzi.s64.f16 %rd1, %rs2;
+ ; CHECK-NEXT:    cvt.rzi.s64.f16 %rd2, %rs1;
+ ; CHECK-NEXT:    st.param.v2.b64 [func_retval0], {%rd2, %rd1};
+@@ -1255,7 +1317,8 @@
+ ; CHECK-NEXT:    .reg .b32 %r<4>;
+ ; CHECK-EMPTY:
+ ; CHECK-NEXT:  // %bb.0:
+-; CHECK-NEXT:    ld.param.v2.b16 {%rs1, %rs2}, [test_fptoui_2xi32_param_0];
++; CHECK-NEXT:    ld.param.b32 %r1, [test_fptoui_2xi32_param_0];
++; CHECK-NEXT:    mov.b32 {%rs1, %rs2}, %r1;
+ ; CHECK-NEXT:    cvt.rzi.u32.f16 %r2, %rs2;
+ ; CHECK-NEXT:    cvt.rzi.u32.f16 %r3, %rs1;
+ ; CHECK-NEXT:    st.param.v2.b32 [func_retval0], {%r3, %r2};
+@@ -1272,7 +1335,8 @@
+ ; CHECK-NEXT:    .reg .b64 %rd<3>;
+ ; CHECK-EMPTY:
+ ; CHECK-NEXT:  // %bb.0:
+-; CHECK-NEXT:    ld.param.v2.b16 {%rs1, %rs2}, [test_fptoui_2xi64_param_0];
++; CHECK-NEXT:    ld.param.b32 %r1, [test_fptoui_2xi64_param_0];
++; CHECK-NEXT:    mov.b32 {%rs1, %rs2}, %r1;
+ ; CHECK-NEXT:    cvt.rzi.u64.f16 %rd1, %rs2;
+ ; CHECK-NEXT:    cvt.rzi.u64.f16 %rd2, %rs1;
+ ; CHECK-NEXT:    st.param.v2.b64 [func_retval0], {%rd2, %rd1};
+@@ -1369,16 +1433,17 @@
+ ; CHECK-NOF16-EMPTY:
+ ; CHECK-NOF16-NEXT:  // %bb.0:
+ ; CHECK-NOF16-NEXT:    ld.param.v2.b32 {%r1, %r2}, [test_uitofp_2xi32_fadd_param_0];
++; CHECK-NOF16-NEXT:    ld.param.b32 %r3, [test_uitofp_2xi32_fadd_param_1];
+ ; CHECK-NOF16-NEXT:    cvt.rn.f16.u32 %rs1, %r1;
+ ; CHECK-NOF16-NEXT:    cvt.rn.f16.u32 %rs2, %r2;
+-; CHECK-NOF16-NEXT:    ld.param.v2.b16 {%rs3, %rs4}, [test_uitofp_2xi32_fadd_param_1];
+-; CHECK-NOF16-NEXT:    cvt.f32.f16 %r4, %rs4;
+-; CHECK-NOF16-NEXT:    cvt.f32.f16 %r5, %rs2;
+-; CHECK-NOF16-NEXT:    add.rn.f32 %r6, %r4, %r5;
++; CHECK-NOF16-NEXT:    cvt.f32.f16 %r4, %rs2;
++; CHECK-NOF16-NEXT:    mov.b32 {%rs3, %rs4}, %r3;
++; CHECK-NOF16-NEXT:    cvt.f32.f16 %r5, %rs4;
++; CHECK-NOF16-NEXT:    add.rn.f32 %r6, %r5, %r4;
+ ; CHECK-NOF16-NEXT:    cvt.rn.f16.f32 %rs5, %r6;
+-; CHECK-NOF16-NEXT:    cvt.f32.f16 %r7, %rs3;
+-; CHECK-NOF16-NEXT:    cvt.f32.f16 %r8, %rs1;
+-; CHECK-NOF16-NEXT:    add.rn.f32 %r9, %r7, %r8;
++; CHECK-NOF16-NEXT:    cvt.f32.f16 %r7, %rs1;
++; CHECK-NOF16-NEXT:    cvt.f32.f16 %r8, %rs3;
++; CHECK-NOF16-NEXT:    add.rn.f32 %r9, %r8, %r7;
+ ; CHECK-NOF16-NEXT:    cvt.rn.f16.f32 %rs6, %r9;
+ ; CHECK-NOF16-NEXT:    mov.b32 %r10, {%rs6, %rs5};
+ ; CHECK-NOF16-NEXT:    st.param.b32 [func_retval0], %r10;
+@@ -1411,16 +1476,17 @@
+ ; CHECK-NOF16-EMPTY:
+ ; CHECK-NOF16-NEXT:  // %bb.0:
+ ; CHECK-NOF16-NEXT:    ld.param.v2.b32 {%r1, %r2}, [test_sitofp_2xi32_fadd_param_0];
++; CHECK-NOF16-NEXT:    ld.param.b32 %r3, [test_sitofp_2xi32_fadd_param_1];
+ ; CHECK-NOF16-NEXT:    cvt.rn.f16.s32 %rs1, %r1;
+ ; CHECK-NOF16-NEXT:    cvt.rn.f16.s32 %rs2, %r2;
+-; CHECK-NOF16-NEXT:    ld.param.v2.b16 {%rs3, %rs4}, [test_sitofp_2xi32_fadd_param_1];
+-; CHECK-NOF16-NEXT:    cvt.f32.f16 %r4, %rs4;
+-; CHECK-NOF16-NEXT:    cvt.f32.f16 %r5, %rs2;
+-; CHECK-NOF16-NEXT:    add.rn.f32 %r6, %r4, %r5;
++; CHECK-NOF16-NEXT:    cvt.f32.f16 %r4, %rs2;
++; CHECK-NOF16-NEXT:    mov.b32 {%rs3, %rs4}, %r3;
++; CHECK-NOF16-NEXT:    cvt.f32.f16 %r5, %rs4;
++; CHECK-NOF16-NEXT:    add.rn.f32 %r6, %r5, %r4;
+ ; CHECK-NOF16-NEXT:    cvt.rn.f16.f32 %rs5, %r6;
+-; CHECK-NOF16-NEXT:    cvt.f32.f16 %r7, %rs3;
+-; CHECK-NOF16-NEXT:    cvt.f32.f16 %r8, %rs1;
+-; CHECK-NOF16-NEXT:    add.rn.f32 %r9, %r7, %r8;
++; CHECK-NOF16-NEXT:    cvt.f32.f16 %r7, %rs1;
++; CHECK-NOF16-NEXT:    cvt.f32.f16 %r8, %rs3;
++; CHECK-NOF16-NEXT:    add.rn.f32 %r9, %r8, %r7;
+ ; CHECK-NOF16-NEXT:    cvt.rn.f16.f32 %rs6, %r9;
+ ; CHECK-NOF16-NEXT:    mov.b32 %r10, {%rs6, %rs5};
+ ; CHECK-NOF16-NEXT:    st.param.b32 [func_retval0], %r10;
+@@ -1433,11 +1499,16 @@
+ define <2 x half> @test_fptrunc_2xfloat(<2 x float> %a) #0 {
+ ; CHECK-LABEL: test_fptrunc_2xfloat(
+ ; CHECK:       {
++; CHECK-NEXT:    .reg .b16 %rs<3>;
++; CHECK-NEXT:    .reg .b32 %r<4>;
+ ; CHECK-NEXT:    .reg .b64 %rd<2>;
+ ; CHECK-EMPTY:
+ ; CHECK-NEXT:  // %bb.0:
+-; CHECK-NEXT:    ld.param.b64 %rd1, [test_fptrunc_2xfloat_param_0];
+-; CHECK-NEXT:    st.param.b32 [func_retval0], %rd1;
++; CHECK-NEXT:    ld.param.v2.b32 {%r1, %r2}, [test_fptrunc_2xfloat_param_0];
++; CHECK-NEXT:    cvt.rn.f16.f32 %rs1, %r2;
++; CHECK-NEXT:    cvt.rn.f16.f32 %rs2, %r1;
++; CHECK-NEXT:    mov.b32 %r3, {%rs2, %rs1};
++; CHECK-NEXT:    st.param.b32 [func_retval0], %r3;
+ ; CHECK-NEXT:    ret;
+   %r = fptrunc <2 x float> %a to <2 x half>
+   ret <2 x half> %r
+@@ -1468,7 +1539,8 @@
+ ; CHECK-NEXT:    .reg .b32 %r<4>;
+ ; CHECK-EMPTY:
+ ; CHECK-NEXT:  // %bb.0:
+-; CHECK-NEXT:    ld.param.v2.b16 {%rs1, %rs2}, [test_fpext_2xfloat_param_0];
++; CHECK-NEXT:    ld.param.b32 %r1, [test_fpext_2xfloat_param_0];
++; CHECK-NEXT:    mov.b32 {%rs1, %rs2}, %r1;
+ ; CHECK-NEXT:    cvt.f32.f16 %r2, %rs2;
+ ; CHECK-NEXT:    cvt.f32.f16 %r3, %rs1;
+ ; CHECK-NEXT:    st.param.v2.b32 [func_retval0], {%r3, %r2};
+@@ -1485,7 +1557,8 @@
+ ; CHECK-NEXT:    .reg .b64 %rd<3>;
+ ; CHECK-EMPTY:
+ ; CHECK-NEXT:  // %bb.0:
+-; CHECK-NEXT:    ld.param.v2.b16 {%rs1, %rs2}, [test_fpext_2xdouble_param_0];
++; CHECK-NEXT:    ld.param.b32 %r1, [test_fpext_2xdouble_param_0];
++; CHECK-NEXT:    mov.b32 {%rs1, %rs2}, %r1;
+ ; CHECK-NEXT:    cvt.f64.f16 %rd1, %rs2;
+ ; CHECK-NEXT:    cvt.f64.f16 %rd2, %rs1;
+ ; CHECK-NEXT:    st.param.v2.b64 [func_retval0], {%rd2, %rd1};
+@@ -1578,7 +1651,8 @@
+ ; CHECK-NEXT:    .reg .b32 %r<7>;
+ ; CHECK-EMPTY:
+ ; CHECK-NEXT:  // %bb.0:
+-; CHECK-NEXT:    ld.param.v2.b16 {%rs1, %rs2}, [test_sqrt_param_0];
++; CHECK-NEXT:    ld.param.b32 %r1, [test_sqrt_param_0];
++; CHECK-NEXT:    mov.b32 {%rs1, %rs2}, %r1;
+ ; CHECK-NEXT:    cvt.f32.f16 %r2, %rs2;
+ ; CHECK-NEXT:    sqrt.rn.f32 %r3, %r2;
+ ; CHECK-NEXT:    cvt.rn.f16.f32 %rs3, %r3;
+@@ -1606,7 +1680,8 @@
+ ; CHECK-NEXT:    .reg .b32 %r<7>;
+ ; CHECK-EMPTY:
+ ; CHECK-NEXT:  // %bb.0:
+-; CHECK-NEXT:    ld.param.v2.b16 {%rs1, %rs2}, [test_sin_param_0];
++; CHECK-NEXT:    ld.param.b32 %r1, [test_sin_param_0];
++; CHECK-NEXT:    mov.b32 {%rs1, %rs2}, %r1;
+ ; CHECK-NEXT:    cvt.f32.f16 %r2, %rs2;
+ ; CHECK-NEXT:    sin.approx.f32 %r3, %r2;
+ ; CHECK-NEXT:    cvt.rn.f16.f32 %rs3, %r3;
+@@ -1627,7 +1702,8 @@
+ ; CHECK-NEXT:    .reg .b32 %r<7>;
+ ; CHECK-EMPTY:
+ ; CHECK-NEXT:  // %bb.0:
+-; CHECK-NEXT:    ld.param.v2.b16 {%rs1, %rs2}, [test_cos_param_0];
++; CHECK-NEXT:    ld.param.b32 %r1, [test_cos_param_0];
++; CHECK-NEXT:    mov.b32 {%rs1, %rs2}, %r1;
+ ; CHECK-NEXT:    cvt.f32.f16 %r2, %rs2;
+ ; CHECK-NEXT:    cos.approx.f32 %r3, %r2;
+ ; CHECK-NEXT:    cvt.rn.f16.f32 %rs3, %r3;
+@@ -1703,17 +1779,20 @@
+ ; CHECK-NOF16-NEXT:    .reg .b32 %r<13>;
+ ; CHECK-NOF16-EMPTY:
+ ; CHECK-NOF16-NEXT:  // %bb.0:
+-; CHECK-NOF16-NEXT:    ld.param.v2.b16 {%rs1, %rs2}, [test_fma_param_0];
+-; CHECK-NOF16-NEXT:    ld.param.v2.b16 {%rs3, %rs4}, [test_fma_param_2];
+-; CHECK-NOF16-NEXT:    cvt.f32.f16 %r4, %rs4;
+-; CHECK-NOF16-NEXT:    ld.param.v2.b16 {%rs5, %rs6}, [test_fma_param_1];
+-; CHECK-NOF16-NEXT:    cvt.f32.f16 %r5, %rs6;
+-; CHECK-NOF16-NEXT:    cvt.f32.f16 %r6, %rs2;
++; CHECK-NOF16-NEXT:    ld.param.b32 %r3, [test_fma_param_2];
++; CHECK-NOF16-NEXT:    ld.param.b32 %r2, [test_fma_param_1];
++; CHECK-NOF16-NEXT:    ld.param.b32 %r1, [test_fma_param_0];
++; CHECK-NOF16-NEXT:    mov.b32 {%rs1, %rs2}, %r3;
++; CHECK-NOF16-NEXT:    cvt.f32.f16 %r4, %rs2;
++; CHECK-NOF16-NEXT:    mov.b32 {%rs3, %rs4}, %r2;
++; CHECK-NOF16-NEXT:    cvt.f32.f16 %r5, %rs4;
++; CHECK-NOF16-NEXT:    mov.b32 {%rs5, %rs6}, %r1;
++; CHECK-NOF16-NEXT:    cvt.f32.f16 %r6, %rs6;
+ ; CHECK-NOF16-NEXT:    fma.rn.f32 %r7, %r6, %r5, %r4;
+ ; CHECK-NOF16-NEXT:    cvt.rn.f16.f32 %rs7, %r7;
+-; CHECK-NOF16-NEXT:    cvt.f32.f16 %r8, %rs3;
+-; CHECK-NOF16-NEXT:    cvt.f32.f16 %r9, %rs5;
+-; CHECK-NOF16-NEXT:    cvt.f32.f16 %r10, %rs1;
++; CHECK-NOF16-NEXT:    cvt.f32.f16 %r8, %rs1;
++; CHECK-NOF16-NEXT:    cvt.f32.f16 %r9, %rs3;
++; CHECK-NOF16-NEXT:    cvt.f32.f16 %r10, %rs5;
+ ; CHECK-NOF16-NEXT:    fma.rn.f32 %r11, %r10, %r9, %r8;
+ ; CHECK-NOF16-NEXT:    cvt.rn.f16.f32 %rs8, %r11;
+ ; CHECK-NOF16-NEXT:    mov.b32 %r12, {%rs8, %rs7};
+@@ -1740,7 +1819,8 @@
+ ; CHECK-NOF16-NEXT:    .reg .b32 %r<7>;
+ ; CHECK-NOF16-EMPTY:
+ ; CHECK-NOF16-NEXT:  // %bb.0:
+-; CHECK-NOF16-NEXT:    ld.param.v2.b16 {%rs1, %rs2}, [test_fabs_param_0];
++; CHECK-NOF16-NEXT:    ld.param.b32 %r1, [test_fabs_param_0];
++; CHECK-NOF16-NEXT:    mov.b32 {%rs1, %rs2}, %r1;
+ ; CHECK-NOF16-NEXT:    cvt.f32.f16 %r2, %rs2;
+ ; CHECK-NOF16-NEXT:    abs.f32 %r3, %r2;
+ ; CHECK-NOF16-NEXT:    cvt.rn.f16.f32 %rs3, %r3;
+@@ -1761,14 +1841,16 @@
+ ; CHECK-NEXT:    .reg .b32 %r<10>;
+ ; CHECK-EMPTY:
+ ; CHECK-NEXT:  // %bb.0:
+-; CHECK-NEXT:    ld.param.v2.b16 {%rs1, %rs2}, [test_minnum_param_0];
+-; CHECK-NEXT:    ld.param.v2.b16 {%rs3, %rs4}, [test_minnum_param_1];
+-; CHECK-NEXT:    cvt.f32.f16 %r3, %rs4;
+-; CHECK-NEXT:    cvt.f32.f16 %r4, %rs2;
++; CHECK-NEXT:    ld.param.b32 %r2, [test_minnum_param_1];
++; CHECK-NEXT:    ld.param.b32 %r1, [test_minnum_param_0];
++; CHECK-NEXT:    mov.b32 {%rs1, %rs2}, %r2;
++; CHECK-NEXT:    cvt.f32.f16 %r3, %rs2;
++; CHECK-NEXT:    mov.b32 {%rs3, %rs4}, %r1;
++; CHECK-NEXT:    cvt.f32.f16 %r4, %rs4;
+ ; CHECK-NEXT:    min.f32 %r5, %r4, %r3;
+ ; CHECK-NEXT:    cvt.rn.f16.f32 %rs5, %r5;
+-; CHECK-NEXT:    cvt.f32.f16 %r6, %rs3;
+-; CHECK-NEXT:    cvt.f32.f16 %r7, %rs1;
++; CHECK-NEXT:    cvt.f32.f16 %r6, %rs1;
++; CHECK-NEXT:    cvt.f32.f16 %r7, %rs3;
+ ; CHECK-NEXT:    min.f32 %r8, %r7, %r6;
+ ; CHECK-NEXT:    cvt.rn.f16.f32 %rs6, %r8;
+ ; CHECK-NEXT:    mov.b32 %r9, {%rs6, %rs5};
+@@ -1785,14 +1867,16 @@
+ ; CHECK-NEXT:    .reg .b32 %r<10>;
+ ; CHECK-EMPTY:
+ ; CHECK-NEXT:  // %bb.0:
+-; CHECK-NEXT:    ld.param.v2.b16 {%rs1, %rs2}, [test_maxnum_param_0];
+-; CHECK-NEXT:    ld.param.v2.b16 {%rs3, %rs4}, [test_maxnum_param_1];
+-; CHECK-NEXT:    cvt.f32.f16 %r3, %rs4;
+-; CHECK-NEXT:    cvt.f32.f16 %r4, %rs2;
++; CHECK-NEXT:    ld.param.b32 %r2, [test_maxnum_param_1];
++; CHECK-NEXT:    ld.param.b32 %r1, [test_maxnum_param_0];
++; CHECK-NEXT:    mov.b32 {%rs1, %rs2}, %r2;
++; CHECK-NEXT:    cvt.f32.f16 %r3, %rs2;
++; CHECK-NEXT:    mov.b32 {%rs3, %rs4}, %r1;
++; CHECK-NEXT:    cvt.f32.f16 %r4, %rs4;
+ ; CHECK-NEXT:    max.f32 %r5, %r4, %r3;
+ ; CHECK-NEXT:    cvt.rn.f16.f32 %rs5, %r5;
+-; CHECK-NEXT:    cvt.f32.f16 %r6, %rs3;
+-; CHECK-NEXT:    cvt.f32.f16 %r7, %rs1;
++; CHECK-NEXT:    cvt.f32.f16 %r6, %rs1;
++; CHECK-NEXT:    cvt.f32.f16 %r7, %rs3;
+ ; CHECK-NEXT:    max.f32 %r8, %r7, %r6;
+ ; CHECK-NEXT:    cvt.rn.f16.f32 %rs6, %r8;
+ ; CHECK-NEXT:    mov.b32 %r9, {%rs6, %rs5};
+@@ -1822,13 +1906,15 @@
+ ; CHECK-NOF16-NEXT:    .reg .b32 %r<3>;
+ ; CHECK-NOF16-EMPTY:
+ ; CHECK-NOF16-NEXT:  // %bb.0:
+-; CHECK-NOF16-NEXT:    ld.param.v2.b16 {%rs1, %rs2}, [test_copysign_param_0];
+-; CHECK-NOF16-NEXT:    ld.param.v2.b16 {%rs3, %rs4}, [test_copysign_param_1];
+-; CHECK-NOF16-NEXT:    and.b16 %rs5, %rs4, -32768;
+-; CHECK-NOF16-NEXT:    and.b16 %rs6, %rs2, 32767;
+-; CHECK-NOF16-NEXT:    or.b16 %rs7, %rs6, %rs5;
+-; CHECK-NOF16-NEXT:    and.b16 %rs8, %rs3, -32768;
+-; CHECK-NOF16-NEXT:    and.b16 %rs9, %rs1, 32767;
++; CHECK-NOF16-NEXT:    ld.param.b32 %r2, [test_copysign_param_1];
++; CHECK-NOF16-NEXT:    ld.param.b32 %r1, [test_copysign_param_0];
++; CHECK-NOF16-NEXT:    mov.b32 {%rs1, %rs2}, %r2;
++; CHECK-NOF16-NEXT:    and.b16 %rs3, %rs2, -32768;
++; CHECK-NOF16-NEXT:    mov.b32 {%rs4, %rs5}, %r1;
++; CHECK-NOF16-NEXT:    and.b16 %rs6, %rs5, 32767;
++; CHECK-NOF16-NEXT:    or.b16 %rs7, %rs6, %rs3;
++; CHECK-NOF16-NEXT:    and.b16 %rs8, %rs1, -32768;
++; CHECK-NOF16-NEXT:    and.b16 %rs9, %rs4, 32767;
+ ; CHECK-NOF16-NEXT:    or.b16 %rs10, %rs9, %rs8;
+ ; CHECK-NOF16-NEXT:    st.param.v2.b16 [func_retval0], {%rs10, %rs7};
+ ; CHECK-NOF16-NEXT:    ret;
+@@ -1844,8 +1930,9 @@
+ ; CHECK-F16-NEXT:    .reg .b64 %rd<2>;
+ ; CHECK-F16-EMPTY:
+ ; CHECK-F16-NEXT:  // %bb.0:
++; CHECK-F16-NEXT:    ld.param.b64 %rd1, [test_copysign_f32_param_1];
+ ; CHECK-F16-NEXT:    ld.param.b32 %r1, [test_copysign_f32_param_0];
+-; CHECK-F16-NEXT:    ld.param.v2.b32 {%r2, %r3}, [test_copysign_f32_param_1];
++; CHECK-F16-NEXT:    mov.b64 {%r2, %r3}, %rd1;
+ ; CHECK-F16-NEXT:    cvt.rn.f16.f32 %rs1, %r3;
+ ; CHECK-F16-NEXT:    cvt.rn.f16.f32 %rs2, %r2;
+ ; CHECK-F16-NEXT:    mov.b32 %r4, {%rs2, %rs1};
+@@ -1862,8 +1949,10 @@
+ ; CHECK-NOF16-NEXT:    .reg .b64 %rd<2>;
+ ; CHECK-NOF16-EMPTY:
+ ; CHECK-NOF16-NEXT:  // %bb.0:
+-; CHECK-NOF16-NEXT:    ld.param.v2.b16 {%rs1, %rs2}, [test_copysign_f32_param_0];
+-; CHECK-NOF16-NEXT:    ld.param.v2.b32 {%r2, %r3}, [test_copysign_f32_param_1];
++; CHECK-NOF16-NEXT:    ld.param.b64 %rd1, [test_copysign_f32_param_1];
++; CHECK-NOF16-NEXT:    ld.param.b32 %r1, [test_copysign_f32_param_0];
++; CHECK-NOF16-NEXT:    mov.b64 {%r2, %r3}, %rd1;
++; CHECK-NOF16-NEXT:    mov.b32 {%rs1, %rs2}, %r1;
+ ; CHECK-NOF16-NEXT:    and.b16 %rs3, %rs2, 32767;
+ ; CHECK-NOF16-NEXT:    and.b32 %r4, %r3, -2147483648;
+ ; CHECK-NOF16-NEXT:    { .reg .b16 tmp; mov.b32 {tmp, %rs4}, %r4; }
+@@ -1906,7 +1995,8 @@
+ ; CHECK-NOF16-EMPTY:
+ ; CHECK-NOF16-NEXT:  // %bb.0:
+ ; CHECK-NOF16-NEXT:    ld.param.v2.b64 {%rd1, %rd2}, [test_copysign_f64_param_1];
+-; CHECK-NOF16-NEXT:    ld.param.v2.b16 {%rs1, %rs2}, [test_copysign_f64_param_0];
++; CHECK-NOF16-NEXT:    ld.param.b32 %r1, [test_copysign_f64_param_0];
++; CHECK-NOF16-NEXT:    mov.b32 {%rs1, %rs2}, %r1;
+ ; CHECK-NOF16-NEXT:    and.b16 %rs3, %rs2, 32767;
+ ; CHECK-NOF16-NEXT:    and.b64 %rd3, %rd2, -9223372036854775808;
+ ; CHECK-NOF16-NEXT:    shr.u64 %rd4, %rd3, 48;
+@@ -1948,13 +2038,15 @@
+ ; CHECK-NOF16-NEXT:    .reg .b32 %r<5>;
+ ; CHECK-NOF16-EMPTY:
+ ; CHECK-NOF16-NEXT:  // %bb.0:
+-; CHECK-NOF16-NEXT:    ld.param.v2.b16 {%rs1, %rs2}, [test_copysign_extended_param_0];
+-; CHECK-NOF16-NEXT:    ld.param.v2.b16 {%rs3, %rs4}, [test_copysign_extended_param_1];
+-; CHECK-NOF16-NEXT:    and.b16 %rs5, %rs3, -32768;
+-; CHECK-NOF16-NEXT:    and.b16 %rs6, %rs1, 32767;
+-; CHECK-NOF16-NEXT:    or.b16 %rs7, %rs6, %rs5;
+-; CHECK-NOF16-NEXT:    and.b16 %rs8, %rs4, -32768;
+-; CHECK-NOF16-NEXT:    and.b16 %rs9, %rs2, 32767;
++; CHECK-NOF16-NEXT:    ld.param.b32 %r2, [test_copysign_extended_param_1];
++; CHECK-NOF16-NEXT:    ld.param.b32 %r1, [test_copysign_extended_param_0];
++; CHECK-NOF16-NEXT:    mov.b32 {%rs1, %rs2}, %r2;
++; CHECK-NOF16-NEXT:    and.b16 %rs3, %rs1, -32768;
++; CHECK-NOF16-NEXT:    mov.b32 {%rs4, %rs5}, %r1;
++; CHECK-NOF16-NEXT:    and.b16 %rs6, %rs4, 32767;
++; CHECK-NOF16-NEXT:    or.b16 %rs7, %rs6, %rs3;
++; CHECK-NOF16-NEXT:    and.b16 %rs8, %rs2, -32768;
++; CHECK-NOF16-NEXT:    and.b16 %rs9, %rs5, 32767;
+ ; CHECK-NOF16-NEXT:    or.b16 %rs10, %rs9, %rs8;
+ ; CHECK-NOF16-NEXT:    cvt.f32.f16 %r3, %rs10;
+ ; CHECK-NOF16-NEXT:    cvt.f32.f16 %r4, %rs7;
+@@ -1972,7 +2064,8 @@
+ ; CHECK-NEXT:    .reg .b32 %r<2>;
+ ; CHECK-EMPTY:
+ ; CHECK-NEXT:  // %bb.0:
+-; CHECK-NEXT:    ld.param.v2.b16 {%rs1, %rs2}, [test_floor_param_0];
++; CHECK-NEXT:    ld.param.b32 %r1, [test_floor_param_0];
++; CHECK-NEXT:    mov.b32 {%rs1, %rs2}, %r1;
+ ; CHECK-NEXT:    cvt.rmi.f16.f16 %rs3, %rs2;
+ ; CHECK-NEXT:    cvt.rmi.f16.f16 %rs4, %rs1;
+ ; CHECK-NEXT:    st.param.v2.b16 [func_retval0], {%rs4, %rs3};
+@@ -1988,7 +2081,8 @@
+ ; CHECK-NEXT:    .reg .b32 %r<2>;
+ ; CHECK-EMPTY:
+ ; CHECK-NEXT:  // %bb.0:
+-; CHECK-NEXT:    ld.param.v2.b16 {%rs1, %rs2}, [test_ceil_param_0];
++; CHECK-NEXT:    ld.param.b32 %r1, [test_ceil_param_0];
++; CHECK-NEXT:    mov.b32 {%rs1, %rs2}, %r1;
+ ; CHECK-NEXT:    cvt.rpi.f16.f16 %rs3, %rs2;
+ ; CHECK-NEXT:    cvt.rpi.f16.f16 %rs4, %rs1;
+ ; CHECK-NEXT:    st.param.v2.b16 [func_retval0], {%rs4, %rs3};
+@@ -2004,7 +2098,8 @@
+ ; CHECK-NEXT:    .reg .b32 %r<2>;
+ ; CHECK-EMPTY:
+ ; CHECK-NEXT:  // %bb.0:
+-; CHECK-NEXT:    ld.param.v2.b16 {%rs1, %rs2}, [test_trunc_param_0];
++; CHECK-NEXT:    ld.param.b32 %r1, [test_trunc_param_0];
++; CHECK-NEXT:    mov.b32 {%rs1, %rs2}, %r1;
+ ; CHECK-NEXT:    cvt.rzi.f16.f16 %rs3, %rs2;
+ ; CHECK-NEXT:    cvt.rzi.f16.f16 %rs4, %rs1;
+ ; CHECK-NEXT:    st.param.v2.b16 [func_retval0], {%rs4, %rs3};
+@@ -2020,7 +2115,8 @@
+ ; CHECK-NEXT:    .reg .b32 %r<2>;
+ ; CHECK-EMPTY:
+ ; CHECK-NEXT:  // %bb.0:
+-; CHECK-NEXT:    ld.param.v2.b16 {%rs1, %rs2}, [test_rint_param_0];
++; CHECK-NEXT:    ld.param.b32 %r1, [test_rint_param_0];
++; CHECK-NEXT:    mov.b32 {%rs1, %rs2}, %r1;
+ ; CHECK-NEXT:    cvt.rni.f16.f16 %rs3, %rs2;
+ ; CHECK-NEXT:    cvt.rni.f16.f16 %rs4, %rs1;
+ ; CHECK-NEXT:    st.param.v2.b16 [func_retval0], {%rs4, %rs3};
+@@ -2036,7 +2132,8 @@
+ ; CHECK-NEXT:    .reg .b32 %r<2>;
+ ; CHECK-EMPTY:
+ ; CHECK-NEXT:  // %bb.0:
+-; CHECK-NEXT:    ld.param.v2.b16 {%rs1, %rs2}, [test_nearbyint_param_0];
++; CHECK-NEXT:    ld.param.b32 %r1, [test_nearbyint_param_0];
++; CHECK-NEXT:    mov.b32 {%rs1, %rs2}, %r1;
+ ; CHECK-NEXT:    cvt.rni.f16.f16 %rs3, %rs2;
+ ; CHECK-NEXT:    cvt.rni.f16.f16 %rs4, %rs1;
+ ; CHECK-NEXT:    st.param.v2.b16 [func_retval0], {%rs4, %rs3};
+@@ -2052,7 +2149,8 @@
+ ; CHECK-NEXT:    .reg .b32 %r<2>;
+ ; CHECK-EMPTY:
+ ; CHECK-NEXT:  // %bb.0:
+-; CHECK-NEXT:    ld.param.v2.b16 {%rs1, %rs2}, [test_roundeven_param_0];
++; CHECK-NEXT:    ld.param.b32 %r1, [test_roundeven_param_0];
++; CHECK-NEXT:    mov.b32 {%rs1, %rs2}, %r1;
+ ; CHECK-NEXT:    cvt.rni.f16.f16 %rs3, %rs2;
+ ; CHECK-NEXT:    cvt.rni.f16.f16 %rs4, %rs1;
+ ; CHECK-NEXT:    st.param.v2.b16 [func_retval0], {%rs4, %rs3};
+@@ -2070,7 +2168,8 @@
+ ; CHECK-NEXT:    .reg .b32 %r<21>;
+ ; CHECK-EMPTY:
+ ; CHECK-NEXT:  // %bb.0:
+-; CHECK-NEXT:    ld.param.v2.b16 {%rs1, %rs2}, [test_round_param_0];
++; CHECK-NEXT:    ld.param.b32 %r1, [test_round_param_0];
++; CHECK-NEXT:    mov.b32 {%rs1, %rs2}, %r1;
+ ; CHECK-NEXT:    cvt.f32.f16 %r2, %rs2;
+ ; CHECK-NEXT:    and.b32 %r3, %r2, -2147483648;
+ ; CHECK-NEXT:    or.b32 %r4, %r3, 1056964608;
+@@ -2121,17 +2220,20 @@
+ ; CHECK-NOF16-NEXT:    .reg .b32 %r<13>;
+ ; CHECK-NOF16-EMPTY:
+ ; CHECK-NOF16-NEXT:  // %bb.0:
+-; CHECK-NOF16-NEXT:    ld.param.v2.b16 {%rs1, %rs2}, [test_fmuladd_param_0];
+-; CHECK-NOF16-NEXT:    ld.param.v2.b16 {%rs3, %rs4}, [test_fmuladd_param_2];
+-; CHECK-NOF16-NEXT:    cvt.f32.f16 %r4, %rs4;
+-; CHECK-NOF16-NEXT:    ld.param.v2.b16 {%rs5, %rs6}, [test_fmuladd_param_1];
+-; CHECK-NOF16-NEXT:    cvt.f32.f16 %r5, %rs6;
+-; CHECK-NOF16-NEXT:    cvt.f32.f16 %r6, %rs2;
++; CHECK-NOF16-NEXT:    ld.param.b32 %r3, [test_fmuladd_param_2];
++; CHECK-NOF16-NEXT:    ld.param.b32 %r2, [test_fmuladd_param_1];
++; CHECK-NOF16-NEXT:    ld.param.b32 %r1, [test_fmuladd_param_0];
++; CHECK-NOF16-NEXT:    mov.b32 {%rs1, %rs2}, %r3;
++; CHECK-NOF16-NEXT:    cvt.f32.f16 %r4, %rs2;
++; CHECK-NOF16-NEXT:    mov.b32 {%rs3, %rs4}, %r2;
++; CHECK-NOF16-NEXT:    cvt.f32.f16 %r5, %rs4;
++; CHECK-NOF16-NEXT:    mov.b32 {%rs5, %rs6}, %r1;
++; CHECK-NOF16-NEXT:    cvt.f32.f16 %r6, %rs6;
+ ; CHECK-NOF16-NEXT:    fma.rn.f32 %r7, %r6, %r5, %r4;
+ ; CHECK-NOF16-NEXT:    cvt.rn.f16.f32 %rs7, %r7;
+-; CHECK-NOF16-NEXT:    cvt.f32.f16 %r8, %rs3;
+-; CHECK-NOF16-NEXT:    cvt.f32.f16 %r9, %rs5;
+-; CHECK-NOF16-NEXT:    cvt.f32.f16 %r10, %rs1;
++; CHECK-NOF16-NEXT:    cvt.f32.f16 %r8, %rs1;
++; CHECK-NOF16-NEXT:    cvt.f32.f16 %r9, %rs3;
++; CHECK-NOF16-NEXT:    cvt.f32.f16 %r10, %rs5;
+ ; CHECK-NOF16-NEXT:    fma.rn.f32 %r11, %r10, %r9, %r8;
+ ; CHECK-NOF16-NEXT:    cvt.rn.f16.f32 %rs8, %r11;
+ ; CHECK-NOF16-NEXT:    mov.b32 %r12, {%rs8, %rs7};
+@@ -2148,7 +2250,8 @@
+ ; CHECK-NEXT:    .reg .b32 %r<2>;
+ ; CHECK-EMPTY:
+ ; CHECK-NEXT:  // %bb.0:
+-; CHECK-NEXT:    ld.param.v2.b16 {%rs1, %rs2}, [test_shufflevector_param_0];
++; CHECK-NEXT:    ld.param.b32 %r1, [test_shufflevector_param_0];
++; CHECK-NEXT:    mov.b32 {%rs1, %rs2}, %r1;
+ ; CHECK-NEXT:    st.param.v2.b16 [func_retval0], {%rs2, %rs1};
+ ; CHECK-NEXT:    ret;
+   %s = shufflevector <2 x half> %a, <2 x half> undef, <2 x i32> <i32 1, i32 0>
+@@ -2158,12 +2261,13 @@
+ define <2 x half> @test_insertelement(<2 x half> %a, half %x) #0 {
+ ; CHECK-LABEL: test_insertelement(
+ ; CHECK:       {
+-; CHECK-NEXT:    .reg .b16 %rs<4>;
++; CHECK-NEXT:    .reg .b16 %rs<3>;
+ ; CHECK-NEXT:    .reg .b32 %r<2>;
+ ; CHECK-EMPTY:
+ ; CHECK-NEXT:  // %bb.0:
+ ; CHECK-NEXT:    ld.param.b16 %rs1, [test_insertelement_param_1];
+-; CHECK-NEXT:    ld.param.v2.b16 {%rs2, %rs3}, [test_insertelement_param_0];
++; CHECK-NEXT:    ld.param.b32 %r1, [test_insertelement_param_0];
++; CHECK-NEXT:    { .reg .b16 tmp; mov.b32 {%rs2, tmp}, %r1; }
+ ; CHECK-NEXT:    st.param.v2.b16 [func_retval0], {%rs2, %rs1};
+ ; CHECK-NEXT:    ret;
+   %i = insertelement <2 x half> %a, half %x, i64 1
+@@ -2177,7 +2281,8 @@
+ ; CHECK-NEXT:    .reg .b32 %r<2>;
+ ; CHECK-EMPTY:
+ ; CHECK-NEXT:  // %bb.0:
+-; CHECK-NEXT:    ld.param.v2.b16 {%rs1, %rs2}, [test_sitofp_2xi16_to_2xhalf_param_0];
++; CHECK-NEXT:    ld.param.b32 %r1, [test_sitofp_2xi16_to_2xhalf_param_0];
++; CHECK-NEXT:    mov.b32 {%rs1, %rs2}, %r1;
+ ; CHECK-NEXT:    cvt.rn.f16.s16 %rs3, %rs2;
+ ; CHECK-NEXT:    cvt.rn.f16.s16 %rs4, %rs1;
+ ; CHECK-NEXT:    st.param.v2.b16 [func_retval0], {%rs4, %rs3};
+@@ -2193,7 +2298,8 @@
+ ; CHECK-NEXT:    .reg .b32 %r<2>;
+ ; CHECK-EMPTY:
+ ; CHECK-NEXT:  // %bb.0:
+-; CHECK-NEXT:    ld.param.v2.b16 {%rs1, %rs2}, [test_uitofp_2xi16_to_2xhalf_param_0];
++; CHECK-NEXT:    ld.param.b32 %r1, [test_uitofp_2xi16_to_2xhalf_param_0];
++; CHECK-NEXT:    mov.b32 {%rs1, %rs2}, %r1;
+ ; CHECK-NEXT:    cvt.rn.f16.u16 %rs3, %rs2;
+ ; CHECK-NEXT:    cvt.rn.f16.u16 %rs4, %rs1;
+ ; CHECK-NEXT:    st.param.v2.b16 [func_retval0], {%rs4, %rs3};
+diff -ruN --strip-trailing-cr a/llvm/test/CodeGen/NVPTX/f32x2-instructions.ll b/llvm/test/CodeGen/NVPTX/f32x2-instructions.ll
+--- a/llvm/test/CodeGen/NVPTX/f32x2-instructions.ll
++++ b/llvm/test/CodeGen/NVPTX/f32x2-instructions.ll
+@@ -28,29 +28,53 @@
  }
  
- /// Print out the file/line/column information and include trace.
-diff -ruN --strip-trailing-cr a/clang/lib/Frontend/TextDiagnostic.cpp b/clang/lib/Frontend/TextDiagnostic.cpp
---- a/clang/lib/Frontend/TextDiagnostic.cpp
-+++ b/clang/lib/Frontend/TextDiagnostic.cpp
-@@ -738,7 +738,39 @@
+ define float @test_extract_0(<2 x float> %a) #0 {
+-; CHECK-LABEL: test_extract_0(
+-; CHECK:       {
+-; CHECK-NEXT:    .reg .b32 %r<3>;
+-; CHECK-NEXT:    .reg .b64 %rd<2>;
+-; CHECK-EMPTY:
+-; CHECK-NEXT:  // %bb.0:
+-; CHECK-NEXT:    ld.param.v2.b32 {%r1, %r2}, [test_extract_0_param_0];
+-; CHECK-NEXT:    st.param.b32 [func_retval0], %r1;
+-; CHECK-NEXT:    ret;
++; CHECK-NOF32X2-LABEL: test_extract_0(
++; CHECK-NOF32X2:       {
++; CHECK-NOF32X2-NEXT:    .reg .b32 %r<2>;
++; CHECK-NOF32X2-NEXT:    .reg .b64 %rd<2>;
++; CHECK-NOF32X2-EMPTY:
++; CHECK-NOF32X2-NEXT:  // %bb.0:
++; CHECK-NOF32X2-NEXT:    ld.param.b64 %rd1, [test_extract_0_param_0];
++; CHECK-NOF32X2-NEXT:    { .reg .b32 tmp; mov.b64 {%r1, tmp}, %rd1; }
++; CHECK-NOF32X2-NEXT:    st.param.b32 [func_retval0], %r1;
++; CHECK-NOF32X2-NEXT:    ret;
++;
++; CHECK-F32X2-LABEL: test_extract_0(
++; CHECK-F32X2:       {
++; CHECK-F32X2-NEXT:    .reg .b32 %r<2>;
++; CHECK-F32X2-NEXT:    .reg .b64 %rd<2>;
++; CHECK-F32X2-EMPTY:
++; CHECK-F32X2-NEXT:  // %bb.0:
++; CHECK-F32X2-NEXT:    ld.param.b64 %rd1, [test_extract_0_param_0];
++; CHECK-F32X2-NEXT:    mov.b64 {%r1, _}, %rd1;
++; CHECK-F32X2-NEXT:    st.param.b32 [func_retval0], %r1;
++; CHECK-F32X2-NEXT:    ret;
+   %e = extractelement <2 x float> %a, i32 0
+   ret float %e
  }
  
- void TextDiagnostic::emitFilename(StringRef Filename, const SourceManager &SM) {
--  OS << SM.getNameForDiagnostic(Filename, DiagOpts);
-+#ifdef _WIN32
-+  SmallString<4096> TmpFilename;
-+#endif
-+  if (DiagOpts.AbsolutePath) {
-+    auto File = SM.getFileManager().getOptionalFileRef(Filename);
-+    if (File) {
-+      // We want to print a simplified absolute path, i. e. without "dots".
-+      //
-+      // The hardest part here are the paths like "<part1>/<link>/../<part2>".
-+      // On Unix-like systems, we cannot just collapse "<link>/..", because
-+      // paths are resolved sequentially, and, thereby, the path
-+      // "<part1>/<part2>" may point to a different location. That is why
-+      // we use FileManager::getCanonicalName(), which expands all indirections
-+      // with llvm::sys::fs::real_path() and caches the result.
-+      //
-+      // On the other hand, it would be better to preserve as much of the
-+      // original path as possible, because that helps a user to recognize it.
-+      // real_path() expands all links, which sometimes too much. Luckily,
-+      // on Windows we can just use llvm::sys::path::remove_dots(), because,
-+      // on that system, both aforementioned paths point to the same place.
-+#ifdef _WIN32
-+      TmpFilename = File->getName();
-+      llvm::sys::fs::make_absolute(TmpFilename);
-+      llvm::sys::path::native(TmpFilename);
-+      llvm::sys::path::remove_dots(TmpFilename, /* remove_dot_dot */ true);
-+      Filename = StringRef(TmpFilename.data(), TmpFilename.size());
-+#else
-+      Filename = SM.getFileManager().getCanonicalName(*File);
-+#endif
-+    }
-+  }
-+
-+  OS << Filename;
+ define float @test_extract_1(<2 x float> %a) #0 {
+-; CHECK-LABEL: test_extract_1(
+-; CHECK:       {
+-; CHECK-NEXT:    .reg .b32 %r<3>;
+-; CHECK-NEXT:    .reg .b64 %rd<2>;
+-; CHECK-EMPTY:
+-; CHECK-NEXT:  // %bb.0:
+-; CHECK-NEXT:    ld.param.v2.b32 {%r1, %r2}, [test_extract_1_param_0];
+-; CHECK-NEXT:    st.param.b32 [func_retval0], %r2;
+-; CHECK-NEXT:    ret;
++; CHECK-NOF32X2-LABEL: test_extract_1(
++; CHECK-NOF32X2:       {
++; CHECK-NOF32X2-NEXT:    .reg .b32 %r<2>;
++; CHECK-NOF32X2-NEXT:    .reg .b64 %rd<2>;
++; CHECK-NOF32X2-EMPTY:
++; CHECK-NOF32X2-NEXT:  // %bb.0:
++; CHECK-NOF32X2-NEXT:    ld.param.b64 %rd1, [test_extract_1_param_0];
++; CHECK-NOF32X2-NEXT:    { .reg .b32 tmp; mov.b64 {tmp, %r1}, %rd1; }
++; CHECK-NOF32X2-NEXT:    st.param.b32 [func_retval0], %r1;
++; CHECK-NOF32X2-NEXT:    ret;
++;
++; CHECK-F32X2-LABEL: test_extract_1(
++; CHECK-F32X2:       {
++; CHECK-F32X2-NEXT:    .reg .b32 %r<2>;
++; CHECK-F32X2-NEXT:    .reg .b64 %rd<2>;
++; CHECK-F32X2-EMPTY:
++; CHECK-F32X2-NEXT:  // %bb.0:
++; CHECK-F32X2-NEXT:    ld.param.b64 %rd1, [test_extract_1_param_0];
++; CHECK-F32X2-NEXT:    mov.b64 {_, %r1}, %rd1;
++; CHECK-F32X2-NEXT:    st.param.b32 [func_retval0], %r1;
++; CHECK-F32X2-NEXT:    ret;
+   %e = extractelement <2 x float> %a, i32 1
+   ret float %e
+ }
+@@ -70,10 +94,12 @@
+ ; CHECK-NOF32X2-NEXT:    .reg .b64 %rd<3>;
+ ; CHECK-NOF32X2-EMPTY:
+ ; CHECK-NOF32X2-NEXT:  // %bb.0:
+-; CHECK-NOF32X2-NEXT:    ld.param.v2.b32 {%r1, %r2}, [test_fadd_param_0];
+-; CHECK-NOF32X2-NEXT:    ld.param.v2.b32 {%r3, %r4}, [test_fadd_param_1];
+-; CHECK-NOF32X2-NEXT:    add.rn.f32 %r5, %r2, %r4;
+-; CHECK-NOF32X2-NEXT:    add.rn.f32 %r6, %r1, %r3;
++; CHECK-NOF32X2-NEXT:    ld.param.b64 %rd2, [test_fadd_param_1];
++; CHECK-NOF32X2-NEXT:    ld.param.b64 %rd1, [test_fadd_param_0];
++; CHECK-NOF32X2-NEXT:    mov.b64 {%r1, %r2}, %rd2;
++; CHECK-NOF32X2-NEXT:    mov.b64 {%r3, %r4}, %rd1;
++; CHECK-NOF32X2-NEXT:    add.rn.f32 %r5, %r4, %r2;
++; CHECK-NOF32X2-NEXT:    add.rn.f32 %r6, %r3, %r1;
+ ; CHECK-NOF32X2-NEXT:    st.param.v2.b32 [func_retval0], {%r6, %r5};
+ ; CHECK-NOF32X2-NEXT:    ret;
+ ;
+@@ -98,7 +124,8 @@
+ ; CHECK-NOF32X2-NEXT:    .reg .b64 %rd<2>;
+ ; CHECK-NOF32X2-EMPTY:
+ ; CHECK-NOF32X2-NEXT:  // %bb.0:
+-; CHECK-NOF32X2-NEXT:    ld.param.v2.b32 {%r1, %r2}, [test_fadd_imm_0_param_0];
++; CHECK-NOF32X2-NEXT:    ld.param.b64 %rd1, [test_fadd_imm_0_param_0];
++; CHECK-NOF32X2-NEXT:    mov.b64 {%r1, %r2}, %rd1;
+ ; CHECK-NOF32X2-NEXT:    add.rn.f32 %r3, %r2, 0f40000000;
+ ; CHECK-NOF32X2-NEXT:    add.rn.f32 %r4, %r1, 0f3F800000;
+ ; CHECK-NOF32X2-NEXT:    st.param.v2.b32 [func_retval0], {%r4, %r3};
+@@ -128,7 +155,8 @@
+ ; CHECK-NOF32X2-NEXT:    .reg .b64 %rd<2>;
+ ; CHECK-NOF32X2-EMPTY:
+ ; CHECK-NOF32X2-NEXT:  // %bb.0:
+-; CHECK-NOF32X2-NEXT:    ld.param.v2.b32 {%r1, %r2}, [test_fadd_imm_1_param_0];
++; CHECK-NOF32X2-NEXT:    ld.param.b64 %rd1, [test_fadd_imm_1_param_0];
++; CHECK-NOF32X2-NEXT:    mov.b64 {%r1, %r2}, %rd1;
+ ; CHECK-NOF32X2-NEXT:    add.rn.f32 %r3, %r2, 0f40000000;
+ ; CHECK-NOF32X2-NEXT:    add.rn.f32 %r4, %r1, 0f3F800000;
+ ; CHECK-NOF32X2-NEXT:    st.param.v2.b32 [func_retval0], {%r4, %r3};
+@@ -158,13 +186,17 @@
+ ; CHECK-NOF32X2-NEXT:    .reg .b64 %rd<5>;
+ ; CHECK-NOF32X2-EMPTY:
+ ; CHECK-NOF32X2-NEXT:  // %bb.0:
+-; CHECK-NOF32X2-NEXT:    ld.param.v4.b32 {%r1, %r2, %r3, %r4}, [test_fadd_v4_param_0];
+-; CHECK-NOF32X2-NEXT:    ld.param.v4.b32 {%r5, %r6, %r7, %r8}, [test_fadd_v4_param_1];
+-; CHECK-NOF32X2-NEXT:    add.rn.f32 %r9, %r4, %r8;
+-; CHECK-NOF32X2-NEXT:    add.rn.f32 %r10, %r3, %r7;
+-; CHECK-NOF32X2-NEXT:    add.rn.f32 %r11, %r2, %r6;
+-; CHECK-NOF32X2-NEXT:    add.rn.f32 %r12, %r1, %r5;
+-; CHECK-NOF32X2-NEXT:    st.param.v4.b32 [func_retval0], {%r12, %r11, %r10, %r9};
++; CHECK-NOF32X2-NEXT:    ld.param.v2.b64 {%rd3, %rd4}, [test_fadd_v4_param_1];
++; CHECK-NOF32X2-NEXT:    ld.param.v2.b64 {%rd1, %rd2}, [test_fadd_v4_param_0];
++; CHECK-NOF32X2-NEXT:    mov.b64 {%r1, %r2}, %rd4;
++; CHECK-NOF32X2-NEXT:    mov.b64 {%r3, %r4}, %rd2;
++; CHECK-NOF32X2-NEXT:    add.rn.f32 %r5, %r4, %r2;
++; CHECK-NOF32X2-NEXT:    add.rn.f32 %r6, %r3, %r1;
++; CHECK-NOF32X2-NEXT:    mov.b64 {%r7, %r8}, %rd3;
++; CHECK-NOF32X2-NEXT:    mov.b64 {%r9, %r10}, %rd1;
++; CHECK-NOF32X2-NEXT:    add.rn.f32 %r11, %r10, %r8;
++; CHECK-NOF32X2-NEXT:    add.rn.f32 %r12, %r9, %r7;
++; CHECK-NOF32X2-NEXT:    st.param.v4.b32 [func_retval0], {%r12, %r11, %r6, %r5};
+ ; CHECK-NOF32X2-NEXT:    ret;
+ ;
+ ; CHECK-F32X2-LABEL: test_fadd_v4(
+@@ -189,12 +221,14 @@
+ ; CHECK-NOF32X2-NEXT:    .reg .b64 %rd<3>;
+ ; CHECK-NOF32X2-EMPTY:
+ ; CHECK-NOF32X2-NEXT:  // %bb.0:
+-; CHECK-NOF32X2-NEXT:    ld.param.v4.b32 {%r1, %r2, %r3, %r4}, [test_fadd_imm_0_v4_param_0];
+-; CHECK-NOF32X2-NEXT:    add.rn.f32 %r5, %r4, 0f40800000;
+-; CHECK-NOF32X2-NEXT:    add.rn.f32 %r6, %r3, 0f40400000;
+-; CHECK-NOF32X2-NEXT:    add.rn.f32 %r7, %r2, 0f40000000;
+-; CHECK-NOF32X2-NEXT:    add.rn.f32 %r8, %r1, 0f3F800000;
+-; CHECK-NOF32X2-NEXT:    st.param.v4.b32 [func_retval0], {%r8, %r7, %r6, %r5};
++; CHECK-NOF32X2-NEXT:    ld.param.v2.b64 {%rd1, %rd2}, [test_fadd_imm_0_v4_param_0];
++; CHECK-NOF32X2-NEXT:    mov.b64 {%r1, %r2}, %rd2;
++; CHECK-NOF32X2-NEXT:    add.rn.f32 %r3, %r2, 0f40800000;
++; CHECK-NOF32X2-NEXT:    add.rn.f32 %r4, %r1, 0f40400000;
++; CHECK-NOF32X2-NEXT:    mov.b64 {%r5, %r6}, %rd1;
++; CHECK-NOF32X2-NEXT:    add.rn.f32 %r7, %r6, 0f40000000;
++; CHECK-NOF32X2-NEXT:    add.rn.f32 %r8, %r5, 0f3F800000;
++; CHECK-NOF32X2-NEXT:    st.param.v4.b32 [func_retval0], {%r8, %r7, %r4, %r3};
+ ; CHECK-NOF32X2-NEXT:    ret;
+ ;
+ ; CHECK-F32X2-LABEL: test_fadd_imm_0_v4(
+@@ -225,12 +259,14 @@
+ ; CHECK-NOF32X2-NEXT:    .reg .b64 %rd<3>;
+ ; CHECK-NOF32X2-EMPTY:
+ ; CHECK-NOF32X2-NEXT:  // %bb.0:
+-; CHECK-NOF32X2-NEXT:    ld.param.v4.b32 {%r1, %r2, %r3, %r4}, [test_fadd_imm_1_v4_param_0];
+-; CHECK-NOF32X2-NEXT:    add.rn.f32 %r5, %r4, 0f40800000;
+-; CHECK-NOF32X2-NEXT:    add.rn.f32 %r6, %r3, 0f40400000;
+-; CHECK-NOF32X2-NEXT:    add.rn.f32 %r7, %r2, 0f40000000;
+-; CHECK-NOF32X2-NEXT:    add.rn.f32 %r8, %r1, 0f3F800000;
+-; CHECK-NOF32X2-NEXT:    st.param.v4.b32 [func_retval0], {%r8, %r7, %r6, %r5};
++; CHECK-NOF32X2-NEXT:    ld.param.v2.b64 {%rd1, %rd2}, [test_fadd_imm_1_v4_param_0];
++; CHECK-NOF32X2-NEXT:    mov.b64 {%r1, %r2}, %rd2;
++; CHECK-NOF32X2-NEXT:    add.rn.f32 %r3, %r2, 0f40800000;
++; CHECK-NOF32X2-NEXT:    add.rn.f32 %r4, %r1, 0f40400000;
++; CHECK-NOF32X2-NEXT:    mov.b64 {%r5, %r6}, %rd1;
++; CHECK-NOF32X2-NEXT:    add.rn.f32 %r7, %r6, 0f40000000;
++; CHECK-NOF32X2-NEXT:    add.rn.f32 %r8, %r5, 0f3F800000;
++; CHECK-NOF32X2-NEXT:    st.param.v4.b32 [func_retval0], {%r8, %r7, %r4, %r3};
+ ; CHECK-NOF32X2-NEXT:    ret;
+ ;
+ ; CHECK-F32X2-LABEL: test_fadd_imm_1_v4(
+@@ -261,10 +297,12 @@
+ ; CHECK-NOF32X2-NEXT:    .reg .b64 %rd<3>;
+ ; CHECK-NOF32X2-EMPTY:
+ ; CHECK-NOF32X2-NEXT:  // %bb.0:
+-; CHECK-NOF32X2-NEXT:    ld.param.v2.b32 {%r1, %r2}, [test_fsub_param_0];
+-; CHECK-NOF32X2-NEXT:    ld.param.v2.b32 {%r3, %r4}, [test_fsub_param_1];
+-; CHECK-NOF32X2-NEXT:    sub.rn.f32 %r5, %r2, %r4;
+-; CHECK-NOF32X2-NEXT:    sub.rn.f32 %r6, %r1, %r3;
++; CHECK-NOF32X2-NEXT:    ld.param.b64 %rd2, [test_fsub_param_1];
++; CHECK-NOF32X2-NEXT:    ld.param.b64 %rd1, [test_fsub_param_0];
++; CHECK-NOF32X2-NEXT:    mov.b64 {%r1, %r2}, %rd2;
++; CHECK-NOF32X2-NEXT:    mov.b64 {%r3, %r4}, %rd1;
++; CHECK-NOF32X2-NEXT:    sub.rn.f32 %r5, %r4, %r2;
++; CHECK-NOF32X2-NEXT:    sub.rn.f32 %r6, %r3, %r1;
+ ; CHECK-NOF32X2-NEXT:    st.param.v2.b32 [func_retval0], {%r6, %r5};
+ ; CHECK-NOF32X2-NEXT:    ret;
+ ;
+@@ -289,7 +327,8 @@
+ ; CHECK-NEXT:    .reg .b64 %rd<2>;
+ ; CHECK-EMPTY:
+ ; CHECK-NEXT:  // %bb.0:
+-; CHECK-NEXT:    ld.param.v2.b32 {%r1, %r2}, [test_fneg_param_0];
++; CHECK-NEXT:    ld.param.b64 %rd1, [test_fneg_param_0];
++; CHECK-NEXT:    mov.b64 {%r1, %r2}, %rd1;
+ ; CHECK-NEXT:    neg.f32 %r3, %r2;
+ ; CHECK-NEXT:    neg.f32 %r4, %r1;
+ ; CHECK-NEXT:    st.param.v2.b32 [func_retval0], {%r4, %r3};
+@@ -305,10 +344,12 @@
+ ; CHECK-NOF32X2-NEXT:    .reg .b64 %rd<3>;
+ ; CHECK-NOF32X2-EMPTY:
+ ; CHECK-NOF32X2-NEXT:  // %bb.0:
+-; CHECK-NOF32X2-NEXT:    ld.param.v2.b32 {%r1, %r2}, [test_fmul_param_0];
+-; CHECK-NOF32X2-NEXT:    ld.param.v2.b32 {%r3, %r4}, [test_fmul_param_1];
+-; CHECK-NOF32X2-NEXT:    mul.rn.f32 %r5, %r2, %r4;
+-; CHECK-NOF32X2-NEXT:    mul.rn.f32 %r6, %r1, %r3;
++; CHECK-NOF32X2-NEXT:    ld.param.b64 %rd2, [test_fmul_param_1];
++; CHECK-NOF32X2-NEXT:    ld.param.b64 %rd1, [test_fmul_param_0];
++; CHECK-NOF32X2-NEXT:    mov.b64 {%r1, %r2}, %rd2;
++; CHECK-NOF32X2-NEXT:    mov.b64 {%r3, %r4}, %rd1;
++; CHECK-NOF32X2-NEXT:    mul.rn.f32 %r5, %r4, %r2;
++; CHECK-NOF32X2-NEXT:    mul.rn.f32 %r6, %r3, %r1;
+ ; CHECK-NOF32X2-NEXT:    st.param.v2.b32 [func_retval0], {%r6, %r5};
+ ; CHECK-NOF32X2-NEXT:    ret;
+ ;
+@@ -333,10 +374,12 @@
+ ; CHECK-NEXT:    .reg .b64 %rd<3>;
+ ; CHECK-EMPTY:
+ ; CHECK-NEXT:  // %bb.0:
+-; CHECK-NEXT:    ld.param.v2.b32 {%r1, %r2}, [test_fdiv_param_0];
+-; CHECK-NEXT:    ld.param.v2.b32 {%r3, %r4}, [test_fdiv_param_1];
+-; CHECK-NEXT:    div.rn.f32 %r5, %r2, %r4;
+-; CHECK-NEXT:    div.rn.f32 %r6, %r1, %r3;
++; CHECK-NEXT:    ld.param.b64 %rd2, [test_fdiv_param_1];
++; CHECK-NEXT:    ld.param.b64 %rd1, [test_fdiv_param_0];
++; CHECK-NEXT:    mov.b64 {%r1, %r2}, %rd2;
++; CHECK-NEXT:    mov.b64 {%r3, %r4}, %rd1;
++; CHECK-NEXT:    div.rn.f32 %r5, %r4, %r2;
++; CHECK-NEXT:    div.rn.f32 %r6, %r3, %r1;
+ ; CHECK-NEXT:    st.param.v2.b32 [func_retval0], {%r6, %r5};
+ ; CHECK-NEXT:    ret;
+   %r = fdiv <2 x float> %a, %b
+@@ -351,20 +394,22 @@
+ ; CHECK-NEXT:    .reg .b64 %rd<3>;
+ ; CHECK-EMPTY:
+ ; CHECK-NEXT:  // %bb.0:
+-; CHECK-NEXT:    ld.param.v2.b32 {%r1, %r2}, [test_frem_param_0];
+-; CHECK-NEXT:    ld.param.v2.b32 {%r3, %r4}, [test_frem_param_1];
+-; CHECK-NEXT:    div.rn.f32 %r5, %r2, %r4;
++; CHECK-NEXT:    ld.param.b64 %rd2, [test_frem_param_1];
++; CHECK-NEXT:    ld.param.b64 %rd1, [test_frem_param_0];
++; CHECK-NEXT:    mov.b64 {%r1, %r2}, %rd2;
++; CHECK-NEXT:    mov.b64 {%r3, %r4}, %rd1;
++; CHECK-NEXT:    div.rn.f32 %r5, %r4, %r2;
+ ; CHECK-NEXT:    cvt.rzi.f32.f32 %r6, %r5;
+ ; CHECK-NEXT:    neg.f32 %r7, %r6;
+-; CHECK-NEXT:    fma.rn.f32 %r8, %r7, %r4, %r2;
+-; CHECK-NEXT:    testp.infinite.f32 %p1, %r4;
+-; CHECK-NEXT:    selp.f32 %r9, %r2, %r8, %p1;
+-; CHECK-NEXT:    div.rn.f32 %r10, %r1, %r3;
++; CHECK-NEXT:    fma.rn.f32 %r8, %r7, %r2, %r4;
++; CHECK-NEXT:    testp.infinite.f32 %p1, %r2;
++; CHECK-NEXT:    selp.f32 %r9, %r4, %r8, %p1;
++; CHECK-NEXT:    div.rn.f32 %r10, %r3, %r1;
+ ; CHECK-NEXT:    cvt.rzi.f32.f32 %r11, %r10;
+ ; CHECK-NEXT:    neg.f32 %r12, %r11;
+-; CHECK-NEXT:    fma.rn.f32 %r13, %r12, %r3, %r1;
+-; CHECK-NEXT:    testp.infinite.f32 %p2, %r3;
+-; CHECK-NEXT:    selp.f32 %r14, %r1, %r13, %p2;
++; CHECK-NEXT:    fma.rn.f32 %r13, %r12, %r1, %r3;
++; CHECK-NEXT:    testp.infinite.f32 %p2, %r1;
++; CHECK-NEXT:    selp.f32 %r14, %r3, %r13, %p2;
+ ; CHECK-NEXT:    st.param.v2.b32 [func_retval0], {%r14, %r9};
+ ; CHECK-NEXT:    ret;
+   %r = frem <2 x float> %a, %b
+@@ -378,10 +423,12 @@
+ ; CHECK-NOF32X2-NEXT:    .reg .b64 %rd<3>;
+ ; CHECK-NOF32X2-EMPTY:
+ ; CHECK-NOF32X2-NEXT:  // %bb.0:
+-; CHECK-NOF32X2-NEXT:    ld.param.v2.b32 {%r1, %r2}, [test_fadd_ftz_param_0];
+-; CHECK-NOF32X2-NEXT:    ld.param.v2.b32 {%r3, %r4}, [test_fadd_ftz_param_1];
+-; CHECK-NOF32X2-NEXT:    add.rn.ftz.f32 %r5, %r2, %r4;
+-; CHECK-NOF32X2-NEXT:    add.rn.ftz.f32 %r6, %r1, %r3;
++; CHECK-NOF32X2-NEXT:    ld.param.b64 %rd2, [test_fadd_ftz_param_1];
++; CHECK-NOF32X2-NEXT:    ld.param.b64 %rd1, [test_fadd_ftz_param_0];
++; CHECK-NOF32X2-NEXT:    mov.b64 {%r1, %r2}, %rd2;
++; CHECK-NOF32X2-NEXT:    mov.b64 {%r3, %r4}, %rd1;
++; CHECK-NOF32X2-NEXT:    add.rn.ftz.f32 %r5, %r4, %r2;
++; CHECK-NOF32X2-NEXT:    add.rn.ftz.f32 %r6, %r3, %r1;
+ ; CHECK-NOF32X2-NEXT:    st.param.v2.b32 [func_retval0], {%r6, %r5};
+ ; CHECK-NOF32X2-NEXT:    ret;
+ ;
+@@ -406,7 +453,8 @@
+ ; CHECK-NOF32X2-NEXT:    .reg .b64 %rd<2>;
+ ; CHECK-NOF32X2-EMPTY:
+ ; CHECK-NOF32X2-NEXT:  // %bb.0:
+-; CHECK-NOF32X2-NEXT:    ld.param.v2.b32 {%r1, %r2}, [test_fadd_imm_0_ftz_param_0];
++; CHECK-NOF32X2-NEXT:    ld.param.b64 %rd1, [test_fadd_imm_0_ftz_param_0];
++; CHECK-NOF32X2-NEXT:    mov.b64 {%r1, %r2}, %rd1;
+ ; CHECK-NOF32X2-NEXT:    add.rn.ftz.f32 %r3, %r2, 0f40000000;
+ ; CHECK-NOF32X2-NEXT:    add.rn.ftz.f32 %r4, %r1, 0f3F800000;
+ ; CHECK-NOF32X2-NEXT:    st.param.v2.b32 [func_retval0], {%r4, %r3};
+@@ -436,7 +484,8 @@
+ ; CHECK-NOF32X2-NEXT:    .reg .b64 %rd<2>;
+ ; CHECK-NOF32X2-EMPTY:
+ ; CHECK-NOF32X2-NEXT:  // %bb.0:
+-; CHECK-NOF32X2-NEXT:    ld.param.v2.b32 {%r1, %r2}, [test_fadd_imm_1_ftz_param_0];
++; CHECK-NOF32X2-NEXT:    ld.param.b64 %rd1, [test_fadd_imm_1_ftz_param_0];
++; CHECK-NOF32X2-NEXT:    mov.b64 {%r1, %r2}, %rd1;
+ ; CHECK-NOF32X2-NEXT:    add.rn.ftz.f32 %r3, %r2, 0f40000000;
+ ; CHECK-NOF32X2-NEXT:    add.rn.ftz.f32 %r4, %r1, 0f3F800000;
+ ; CHECK-NOF32X2-NEXT:    st.param.v2.b32 [func_retval0], {%r4, %r3};
+@@ -466,13 +515,17 @@
+ ; CHECK-NOF32X2-NEXT:    .reg .b64 %rd<5>;
+ ; CHECK-NOF32X2-EMPTY:
+ ; CHECK-NOF32X2-NEXT:  // %bb.0:
+-; CHECK-NOF32X2-NEXT:    ld.param.v4.b32 {%r1, %r2, %r3, %r4}, [test_fadd_v4_ftz_param_0];
+-; CHECK-NOF32X2-NEXT:    ld.param.v4.b32 {%r5, %r6, %r7, %r8}, [test_fadd_v4_ftz_param_1];
+-; CHECK-NOF32X2-NEXT:    add.rn.ftz.f32 %r9, %r4, %r8;
+-; CHECK-NOF32X2-NEXT:    add.rn.ftz.f32 %r10, %r3, %r7;
+-; CHECK-NOF32X2-NEXT:    add.rn.ftz.f32 %r11, %r2, %r6;
+-; CHECK-NOF32X2-NEXT:    add.rn.ftz.f32 %r12, %r1, %r5;
+-; CHECK-NOF32X2-NEXT:    st.param.v4.b32 [func_retval0], {%r12, %r11, %r10, %r9};
++; CHECK-NOF32X2-NEXT:    ld.param.v2.b64 {%rd3, %rd4}, [test_fadd_v4_ftz_param_1];
++; CHECK-NOF32X2-NEXT:    ld.param.v2.b64 {%rd1, %rd2}, [test_fadd_v4_ftz_param_0];
++; CHECK-NOF32X2-NEXT:    mov.b64 {%r1, %r2}, %rd4;
++; CHECK-NOF32X2-NEXT:    mov.b64 {%r3, %r4}, %rd2;
++; CHECK-NOF32X2-NEXT:    add.rn.ftz.f32 %r5, %r4, %r2;
++; CHECK-NOF32X2-NEXT:    add.rn.ftz.f32 %r6, %r3, %r1;
++; CHECK-NOF32X2-NEXT:    mov.b64 {%r7, %r8}, %rd3;
++; CHECK-NOF32X2-NEXT:    mov.b64 {%r9, %r10}, %rd1;
++; CHECK-NOF32X2-NEXT:    add.rn.ftz.f32 %r11, %r10, %r8;
++; CHECK-NOF32X2-NEXT:    add.rn.ftz.f32 %r12, %r9, %r7;
++; CHECK-NOF32X2-NEXT:    st.param.v4.b32 [func_retval0], {%r12, %r11, %r6, %r5};
+ ; CHECK-NOF32X2-NEXT:    ret;
+ ;
+ ; CHECK-F32X2-LABEL: test_fadd_v4_ftz(
+@@ -497,12 +550,14 @@
+ ; CHECK-NOF32X2-NEXT:    .reg .b64 %rd<3>;
+ ; CHECK-NOF32X2-EMPTY:
+ ; CHECK-NOF32X2-NEXT:  // %bb.0:
+-; CHECK-NOF32X2-NEXT:    ld.param.v4.b32 {%r1, %r2, %r3, %r4}, [test_fadd_imm_0_v4_ftz_param_0];
+-; CHECK-NOF32X2-NEXT:    add.rn.ftz.f32 %r5, %r4, 0f40800000;
+-; CHECK-NOF32X2-NEXT:    add.rn.ftz.f32 %r6, %r3, 0f40400000;
+-; CHECK-NOF32X2-NEXT:    add.rn.ftz.f32 %r7, %r2, 0f40000000;
+-; CHECK-NOF32X2-NEXT:    add.rn.ftz.f32 %r8, %r1, 0f3F800000;
+-; CHECK-NOF32X2-NEXT:    st.param.v4.b32 [func_retval0], {%r8, %r7, %r6, %r5};
++; CHECK-NOF32X2-NEXT:    ld.param.v2.b64 {%rd1, %rd2}, [test_fadd_imm_0_v4_ftz_param_0];
++; CHECK-NOF32X2-NEXT:    mov.b64 {%r1, %r2}, %rd2;
++; CHECK-NOF32X2-NEXT:    add.rn.ftz.f32 %r3, %r2, 0f40800000;
++; CHECK-NOF32X2-NEXT:    add.rn.ftz.f32 %r4, %r1, 0f40400000;
++; CHECK-NOF32X2-NEXT:    mov.b64 {%r5, %r6}, %rd1;
++; CHECK-NOF32X2-NEXT:    add.rn.ftz.f32 %r7, %r6, 0f40000000;
++; CHECK-NOF32X2-NEXT:    add.rn.ftz.f32 %r8, %r5, 0f3F800000;
++; CHECK-NOF32X2-NEXT:    st.param.v4.b32 [func_retval0], {%r8, %r7, %r4, %r3};
+ ; CHECK-NOF32X2-NEXT:    ret;
+ ;
+ ; CHECK-F32X2-LABEL: test_fadd_imm_0_v4_ftz(
+@@ -533,12 +588,14 @@
+ ; CHECK-NOF32X2-NEXT:    .reg .b64 %rd<3>;
+ ; CHECK-NOF32X2-EMPTY:
+ ; CHECK-NOF32X2-NEXT:  // %bb.0:
+-; CHECK-NOF32X2-NEXT:    ld.param.v4.b32 {%r1, %r2, %r3, %r4}, [test_fadd_imm_1_v4_ftz_param_0];
+-; CHECK-NOF32X2-NEXT:    add.rn.ftz.f32 %r5, %r4, 0f40800000;
+-; CHECK-NOF32X2-NEXT:    add.rn.ftz.f32 %r6, %r3, 0f40400000;
+-; CHECK-NOF32X2-NEXT:    add.rn.ftz.f32 %r7, %r2, 0f40000000;
+-; CHECK-NOF32X2-NEXT:    add.rn.ftz.f32 %r8, %r1, 0f3F800000;
+-; CHECK-NOF32X2-NEXT:    st.param.v4.b32 [func_retval0], {%r8, %r7, %r6, %r5};
++; CHECK-NOF32X2-NEXT:    ld.param.v2.b64 {%rd1, %rd2}, [test_fadd_imm_1_v4_ftz_param_0];
++; CHECK-NOF32X2-NEXT:    mov.b64 {%r1, %r2}, %rd2;
++; CHECK-NOF32X2-NEXT:    add.rn.ftz.f32 %r3, %r2, 0f40800000;
++; CHECK-NOF32X2-NEXT:    add.rn.ftz.f32 %r4, %r1, 0f40400000;
++; CHECK-NOF32X2-NEXT:    mov.b64 {%r5, %r6}, %rd1;
++; CHECK-NOF32X2-NEXT:    add.rn.ftz.f32 %r7, %r6, 0f40000000;
++; CHECK-NOF32X2-NEXT:    add.rn.ftz.f32 %r8, %r5, 0f3F800000;
++; CHECK-NOF32X2-NEXT:    st.param.v4.b32 [func_retval0], {%r8, %r7, %r4, %r3};
+ ; CHECK-NOF32X2-NEXT:    ret;
+ ;
+ ; CHECK-F32X2-LABEL: test_fadd_imm_1_v4_ftz(
+@@ -569,10 +626,12 @@
+ ; CHECK-NOF32X2-NEXT:    .reg .b64 %rd<3>;
+ ; CHECK-NOF32X2-EMPTY:
+ ; CHECK-NOF32X2-NEXT:  // %bb.0:
+-; CHECK-NOF32X2-NEXT:    ld.param.v2.b32 {%r1, %r2}, [test_fsub_ftz_param_0];
+-; CHECK-NOF32X2-NEXT:    ld.param.v2.b32 {%r3, %r4}, [test_fsub_ftz_param_1];
+-; CHECK-NOF32X2-NEXT:    sub.rn.ftz.f32 %r5, %r2, %r4;
+-; CHECK-NOF32X2-NEXT:    sub.rn.ftz.f32 %r6, %r1, %r3;
++; CHECK-NOF32X2-NEXT:    ld.param.b64 %rd2, [test_fsub_ftz_param_1];
++; CHECK-NOF32X2-NEXT:    ld.param.b64 %rd1, [test_fsub_ftz_param_0];
++; CHECK-NOF32X2-NEXT:    mov.b64 {%r1, %r2}, %rd2;
++; CHECK-NOF32X2-NEXT:    mov.b64 {%r3, %r4}, %rd1;
++; CHECK-NOF32X2-NEXT:    sub.rn.ftz.f32 %r5, %r4, %r2;
++; CHECK-NOF32X2-NEXT:    sub.rn.ftz.f32 %r6, %r3, %r1;
+ ; CHECK-NOF32X2-NEXT:    st.param.v2.b32 [func_retval0], {%r6, %r5};
+ ; CHECK-NOF32X2-NEXT:    ret;
+ ;
+@@ -597,7 +656,8 @@
+ ; CHECK-NEXT:    .reg .b64 %rd<2>;
+ ; CHECK-EMPTY:
+ ; CHECK-NEXT:  // %bb.0:
+-; CHECK-NEXT:    ld.param.v2.b32 {%r1, %r2}, [test_fneg_ftz_param_0];
++; CHECK-NEXT:    ld.param.b64 %rd1, [test_fneg_ftz_param_0];
++; CHECK-NEXT:    mov.b64 {%r1, %r2}, %rd1;
+ ; CHECK-NEXT:    neg.ftz.f32 %r3, %r2;
+ ; CHECK-NEXT:    neg.ftz.f32 %r4, %r1;
+ ; CHECK-NEXT:    st.param.v2.b32 [func_retval0], {%r4, %r3};
+@@ -613,10 +673,12 @@
+ ; CHECK-NOF32X2-NEXT:    .reg .b64 %rd<3>;
+ ; CHECK-NOF32X2-EMPTY:
+ ; CHECK-NOF32X2-NEXT:  // %bb.0:
+-; CHECK-NOF32X2-NEXT:    ld.param.v2.b32 {%r1, %r2}, [test_fmul_ftz_param_0];
+-; CHECK-NOF32X2-NEXT:    ld.param.v2.b32 {%r3, %r4}, [test_fmul_ftz_param_1];
+-; CHECK-NOF32X2-NEXT:    mul.rn.ftz.f32 %r5, %r2, %r4;
+-; CHECK-NOF32X2-NEXT:    mul.rn.ftz.f32 %r6, %r1, %r3;
++; CHECK-NOF32X2-NEXT:    ld.param.b64 %rd2, [test_fmul_ftz_param_1];
++; CHECK-NOF32X2-NEXT:    ld.param.b64 %rd1, [test_fmul_ftz_param_0];
++; CHECK-NOF32X2-NEXT:    mov.b64 {%r1, %r2}, %rd2;
++; CHECK-NOF32X2-NEXT:    mov.b64 {%r3, %r4}, %rd1;
++; CHECK-NOF32X2-NEXT:    mul.rn.ftz.f32 %r5, %r4, %r2;
++; CHECK-NOF32X2-NEXT:    mul.rn.ftz.f32 %r6, %r3, %r1;
+ ; CHECK-NOF32X2-NEXT:    st.param.v2.b32 [func_retval0], {%r6, %r5};
+ ; CHECK-NOF32X2-NEXT:    ret;
+ ;
+@@ -641,11 +703,14 @@
+ ; CHECK-NOF32X2-NEXT:    .reg .b64 %rd<4>;
+ ; CHECK-NOF32X2-EMPTY:
+ ; CHECK-NOF32X2-NEXT:  // %bb.0:
+-; CHECK-NOF32X2-NEXT:    ld.param.v2.b32 {%r1, %r2}, [test_fma_ftz_param_0];
+-; CHECK-NOF32X2-NEXT:    ld.param.v2.b32 {%r3, %r4}, [test_fma_ftz_param_1];
+-; CHECK-NOF32X2-NEXT:    ld.param.v2.b32 {%r5, %r6}, [test_fma_ftz_param_2];
+-; CHECK-NOF32X2-NEXT:    fma.rn.ftz.f32 %r7, %r2, %r4, %r6;
+-; CHECK-NOF32X2-NEXT:    fma.rn.ftz.f32 %r8, %r1, %r3, %r5;
++; CHECK-NOF32X2-NEXT:    ld.param.b64 %rd3, [test_fma_ftz_param_2];
++; CHECK-NOF32X2-NEXT:    ld.param.b64 %rd2, [test_fma_ftz_param_1];
++; CHECK-NOF32X2-NEXT:    ld.param.b64 %rd1, [test_fma_ftz_param_0];
++; CHECK-NOF32X2-NEXT:    mov.b64 {%r1, %r2}, %rd3;
++; CHECK-NOF32X2-NEXT:    mov.b64 {%r3, %r4}, %rd2;
++; CHECK-NOF32X2-NEXT:    mov.b64 {%r5, %r6}, %rd1;
++; CHECK-NOF32X2-NEXT:    fma.rn.ftz.f32 %r7, %r6, %r4, %r2;
++; CHECK-NOF32X2-NEXT:    fma.rn.ftz.f32 %r8, %r5, %r3, %r1;
+ ; CHECK-NOF32X2-NEXT:    st.param.v2.b32 [func_retval0], {%r8, %r7};
+ ; CHECK-NOF32X2-NEXT:    ret;
+ ;
+@@ -671,10 +736,12 @@
+ ; CHECK-NEXT:    .reg .b64 %rd<3>;
+ ; CHECK-EMPTY:
+ ; CHECK-NEXT:  // %bb.0:
+-; CHECK-NEXT:    ld.param.v2.b32 {%r1, %r2}, [test_fdiv_ftz_param_0];
+-; CHECK-NEXT:    ld.param.v2.b32 {%r3, %r4}, [test_fdiv_ftz_param_1];
+-; CHECK-NEXT:    div.rn.ftz.f32 %r5, %r2, %r4;
+-; CHECK-NEXT:    div.rn.ftz.f32 %r6, %r1, %r3;
++; CHECK-NEXT:    ld.param.b64 %rd2, [test_fdiv_ftz_param_1];
++; CHECK-NEXT:    ld.param.b64 %rd1, [test_fdiv_ftz_param_0];
++; CHECK-NEXT:    mov.b64 {%r1, %r2}, %rd2;
++; CHECK-NEXT:    mov.b64 {%r3, %r4}, %rd1;
++; CHECK-NEXT:    div.rn.ftz.f32 %r5, %r4, %r2;
++; CHECK-NEXT:    div.rn.ftz.f32 %r6, %r3, %r1;
+ ; CHECK-NEXT:    st.param.v2.b32 [func_retval0], {%r6, %r5};
+ ; CHECK-NEXT:    ret;
+   %r = fdiv <2 x float> %a, %b
+@@ -689,20 +756,22 @@
+ ; CHECK-NEXT:    .reg .b64 %rd<3>;
+ ; CHECK-EMPTY:
+ ; CHECK-NEXT:  // %bb.0:
+-; CHECK-NEXT:    ld.param.v2.b32 {%r1, %r2}, [test_frem_ftz_param_0];
+-; CHECK-NEXT:    ld.param.v2.b32 {%r3, %r4}, [test_frem_ftz_param_1];
+-; CHECK-NEXT:    div.rn.ftz.f32 %r5, %r2, %r4;
++; CHECK-NEXT:    ld.param.b64 %rd2, [test_frem_ftz_param_1];
++; CHECK-NEXT:    ld.param.b64 %rd1, [test_frem_ftz_param_0];
++; CHECK-NEXT:    mov.b64 {%r1, %r2}, %rd2;
++; CHECK-NEXT:    mov.b64 {%r3, %r4}, %rd1;
++; CHECK-NEXT:    div.rn.ftz.f32 %r5, %r4, %r2;
+ ; CHECK-NEXT:    cvt.rzi.ftz.f32.f32 %r6, %r5;
+ ; CHECK-NEXT:    neg.ftz.f32 %r7, %r6;
+-; CHECK-NEXT:    fma.rn.ftz.f32 %r8, %r7, %r4, %r2;
+-; CHECK-NEXT:    testp.infinite.f32 %p1, %r4;
+-; CHECK-NEXT:    selp.f32 %r9, %r2, %r8, %p1;
+-; CHECK-NEXT:    div.rn.ftz.f32 %r10, %r1, %r3;
++; CHECK-NEXT:    fma.rn.ftz.f32 %r8, %r7, %r2, %r4;
++; CHECK-NEXT:    testp.infinite.f32 %p1, %r2;
++; CHECK-NEXT:    selp.f32 %r9, %r4, %r8, %p1;
++; CHECK-NEXT:    div.rn.ftz.f32 %r10, %r3, %r1;
+ ; CHECK-NEXT:    cvt.rzi.ftz.f32.f32 %r11, %r10;
+ ; CHECK-NEXT:    neg.ftz.f32 %r12, %r11;
+-; CHECK-NEXT:    fma.rn.ftz.f32 %r13, %r12, %r3, %r1;
+-; CHECK-NEXT:    testp.infinite.f32 %p2, %r3;
+-; CHECK-NEXT:    selp.f32 %r14, %r1, %r13, %p2;
++; CHECK-NEXT:    fma.rn.ftz.f32 %r13, %r12, %r1, %r3;
++; CHECK-NEXT:    testp.infinite.f32 %p2, %r1;
++; CHECK-NEXT:    selp.f32 %r14, %r3, %r13, %p2;
+ ; CHECK-NEXT:    st.param.v2.b32 [func_retval0], {%r14, %r9};
+ ; CHECK-NEXT:    ret;
+   %r = frem <2 x float> %a, %b
+@@ -877,14 +946,18 @@
+ ; CHECK-NEXT:    .reg .b64 %rd<5>;
+ ; CHECK-EMPTY:
+ ; CHECK-NEXT:  // %bb.0:
+-; CHECK-NEXT:    ld.param.v2.b32 {%r1, %r2}, [test_select_cc_param_0];
+-; CHECK-NEXT:    ld.param.v2.b32 {%r3, %r4}, [test_select_cc_param_2];
+-; CHECK-NEXT:    ld.param.v2.b32 {%r5, %r6}, [test_select_cc_param_3];
+-; CHECK-NEXT:    setp.neu.f32 %p1, %r3, %r5;
+-; CHECK-NEXT:    setp.neu.f32 %p2, %r4, %r6;
+-; CHECK-NEXT:    ld.param.v2.b32 {%r7, %r8}, [test_select_cc_param_1];
+-; CHECK-NEXT:    selp.f32 %r9, %r2, %r8, %p2;
+-; CHECK-NEXT:    selp.f32 %r10, %r1, %r7, %p1;
++; CHECK-NEXT:    ld.param.b64 %rd4, [test_select_cc_param_3];
++; CHECK-NEXT:    ld.param.b64 %rd3, [test_select_cc_param_2];
++; CHECK-NEXT:    ld.param.b64 %rd2, [test_select_cc_param_1];
++; CHECK-NEXT:    ld.param.b64 %rd1, [test_select_cc_param_0];
++; CHECK-NEXT:    mov.b64 {%r1, %r2}, %rd4;
++; CHECK-NEXT:    mov.b64 {%r3, %r4}, %rd3;
++; CHECK-NEXT:    setp.neu.f32 %p1, %r3, %r1;
++; CHECK-NEXT:    setp.neu.f32 %p2, %r4, %r2;
++; CHECK-NEXT:    mov.b64 {%r5, %r6}, %rd2;
++; CHECK-NEXT:    mov.b64 {%r7, %r8}, %rd1;
++; CHECK-NEXT:    selp.f32 %r9, %r8, %r6, %p2;
++; CHECK-NEXT:    selp.f32 %r10, %r7, %r5, %p1;
+ ; CHECK-NEXT:    st.param.v2.b32 [func_retval0], {%r10, %r9};
+ ; CHECK-NEXT:    ret;
+   %cc = fcmp une <2 x float> %c, %d
+@@ -902,10 +975,12 @@
+ ; CHECK-NEXT:  // %bb.0:
+ ; CHECK-NEXT:    ld.param.v2.b64 {%rd3, %rd4}, [test_select_cc_f64_f32_param_1];
+ ; CHECK-NEXT:    ld.param.v2.b64 {%rd1, %rd2}, [test_select_cc_f64_f32_param_0];
+-; CHECK-NEXT:    ld.param.v2.b32 {%r1, %r2}, [test_select_cc_f64_f32_param_2];
+-; CHECK-NEXT:    ld.param.v2.b32 {%r3, %r4}, [test_select_cc_f64_f32_param_3];
+-; CHECK-NEXT:    setp.neu.f32 %p1, %r1, %r3;
+-; CHECK-NEXT:    setp.neu.f32 %p2, %r2, %r4;
++; CHECK-NEXT:    ld.param.b64 %rd6, [test_select_cc_f64_f32_param_3];
++; CHECK-NEXT:    ld.param.b64 %rd5, [test_select_cc_f64_f32_param_2];
++; CHECK-NEXT:    mov.b64 {%r1, %r2}, %rd6;
++; CHECK-NEXT:    mov.b64 {%r3, %r4}, %rd5;
++; CHECK-NEXT:    setp.neu.f32 %p1, %r3, %r1;
++; CHECK-NEXT:    setp.neu.f32 %p2, %r4, %r2;
+ ; CHECK-NEXT:    selp.f64 %rd7, %rd2, %rd4, %p2;
+ ; CHECK-NEXT:    selp.f64 %rd8, %rd1, %rd3, %p1;
+ ; CHECK-NEXT:    st.param.v2.b64 [func_retval0], {%rd8, %rd7};
+@@ -925,12 +1000,14 @@
+ ; CHECK-NEXT:  // %bb.0:
+ ; CHECK-NEXT:    ld.param.v2.b64 {%rd5, %rd6}, [test_select_cc_f32_f64_param_3];
+ ; CHECK-NEXT:    ld.param.v2.b64 {%rd3, %rd4}, [test_select_cc_f32_f64_param_2];
+-; CHECK-NEXT:    ld.param.v2.b32 {%r1, %r2}, [test_select_cc_f32_f64_param_0];
++; CHECK-NEXT:    ld.param.b64 %rd2, [test_select_cc_f32_f64_param_1];
++; CHECK-NEXT:    ld.param.b64 %rd1, [test_select_cc_f32_f64_param_0];
+ ; CHECK-NEXT:    setp.neu.f64 %p1, %rd3, %rd5;
+ ; CHECK-NEXT:    setp.neu.f64 %p2, %rd4, %rd6;
+-; CHECK-NEXT:    ld.param.v2.b32 {%r3, %r4}, [test_select_cc_f32_f64_param_1];
+-; CHECK-NEXT:    selp.f32 %r5, %r2, %r4, %p2;
+-; CHECK-NEXT:    selp.f32 %r6, %r1, %r3, %p1;
++; CHECK-NEXT:    mov.b64 {%r1, %r2}, %rd2;
++; CHECK-NEXT:    mov.b64 {%r3, %r4}, %rd1;
++; CHECK-NEXT:    selp.f32 %r5, %r4, %r2, %p2;
++; CHECK-NEXT:    selp.f32 %r6, %r3, %r1, %p1;
+ ; CHECK-NEXT:    st.param.v2.b32 [func_retval0], {%r6, %r5};
+ ; CHECK-NEXT:    ret;
+   %cc = fcmp une <2 x double> %c, %d
+@@ -947,10 +1024,12 @@
+ ; CHECK-NEXT:    .reg .b64 %rd<3>;
+ ; CHECK-EMPTY:
+ ; CHECK-NEXT:  // %bb.0:
+-; CHECK-NEXT:    ld.param.v2.b32 {%r1, %r2}, [test_fcmp_une_param_0];
+-; CHECK-NEXT:    ld.param.v2.b32 {%r3, %r4}, [test_fcmp_une_param_1];
+-; CHECK-NEXT:    setp.neu.f32 %p1, %r2, %r4;
+-; CHECK-NEXT:    setp.neu.f32 %p2, %r1, %r3;
++; CHECK-NEXT:    ld.param.b64 %rd2, [test_fcmp_une_param_1];
++; CHECK-NEXT:    ld.param.b64 %rd1, [test_fcmp_une_param_0];
++; CHECK-NEXT:    mov.b64 {%r1, %r2}, %rd2;
++; CHECK-NEXT:    mov.b64 {%r3, %r4}, %rd1;
++; CHECK-NEXT:    setp.neu.f32 %p1, %r4, %r2;
++; CHECK-NEXT:    setp.neu.f32 %p2, %r3, %r1;
+ ; CHECK-NEXT:    selp.b16 %rs1, -1, 0, %p2;
+ ; CHECK-NEXT:    st.param.b8 [func_retval0], %rs1;
+ ; CHECK-NEXT:    selp.b16 %rs2, -1, 0, %p1;
+@@ -969,10 +1048,12 @@
+ ; CHECK-NEXT:    .reg .b64 %rd<3>;
+ ; CHECK-EMPTY:
+ ; CHECK-NEXT:  // %bb.0:
+-; CHECK-NEXT:    ld.param.v2.b32 {%r1, %r2}, [test_fcmp_ueq_param_0];
+-; CHECK-NEXT:    ld.param.v2.b32 {%r3, %r4}, [test_fcmp_ueq_param_1];
+-; CHECK-NEXT:    setp.equ.f32 %p1, %r2, %r4;
+-; CHECK-NEXT:    setp.equ.f32 %p2, %r1, %r3;
++; CHECK-NEXT:    ld.param.b64 %rd2, [test_fcmp_ueq_param_1];
++; CHECK-NEXT:    ld.param.b64 %rd1, [test_fcmp_ueq_param_0];
++; CHECK-NEXT:    mov.b64 {%r1, %r2}, %rd2;
++; CHECK-NEXT:    mov.b64 {%r3, %r4}, %rd1;
++; CHECK-NEXT:    setp.equ.f32 %p1, %r4, %r2;
++; CHECK-NEXT:    setp.equ.f32 %p2, %r3, %r1;
+ ; CHECK-NEXT:    selp.b16 %rs1, -1, 0, %p2;
+ ; CHECK-NEXT:    st.param.b8 [func_retval0], %rs1;
+ ; CHECK-NEXT:    selp.b16 %rs2, -1, 0, %p1;
+@@ -991,10 +1072,12 @@
+ ; CHECK-NEXT:    .reg .b64 %rd<3>;
+ ; CHECK-EMPTY:
+ ; CHECK-NEXT:  // %bb.0:
+-; CHECK-NEXT:    ld.param.v2.b32 {%r1, %r2}, [test_fcmp_ugt_param_0];
+-; CHECK-NEXT:    ld.param.v2.b32 {%r3, %r4}, [test_fcmp_ugt_param_1];
+-; CHECK-NEXT:    setp.gtu.f32 %p1, %r2, %r4;
+-; CHECK-NEXT:    setp.gtu.f32 %p2, %r1, %r3;
++; CHECK-NEXT:    ld.param.b64 %rd2, [test_fcmp_ugt_param_1];
++; CHECK-NEXT:    ld.param.b64 %rd1, [test_fcmp_ugt_param_0];
++; CHECK-NEXT:    mov.b64 {%r1, %r2}, %rd2;
++; CHECK-NEXT:    mov.b64 {%r3, %r4}, %rd1;
++; CHECK-NEXT:    setp.gtu.f32 %p1, %r4, %r2;
++; CHECK-NEXT:    setp.gtu.f32 %p2, %r3, %r1;
+ ; CHECK-NEXT:    selp.b16 %rs1, -1, 0, %p2;
+ ; CHECK-NEXT:    st.param.b8 [func_retval0], %rs1;
+ ; CHECK-NEXT:    selp.b16 %rs2, -1, 0, %p1;
+@@ -1013,10 +1096,12 @@
+ ; CHECK-NEXT:    .reg .b64 %rd<3>;
+ ; CHECK-EMPTY:
+ ; CHECK-NEXT:  // %bb.0:
+-; CHECK-NEXT:    ld.param.v2.b32 {%r1, %r2}, [test_fcmp_uge_param_0];
+-; CHECK-NEXT:    ld.param.v2.b32 {%r3, %r4}, [test_fcmp_uge_param_1];
+-; CHECK-NEXT:    setp.geu.f32 %p1, %r2, %r4;
+-; CHECK-NEXT:    setp.geu.f32 %p2, %r1, %r3;
++; CHECK-NEXT:    ld.param.b64 %rd2, [test_fcmp_uge_param_1];
++; CHECK-NEXT:    ld.param.b64 %rd1, [test_fcmp_uge_param_0];
++; CHECK-NEXT:    mov.b64 {%r1, %r2}, %rd2;
++; CHECK-NEXT:    mov.b64 {%r3, %r4}, %rd1;
++; CHECK-NEXT:    setp.geu.f32 %p1, %r4, %r2;
++; CHECK-NEXT:    setp.geu.f32 %p2, %r3, %r1;
+ ; CHECK-NEXT:    selp.b16 %rs1, -1, 0, %p2;
+ ; CHECK-NEXT:    st.param.b8 [func_retval0], %rs1;
+ ; CHECK-NEXT:    selp.b16 %rs2, -1, 0, %p1;
+@@ -1035,10 +1120,12 @@
+ ; CHECK-NEXT:    .reg .b64 %rd<3>;
+ ; CHECK-EMPTY:
+ ; CHECK-NEXT:  // %bb.0:
+-; CHECK-NEXT:    ld.param.v2.b32 {%r1, %r2}, [test_fcmp_ult_param_0];
+-; CHECK-NEXT:    ld.param.v2.b32 {%r3, %r4}, [test_fcmp_ult_param_1];
+-; CHECK-NEXT:    setp.ltu.f32 %p1, %r2, %r4;
+-; CHECK-NEXT:    setp.ltu.f32 %p2, %r1, %r3;
++; CHECK-NEXT:    ld.param.b64 %rd2, [test_fcmp_ult_param_1];
++; CHECK-NEXT:    ld.param.b64 %rd1, [test_fcmp_ult_param_0];
++; CHECK-NEXT:    mov.b64 {%r1, %r2}, %rd2;
++; CHECK-NEXT:    mov.b64 {%r3, %r4}, %rd1;
++; CHECK-NEXT:    setp.ltu.f32 %p1, %r4, %r2;
++; CHECK-NEXT:    setp.ltu.f32 %p2, %r3, %r1;
+ ; CHECK-NEXT:    selp.b16 %rs1, -1, 0, %p2;
+ ; CHECK-NEXT:    st.param.b8 [func_retval0], %rs1;
+ ; CHECK-NEXT:    selp.b16 %rs2, -1, 0, %p1;
+@@ -1057,10 +1144,12 @@
+ ; CHECK-NEXT:    .reg .b64 %rd<3>;
+ ; CHECK-EMPTY:
+ ; CHECK-NEXT:  // %bb.0:
+-; CHECK-NEXT:    ld.param.v2.b32 {%r1, %r2}, [test_fcmp_ule_param_0];
+-; CHECK-NEXT:    ld.param.v2.b32 {%r3, %r4}, [test_fcmp_ule_param_1];
+-; CHECK-NEXT:    setp.leu.f32 %p1, %r2, %r4;
+-; CHECK-NEXT:    setp.leu.f32 %p2, %r1, %r3;
++; CHECK-NEXT:    ld.param.b64 %rd2, [test_fcmp_ule_param_1];
++; CHECK-NEXT:    ld.param.b64 %rd1, [test_fcmp_ule_param_0];
++; CHECK-NEXT:    mov.b64 {%r1, %r2}, %rd2;
++; CHECK-NEXT:    mov.b64 {%r3, %r4}, %rd1;
++; CHECK-NEXT:    setp.leu.f32 %p1, %r4, %r2;
++; CHECK-NEXT:    setp.leu.f32 %p2, %r3, %r1;
+ ; CHECK-NEXT:    selp.b16 %rs1, -1, 0, %p2;
+ ; CHECK-NEXT:    st.param.b8 [func_retval0], %rs1;
+ ; CHECK-NEXT:    selp.b16 %rs2, -1, 0, %p1;
+@@ -1079,10 +1168,12 @@
+ ; CHECK-NEXT:    .reg .b64 %rd<3>;
+ ; CHECK-EMPTY:
+ ; CHECK-NEXT:  // %bb.0:
+-; CHECK-NEXT:    ld.param.v2.b32 {%r1, %r2}, [test_fcmp_uno_param_0];
+-; CHECK-NEXT:    ld.param.v2.b32 {%r3, %r4}, [test_fcmp_uno_param_1];
+-; CHECK-NEXT:    setp.nan.f32 %p1, %r2, %r4;
+-; CHECK-NEXT:    setp.nan.f32 %p2, %r1, %r3;
++; CHECK-NEXT:    ld.param.b64 %rd2, [test_fcmp_uno_param_1];
++; CHECK-NEXT:    ld.param.b64 %rd1, [test_fcmp_uno_param_0];
++; CHECK-NEXT:    mov.b64 {%r1, %r2}, %rd2;
++; CHECK-NEXT:    mov.b64 {%r3, %r4}, %rd1;
++; CHECK-NEXT:    setp.nan.f32 %p1, %r4, %r2;
++; CHECK-NEXT:    setp.nan.f32 %p2, %r3, %r1;
+ ; CHECK-NEXT:    selp.b16 %rs1, -1, 0, %p2;
+ ; CHECK-NEXT:    st.param.b8 [func_retval0], %rs1;
+ ; CHECK-NEXT:    selp.b16 %rs2, -1, 0, %p1;
+@@ -1101,10 +1192,12 @@
+ ; CHECK-NEXT:    .reg .b64 %rd<3>;
+ ; CHECK-EMPTY:
+ ; CHECK-NEXT:  // %bb.0:
+-; CHECK-NEXT:    ld.param.v2.b32 {%r1, %r2}, [test_fcmp_one_param_0];
+-; CHECK-NEXT:    ld.param.v2.b32 {%r3, %r4}, [test_fcmp_one_param_1];
+-; CHECK-NEXT:    setp.ne.f32 %p1, %r2, %r4;
+-; CHECK-NEXT:    setp.ne.f32 %p2, %r1, %r3;
++; CHECK-NEXT:    ld.param.b64 %rd2, [test_fcmp_one_param_1];
++; CHECK-NEXT:    ld.param.b64 %rd1, [test_fcmp_one_param_0];
++; CHECK-NEXT:    mov.b64 {%r1, %r2}, %rd2;
++; CHECK-NEXT:    mov.b64 {%r3, %r4}, %rd1;
++; CHECK-NEXT:    setp.ne.f32 %p1, %r4, %r2;
++; CHECK-NEXT:    setp.ne.f32 %p2, %r3, %r1;
+ ; CHECK-NEXT:    selp.b16 %rs1, -1, 0, %p2;
+ ; CHECK-NEXT:    st.param.b8 [func_retval0], %rs1;
+ ; CHECK-NEXT:    selp.b16 %rs2, -1, 0, %p1;
+@@ -1123,10 +1216,12 @@
+ ; CHECK-NEXT:    .reg .b64 %rd<3>;
+ ; CHECK-EMPTY:
+ ; CHECK-NEXT:  // %bb.0:
+-; CHECK-NEXT:    ld.param.v2.b32 {%r1, %r2}, [test_fcmp_oeq_param_0];
+-; CHECK-NEXT:    ld.param.v2.b32 {%r3, %r4}, [test_fcmp_oeq_param_1];
+-; CHECK-NEXT:    setp.eq.f32 %p1, %r2, %r4;
+-; CHECK-NEXT:    setp.eq.f32 %p2, %r1, %r3;
++; CHECK-NEXT:    ld.param.b64 %rd2, [test_fcmp_oeq_param_1];
++; CHECK-NEXT:    ld.param.b64 %rd1, [test_fcmp_oeq_param_0];
++; CHECK-NEXT:    mov.b64 {%r1, %r2}, %rd2;
++; CHECK-NEXT:    mov.b64 {%r3, %r4}, %rd1;
++; CHECK-NEXT:    setp.eq.f32 %p1, %r4, %r2;
++; CHECK-NEXT:    setp.eq.f32 %p2, %r3, %r1;
+ ; CHECK-NEXT:    selp.b16 %rs1, -1, 0, %p2;
+ ; CHECK-NEXT:    st.param.b8 [func_retval0], %rs1;
+ ; CHECK-NEXT:    selp.b16 %rs2, -1, 0, %p1;
+@@ -1145,10 +1240,12 @@
+ ; CHECK-NEXT:    .reg .b64 %rd<3>;
+ ; CHECK-EMPTY:
+ ; CHECK-NEXT:  // %bb.0:
+-; CHECK-NEXT:    ld.param.v2.b32 {%r1, %r2}, [test_fcmp_ogt_param_0];
+-; CHECK-NEXT:    ld.param.v2.b32 {%r3, %r4}, [test_fcmp_ogt_param_1];
+-; CHECK-NEXT:    setp.gt.f32 %p1, %r2, %r4;
+-; CHECK-NEXT:    setp.gt.f32 %p2, %r1, %r3;
++; CHECK-NEXT:    ld.param.b64 %rd2, [test_fcmp_ogt_param_1];
++; CHECK-NEXT:    ld.param.b64 %rd1, [test_fcmp_ogt_param_0];
++; CHECK-NEXT:    mov.b64 {%r1, %r2}, %rd2;
++; CHECK-NEXT:    mov.b64 {%r3, %r4}, %rd1;
++; CHECK-NEXT:    setp.gt.f32 %p1, %r4, %r2;
++; CHECK-NEXT:    setp.gt.f32 %p2, %r3, %r1;
+ ; CHECK-NEXT:    selp.b16 %rs1, -1, 0, %p2;
+ ; CHECK-NEXT:    st.param.b8 [func_retval0], %rs1;
+ ; CHECK-NEXT:    selp.b16 %rs2, -1, 0, %p1;
+@@ -1167,10 +1264,12 @@
+ ; CHECK-NEXT:    .reg .b64 %rd<3>;
+ ; CHECK-EMPTY:
+ ; CHECK-NEXT:  // %bb.0:
+-; CHECK-NEXT:    ld.param.v2.b32 {%r1, %r2}, [test_fcmp_oge_param_0];
+-; CHECK-NEXT:    ld.param.v2.b32 {%r3, %r4}, [test_fcmp_oge_param_1];
+-; CHECK-NEXT:    setp.ge.f32 %p1, %r2, %r4;
+-; CHECK-NEXT:    setp.ge.f32 %p2, %r1, %r3;
++; CHECK-NEXT:    ld.param.b64 %rd2, [test_fcmp_oge_param_1];
++; CHECK-NEXT:    ld.param.b64 %rd1, [test_fcmp_oge_param_0];
++; CHECK-NEXT:    mov.b64 {%r1, %r2}, %rd2;
++; CHECK-NEXT:    mov.b64 {%r3, %r4}, %rd1;
++; CHECK-NEXT:    setp.ge.f32 %p1, %r4, %r2;
++; CHECK-NEXT:    setp.ge.f32 %p2, %r3, %r1;
+ ; CHECK-NEXT:    selp.b16 %rs1, -1, 0, %p2;
+ ; CHECK-NEXT:    st.param.b8 [func_retval0], %rs1;
+ ; CHECK-NEXT:    selp.b16 %rs2, -1, 0, %p1;
+@@ -1189,10 +1288,12 @@
+ ; CHECK-NEXT:    .reg .b64 %rd<3>;
+ ; CHECK-EMPTY:
+ ; CHECK-NEXT:  // %bb.0:
+-; CHECK-NEXT:    ld.param.v2.b32 {%r1, %r2}, [test_fcmp_olt_param_0];
+-; CHECK-NEXT:    ld.param.v2.b32 {%r3, %r4}, [test_fcmp_olt_param_1];
+-; CHECK-NEXT:    setp.lt.f32 %p1, %r2, %r4;
+-; CHECK-NEXT:    setp.lt.f32 %p2, %r1, %r3;
++; CHECK-NEXT:    ld.param.b64 %rd2, [test_fcmp_olt_param_1];
++; CHECK-NEXT:    ld.param.b64 %rd1, [test_fcmp_olt_param_0];
++; CHECK-NEXT:    mov.b64 {%r1, %r2}, %rd2;
++; CHECK-NEXT:    mov.b64 {%r3, %r4}, %rd1;
++; CHECK-NEXT:    setp.lt.f32 %p1, %r4, %r2;
++; CHECK-NEXT:    setp.lt.f32 %p2, %r3, %r1;
+ ; CHECK-NEXT:    selp.b16 %rs1, -1, 0, %p2;
+ ; CHECK-NEXT:    st.param.b8 [func_retval0], %rs1;
+ ; CHECK-NEXT:    selp.b16 %rs2, -1, 0, %p1;
+@@ -1211,10 +1312,12 @@
+ ; CHECK-NEXT:    .reg .b64 %rd<3>;
+ ; CHECK-EMPTY:
+ ; CHECK-NEXT:  // %bb.0:
+-; CHECK-NEXT:    ld.param.v2.b32 {%r1, %r2}, [test_fcmp_ole_param_0];
+-; CHECK-NEXT:    ld.param.v2.b32 {%r3, %r4}, [test_fcmp_ole_param_1];
+-; CHECK-NEXT:    setp.le.f32 %p1, %r2, %r4;
+-; CHECK-NEXT:    setp.le.f32 %p2, %r1, %r3;
++; CHECK-NEXT:    ld.param.b64 %rd2, [test_fcmp_ole_param_1];
++; CHECK-NEXT:    ld.param.b64 %rd1, [test_fcmp_ole_param_0];
++; CHECK-NEXT:    mov.b64 {%r1, %r2}, %rd2;
++; CHECK-NEXT:    mov.b64 {%r3, %r4}, %rd1;
++; CHECK-NEXT:    setp.le.f32 %p1, %r4, %r2;
++; CHECK-NEXT:    setp.le.f32 %p2, %r3, %r1;
+ ; CHECK-NEXT:    selp.b16 %rs1, -1, 0, %p2;
+ ; CHECK-NEXT:    st.param.b8 [func_retval0], %rs1;
+ ; CHECK-NEXT:    selp.b16 %rs2, -1, 0, %p1;
+@@ -1233,10 +1336,12 @@
+ ; CHECK-NEXT:    .reg .b64 %rd<3>;
+ ; CHECK-EMPTY:
+ ; CHECK-NEXT:  // %bb.0:
+-; CHECK-NEXT:    ld.param.v2.b32 {%r1, %r2}, [test_fcmp_ord_param_0];
+-; CHECK-NEXT:    ld.param.v2.b32 {%r3, %r4}, [test_fcmp_ord_param_1];
+-; CHECK-NEXT:    setp.num.f32 %p1, %r2, %r4;
+-; CHECK-NEXT:    setp.num.f32 %p2, %r1, %r3;
++; CHECK-NEXT:    ld.param.b64 %rd2, [test_fcmp_ord_param_1];
++; CHECK-NEXT:    ld.param.b64 %rd1, [test_fcmp_ord_param_0];
++; CHECK-NEXT:    mov.b64 {%r1, %r2}, %rd2;
++; CHECK-NEXT:    mov.b64 {%r3, %r4}, %rd1;
++; CHECK-NEXT:    setp.num.f32 %p1, %r4, %r2;
++; CHECK-NEXT:    setp.num.f32 %p2, %r3, %r1;
+ ; CHECK-NEXT:    selp.b16 %rs1, -1, 0, %p2;
+ ; CHECK-NEXT:    st.param.b8 [func_retval0], %rs1;
+ ; CHECK-NEXT:    selp.b16 %rs2, -1, 0, %p1;
+@@ -1253,7 +1358,8 @@
+ ; CHECK-NEXT:    .reg .b64 %rd<2>;
+ ; CHECK-EMPTY:
+ ; CHECK-NEXT:  // %bb.0:
+-; CHECK-NEXT:    ld.param.v2.b32 {%r1, %r2}, [test_fptosi_i32_param_0];
++; CHECK-NEXT:    ld.param.b64 %rd1, [test_fptosi_i32_param_0];
++; CHECK-NEXT:    mov.b64 {%r1, %r2}, %rd1;
+ ; CHECK-NEXT:    cvt.rzi.s32.f32 %r3, %r2;
+ ; CHECK-NEXT:    cvt.rzi.s32.f32 %r4, %r1;
+ ; CHECK-NEXT:    st.param.v2.b32 [func_retval0], {%r4, %r3};
+@@ -1269,7 +1375,8 @@
+ ; CHECK-NEXT:    .reg .b64 %rd<4>;
+ ; CHECK-EMPTY:
+ ; CHECK-NEXT:  // %bb.0:
+-; CHECK-NEXT:    ld.param.v2.b32 {%r1, %r2}, [test_fptosi_i64_param_0];
++; CHECK-NEXT:    ld.param.b64 %rd1, [test_fptosi_i64_param_0];
++; CHECK-NEXT:    mov.b64 {%r1, %r2}, %rd1;
+ ; CHECK-NEXT:    cvt.rzi.s64.f32 %rd2, %r2;
+ ; CHECK-NEXT:    cvt.rzi.s64.f32 %rd3, %r1;
+ ; CHECK-NEXT:    st.param.v2.b64 [func_retval0], {%rd3, %rd2};
+@@ -1285,7 +1392,8 @@
+ ; CHECK-NEXT:    .reg .b64 %rd<2>;
+ ; CHECK-EMPTY:
+ ; CHECK-NEXT:  // %bb.0:
+-; CHECK-NEXT:    ld.param.v2.b32 {%r1, %r2}, [test_fptoui_2xi32_param_0];
++; CHECK-NEXT:    ld.param.b64 %rd1, [test_fptoui_2xi32_param_0];
++; CHECK-NEXT:    mov.b64 {%r1, %r2}, %rd1;
+ ; CHECK-NEXT:    cvt.rzi.u32.f32 %r3, %r2;
+ ; CHECK-NEXT:    cvt.rzi.u32.f32 %r4, %r1;
+ ; CHECK-NEXT:    st.param.v2.b32 [func_retval0], {%r4, %r3};
+@@ -1301,7 +1409,8 @@
+ ; CHECK-NEXT:    .reg .b64 %rd<4>;
+ ; CHECK-EMPTY:
+ ; CHECK-NEXT:  // %bb.0:
+-; CHECK-NEXT:    ld.param.v2.b32 {%r1, %r2}, [test_fptoui_2xi64_param_0];
++; CHECK-NEXT:    ld.param.b64 %rd1, [test_fptoui_2xi64_param_0];
++; CHECK-NEXT:    mov.b64 {%r1, %r2}, %rd1;
+ ; CHECK-NEXT:    cvt.rzi.u64.f32 %rd2, %r2;
+ ; CHECK-NEXT:    cvt.rzi.u64.f32 %rd3, %r1;
+ ; CHECK-NEXT:    st.param.v2.b64 [func_retval0], {%rd3, %rd2};
+@@ -1380,9 +1489,10 @@
+ ; CHECK-NOF32X2-EMPTY:
+ ; CHECK-NOF32X2-NEXT:  // %bb.0:
+ ; CHECK-NOF32X2-NEXT:    ld.param.v2.b32 {%r1, %r2}, [test_uitofp_2xi32_fadd_param_0];
++; CHECK-NOF32X2-NEXT:    ld.param.b64 %rd1, [test_uitofp_2xi32_fadd_param_1];
+ ; CHECK-NOF32X2-NEXT:    cvt.rn.f32.u32 %r3, %r1;
+ ; CHECK-NOF32X2-NEXT:    cvt.rn.f32.u32 %r4, %r2;
+-; CHECK-NOF32X2-NEXT:    ld.param.v2.b32 {%r5, %r6}, [test_uitofp_2xi32_fadd_param_1];
++; CHECK-NOF32X2-NEXT:    mov.b64 {%r5, %r6}, %rd1;
+ ; CHECK-NOF32X2-NEXT:    add.rn.f32 %r7, %r6, %r4;
+ ; CHECK-NOF32X2-NEXT:    add.rn.f32 %r8, %r5, %r3;
+ ; CHECK-NOF32X2-NEXT:    st.param.v2.b32 [func_retval0], {%r8, %r7};
+@@ -1431,7 +1541,8 @@
+ ; CHECK-NEXT:    .reg .b64 %rd<4>;
+ ; CHECK-EMPTY:
+ ; CHECK-NEXT:  // %bb.0:
+-; CHECK-NEXT:    ld.param.v2.b32 {%r1, %r2}, [test_fpext_2xdouble_param_0];
++; CHECK-NEXT:    ld.param.b64 %rd1, [test_fpext_2xdouble_param_0];
++; CHECK-NEXT:    mov.b64 {%r1, %r2}, %rd1;
+ ; CHECK-NEXT:    cvt.f64.f32 %rd2, %r2;
+ ; CHECK-NEXT:    cvt.f64.f32 %rd3, %r1;
+ ; CHECK-NEXT:    st.param.v2.b64 [func_retval0], {%rd3, %rd2};
+@@ -1499,7 +1610,8 @@
+ ; CHECK-NEXT:    .reg .b64 %rd<2>;
+ ; CHECK-EMPTY:
+ ; CHECK-NEXT:  // %bb.0:
+-; CHECK-NEXT:    ld.param.v2.b32 {%r1, %r2}, [test_sqrt_param_0];
++; CHECK-NEXT:    ld.param.b64 %rd1, [test_sqrt_param_0];
++; CHECK-NEXT:    mov.b64 {%r1, %r2}, %rd1;
+ ; CHECK-NEXT:    sqrt.rn.f32 %r3, %r2;
+ ; CHECK-NEXT:    sqrt.rn.f32 %r4, %r1;
+ ; CHECK-NEXT:    st.param.v2.b32 [func_retval0], {%r4, %r3};
+@@ -1522,7 +1634,8 @@
+ ; CHECK-NEXT:    .reg .b64 %rd<2>;
+ ; CHECK-EMPTY:
+ ; CHECK-NEXT:  // %bb.0:
+-; CHECK-NEXT:    ld.param.v2.b32 {%r1, %r2}, [test_sin_param_0];
++; CHECK-NEXT:    ld.param.b64 %rd1, [test_sin_param_0];
++; CHECK-NEXT:    mov.b64 {%r1, %r2}, %rd1;
+ ; CHECK-NEXT:    sin.approx.f32 %r3, %r2;
+ ; CHECK-NEXT:    sin.approx.f32 %r4, %r1;
+ ; CHECK-NEXT:    st.param.v2.b32 [func_retval0], {%r4, %r3};
+@@ -1538,7 +1651,8 @@
+ ; CHECK-NEXT:    .reg .b64 %rd<2>;
+ ; CHECK-EMPTY:
+ ; CHECK-NEXT:  // %bb.0:
+-; CHECK-NEXT:    ld.param.v2.b32 {%r1, %r2}, [test_cos_param_0];
++; CHECK-NEXT:    ld.param.b64 %rd1, [test_cos_param_0];
++; CHECK-NEXT:    mov.b64 {%r1, %r2}, %rd1;
+ ; CHECK-NEXT:    cos.approx.f32 %r3, %r2;
+ ; CHECK-NEXT:    cos.approx.f32 %r4, %r1;
+ ; CHECK-NEXT:    st.param.v2.b32 [func_retval0], {%r4, %r3};
+@@ -1597,11 +1711,14 @@
+ ; CHECK-NOF32X2-NEXT:    .reg .b64 %rd<4>;
+ ; CHECK-NOF32X2-EMPTY:
+ ; CHECK-NOF32X2-NEXT:  // %bb.0:
+-; CHECK-NOF32X2-NEXT:    ld.param.v2.b32 {%r1, %r2}, [test_fma_param_0];
+-; CHECK-NOF32X2-NEXT:    ld.param.v2.b32 {%r3, %r4}, [test_fma_param_1];
+-; CHECK-NOF32X2-NEXT:    ld.param.v2.b32 {%r5, %r6}, [test_fma_param_2];
+-; CHECK-NOF32X2-NEXT:    fma.rn.f32 %r7, %r2, %r4, %r6;
+-; CHECK-NOF32X2-NEXT:    fma.rn.f32 %r8, %r1, %r3, %r5;
++; CHECK-NOF32X2-NEXT:    ld.param.b64 %rd3, [test_fma_param_2];
++; CHECK-NOF32X2-NEXT:    ld.param.b64 %rd2, [test_fma_param_1];
++; CHECK-NOF32X2-NEXT:    ld.param.b64 %rd1, [test_fma_param_0];
++; CHECK-NOF32X2-NEXT:    mov.b64 {%r1, %r2}, %rd3;
++; CHECK-NOF32X2-NEXT:    mov.b64 {%r3, %r4}, %rd2;
++; CHECK-NOF32X2-NEXT:    mov.b64 {%r5, %r6}, %rd1;
++; CHECK-NOF32X2-NEXT:    fma.rn.f32 %r7, %r6, %r4, %r2;
++; CHECK-NOF32X2-NEXT:    fma.rn.f32 %r8, %r5, %r3, %r1;
+ ; CHECK-NOF32X2-NEXT:    st.param.v2.b32 [func_retval0], {%r8, %r7};
+ ; CHECK-NOF32X2-NEXT:    ret;
+ ;
+@@ -1627,7 +1744,8 @@
+ ; CHECK-NEXT:    .reg .b64 %rd<2>;
+ ; CHECK-EMPTY:
+ ; CHECK-NEXT:  // %bb.0:
+-; CHECK-NEXT:    ld.param.v2.b32 {%r1, %r2}, [test_fabs_param_0];
++; CHECK-NEXT:    ld.param.b64 %rd1, [test_fabs_param_0];
++; CHECK-NEXT:    mov.b64 {%r1, %r2}, %rd1;
+ ; CHECK-NEXT:    abs.f32 %r3, %r2;
+ ; CHECK-NEXT:    abs.f32 %r4, %r1;
+ ; CHECK-NEXT:    st.param.v2.b32 [func_retval0], {%r4, %r3};
+@@ -1643,10 +1761,12 @@
+ ; CHECK-NEXT:    .reg .b64 %rd<3>;
+ ; CHECK-EMPTY:
+ ; CHECK-NEXT:  // %bb.0:
+-; CHECK-NEXT:    ld.param.v2.b32 {%r1, %r2}, [test_minnum_param_0];
+-; CHECK-NEXT:    ld.param.v2.b32 {%r3, %r4}, [test_minnum_param_1];
+-; CHECK-NEXT:    min.f32 %r5, %r2, %r4;
+-; CHECK-NEXT:    min.f32 %r6, %r1, %r3;
++; CHECK-NEXT:    ld.param.b64 %rd2, [test_minnum_param_1];
++; CHECK-NEXT:    ld.param.b64 %rd1, [test_minnum_param_0];
++; CHECK-NEXT:    mov.b64 {%r1, %r2}, %rd2;
++; CHECK-NEXT:    mov.b64 {%r3, %r4}, %rd1;
++; CHECK-NEXT:    min.f32 %r5, %r4, %r2;
++; CHECK-NEXT:    min.f32 %r6, %r3, %r1;
+ ; CHECK-NEXT:    st.param.v2.b32 [func_retval0], {%r6, %r5};
+ ; CHECK-NEXT:    ret;
+   %r = call <2 x float> @llvm.minnum(<2 x float> %a, <2 x float> %b)
+@@ -1660,10 +1780,12 @@
+ ; CHECK-NEXT:    .reg .b64 %rd<3>;
+ ; CHECK-EMPTY:
+ ; CHECK-NEXT:  // %bb.0:
+-; CHECK-NEXT:    ld.param.v2.b32 {%r1, %r2}, [test_maxnum_param_0];
+-; CHECK-NEXT:    ld.param.v2.b32 {%r3, %r4}, [test_maxnum_param_1];
+-; CHECK-NEXT:    max.f32 %r5, %r2, %r4;
+-; CHECK-NEXT:    max.f32 %r6, %r1, %r3;
++; CHECK-NEXT:    ld.param.b64 %rd2, [test_maxnum_param_1];
++; CHECK-NEXT:    ld.param.b64 %rd1, [test_maxnum_param_0];
++; CHECK-NEXT:    mov.b64 {%r1, %r2}, %rd2;
++; CHECK-NEXT:    mov.b64 {%r3, %r4}, %rd1;
++; CHECK-NEXT:    max.f32 %r5, %r4, %r2;
++; CHECK-NEXT:    max.f32 %r6, %r3, %r1;
+ ; CHECK-NEXT:    st.param.v2.b32 [func_retval0], {%r6, %r5};
+ ; CHECK-NEXT:    ret;
+   %r = call <2 x float> @llvm.maxnum(<2 x float> %a, <2 x float> %b)
+@@ -1677,8 +1799,10 @@
+ ; CHECK-NEXT:    .reg .b64 %rd<3>;
+ ; CHECK-EMPTY:
+ ; CHECK-NEXT:  // %bb.0:
+-; CHECK-NEXT:    ld.param.v2.b32 {%r1, %r2}, [test_copysign_param_0];
+-; CHECK-NEXT:    ld.param.v2.b32 {%r3, %r4}, [test_copysign_param_1];
++; CHECK-NEXT:    ld.param.b64 %rd2, [test_copysign_param_1];
++; CHECK-NEXT:    ld.param.b64 %rd1, [test_copysign_param_0];
++; CHECK-NEXT:    mov.b64 {%r1, %r2}, %rd1;
++; CHECK-NEXT:    mov.b64 {%r3, %r4}, %rd2;
+ ; CHECK-NEXT:    copysign.f32 %r5, %r4, %r2;
+ ; CHECK-NEXT:    copysign.f32 %r6, %r3, %r1;
+ ; CHECK-NEXT:    st.param.v2.b32 [func_retval0], {%r6, %r5};
+@@ -1696,18 +1820,19 @@
+ ; CHECK-EMPTY:
+ ; CHECK-NEXT:  // %bb.0:
+ ; CHECK-NEXT:    ld.param.v2.b64 {%rd2, %rd3}, [test_copysign_f64_param_1];
+-; CHECK-NEXT:    ld.param.v2.b32 {%r1, %r2}, [test_copysign_f64_param_0];
+-; CHECK-NEXT:    abs.f32 %r3, %r2;
+-; CHECK-NEXT:    neg.f32 %r4, %r3;
++; CHECK-NEXT:    ld.param.b64 %rd1, [test_copysign_f64_param_0];
+ ; CHECK-NEXT:    shr.u64 %rd4, %rd3, 63;
+ ; CHECK-NEXT:    and.b64 %rd5, %rd4, 1;
+ ; CHECK-NEXT:    setp.ne.b64 %p1, %rd5, 0;
++; CHECK-NEXT:    mov.b64 {%r1, %r2}, %rd1;
++; CHECK-NEXT:    abs.f32 %r3, %r2;
++; CHECK-NEXT:    neg.f32 %r4, %r3;
+ ; CHECK-NEXT:    selp.f32 %r5, %r4, %r3, %p1;
+-; CHECK-NEXT:    abs.f32 %r6, %r1;
+-; CHECK-NEXT:    neg.f32 %r7, %r6;
+ ; CHECK-NEXT:    shr.u64 %rd6, %rd2, 63;
+ ; CHECK-NEXT:    and.b64 %rd7, %rd6, 1;
+ ; CHECK-NEXT:    setp.ne.b64 %p2, %rd7, 0;
++; CHECK-NEXT:    abs.f32 %r6, %r1;
++; CHECK-NEXT:    neg.f32 %r7, %r6;
+ ; CHECK-NEXT:    selp.f32 %r8, %r7, %r6, %p2;
+ ; CHECK-NEXT:    st.param.v2.b32 [func_retval0], {%r8, %r5};
+ ; CHECK-NEXT:    ret;
+@@ -1723,8 +1848,10 @@
+ ; CHECK-NEXT:    .reg .b64 %rd<5>;
+ ; CHECK-EMPTY:
+ ; CHECK-NEXT:  // %bb.0:
+-; CHECK-NEXT:    ld.param.v2.b32 {%r1, %r2}, [test_copysign_extended_param_0];
+-; CHECK-NEXT:    ld.param.v2.b32 {%r3, %r4}, [test_copysign_extended_param_1];
++; CHECK-NEXT:    ld.param.b64 %rd2, [test_copysign_extended_param_1];
++; CHECK-NEXT:    ld.param.b64 %rd1, [test_copysign_extended_param_0];
++; CHECK-NEXT:    mov.b64 {%r1, %r2}, %rd1;
++; CHECK-NEXT:    mov.b64 {%r3, %r4}, %rd2;
+ ; CHECK-NEXT:    copysign.f32 %r5, %r3, %r1;
+ ; CHECK-NEXT:    copysign.f32 %r6, %r4, %r2;
+ ; CHECK-NEXT:    cvt.f64.f32 %rd3, %r6;
+@@ -1743,7 +1870,8 @@
+ ; CHECK-NEXT:    .reg .b64 %rd<2>;
+ ; CHECK-EMPTY:
+ ; CHECK-NEXT:  // %bb.0:
+-; CHECK-NEXT:    ld.param.v2.b32 {%r1, %r2}, [test_floor_param_0];
++; CHECK-NEXT:    ld.param.b64 %rd1, [test_floor_param_0];
++; CHECK-NEXT:    mov.b64 {%r1, %r2}, %rd1;
+ ; CHECK-NEXT:    cvt.rmi.f32.f32 %r3, %r2;
+ ; CHECK-NEXT:    cvt.rmi.f32.f32 %r4, %r1;
+ ; CHECK-NEXT:    st.param.v2.b32 [func_retval0], {%r4, %r3};
+@@ -1759,7 +1887,8 @@
+ ; CHECK-NEXT:    .reg .b64 %rd<2>;
+ ; CHECK-EMPTY:
+ ; CHECK-NEXT:  // %bb.0:
+-; CHECK-NEXT:    ld.param.v2.b32 {%r1, %r2}, [test_ceil_param_0];
++; CHECK-NEXT:    ld.param.b64 %rd1, [test_ceil_param_0];
++; CHECK-NEXT:    mov.b64 {%r1, %r2}, %rd1;
+ ; CHECK-NEXT:    cvt.rpi.f32.f32 %r3, %r2;
+ ; CHECK-NEXT:    cvt.rpi.f32.f32 %r4, %r1;
+ ; CHECK-NEXT:    st.param.v2.b32 [func_retval0], {%r4, %r3};
+@@ -1775,7 +1904,8 @@
+ ; CHECK-NEXT:    .reg .b64 %rd<2>;
+ ; CHECK-EMPTY:
+ ; CHECK-NEXT:  // %bb.0:
+-; CHECK-NEXT:    ld.param.v2.b32 {%r1, %r2}, [test_trunc_param_0];
++; CHECK-NEXT:    ld.param.b64 %rd1, [test_trunc_param_0];
++; CHECK-NEXT:    mov.b64 {%r1, %r2}, %rd1;
+ ; CHECK-NEXT:    cvt.rzi.f32.f32 %r3, %r2;
+ ; CHECK-NEXT:    cvt.rzi.f32.f32 %r4, %r1;
+ ; CHECK-NEXT:    st.param.v2.b32 [func_retval0], {%r4, %r3};
+@@ -1791,7 +1921,8 @@
+ ; CHECK-NEXT:    .reg .b64 %rd<2>;
+ ; CHECK-EMPTY:
+ ; CHECK-NEXT:  // %bb.0:
+-; CHECK-NEXT:    ld.param.v2.b32 {%r1, %r2}, [test_rint_param_0];
++; CHECK-NEXT:    ld.param.b64 %rd1, [test_rint_param_0];
++; CHECK-NEXT:    mov.b64 {%r1, %r2}, %rd1;
+ ; CHECK-NEXT:    cvt.rni.f32.f32 %r3, %r2;
+ ; CHECK-NEXT:    cvt.rni.f32.f32 %r4, %r1;
+ ; CHECK-NEXT:    st.param.v2.b32 [func_retval0], {%r4, %r3};
+@@ -1807,7 +1938,8 @@
+ ; CHECK-NEXT:    .reg .b64 %rd<2>;
+ ; CHECK-EMPTY:
+ ; CHECK-NEXT:  // %bb.0:
+-; CHECK-NEXT:    ld.param.v2.b32 {%r1, %r2}, [test_nearbyint_param_0];
++; CHECK-NEXT:    ld.param.b64 %rd1, [test_nearbyint_param_0];
++; CHECK-NEXT:    mov.b64 {%r1, %r2}, %rd1;
+ ; CHECK-NEXT:    cvt.rni.f32.f32 %r3, %r2;
+ ; CHECK-NEXT:    cvt.rni.f32.f32 %r4, %r1;
+ ; CHECK-NEXT:    st.param.v2.b32 [func_retval0], {%r4, %r3};
+@@ -1823,7 +1955,8 @@
+ ; CHECK-NEXT:    .reg .b64 %rd<2>;
+ ; CHECK-EMPTY:
+ ; CHECK-NEXT:  // %bb.0:
+-; CHECK-NEXT:    ld.param.v2.b32 {%r1, %r2}, [test_roundeven_param_0];
++; CHECK-NEXT:    ld.param.b64 %rd1, [test_roundeven_param_0];
++; CHECK-NEXT:    mov.b64 {%r1, %r2}, %rd1;
+ ; CHECK-NEXT:    cvt.rni.f32.f32 %r3, %r2;
+ ; CHECK-NEXT:    cvt.rni.f32.f32 %r4, %r1;
+ ; CHECK-NEXT:    st.param.v2.b32 [func_retval0], {%r4, %r3};
+@@ -1841,7 +1974,8 @@
+ ; CHECK-NEXT:    .reg .b64 %rd<2>;
+ ; CHECK-EMPTY:
+ ; CHECK-NEXT:  // %bb.0:
+-; CHECK-NEXT:    ld.param.v2.b32 {%r1, %r2}, [test_round_param_0];
++; CHECK-NEXT:    ld.param.b64 %rd1, [test_round_param_0];
++; CHECK-NEXT:    mov.b64 {%r1, %r2}, %rd1;
+ ; CHECK-NEXT:    and.b32 %r3, %r2, -2147483648;
+ ; CHECK-NEXT:    or.b32 %r4, %r3, 1056964608;
+ ; CHECK-NEXT:    add.rn.f32 %r5, %r2, %r4;
+@@ -1875,11 +2009,14 @@
+ ; CHECK-NOF32X2-NEXT:    .reg .b64 %rd<4>;
+ ; CHECK-NOF32X2-EMPTY:
+ ; CHECK-NOF32X2-NEXT:  // %bb.0:
+-; CHECK-NOF32X2-NEXT:    ld.param.v2.b32 {%r1, %r2}, [test_fmuladd_param_0];
+-; CHECK-NOF32X2-NEXT:    ld.param.v2.b32 {%r3, %r4}, [test_fmuladd_param_1];
+-; CHECK-NOF32X2-NEXT:    ld.param.v2.b32 {%r5, %r6}, [test_fmuladd_param_2];
+-; CHECK-NOF32X2-NEXT:    fma.rn.f32 %r7, %r2, %r4, %r6;
+-; CHECK-NOF32X2-NEXT:    fma.rn.f32 %r8, %r1, %r3, %r5;
++; CHECK-NOF32X2-NEXT:    ld.param.b64 %rd3, [test_fmuladd_param_2];
++; CHECK-NOF32X2-NEXT:    ld.param.b64 %rd2, [test_fmuladd_param_1];
++; CHECK-NOF32X2-NEXT:    ld.param.b64 %rd1, [test_fmuladd_param_0];
++; CHECK-NOF32X2-NEXT:    mov.b64 {%r1, %r2}, %rd3;
++; CHECK-NOF32X2-NEXT:    mov.b64 {%r3, %r4}, %rd2;
++; CHECK-NOF32X2-NEXT:    mov.b64 {%r5, %r6}, %rd1;
++; CHECK-NOF32X2-NEXT:    fma.rn.f32 %r7, %r6, %r4, %r2;
++; CHECK-NOF32X2-NEXT:    fma.rn.f32 %r8, %r5, %r3, %r1;
+ ; CHECK-NOF32X2-NEXT:    st.param.v2.b32 [func_retval0], {%r8, %r7};
+ ; CHECK-NOF32X2-NEXT:    ret;
+ ;
+@@ -1905,7 +2042,8 @@
+ ; CHECK-NEXT:    .reg .b64 %rd<2>;
+ ; CHECK-EMPTY:
+ ; CHECK-NEXT:  // %bb.0:
+-; CHECK-NEXT:    ld.param.v2.b32 {%r1, %r2}, [test_shufflevector_param_0];
++; CHECK-NEXT:    ld.param.b64 %rd1, [test_shufflevector_param_0];
++; CHECK-NEXT:    mov.b64 {%r1, %r2}, %rd1;
+ ; CHECK-NEXT:    st.param.v2.b32 [func_retval0], {%r2, %r1};
+ ; CHECK-NEXT:    ret;
+   %s = shufflevector <2 x float> %a, <2 x float> poison, <2 x i32> <i32 1, i32 0>
+@@ -1913,16 +2051,29 @@
  }
  
- /// Print out the file/line/column information and include trace.
-diff -ruN --strip-trailing-cr a/clang/lib/Headers/CMakeLists.txt b/clang/lib/Headers/CMakeLists.txt
---- a/clang/lib/Headers/CMakeLists.txt
-+++ b/clang/lib/Headers/CMakeLists.txt
-@@ -347,6 +347,10 @@
-   cuda_wrappers/bits/basic_string.tcc
- )
- 
-+set(cuda_wrapper_utility_files
-+  cuda_wrappers/__utility/declval.h
-+)
-+
- set(ppc_wrapper_files
-   ppc_wrappers/mmintrin.h
-   ppc_wrappers/xmmintrin.h
-@@ -443,8 +447,9 @@
- 
- # Copy header files from the source directory to the build directory
- foreach( f ${files} ${cuda_wrapper_files} ${cuda_wrapper_bits_files}
--           ${ppc_wrapper_files} ${openmp_wrapper_files} ${zos_wrapper_files} ${hlsl_files}
--	   ${llvm_libc_wrapper_files} ${llvm_offload_wrapper_files})
-+           ${cuda_wrapper_utility_files} ${ppc_wrapper_files} ${openmp_wrapper_files}
-+           ${zos_wrapper_files} ${hlsl_files} ${llvm_libc_wrapper_files}
-+           ${llvm_offload_wrapper_files})
-   copy_header_to_output_dir(${CMAKE_CURRENT_SOURCE_DIR} ${f})
- endforeach( f )
- 
-@@ -553,7 +558,7 @@
- # Architecture/platform specific targets
- add_header_target("arm-resource-headers" "${arm_only_files};${arm_only_generated_files}")
- add_header_target("aarch64-resource-headers" "${aarch64_only_files};${aarch64_only_generated_files}")
--add_header_target("cuda-resource-headers" "${cuda_files};${cuda_wrapper_files};${cuda_wrapper_bits_files}")
-+add_header_target("cuda-resource-headers" "${cuda_files};${cuda_wrapper_files};${cuda_wrapper_bits_files};${cuda_wrapper_utility_files}")
- add_header_target("hexagon-resource-headers" "${hexagon_files}")
- add_header_target("hip-resource-headers" "${hip_files}")
- add_header_target("loongarch-resource-headers" "${loongarch_files}")
-@@ -601,6 +606,11 @@
-   COMPONENT clang-resource-headers)
- 
- install(
-+  FILES ${cuda_wrapper_utility_files}
-+  DESTINATION ${header_install_dir}/cuda_wrappers/__utility
-+  COMPONENT clang-resource-headers)
-+
-+install(
-   FILES ${ppc_wrapper_files}
-   DESTINATION ${header_install_dir}/ppc_wrappers
-   COMPONENT clang-resource-headers)
-@@ -663,6 +673,12 @@
-   EXCLUDE_FROM_ALL
-   COMPONENT cuda-resource-headers)
+ define <2 x float> @test_insertelement(<2 x float> %a, float %x) #0 {
+-; CHECK-LABEL: test_insertelement(
+-; CHECK:       {
+-; CHECK-NEXT:    .reg .b32 %r<4>;
+-; CHECK-NEXT:    .reg .b64 %rd<2>;
+-; CHECK-EMPTY:
+-; CHECK-NEXT:  // %bb.0:
+-; CHECK-NEXT:    ld.param.b32 %r1, [test_insertelement_param_1];
+-; CHECK-NEXT:    ld.param.v2.b32 {%r2, %r3}, [test_insertelement_param_0];
+-; CHECK-NEXT:    st.param.v2.b32 [func_retval0], {%r2, %r1};
+-; CHECK-NEXT:    ret;
++; CHECK-NOF32X2-LABEL: test_insertelement(
++; CHECK-NOF32X2:       {
++; CHECK-NOF32X2-NEXT:    .reg .b32 %r<3>;
++; CHECK-NOF32X2-NEXT:    .reg .b64 %rd<2>;
++; CHECK-NOF32X2-EMPTY:
++; CHECK-NOF32X2-NEXT:  // %bb.0:
++; CHECK-NOF32X2-NEXT:    ld.param.b32 %r1, [test_insertelement_param_1];
++; CHECK-NOF32X2-NEXT:    ld.param.b64 %rd1, [test_insertelement_param_0];
++; CHECK-NOF32X2-NEXT:    { .reg .b32 tmp; mov.b64 {%r2, tmp}, %rd1; }
++; CHECK-NOF32X2-NEXT:    st.param.v2.b32 [func_retval0], {%r2, %r1};
++; CHECK-NOF32X2-NEXT:    ret;
++;
++; CHECK-F32X2-LABEL: test_insertelement(
++; CHECK-F32X2:       {
++; CHECK-F32X2-NEXT:    .reg .b32 %r<3>;
++; CHECK-F32X2-NEXT:    .reg .b64 %rd<2>;
++; CHECK-F32X2-EMPTY:
++; CHECK-F32X2-NEXT:  // %bb.0:
++; CHECK-F32X2-NEXT:    ld.param.b32 %r1, [test_insertelement_param_1];
++; CHECK-F32X2-NEXT:    ld.param.b64 %rd1, [test_insertelement_param_0];
++; CHECK-F32X2-NEXT:    mov.b64 {%r2, _}, %rd1;
++; CHECK-F32X2-NEXT:    st.param.v2.b32 [func_retval0], {%r2, %r1};
++; CHECK-F32X2-NEXT:    ret;
+   %i = insertelement <2 x float> %a, float %x, i64 1
+   ret <2 x float> %i
+ }
+@@ -1957,6 +2108,41 @@
+   ret <2 x float> %r
+ }
  
-+install(
-+  FILES ${cuda_wrapper_utility_files}
-+  DESTINATION ${header_install_dir}/cuda_wrappers/__utility
-+  EXCLUDE_FROM_ALL
-+  COMPONENT cuda-resource-headers)
-+
- install(
-   FILES ${cuda_files}
-   DESTINATION ${header_install_dir}
-diff -ruN --strip-trailing-cr a/clang/lib/Headers/cuda_wrappers/__utility/declval.h b/clang/lib/Headers/cuda_wrappers/__utility/declval.h
---- a/clang/lib/Headers/cuda_wrappers/__utility/declval.h
-+++ b/clang/lib/Headers/cuda_wrappers/__utility/declval.h
-@@ -0,0 +1,28 @@
-+#ifndef __CUDA_WRAPPERS_UTILITY_DECLVAL_H__
-+#define __CUDA_WRAPPERS_UTILITY_DECLVAL_H__
-+
-+#include_next <__utility/declval.h>
-+
-+// The stuff below is the exact copy of the <__utility/declval.h>,
-+// but with __device__ attribute applied to the functions, so it works on a GPU.
-+
-+_LIBCPP_BEGIN_NAMESPACE_STD
-+
-+// Suppress deprecation notice for volatile-qualified return type resulting
-+// from volatile-qualified types _Tp.
-+_LIBCPP_SUPPRESS_DEPRECATED_PUSH
-+template <class _Tp> __attribute__((device)) _Tp &&__declval(int);
-+template <class _Tp> __attribute__((device)) _Tp __declval(long);
-+_LIBCPP_SUPPRESS_DEPRECATED_POP
-+
-+template <class _Tp>
-+__attribute__((device)) _LIBCPP_HIDE_FROM_ABI decltype(std::__declval<_Tp>(0))
-+declval() _NOEXCEPT {
-+  static_assert(!__is_same(_Tp, _Tp),
-+                "std::declval can only be used in an unevaluated context. "
-+                "It's likely that your current usage is trying to extract a "
-+                "value from the function.");
++define void @test_trunc_to_v2bf16(<2 x float> %a, ptr %p) {
++; CHECK-LABEL: test_trunc_to_v2bf16(
++; CHECK:       {
++; CHECK-NEXT:    .reg .b32 %r<4>;
++; CHECK-NEXT:    .reg .b64 %rd<3>;
++; CHECK-EMPTY:
++; CHECK-NEXT:  // %bb.0:
++; CHECK-NEXT:    ld.param.b64 %rd2, [test_trunc_to_v2bf16_param_1];
++; CHECK-NEXT:    ld.param.v2.b32 {%r1, %r2}, [test_trunc_to_v2bf16_param_0];
++; CHECK-NEXT:    cvt.rn.bf16x2.f32 %r3, %r2, %r1;
++; CHECK-NEXT:    st.b32 [%rd2], %r3;
++; CHECK-NEXT:    ret;
++  %trunc = fptrunc <2 x float> %a to <2 x bfloat>
++  store <2 x bfloat> %trunc, ptr %p
++  ret void
 +}
 +
-+_LIBCPP_END_NAMESPACE_STD
-+#endif // __CUDA_WRAPPERS_UTILITY_DECLVAL_H__
-diff -ruN --strip-trailing-cr a/clang/lib/Sema/AnalysisBasedWarnings.cpp b/clang/lib/Sema/AnalysisBasedWarnings.cpp
---- a/clang/lib/Sema/AnalysisBasedWarnings.cpp
-+++ b/clang/lib/Sema/AnalysisBasedWarnings.cpp
-@@ -1943,11 +1943,26 @@
- 
-   void handleNoMutexHeld(const NamedDecl *D, ProtectedOperationKind POK,
-                          AccessKind AK, SourceLocation Loc) override {
--    assert((POK == POK_VarAccess || POK == POK_VarDereference) &&
--           "Only works for variables");
--    unsigned DiagID = POK == POK_VarAccess?
--                        diag::warn_variable_requires_any_lock:
--                        diag::warn_var_deref_requires_any_lock;
-+    unsigned DiagID = 0;
-+    switch (POK) {
-+    case POK_VarAccess:
-+    case POK_PassByRef:
-+    case POK_ReturnByRef:
-+    case POK_PassPointer:
-+    case POK_ReturnPointer:
-+      DiagID = diag::warn_variable_requires_any_lock;
-+      break;
-+    case POK_VarDereference:
-+    case POK_PtPassByRef:
-+    case POK_PtReturnByRef:
-+    case POK_PtPassPointer:
-+    case POK_PtReturnPointer:
-+      DiagID = diag::warn_var_deref_requires_any_lock;
-+      break;
-+    case POK_FunctionCall:
-+      llvm_unreachable("Only works for variables");
-+      break;
-+    }
-     PartialDiagnosticAt Warning(Loc, S.PDiag(DiagID)
-       << D << getLockKindFromAccessKind(AK));
-     Warnings.emplace_back(std::move(Warning), getNotes());
-diff -ruN --strip-trailing-cr a/clang/test/ClangScanDeps/visible-modules.c b/clang/test/ClangScanDeps/visible-modules.c
---- a/clang/test/ClangScanDeps/visible-modules.c
-+++ b/clang/test/ClangScanDeps/visible-modules.c
-@@ -30,7 +30,7 @@
- // RUN: %clang @%t/A.rsp
- 
- /// Verify compilation & scan agree with each other.
--// RUN: not %clang @%t/tu.rsp 2>&1 | FileCheck %s --check-prefix=COMPILE
-+// RUN: not %clang @%t/tu.rsp -o %t/blah.o 2>&1 | FileCheck %s --check-prefix=COMPILE
- 
- // SINGLE:        "visible-clang-modules": [
- // SINGLE-NEXT:     "A"
-diff -ruN --strip-trailing-cr a/clang/test/Frontend/absolute-paths.c b/clang/test/Frontend/absolute-paths.c
---- a/clang/test/Frontend/absolute-paths.c
-+++ b/clang/test/Frontend/absolute-paths.c
-@@ -8,9 +8,9 @@
- 
- #include "absolute-paths.h"
- 
--// Check that the bogus prefix we added is stripped out even if absolute paths
--// are disabled.
--// NORMAL-NOT: SystemHeaderPrefix
-+// Check whether the diagnostic from the header above includes the dummy
-+// directory in the path.
-+// NORMAL: SystemHeaderPrefix
- // ABSOLUTE-NOT: SystemHeaderPrefix
- // CHECK: warning: non-void function does not return a value
- 
-diff -ruN --strip-trailing-cr a/clang/test/Frontend/simplify-paths.c b/clang/test/Frontend/simplify-paths.c
---- a/clang/test/Frontend/simplify-paths.c
-+++ b/clang/test/Frontend/simplify-paths.c
-@@ -1,18 +0,0 @@
--// REQUIRES: shell
--
--// RUN: rm -rf %t
--// RUN: mkdir -p %t/a/b/
--// RUN: echo 'void x;' > %t/test.h
--// RUN: echo 'const void x;' > %t/header_with_a_really_long_name.h
--// RUN: ln -s %t/header_with_a_really_long_name.h %t/a/shorter_name.h
--//
--// RUN: %clang_cc1 -fsyntax-only -I %t %s 2> %t/output.txt || true
--// RUN: cat %t/output.txt | FileCheck %s
--
--// Check that we strip '..' by canonicalising the path...
--#include "a/b/../../test.h"
--// CHECK: simplify-paths.c.tmp/test.h:1:6: error: variable has incomplete type 'void'
--
--// ... but only if the resulting path is actually shorter.
--#include "a/b/../shorter_name.h"
--// CHECK: simplify-paths.c.tmp/a/b/../shorter_name.h:1:12: error: variable has incomplete type 'const void'
-diff -ruN --strip-trailing-cr a/clang/test/SemaCXX/warn-thread-safety-analysis.cpp b/clang/test/SemaCXX/warn-thread-safety-analysis.cpp
---- a/clang/test/SemaCXX/warn-thread-safety-analysis.cpp
-+++ b/clang/test/SemaCXX/warn-thread-safety-analysis.cpp
-@@ -6196,6 +6196,8 @@
-   Mutex mu;
-   Foo foo GUARDED_BY(mu);
-   Foo* foo_ptr PT_GUARDED_BY(mu);
-+  Foo foo_depr GUARDED_VAR;          // test deprecated attribute
-+  Foo* foo_ptr_depr PT_GUARDED_VAR;  // test deprecated attribute
- 
-   Foo returns_value_locked() {
-     MutexLock lock(&mu);
-@@ -6297,6 +6299,18 @@
-     return *foo_ptr;          // expected-warning {{returning the value that 'foo_ptr' points to by reference requires holding mutex 'mu' exclusively}}
-   }
- 
-+  Foo *returns_ptr_deprecated() {
-+    return &foo_depr;          // expected-warning {{writing variable 'foo_depr' requires holding any mutex exclusively}}
-+  }
-+
-+  Foo *returns_pt_ptr_deprecated() {
-+    return foo_ptr_depr;       // expected-warning {{writing the value pointed to by 'foo_ptr_depr' requires holding any mutex exclusively}}
-+  }
++define void @test_trunc_to_v2f16(<2 x float> %a, ptr %p) {
++; CHECK-LABEL: test_trunc_to_v2f16(
++; CHECK:       {
++; CHECK-NEXT:    .reg .b32 %r<4>;
++; CHECK-NEXT:    .reg .b64 %rd<3>;
++; CHECK-EMPTY:
++; CHECK-NEXT:  // %bb.0:
++; CHECK-NEXT:    ld.param.b64 %rd2, [test_trunc_to_v2f16_param_1];
++; CHECK-NEXT:    ld.param.v2.b32 {%r1, %r2}, [test_trunc_to_v2f16_param_0];
++; CHECK-NEXT:    cvt.rn.f16x2.f32 %r3, %r2, %r1;
++; CHECK-NEXT:    st.b32 [%rd2], %r3;
++; CHECK-NEXT:    ret;
++  %trunc = fptrunc <2 x float> %a to <2 x half>
++  store <2 x half> %trunc, ptr %p
++  ret void
++}
 +
-+  Foo &returns_ref_deprecated() {
-+    return *foo_ptr_depr;      // expected-warning {{writing the value pointed to by 'foo_ptr_depr' requires holding any mutex exclusively}}
-+  }
 +
-   // FIXME: Basic alias analysis would help catch cases like below.
-   Foo *returns_ptr_alias() {
-     mu.Lock();
-diff -ruN --strip-trailing-cr a/clang-tools-extra/test/clang-tidy/infrastructure/file-filter-symlinks.cpp b/clang-tools-extra/test/clang-tidy/infrastructure/file-filter-symlinks.cpp
---- a/clang-tools-extra/test/clang-tidy/infrastructure/file-filter-symlinks.cpp
-+++ b/clang-tools-extra/test/clang-tidy/infrastructure/file-filter-symlinks.cpp
-@@ -12,9 +12,8 @@
- // RUN: clang-tidy -checks='-*,google-explicit-constructor' -header-filter='header\.h' %s -- -I %t 2>&1 | FileCheck --check-prefix=CHECK_HEADER %s
- // RUN: clang-tidy -checks='-*,google-explicit-constructor' -header-filter='header\.h' -quiet %s -- -I %t 2>&1 | FileCheck --check-prefix=CHECK_HEADER %s
- 
--// `-header-filter` operates on the actual file path that the user provided in
--// the #include directive; however, Clang's path name simplification causes the
--// path to be printed in canonicalised form here.
-+// Check that `-header-filter` operates on the same file paths as paths in
-+// diagnostics printed by ClangTidy.
- #include "dir1/dir2/../header_alias.h"
--// CHECK_HEADER_ALIAS: dir1/header.h:1:11: warning: single-argument constructors
-+// CHECK_HEADER_ALIAS: dir1/dir2/../header_alias.h:1:11: warning: single-argument constructors
- // CHECK_HEADER-NOT: warning:
-diff -ruN --strip-trailing-cr a/libcxx/include/ext/hash_map b/libcxx/include/ext/hash_map
---- a/libcxx/include/ext/hash_map
-+++ b/libcxx/include/ext/hash_map
-@@ -744,7 +744,7 @@
-   _LIBCPP_HIDE_FROM_ABI const_iterator begin() const { return __table_.begin(); }
-   _LIBCPP_HIDE_FROM_ABI const_iterator end() const { return __table_.end(); }
- 
--  _LIBCPP_HIDE_FROM_ABI iterator insert(const value_type& __x) { return __table_.__emplace_unique(__x); }
-+  _LIBCPP_HIDE_FROM_ABI iterator insert(const value_type& __x) { return __table_.__emplace_multi(__x); }
-   _LIBCPP_HIDE_FROM_ABI iterator insert(const_iterator, const value_type& __x) { return insert(__x); }
-   template <class _InputIterator>
-   _LIBCPP_HIDE_FROM_ABI void insert(_InputIterator __first, _InputIterator __last);
-@@ -831,7 +831,7 @@
- template <class _InputIterator>
- inline void hash_multimap<_Key, _Tp, _Hash, _Pred, _Alloc>::insert(_InputIterator __first, _InputIterator __last) {
-   for (; __first != __last; ++__first)
--    __table_.__emplace_unique(*__first);
-+    __table_.__emplace_multi(*__first);
+ attributes #0 = { nounwind }
+ attributes #1 = { "unsafe-fp-math" = "true" }
+ attributes #2 = { "denormal-fp-math"="preserve-sign" }
+diff -ruN --strip-trailing-cr a/llvm/test/CodeGen/NVPTX/i16x2-instructions.ll b/llvm/test/CodeGen/NVPTX/i16x2-instructions.ll
+--- a/llvm/test/CodeGen/NVPTX/i16x2-instructions.ll
++++ b/llvm/test/CodeGen/NVPTX/i16x2-instructions.ll
+@@ -32,31 +32,57 @@
  }
  
- template <class _Key, class _Tp, class _Hash, class _Pred, class _Alloc>
-diff -ruN --strip-trailing-cr a/libcxx/include/ext/hash_set b/libcxx/include/ext/hash_set
---- a/libcxx/include/ext/hash_set
-+++ b/libcxx/include/ext/hash_set
-@@ -458,7 +458,7 @@
-   _LIBCPP_HIDE_FROM_ABI const_iterator begin() const { return __table_.begin(); }
-   _LIBCPP_HIDE_FROM_ABI const_iterator end() const { return __table_.end(); }
- 
--  _LIBCPP_HIDE_FROM_ABI iterator insert(const value_type& __x) { return __table_.__emplace_unique(__x); }
-+  _LIBCPP_HIDE_FROM_ABI iterator insert(const value_type& __x) { return __table_.__emplace_multi(__x); }
-   _LIBCPP_HIDE_FROM_ABI iterator insert(const_iterator, const value_type& __x) { return insert(__x); }
-   template <class _InputIterator>
-   _LIBCPP_HIDE_FROM_ABI void insert(_InputIterator __first, _InputIterator __last);
-@@ -543,7 +543,7 @@
- template <class _InputIterator>
- inline void hash_multiset<_Value, _Hash, _Pred, _Alloc>::insert(_InputIterator __first, _InputIterator __last) {
-   for (; __first != __last; ++__first)
--    __table_.__emplace_unique(*__first);
-+    __table_.__emplace_multi(*__first);
+ define i16 @test_extract_0(<2 x i16> %a) #0 {
+-; COMMON-LABEL: test_extract_0(
+-; COMMON:       {
+-; COMMON-NEXT:    .reg .b16 %rs<3>;
+-; COMMON-NEXT:    .reg .b32 %r<3>;
+-; COMMON-EMPTY:
+-; COMMON-NEXT:  // %bb.0:
+-; COMMON-NEXT:    ld.param.v2.b16 {%rs1, %rs2}, [test_extract_0_param_0];
+-; COMMON-NEXT:    cvt.u32.u16 %r2, %rs1;
+-; COMMON-NEXT:    st.param.b32 [func_retval0], %r2;
+-; COMMON-NEXT:    ret;
++; I16x2-LABEL: test_extract_0(
++; I16x2:       {
++; I16x2-NEXT:    .reg .b16 %rs<2>;
++; I16x2-NEXT:    .reg .b32 %r<3>;
++; I16x2-EMPTY:
++; I16x2-NEXT:  // %bb.0:
++; I16x2-NEXT:    ld.param.b32 %r1, [test_extract_0_param_0];
++; I16x2-NEXT:    mov.b32 {%rs1, _}, %r1;
++; I16x2-NEXT:    cvt.u32.u16 %r2, %rs1;
++; I16x2-NEXT:    st.param.b32 [func_retval0], %r2;
++; I16x2-NEXT:    ret;
++;
++; NO-I16x2-LABEL: test_extract_0(
++; NO-I16x2:       {
++; NO-I16x2-NEXT:    .reg .b16 %rs<2>;
++; NO-I16x2-NEXT:    .reg .b32 %r<3>;
++; NO-I16x2-EMPTY:
++; NO-I16x2-NEXT:  // %bb.0:
++; NO-I16x2-NEXT:    ld.param.b32 %r1, [test_extract_0_param_0];
++; NO-I16x2-NEXT:    { .reg .b16 tmp; mov.b32 {%rs1, tmp}, %r1; }
++; NO-I16x2-NEXT:    cvt.u32.u16 %r2, %rs1;
++; NO-I16x2-NEXT:    st.param.b32 [func_retval0], %r2;
++; NO-I16x2-NEXT:    ret;
+   %e = extractelement <2 x i16> %a, i32 0
+   ret i16 %e
  }
  
- template <class _Value, class _Hash, class _Pred, class _Alloc>
-diff -ruN --strip-trailing-cr a/libcxx/include/unordered_map b/libcxx/include/unordered_map
---- a/libcxx/include/unordered_map
-+++ b/libcxx/include/unordered_map
-@@ -967,9 +967,8 @@
-   typedef __hash_value_type<key_type, mapped_type> __value_type;
-   typedef __unordered_map_hasher<key_type, value_type, hasher, key_equal> __hasher;
-   typedef __unordered_map_equal<key_type, value_type, key_equal, hasher> __key_equal;
--  typedef __rebind_alloc<allocator_traits<allocator_type>, __value_type> __allocator_type;
- 
--  typedef __hash_table<__value_type, __hasher, __key_equal, __allocator_type> __table;
-+  typedef __hash_table<__value_type, __hasher, __key_equal, allocator_type> __table;
- 
-   __table __table_;
- 
-@@ -1777,9 +1776,8 @@
-   typedef __hash_value_type<key_type, mapped_type> __value_type;
-   typedef __unordered_map_hasher<key_type, value_type, hasher, key_equal> __hasher;
-   typedef __unordered_map_equal<key_type, value_type, key_equal, hasher> __key_equal;
--  typedef __rebind_alloc<allocator_traits<allocator_type>, __value_type> __allocator_type;
- 
--  typedef __hash_table<__value_type, __hasher, __key_equal, __allocator_type> __table;
-+  typedef __hash_table<__value_type, __hasher, __key_equal, allocator_type> __table;
- 
-   __table __table_;
+ define i16 @test_extract_1(<2 x i16> %a) #0 {
+-; COMMON-LABEL: test_extract_1(
+-; COMMON:       {
+-; COMMON-NEXT:    .reg .b16 %rs<3>;
+-; COMMON-NEXT:    .reg .b32 %r<3>;
+-; COMMON-EMPTY:
+-; COMMON-NEXT:  // %bb.0:
+-; COMMON-NEXT:    ld.param.v2.b16 {%rs1, %rs2}, [test_extract_1_param_0];
+-; COMMON-NEXT:    cvt.u32.u16 %r2, %rs2;
+-; COMMON-NEXT:    st.param.b32 [func_retval0], %r2;
+-; COMMON-NEXT:    ret;
++; I16x2-LABEL: test_extract_1(
++; I16x2:       {
++; I16x2-NEXT:    .reg .b16 %rs<2>;
++; I16x2-NEXT:    .reg .b32 %r<3>;
++; I16x2-EMPTY:
++; I16x2-NEXT:  // %bb.0:
++; I16x2-NEXT:    ld.param.b32 %r1, [test_extract_1_param_0];
++; I16x2-NEXT:    mov.b32 {_, %rs1}, %r1;
++; I16x2-NEXT:    cvt.u32.u16 %r2, %rs1;
++; I16x2-NEXT:    st.param.b32 [func_retval0], %r2;
++; I16x2-NEXT:    ret;
++;
++; NO-I16x2-LABEL: test_extract_1(
++; NO-I16x2:       {
++; NO-I16x2-NEXT:    .reg .b16 %rs<2>;
++; NO-I16x2-NEXT:    .reg .b32 %r<3>;
++; NO-I16x2-EMPTY:
++; NO-I16x2-NEXT:  // %bb.0:
++; NO-I16x2-NEXT:    ld.param.b32 %r1, [test_extract_1_param_0];
++; NO-I16x2-NEXT:    { .reg .b16 tmp; mov.b32 {tmp, %rs1}, %r1; }
++; NO-I16x2-NEXT:    cvt.u32.u16 %r2, %rs1;
++; NO-I16x2-NEXT:    st.param.b32 [func_retval0], %r2;
++; NO-I16x2-NEXT:    ret;
+   %e = extractelement <2 x i16> %a, i32 1
+   ret i16 %e
+ }
+@@ -71,8 +97,9 @@
+ ; COMMON-EMPTY:
+ ; COMMON-NEXT:  // %bb.0:
+ ; COMMON-NEXT:    ld.param.b64 %rd1, [test_extract_i_param_1];
+-; COMMON-NEXT:    ld.param.v2.b16 {%rs1, %rs2}, [test_extract_i_param_0];
++; COMMON-NEXT:    ld.param.b32 %r1, [test_extract_i_param_0];
+ ; COMMON-NEXT:    setp.eq.b64 %p1, %rd1, 0;
++; COMMON-NEXT:    mov.b32 {%rs1, %rs2}, %r1;
+ ; COMMON-NEXT:    selp.b16 %rs3, %rs1, %rs2, %p1;
+ ; COMMON-NEXT:    cvt.u32.u16 %r2, %rs3;
+ ; COMMON-NEXT:    st.param.b32 [func_retval0], %r2;
+@@ -99,10 +126,12 @@
+ ; NO-I16x2-NEXT:    .reg .b32 %r<3>;
+ ; NO-I16x2-EMPTY:
+ ; NO-I16x2-NEXT:  // %bb.0:
+-; NO-I16x2-NEXT:    ld.param.v2.b16 {%rs1, %rs2}, [test_add_param_0];
+-; NO-I16x2-NEXT:    ld.param.v2.b16 {%rs3, %rs4}, [test_add_param_1];
+-; NO-I16x2-NEXT:    add.s16 %rs5, %rs2, %rs4;
+-; NO-I16x2-NEXT:    add.s16 %rs6, %rs1, %rs3;
++; NO-I16x2-NEXT:    ld.param.b32 %r2, [test_add_param_1];
++; NO-I16x2-NEXT:    ld.param.b32 %r1, [test_add_param_0];
++; NO-I16x2-NEXT:    mov.b32 {%rs1, %rs2}, %r2;
++; NO-I16x2-NEXT:    mov.b32 {%rs3, %rs4}, %r1;
++; NO-I16x2-NEXT:    add.s16 %rs5, %rs4, %rs2;
++; NO-I16x2-NEXT:    add.s16 %rs6, %rs3, %rs1;
+ ; NO-I16x2-NEXT:    st.param.v2.b16 [func_retval0], {%rs6, %rs5};
+ ; NO-I16x2-NEXT:    ret;
+   %r = add <2 x i16> %a, %b
+@@ -128,7 +157,8 @@
+ ; NO-I16x2-NEXT:    .reg .b32 %r<2>;
+ ; NO-I16x2-EMPTY:
+ ; NO-I16x2-NEXT:  // %bb.0:
+-; NO-I16x2-NEXT:    ld.param.v2.b16 {%rs1, %rs2}, [test_add_imm_0_param_0];
++; NO-I16x2-NEXT:    ld.param.b32 %r1, [test_add_imm_0_param_0];
++; NO-I16x2-NEXT:    mov.b32 {%rs1, %rs2}, %r1;
+ ; NO-I16x2-NEXT:    add.s16 %rs3, %rs2, 2;
+ ; NO-I16x2-NEXT:    add.s16 %rs4, %rs1, 1;
+ ; NO-I16x2-NEXT:    st.param.v2.b16 [func_retval0], {%rs4, %rs3};
+@@ -155,7 +185,8 @@
+ ; NO-I16x2-NEXT:    .reg .b32 %r<2>;
+ ; NO-I16x2-EMPTY:
+ ; NO-I16x2-NEXT:  // %bb.0:
+-; NO-I16x2-NEXT:    ld.param.v2.b16 {%rs1, %rs2}, [test_add_imm_1_param_0];
++; NO-I16x2-NEXT:    ld.param.b32 %r1, [test_add_imm_1_param_0];
++; NO-I16x2-NEXT:    mov.b32 {%rs1, %rs2}, %r1;
+ ; NO-I16x2-NEXT:    add.s16 %rs3, %rs2, 2;
+ ; NO-I16x2-NEXT:    add.s16 %rs4, %rs1, 1;
+ ; NO-I16x2-NEXT:    st.param.v2.b16 [func_retval0], {%rs4, %rs3};
+@@ -171,10 +202,12 @@
+ ; COMMON-NEXT:    .reg .b32 %r<3>;
+ ; COMMON-EMPTY:
+ ; COMMON-NEXT:  // %bb.0:
+-; COMMON-NEXT:    ld.param.v2.b16 {%rs1, %rs2}, [test_sub_param_0];
+-; COMMON-NEXT:    ld.param.v2.b16 {%rs3, %rs4}, [test_sub_param_1];
+-; COMMON-NEXT:    sub.s16 %rs5, %rs2, %rs4;
+-; COMMON-NEXT:    sub.s16 %rs6, %rs1, %rs3;
++; COMMON-NEXT:    ld.param.b32 %r2, [test_sub_param_1];
++; COMMON-NEXT:    ld.param.b32 %r1, [test_sub_param_0];
++; COMMON-NEXT:    mov.b32 {%rs1, %rs2}, %r2;
++; COMMON-NEXT:    mov.b32 {%rs3, %rs4}, %r1;
++; COMMON-NEXT:    sub.s16 %rs5, %rs4, %rs2;
++; COMMON-NEXT:    sub.s16 %rs6, %rs3, %rs1;
+ ; COMMON-NEXT:    st.param.v2.b16 [func_retval0], {%rs6, %rs5};
+ ; COMMON-NEXT:    ret;
+   %r = sub <2 x i16> %a, %b
+@@ -199,10 +232,12 @@
+ ; NO-I16x2-NEXT:    .reg .b32 %r<3>;
+ ; NO-I16x2-EMPTY:
+ ; NO-I16x2-NEXT:  // %bb.0:
+-; NO-I16x2-NEXT:    ld.param.v2.b16 {%rs1, %rs2}, [test_smax_param_0];
+-; NO-I16x2-NEXT:    ld.param.v2.b16 {%rs3, %rs4}, [test_smax_param_1];
+-; NO-I16x2-NEXT:    max.s16 %rs5, %rs2, %rs4;
+-; NO-I16x2-NEXT:    max.s16 %rs6, %rs1, %rs3;
++; NO-I16x2-NEXT:    ld.param.b32 %r2, [test_smax_param_1];
++; NO-I16x2-NEXT:    ld.param.b32 %r1, [test_smax_param_0];
++; NO-I16x2-NEXT:    mov.b32 {%rs1, %rs2}, %r2;
++; NO-I16x2-NEXT:    mov.b32 {%rs3, %rs4}, %r1;
++; NO-I16x2-NEXT:    max.s16 %rs5, %rs4, %rs2;
++; NO-I16x2-NEXT:    max.s16 %rs6, %rs3, %rs1;
+ ; NO-I16x2-NEXT:    st.param.v2.b16 [func_retval0], {%rs6, %rs5};
+ ; NO-I16x2-NEXT:    ret;
+   %cmp = icmp sgt <2 x i16> %a, %b
+@@ -228,10 +263,12 @@
+ ; NO-I16x2-NEXT:    .reg .b32 %r<3>;
+ ; NO-I16x2-EMPTY:
+ ; NO-I16x2-NEXT:  // %bb.0:
+-; NO-I16x2-NEXT:    ld.param.v2.b16 {%rs1, %rs2}, [test_umax_param_0];
+-; NO-I16x2-NEXT:    ld.param.v2.b16 {%rs3, %rs4}, [test_umax_param_1];
+-; NO-I16x2-NEXT:    max.u16 %rs5, %rs2, %rs4;
+-; NO-I16x2-NEXT:    max.u16 %rs6, %rs1, %rs3;
++; NO-I16x2-NEXT:    ld.param.b32 %r2, [test_umax_param_1];
++; NO-I16x2-NEXT:    ld.param.b32 %r1, [test_umax_param_0];
++; NO-I16x2-NEXT:    mov.b32 {%rs1, %rs2}, %r2;
++; NO-I16x2-NEXT:    mov.b32 {%rs3, %rs4}, %r1;
++; NO-I16x2-NEXT:    max.u16 %rs5, %rs4, %rs2;
++; NO-I16x2-NEXT:    max.u16 %rs6, %rs3, %rs1;
+ ; NO-I16x2-NEXT:    st.param.v2.b16 [func_retval0], {%rs6, %rs5};
+ ; NO-I16x2-NEXT:    ret;
+   %cmp = icmp ugt <2 x i16> %a, %b
+@@ -257,10 +294,12 @@
+ ; NO-I16x2-NEXT:    .reg .b32 %r<3>;
+ ; NO-I16x2-EMPTY:
+ ; NO-I16x2-NEXT:  // %bb.0:
+-; NO-I16x2-NEXT:    ld.param.v2.b16 {%rs1, %rs2}, [test_smin_param_0];
+-; NO-I16x2-NEXT:    ld.param.v2.b16 {%rs3, %rs4}, [test_smin_param_1];
+-; NO-I16x2-NEXT:    min.s16 %rs5, %rs2, %rs4;
+-; NO-I16x2-NEXT:    min.s16 %rs6, %rs1, %rs3;
++; NO-I16x2-NEXT:    ld.param.b32 %r2, [test_smin_param_1];
++; NO-I16x2-NEXT:    ld.param.b32 %r1, [test_smin_param_0];
++; NO-I16x2-NEXT:    mov.b32 {%rs1, %rs2}, %r2;
++; NO-I16x2-NEXT:    mov.b32 {%rs3, %rs4}, %r1;
++; NO-I16x2-NEXT:    min.s16 %rs5, %rs4, %rs2;
++; NO-I16x2-NEXT:    min.s16 %rs6, %rs3, %rs1;
+ ; NO-I16x2-NEXT:    st.param.v2.b16 [func_retval0], {%rs6, %rs5};
+ ; NO-I16x2-NEXT:    ret;
+   %cmp = icmp sle <2 x i16> %a, %b
+@@ -286,10 +325,12 @@
+ ; NO-I16x2-NEXT:    .reg .b32 %r<3>;
+ ; NO-I16x2-EMPTY:
+ ; NO-I16x2-NEXT:  // %bb.0:
+-; NO-I16x2-NEXT:    ld.param.v2.b16 {%rs1, %rs2}, [test_umin_param_0];
+-; NO-I16x2-NEXT:    ld.param.v2.b16 {%rs3, %rs4}, [test_umin_param_1];
+-; NO-I16x2-NEXT:    min.u16 %rs5, %rs2, %rs4;
+-; NO-I16x2-NEXT:    min.u16 %rs6, %rs1, %rs3;
++; NO-I16x2-NEXT:    ld.param.b32 %r2, [test_umin_param_1];
++; NO-I16x2-NEXT:    ld.param.b32 %r1, [test_umin_param_0];
++; NO-I16x2-NEXT:    mov.b32 {%rs1, %rs2}, %r2;
++; NO-I16x2-NEXT:    mov.b32 {%rs3, %rs4}, %r1;
++; NO-I16x2-NEXT:    min.u16 %rs5, %rs4, %rs2;
++; NO-I16x2-NEXT:    min.u16 %rs6, %rs3, %rs1;
+ ; NO-I16x2-NEXT:    st.param.v2.b16 [func_retval0], {%rs6, %rs5};
+ ; NO-I16x2-NEXT:    ret;
+   %cmp = icmp ule <2 x i16> %a, %b
+@@ -304,10 +345,12 @@
+ ; COMMON-NEXT:    .reg .b32 %r<3>;
+ ; COMMON-EMPTY:
+ ; COMMON-NEXT:  // %bb.0:
+-; COMMON-NEXT:    ld.param.v2.b16 {%rs1, %rs2}, [test_mul_param_0];
+-; COMMON-NEXT:    ld.param.v2.b16 {%rs3, %rs4}, [test_mul_param_1];
+-; COMMON-NEXT:    mul.lo.s16 %rs5, %rs2, %rs4;
+-; COMMON-NEXT:    mul.lo.s16 %rs6, %rs1, %rs3;
++; COMMON-NEXT:    ld.param.b32 %r2, [test_mul_param_1];
++; COMMON-NEXT:    ld.param.b32 %r1, [test_mul_param_0];
++; COMMON-NEXT:    mov.b32 {%rs1, %rs2}, %r2;
++; COMMON-NEXT:    mov.b32 {%rs3, %rs4}, %r1;
++; COMMON-NEXT:    mul.lo.s16 %rs5, %rs4, %rs2;
++; COMMON-NEXT:    mul.lo.s16 %rs6, %rs3, %rs1;
+ ; COMMON-NEXT:    st.param.v2.b16 [func_retval0], {%rs6, %rs5};
+ ; COMMON-NEXT:    ret;
+   %r = mul <2 x i16> %a, %b
+@@ -686,14 +729,18 @@
+ ; COMMON-NEXT:    .reg .b32 %r<5>;
+ ; COMMON-EMPTY:
+ ; COMMON-NEXT:  // %bb.0:
+-; COMMON-NEXT:    ld.param.v2.b16 {%rs1, %rs2}, [test_select_cc_param_0];
+-; COMMON-NEXT:    ld.param.v2.b16 {%rs3, %rs4}, [test_select_cc_param_2];
+-; COMMON-NEXT:    ld.param.v2.b16 {%rs5, %rs6}, [test_select_cc_param_3];
+-; COMMON-NEXT:    setp.ne.b16 %p1, %rs3, %rs5;
+-; COMMON-NEXT:    setp.ne.b16 %p2, %rs4, %rs6;
+-; COMMON-NEXT:    ld.param.v2.b16 {%rs7, %rs8}, [test_select_cc_param_1];
+-; COMMON-NEXT:    selp.b16 %rs9, %rs2, %rs8, %p2;
+-; COMMON-NEXT:    selp.b16 %rs10, %rs1, %rs7, %p1;
++; COMMON-NEXT:    ld.param.b32 %r4, [test_select_cc_param_3];
++; COMMON-NEXT:    ld.param.b32 %r3, [test_select_cc_param_2];
++; COMMON-NEXT:    ld.param.b32 %r2, [test_select_cc_param_1];
++; COMMON-NEXT:    ld.param.b32 %r1, [test_select_cc_param_0];
++; COMMON-NEXT:    mov.b32 {%rs1, %rs2}, %r4;
++; COMMON-NEXT:    mov.b32 {%rs3, %rs4}, %r3;
++; COMMON-NEXT:    setp.ne.b16 %p1, %rs3, %rs1;
++; COMMON-NEXT:    setp.ne.b16 %p2, %rs4, %rs2;
++; COMMON-NEXT:    mov.b32 {%rs5, %rs6}, %r2;
++; COMMON-NEXT:    mov.b32 {%rs7, %rs8}, %r1;
++; COMMON-NEXT:    selp.b16 %rs9, %rs8, %rs6, %p2;
++; COMMON-NEXT:    selp.b16 %rs10, %rs7, %rs5, %p1;
+ ; COMMON-NEXT:    st.param.v2.b16 [func_retval0], {%rs10, %rs9};
+ ; COMMON-NEXT:    ret;
+   %cc = icmp ne <2 x i16> %c, %d
+@@ -711,10 +758,12 @@
+ ; COMMON-NEXT:  // %bb.0:
+ ; COMMON-NEXT:    ld.param.v2.b32 {%r3, %r4}, [test_select_cc_i32_i16_param_1];
+ ; COMMON-NEXT:    ld.param.v2.b32 {%r1, %r2}, [test_select_cc_i32_i16_param_0];
+-; COMMON-NEXT:    ld.param.v2.b16 {%rs1, %rs2}, [test_select_cc_i32_i16_param_2];
+-; COMMON-NEXT:    ld.param.v2.b16 {%rs3, %rs4}, [test_select_cc_i32_i16_param_3];
+-; COMMON-NEXT:    setp.ne.b16 %p1, %rs1, %rs3;
+-; COMMON-NEXT:    setp.ne.b16 %p2, %rs2, %rs4;
++; COMMON-NEXT:    ld.param.b32 %r6, [test_select_cc_i32_i16_param_3];
++; COMMON-NEXT:    ld.param.b32 %r5, [test_select_cc_i32_i16_param_2];
++; COMMON-NEXT:    mov.b32 {%rs1, %rs2}, %r6;
++; COMMON-NEXT:    mov.b32 {%rs3, %rs4}, %r5;
++; COMMON-NEXT:    setp.ne.b16 %p1, %rs3, %rs1;
++; COMMON-NEXT:    setp.ne.b16 %p2, %rs4, %rs2;
+ ; COMMON-NEXT:    selp.b32 %r7, %r2, %r4, %p2;
+ ; COMMON-NEXT:    selp.b32 %r8, %r1, %r3, %p1;
+ ; COMMON-NEXT:    st.param.v2.b32 [func_retval0], {%r8, %r7};
+@@ -735,12 +784,14 @@
+ ; COMMON-NEXT:  // %bb.0:
+ ; COMMON-NEXT:    ld.param.v2.b32 {%r5, %r6}, [test_select_cc_i16_i32_param_3];
+ ; COMMON-NEXT:    ld.param.v2.b32 {%r3, %r4}, [test_select_cc_i16_i32_param_2];
+-; COMMON-NEXT:    ld.param.v2.b16 {%rs1, %rs2}, [test_select_cc_i16_i32_param_0];
++; COMMON-NEXT:    ld.param.b32 %r2, [test_select_cc_i16_i32_param_1];
++; COMMON-NEXT:    ld.param.b32 %r1, [test_select_cc_i16_i32_param_0];
+ ; COMMON-NEXT:    setp.ne.b32 %p1, %r3, %r5;
+ ; COMMON-NEXT:    setp.ne.b32 %p2, %r4, %r6;
+-; COMMON-NEXT:    ld.param.v2.b16 {%rs3, %rs4}, [test_select_cc_i16_i32_param_1];
+-; COMMON-NEXT:    selp.b16 %rs5, %rs2, %rs4, %p2;
+-; COMMON-NEXT:    selp.b16 %rs6, %rs1, %rs3, %p1;
++; COMMON-NEXT:    mov.b32 {%rs1, %rs2}, %r2;
++; COMMON-NEXT:    mov.b32 {%rs3, %rs4}, %r1;
++; COMMON-NEXT:    selp.b16 %rs5, %rs4, %rs2, %p2;
++; COMMON-NEXT:    selp.b16 %rs6, %rs3, %rs1, %p1;
+ ; COMMON-NEXT:    st.param.v2.b16 [func_retval0], {%rs6, %rs5};
+ ; COMMON-NEXT:    ret;
+                                           <2 x i32> %c, <2 x i32> %d) #0 {
+@@ -851,7 +902,8 @@
+ ; COMMON-NEXT:    .reg .b32 %r<4>;
+ ; COMMON-EMPTY:
+ ; COMMON-NEXT:  // %bb.0:
+-; COMMON-NEXT:    ld.param.v2.b16 {%rs1, %rs2}, [test_zext_2xi32_param_0];
++; COMMON-NEXT:    ld.param.b32 %r1, [test_zext_2xi32_param_0];
++; COMMON-NEXT:    mov.b32 {%rs1, %rs2}, %r1;
+ ; COMMON-NEXT:    cvt.u32.u16 %r2, %rs2;
+ ; COMMON-NEXT:    cvt.u32.u16 %r3, %rs1;
+ ; COMMON-NEXT:    st.param.v2.b32 [func_retval0], {%r3, %r2};
+@@ -868,7 +920,8 @@
+ ; COMMON-NEXT:    .reg .b64 %rd<3>;
+ ; COMMON-EMPTY:
+ ; COMMON-NEXT:  // %bb.0:
+-; COMMON-NEXT:    ld.param.v2.b16 {%rs1, %rs2}, [test_zext_2xi64_param_0];
++; COMMON-NEXT:    ld.param.b32 %r1, [test_zext_2xi64_param_0];
++; COMMON-NEXT:    mov.b32 {%rs1, %rs2}, %r1;
+ ; COMMON-NEXT:    cvt.u64.u16 %rd1, %rs2;
+ ; COMMON-NEXT:    cvt.u64.u16 %rd2, %rs1;
+ ; COMMON-NEXT:    st.param.v2.b64 [func_retval0], {%rd2, %rd1};
+@@ -926,7 +979,8 @@
+ ; COMMON-NEXT:    .reg .b32 %r<2>;
+ ; COMMON-EMPTY:
+ ; COMMON-NEXT:  // %bb.0:
+-; COMMON-NEXT:    ld.param.v2.b16 {%rs1, %rs2}, [test_shufflevector_param_0];
++; COMMON-NEXT:    ld.param.b32 %r1, [test_shufflevector_param_0];
++; COMMON-NEXT:    mov.b32 {%rs1, %rs2}, %r1;
+ ; COMMON-NEXT:    st.param.v2.b16 [func_retval0], {%rs2, %rs1};
+ ; COMMON-NEXT:    ret;
+   %s = shufflevector <2 x i16> %a, <2 x i16> undef, <2 x i32> <i32 1, i32 0>
+@@ -934,16 +988,29 @@
+ }
  
-diff -ruN --strip-trailing-cr a/libcxx/test/extensions/gnu/hash_multimap/insert.pass.cpp b/libcxx/test/extensions/gnu/hash_multimap/insert.pass.cpp
---- a/libcxx/test/extensions/gnu/hash_multimap/insert.pass.cpp
-+++ b/libcxx/test/extensions/gnu/hash_multimap/insert.pass.cpp
-@@ -0,0 +1,35 @@
-+//===----------------------------------------------------------------------===//
-+//
-+// Part of the LLVM Project, under the Apache License v2.0 with LLVM Exceptions.
-+// See https://llvm.org/LICENSE.txt for license information.
-+// SPDX-License-Identifier: Apache-2.0 WITH LLVM-exception
-+//
-+//===----------------------------------------------------------------------===//
-+
-+// ADDITIONAL_COMPILE_FLAGS: -Wno-deprecated
-+
-+// hash_multimap::insert
-+
-+#include <cassert>
-+#include <ext/hash_map>
-+
-+int main(int, char**) {
-+  __gnu_cxx::hash_multimap<int, int> map;
-+
-+  map.insert(std::make_pair(1, 1));
-+  map.insert(std::make_pair(1, 1));
-+
-+  assert(map.size() == 2);
-+  assert(map.equal_range(1).first == map.begin());
-+  assert(map.equal_range(1).second == map.end());
+ define <2 x i16> @test_insertelement(<2 x i16> %a, i16 %x) #0 {
+-; COMMON-LABEL: test_insertelement(
+-; COMMON:       {
+-; COMMON-NEXT:    .reg .b16 %rs<4>;
+-; COMMON-NEXT:    .reg .b32 %r<2>;
+-; COMMON-EMPTY:
+-; COMMON-NEXT:  // %bb.0:
+-; COMMON-NEXT:    ld.param.b16 %rs1, [test_insertelement_param_1];
+-; COMMON-NEXT:    ld.param.v2.b16 {%rs2, %rs3}, [test_insertelement_param_0];
+-; COMMON-NEXT:    st.param.v2.b16 [func_retval0], {%rs2, %rs1};
+-; COMMON-NEXT:    ret;
++; I16x2-LABEL: test_insertelement(
++; I16x2:       {
++; I16x2-NEXT:    .reg .b16 %rs<3>;
++; I16x2-NEXT:    .reg .b32 %r<2>;
++; I16x2-EMPTY:
++; I16x2-NEXT:  // %bb.0:
++; I16x2-NEXT:    ld.param.b16 %rs1, [test_insertelement_param_1];
++; I16x2-NEXT:    ld.param.b32 %r1, [test_insertelement_param_0];
++; I16x2-NEXT:    mov.b32 {%rs2, _}, %r1;
++; I16x2-NEXT:    st.param.v2.b16 [func_retval0], {%rs2, %rs1};
++; I16x2-NEXT:    ret;
++;
++; NO-I16x2-LABEL: test_insertelement(
++; NO-I16x2:       {
++; NO-I16x2-NEXT:    .reg .b16 %rs<3>;
++; NO-I16x2-NEXT:    .reg .b32 %r<2>;
++; NO-I16x2-EMPTY:
++; NO-I16x2-NEXT:  // %bb.0:
++; NO-I16x2-NEXT:    ld.param.b16 %rs1, [test_insertelement_param_1];
++; NO-I16x2-NEXT:    ld.param.b32 %r1, [test_insertelement_param_0];
++; NO-I16x2-NEXT:    { .reg .b16 tmp; mov.b32 {%rs2, tmp}, %r1; }
++; NO-I16x2-NEXT:    st.param.v2.b16 [func_retval0], {%rs2, %rs1};
++; NO-I16x2-NEXT:    ret;
+   %i = insertelement <2 x i16> %a, i16 %x, i64 1
+   ret <2 x i16> %i
+ }
+@@ -955,7 +1022,8 @@
+ ; COMMON-NEXT:    .reg .b32 %r<2>;
+ ; COMMON-EMPTY:
+ ; COMMON-NEXT:  // %bb.0:
+-; COMMON-NEXT:    ld.param.v2.b16 {%rs1, %rs2}, [test_fptosi_2xhalf_to_2xi16_param_0];
++; COMMON-NEXT:    ld.param.b32 %r1, [test_fptosi_2xhalf_to_2xi16_param_0];
++; COMMON-NEXT:    mov.b32 {%rs1, %rs2}, %r1;
+ ; COMMON-NEXT:    cvt.rzi.s16.f16 %rs3, %rs2;
+ ; COMMON-NEXT:    cvt.rzi.s16.f16 %rs4, %rs1;
+ ; COMMON-NEXT:    st.param.v2.b16 [func_retval0], {%rs4, %rs3};
+@@ -971,7 +1039,8 @@
+ ; COMMON-NEXT:    .reg .b32 %r<2>;
+ ; COMMON-EMPTY:
+ ; COMMON-NEXT:  // %bb.0:
+-; COMMON-NEXT:    ld.param.v2.b16 {%rs1, %rs2}, [test_fptoui_2xhalf_to_2xi16_param_0];
++; COMMON-NEXT:    ld.param.b32 %r1, [test_fptoui_2xhalf_to_2xi16_param_0];
++; COMMON-NEXT:    mov.b32 {%rs1, %rs2}, %r1;
+ ; COMMON-NEXT:    cvt.rzi.u16.f16 %rs3, %rs2;
+ ; COMMON-NEXT:    cvt.rzi.u16.f16 %rs4, %rs1;
+ ; COMMON-NEXT:    st.param.v2.b16 [func_retval0], {%rs4, %rs3};
+diff -ruN --strip-trailing-cr a/llvm/test/CodeGen/NVPTX/i8x4-instructions.ll b/llvm/test/CodeGen/NVPTX/i8x4-instructions.ll
+--- a/llvm/test/CodeGen/NVPTX/i8x4-instructions.ll
++++ b/llvm/test/CodeGen/NVPTX/i8x4-instructions.ll
+@@ -1935,16 +1935,18 @@
+ ; O0-NEXT:    .reg .b32 %r<12>;
+ ; O0-EMPTY:
+ ; O0-NEXT:  // %bb.0:
+-; O0-NEXT:    ld.param.v4.b16 {%rs1, %rs2, %rs3, %rs4}, [test_fptosi_4xhalf_to_4xi8_param_0];
+-; O0-NEXT:    cvt.rzi.s16.f16 %rs5, %rs4;
+-; O0-NEXT:    cvt.rzi.s16.f16 %rs6, %rs3;
+-; O0-NEXT:    mov.b32 %r3, {%rs6, %rs5};
+-; O0-NEXT:    mov.b32 {%rs7, %rs8}, %r3;
+-; O0-NEXT:    cvt.u32.u16 %r4, %rs8;
+-; O0-NEXT:    cvt.u32.u16 %r5, %rs7;
++; O0-NEXT:    ld.param.v2.b32 {%r1, %r2}, [test_fptosi_4xhalf_to_4xi8_param_0];
++; O0-NEXT:    mov.b32 {%rs1, %rs2}, %r2;
++; O0-NEXT:    cvt.rzi.s16.f16 %rs3, %rs2;
++; O0-NEXT:    cvt.rzi.s16.f16 %rs4, %rs1;
++; O0-NEXT:    mov.b32 %r3, {%rs4, %rs3};
++; O0-NEXT:    mov.b32 {%rs5, %rs6}, %r3;
++; O0-NEXT:    cvt.u32.u16 %r4, %rs6;
++; O0-NEXT:    cvt.u32.u16 %r5, %rs5;
+ ; O0-NEXT:    prmt.b32 %r6, %r5, %r4, 0x3340U;
+-; O0-NEXT:    cvt.rzi.s16.f16 %rs9, %rs2;
+-; O0-NEXT:    cvt.rzi.s16.f16 %rs10, %rs1;
++; O0-NEXT:    mov.b32 {%rs7, %rs8}, %r1;
++; O0-NEXT:    cvt.rzi.s16.f16 %rs9, %rs8;
++; O0-NEXT:    cvt.rzi.s16.f16 %rs10, %rs7;
+ ; O0-NEXT:    mov.b32 %r7, {%rs10, %rs9};
+ ; O0-NEXT:    mov.b32 {%rs11, %rs12}, %r7;
+ ; O0-NEXT:    cvt.u32.u16 %r8, %rs12;
+@@ -1989,16 +1991,18 @@
+ ; O0-NEXT:    .reg .b32 %r<12>;
+ ; O0-EMPTY:
+ ; O0-NEXT:  // %bb.0:
+-; O0-NEXT:    ld.param.v4.b16 {%rs1, %rs2, %rs3, %rs4}, [test_fptoui_4xhalf_to_4xi8_param_0];
+-; O0-NEXT:    cvt.rzi.u16.f16 %rs5, %rs4;
+-; O0-NEXT:    cvt.rzi.u16.f16 %rs6, %rs3;
+-; O0-NEXT:    mov.b32 %r3, {%rs6, %rs5};
+-; O0-NEXT:    mov.b32 {%rs7, %rs8}, %r3;
+-; O0-NEXT:    cvt.u32.u16 %r4, %rs8;
+-; O0-NEXT:    cvt.u32.u16 %r5, %rs7;
++; O0-NEXT:    ld.param.v2.b32 {%r1, %r2}, [test_fptoui_4xhalf_to_4xi8_param_0];
++; O0-NEXT:    mov.b32 {%rs1, %rs2}, %r2;
++; O0-NEXT:    cvt.rzi.u16.f16 %rs3, %rs2;
++; O0-NEXT:    cvt.rzi.u16.f16 %rs4, %rs1;
++; O0-NEXT:    mov.b32 %r3, {%rs4, %rs3};
++; O0-NEXT:    mov.b32 {%rs5, %rs6}, %r3;
++; O0-NEXT:    cvt.u32.u16 %r4, %rs6;
++; O0-NEXT:    cvt.u32.u16 %r5, %rs5;
+ ; O0-NEXT:    prmt.b32 %r6, %r5, %r4, 0x3340U;
+-; O0-NEXT:    cvt.rzi.u16.f16 %rs9, %rs2;
+-; O0-NEXT:    cvt.rzi.u16.f16 %rs10, %rs1;
++; O0-NEXT:    mov.b32 {%rs7, %rs8}, %r1;
++; O0-NEXT:    cvt.rzi.u16.f16 %rs9, %rs8;
++; O0-NEXT:    cvt.rzi.u16.f16 %rs10, %rs7;
+ ; O0-NEXT:    mov.b32 %r7, {%rs10, %rs9};
+ ; O0-NEXT:    mov.b32 {%rs11, %rs12}, %r7;
+ ; O0-NEXT:    cvt.u32.u16 %r8, %rs12;
+diff -ruN --strip-trailing-cr a/llvm/test/CodeGen/NVPTX/pr126337.ll b/llvm/test/CodeGen/NVPTX/pr126337.ll
+--- a/llvm/test/CodeGen/NVPTX/pr126337.ll
++++ b/llvm/test/CodeGen/NVPTX/pr126337.ll
+@@ -0,0 +1,41 @@
++; NOTE: Assertions have been autogenerated by utils/update_llc_test_checks.py UTC_ARGS: --version 5
++; RUN: llc < %s -mtriple=nvptx64 -mcpu=sm_70 | FileCheck %s
++; RUN: %if ptxas %{ llc < %s -mtriple=nvptx64 -mcpu=sm_70 | %ptxas -arch=sm_70 -c - %}
 +
-+  std::pair<int, int> arr[] = {std::make_pair(1, 1), std::make_pair(1, 1)};
++; This IR should compile without triggering assertions in LICM
++; when the CopyToReg from %0 in the first BB gets eliminated
++; but we still use its result in the second BB.
++; Technically the problem happens in MIR, but there are multiple
++; passes involved, so testing with the IR reproducer is more convenient.
++; https://github.com/llvm/llvm-project/pull/126337#issuecomment-3081431594
 +
-+  map.insert(arr, arr + 2);
++target datalayout = "e-p6:32:32-i64:64-i128:128-v16:16-v32:32-n16:32:64"
++target triple = "nvptx64-nvidia-cuda"
 +
-+  assert(map.size() == 4);
-+  assert(map.equal_range(1).first == map.begin());
-+  assert(map.equal_range(1).second == map.end());
++define ptx_kernel void @Equal_GPU_DT_COMPLEX64_DT_BOOL_kernel(<2 x float> %0) {
++; CHECK-LABEL: Equal_GPU_DT_COMPLEX64_DT_BOOL_kernel(
++; CHECK:       {
++; CHECK-NEXT:    .reg .pred %p<2>;
++; CHECK-NEXT:    .reg .b16 %rs<2>;
++; CHECK-NEXT:    .reg .b32 %r<2>;
++; CHECK-NEXT:    .reg .b64 %rd<3>;
++; CHECK-EMPTY:
++; CHECK-NEXT:  // %bb.0: // %.preheader15
++; CHECK-NEXT:    ld.param.b64 %rd1, [Equal_GPU_DT_COMPLEX64_DT_BOOL_kernel_param_0];
++; CHECK-NEXT:    { .reg .b32 tmp; mov.b64 {%r1, tmp}, %rd1; }
++; CHECK-NEXT:    setp.eq.f32 %p1, %r1, 0f00000000;
++; CHECK-NEXT:    selp.b16 %rs1, 1, 0, %p1;
++; CHECK-NEXT:  $L__BB0_1: // =>This Inner Loop Header: Depth=1
++; CHECK-NEXT:    mov.b64 %rd2, 0;
++; CHECK-NEXT:    st.b8 [%rd2], %rs1;
++; CHECK-NEXT:    bra.uni $L__BB0_1;
++.preheader15:
++  br label %1
 +
-+  return 0;
++1:                                                ; preds = %1, %.preheader15
++  %2 = fcmp oeq <2 x float> %0, zeroinitializer
++  %3 = extractelement <2 x i1> %2, i64 0
++  store i1 %3, ptr null, align 4
++  br label %1
 +}
-diff -ruN --strip-trailing-cr a/libcxx/test/extensions/gnu/hash_multiset/insert.pass.cpp b/libcxx/test/extensions/gnu/hash_multiset/insert.pass.cpp
---- a/libcxx/test/extensions/gnu/hash_multiset/insert.pass.cpp
-+++ b/libcxx/test/extensions/gnu/hash_multiset/insert.pass.cpp
-@@ -0,0 +1,35 @@
-+//===----------------------------------------------------------------------===//
-+//
-+// Part of the LLVM Project, under the Apache License v2.0 with LLVM Exceptions.
-+// See https://llvm.org/LICENSE.txt for license information.
-+// SPDX-License-Identifier: Apache-2.0 WITH LLVM-exception
-+//
-+//===----------------------------------------------------------------------===//
 +
-+// ADDITIONAL_COMPILE_FLAGS: -Wno-deprecated
+diff -ruN --strip-trailing-cr a/llvm/test/CodeGen/NVPTX/reduction-intrinsics.ll b/llvm/test/CodeGen/NVPTX/reduction-intrinsics.ll
+--- a/llvm/test/CodeGen/NVPTX/reduction-intrinsics.ll
++++ b/llvm/test/CodeGen/NVPTX/reduction-intrinsics.ll
+@@ -117,16 +117,20 @@
+ ; CHECK-NEXT:    .reg .b64 %rd<5>;
+ ; CHECK-EMPTY:
+ ; CHECK-NEXT:  // %bb.0:
+-; CHECK-NEXT:    ld.param.v4.b32 {%r1, %r2, %r3, %r4}, [reduce_fadd_float_param_0+16];
+-; CHECK-NEXT:    ld.param.v4.b32 {%r5, %r6, %r7, %r8}, [reduce_fadd_float_param_0];
+-; CHECK-NEXT:    add.rn.f32 %r9, %r5, 0f00000000;
+-; CHECK-NEXT:    add.rn.f32 %r10, %r9, %r6;
+-; CHECK-NEXT:    add.rn.f32 %r11, %r10, %r7;
+-; CHECK-NEXT:    add.rn.f32 %r12, %r11, %r8;
+-; CHECK-NEXT:    add.rn.f32 %r13, %r12, %r1;
+-; CHECK-NEXT:    add.rn.f32 %r14, %r13, %r2;
+-; CHECK-NEXT:    add.rn.f32 %r15, %r14, %r3;
+-; CHECK-NEXT:    add.rn.f32 %r16, %r15, %r4;
++; CHECK-NEXT:    ld.param.v2.b64 {%rd3, %rd4}, [reduce_fadd_float_param_0+16];
++; CHECK-NEXT:    mov.b64 {%r1, %r2}, %rd4;
++; CHECK-NEXT:    mov.b64 {%r3, %r4}, %rd3;
++; CHECK-NEXT:    ld.param.v2.b64 {%rd1, %rd2}, [reduce_fadd_float_param_0];
++; CHECK-NEXT:    mov.b64 {%r5, %r6}, %rd2;
++; CHECK-NEXT:    mov.b64 {%r7, %r8}, %rd1;
++; CHECK-NEXT:    add.rn.f32 %r9, %r7, 0f00000000;
++; CHECK-NEXT:    add.rn.f32 %r10, %r9, %r8;
++; CHECK-NEXT:    add.rn.f32 %r11, %r10, %r5;
++; CHECK-NEXT:    add.rn.f32 %r12, %r11, %r6;
++; CHECK-NEXT:    add.rn.f32 %r13, %r12, %r3;
++; CHECK-NEXT:    add.rn.f32 %r14, %r13, %r4;
++; CHECK-NEXT:    add.rn.f32 %r15, %r14, %r1;
++; CHECK-NEXT:    add.rn.f32 %r16, %r15, %r2;
+ ; CHECK-NEXT:    st.param.b32 [func_retval0], %r16;
+ ; CHECK-NEXT:    ret;
+   %res = call float @llvm.vector.reduce.fadd(float 0.0, <8 x float> %in)
+@@ -140,14 +144,18 @@
+ ; CHECK-SM80-NEXT:    .reg .b64 %rd<5>;
+ ; CHECK-SM80-EMPTY:
+ ; CHECK-SM80-NEXT:  // %bb.0:
+-; CHECK-SM80-NEXT:    ld.param.v4.b32 {%r1, %r2, %r3, %r4}, [reduce_fadd_float_reassoc_param_0+16];
+-; CHECK-SM80-NEXT:    ld.param.v4.b32 {%r5, %r6, %r7, %r8}, [reduce_fadd_float_reassoc_param_0];
+-; CHECK-SM80-NEXT:    add.rn.f32 %r9, %r7, %r3;
+-; CHECK-SM80-NEXT:    add.rn.f32 %r10, %r5, %r1;
+-; CHECK-SM80-NEXT:    add.rn.f32 %r11, %r8, %r4;
+-; CHECK-SM80-NEXT:    add.rn.f32 %r12, %r6, %r2;
++; CHECK-SM80-NEXT:    ld.param.v2.b64 {%rd3, %rd4}, [reduce_fadd_float_reassoc_param_0+16];
++; CHECK-SM80-NEXT:    ld.param.v2.b64 {%rd1, %rd2}, [reduce_fadd_float_reassoc_param_0];
++; CHECK-SM80-NEXT:    mov.b64 {%r1, %r2}, %rd4;
++; CHECK-SM80-NEXT:    mov.b64 {%r3, %r4}, %rd2;
++; CHECK-SM80-NEXT:    add.rn.f32 %r5, %r3, %r1;
++; CHECK-SM80-NEXT:    mov.b64 {%r6, %r7}, %rd3;
++; CHECK-SM80-NEXT:    mov.b64 {%r8, %r9}, %rd1;
++; CHECK-SM80-NEXT:    add.rn.f32 %r10, %r8, %r6;
++; CHECK-SM80-NEXT:    add.rn.f32 %r11, %r4, %r2;
++; CHECK-SM80-NEXT:    add.rn.f32 %r12, %r9, %r7;
+ ; CHECK-SM80-NEXT:    add.rn.f32 %r13, %r12, %r11;
+-; CHECK-SM80-NEXT:    add.rn.f32 %r14, %r10, %r9;
++; CHECK-SM80-NEXT:    add.rn.f32 %r14, %r10, %r5;
+ ; CHECK-SM80-NEXT:    add.rn.f32 %r15, %r14, %r13;
+ ; CHECK-SM80-NEXT:    add.rn.f32 %r16, %r15, 0f00000000;
+ ; CHECK-SM80-NEXT:    st.param.b32 [func_retval0], %r16;
+@@ -321,15 +329,19 @@
+ ; CHECK-NEXT:    .reg .b64 %rd<5>;
+ ; CHECK-EMPTY:
+ ; CHECK-NEXT:  // %bb.0:
+-; CHECK-NEXT:    ld.param.v4.b32 {%r1, %r2, %r3, %r4}, [reduce_fmul_float_param_0+16];
+-; CHECK-NEXT:    ld.param.v4.b32 {%r5, %r6, %r7, %r8}, [reduce_fmul_float_param_0];
+-; CHECK-NEXT:    mul.rn.f32 %r9, %r5, %r6;
+-; CHECK-NEXT:    mul.rn.f32 %r10, %r9, %r7;
+-; CHECK-NEXT:    mul.rn.f32 %r11, %r10, %r8;
+-; CHECK-NEXT:    mul.rn.f32 %r12, %r11, %r1;
+-; CHECK-NEXT:    mul.rn.f32 %r13, %r12, %r2;
+-; CHECK-NEXT:    mul.rn.f32 %r14, %r13, %r3;
+-; CHECK-NEXT:    mul.rn.f32 %r15, %r14, %r4;
++; CHECK-NEXT:    ld.param.v2.b64 {%rd3, %rd4}, [reduce_fmul_float_param_0+16];
++; CHECK-NEXT:    mov.b64 {%r1, %r2}, %rd4;
++; CHECK-NEXT:    mov.b64 {%r3, %r4}, %rd3;
++; CHECK-NEXT:    ld.param.v2.b64 {%rd1, %rd2}, [reduce_fmul_float_param_0];
++; CHECK-NEXT:    mov.b64 {%r5, %r6}, %rd2;
++; CHECK-NEXT:    mov.b64 {%r7, %r8}, %rd1;
++; CHECK-NEXT:    mul.rn.f32 %r9, %r7, %r8;
++; CHECK-NEXT:    mul.rn.f32 %r10, %r9, %r5;
++; CHECK-NEXT:    mul.rn.f32 %r11, %r10, %r6;
++; CHECK-NEXT:    mul.rn.f32 %r12, %r11, %r3;
++; CHECK-NEXT:    mul.rn.f32 %r13, %r12, %r4;
++; CHECK-NEXT:    mul.rn.f32 %r14, %r13, %r1;
++; CHECK-NEXT:    mul.rn.f32 %r15, %r14, %r2;
+ ; CHECK-NEXT:    st.param.b32 [func_retval0], %r15;
+ ; CHECK-NEXT:    ret;
+   %res = call float @llvm.vector.reduce.fmul(float 1.0, <8 x float> %in)
+@@ -343,14 +355,18 @@
+ ; CHECK-SM80-NEXT:    .reg .b64 %rd<5>;
+ ; CHECK-SM80-EMPTY:
+ ; CHECK-SM80-NEXT:  // %bb.0:
+-; CHECK-SM80-NEXT:    ld.param.v4.b32 {%r1, %r2, %r3, %r4}, [reduce_fmul_float_reassoc_param_0+16];
+-; CHECK-SM80-NEXT:    ld.param.v4.b32 {%r5, %r6, %r7, %r8}, [reduce_fmul_float_reassoc_param_0];
+-; CHECK-SM80-NEXT:    mul.rn.f32 %r9, %r7, %r3;
+-; CHECK-SM80-NEXT:    mul.rn.f32 %r10, %r5, %r1;
+-; CHECK-SM80-NEXT:    mul.rn.f32 %r11, %r8, %r4;
+-; CHECK-SM80-NEXT:    mul.rn.f32 %r12, %r6, %r2;
++; CHECK-SM80-NEXT:    ld.param.v2.b64 {%rd3, %rd4}, [reduce_fmul_float_reassoc_param_0+16];
++; CHECK-SM80-NEXT:    ld.param.v2.b64 {%rd1, %rd2}, [reduce_fmul_float_reassoc_param_0];
++; CHECK-SM80-NEXT:    mov.b64 {%r1, %r2}, %rd4;
++; CHECK-SM80-NEXT:    mov.b64 {%r3, %r4}, %rd2;
++; CHECK-SM80-NEXT:    mul.rn.f32 %r5, %r3, %r1;
++; CHECK-SM80-NEXT:    mov.b64 {%r6, %r7}, %rd3;
++; CHECK-SM80-NEXT:    mov.b64 {%r8, %r9}, %rd1;
++; CHECK-SM80-NEXT:    mul.rn.f32 %r10, %r8, %r6;
++; CHECK-SM80-NEXT:    mul.rn.f32 %r11, %r4, %r2;
++; CHECK-SM80-NEXT:    mul.rn.f32 %r12, %r9, %r7;
+ ; CHECK-SM80-NEXT:    mul.rn.f32 %r13, %r12, %r11;
+-; CHECK-SM80-NEXT:    mul.rn.f32 %r14, %r10, %r9;
++; CHECK-SM80-NEXT:    mul.rn.f32 %r14, %r10, %r5;
+ ; CHECK-SM80-NEXT:    mul.rn.f32 %r15, %r14, %r13;
+ ; CHECK-SM80-NEXT:    st.param.b32 [func_retval0], %r15;
+ ; CHECK-SM80-NEXT:    ret;
+@@ -494,13 +510,17 @@
+ ; CHECK-NEXT:    .reg .b64 %rd<5>;
+ ; CHECK-EMPTY:
+ ; CHECK-NEXT:  // %bb.0:
+-; CHECK-NEXT:    ld.param.v4.b32 {%r1, %r2, %r3, %r4}, [reduce_fmax_float_param_0+16];
+-; CHECK-NEXT:    ld.param.v4.b32 {%r5, %r6, %r7, %r8}, [reduce_fmax_float_param_0];
+-; CHECK-NEXT:    max.f32 %r9, %r8, %r4;
+-; CHECK-NEXT:    max.f32 %r10, %r6, %r2;
+-; CHECK-NEXT:    max.f32 %r11, %r10, %r9;
+-; CHECK-NEXT:    max.f32 %r12, %r7, %r3;
+-; CHECK-NEXT:    max.f32 %r13, %r5, %r1;
++; CHECK-NEXT:    ld.param.v2.b64 {%rd3, %rd4}, [reduce_fmax_float_param_0+16];
++; CHECK-NEXT:    ld.param.v2.b64 {%rd1, %rd2}, [reduce_fmax_float_param_0];
++; CHECK-NEXT:    mov.b64 {%r1, %r2}, %rd4;
++; CHECK-NEXT:    mov.b64 {%r3, %r4}, %rd2;
++; CHECK-NEXT:    max.f32 %r5, %r4, %r2;
++; CHECK-NEXT:    mov.b64 {%r6, %r7}, %rd3;
++; CHECK-NEXT:    mov.b64 {%r8, %r9}, %rd1;
++; CHECK-NEXT:    max.f32 %r10, %r9, %r7;
++; CHECK-NEXT:    max.f32 %r11, %r10, %r5;
++; CHECK-NEXT:    max.f32 %r12, %r3, %r1;
++; CHECK-NEXT:    max.f32 %r13, %r8, %r6;
+ ; CHECK-NEXT:    max.f32 %r14, %r13, %r12;
+ ; CHECK-NEXT:    max.f32 %r15, %r14, %r11;
+ ; CHECK-NEXT:    st.param.b32 [func_retval0], %r15;
+@@ -517,13 +537,17 @@
+ ; CHECK-NEXT:    .reg .b64 %rd<5>;
+ ; CHECK-EMPTY:
+ ; CHECK-NEXT:  // %bb.0:
+-; CHECK-NEXT:    ld.param.v4.b32 {%r1, %r2, %r3, %r4}, [reduce_fmax_float_reassoc_param_0+16];
+-; CHECK-NEXT:    ld.param.v4.b32 {%r5, %r6, %r7, %r8}, [reduce_fmax_float_reassoc_param_0];
+-; CHECK-NEXT:    max.f32 %r9, %r8, %r4;
+-; CHECK-NEXT:    max.f32 %r10, %r6, %r2;
+-; CHECK-NEXT:    max.f32 %r11, %r10, %r9;
+-; CHECK-NEXT:    max.f32 %r12, %r7, %r3;
+-; CHECK-NEXT:    max.f32 %r13, %r5, %r1;
++; CHECK-NEXT:    ld.param.v2.b64 {%rd3, %rd4}, [reduce_fmax_float_reassoc_param_0+16];
++; CHECK-NEXT:    ld.param.v2.b64 {%rd1, %rd2}, [reduce_fmax_float_reassoc_param_0];
++; CHECK-NEXT:    mov.b64 {%r1, %r2}, %rd4;
++; CHECK-NEXT:    mov.b64 {%r3, %r4}, %rd2;
++; CHECK-NEXT:    max.f32 %r5, %r4, %r2;
++; CHECK-NEXT:    mov.b64 {%r6, %r7}, %rd3;
++; CHECK-NEXT:    mov.b64 {%r8, %r9}, %rd1;
++; CHECK-NEXT:    max.f32 %r10, %r9, %r7;
++; CHECK-NEXT:    max.f32 %r11, %r10, %r5;
++; CHECK-NEXT:    max.f32 %r12, %r3, %r1;
++; CHECK-NEXT:    max.f32 %r13, %r8, %r6;
+ ; CHECK-NEXT:    max.f32 %r14, %r13, %r12;
+ ; CHECK-NEXT:    max.f32 %r15, %r14, %r11;
+ ; CHECK-NEXT:    st.param.b32 [func_retval0], %r15;
+@@ -628,13 +652,17 @@
+ ; CHECK-NEXT:    .reg .b64 %rd<5>;
+ ; CHECK-EMPTY:
+ ; CHECK-NEXT:  // %bb.0:
+-; CHECK-NEXT:    ld.param.v4.b32 {%r1, %r2, %r3, %r4}, [reduce_fmin_float_param_0+16];
+-; CHECK-NEXT:    ld.param.v4.b32 {%r5, %r6, %r7, %r8}, [reduce_fmin_float_param_0];
+-; CHECK-NEXT:    min.f32 %r9, %r8, %r4;
+-; CHECK-NEXT:    min.f32 %r10, %r6, %r2;
+-; CHECK-NEXT:    min.f32 %r11, %r10, %r9;
+-; CHECK-NEXT:    min.f32 %r12, %r7, %r3;
+-; CHECK-NEXT:    min.f32 %r13, %r5, %r1;
++; CHECK-NEXT:    ld.param.v2.b64 {%rd3, %rd4}, [reduce_fmin_float_param_0+16];
++; CHECK-NEXT:    ld.param.v2.b64 {%rd1, %rd2}, [reduce_fmin_float_param_0];
++; CHECK-NEXT:    mov.b64 {%r1, %r2}, %rd4;
++; CHECK-NEXT:    mov.b64 {%r3, %r4}, %rd2;
++; CHECK-NEXT:    min.f32 %r5, %r4, %r2;
++; CHECK-NEXT:    mov.b64 {%r6, %r7}, %rd3;
++; CHECK-NEXT:    mov.b64 {%r8, %r9}, %rd1;
++; CHECK-NEXT:    min.f32 %r10, %r9, %r7;
++; CHECK-NEXT:    min.f32 %r11, %r10, %r5;
++; CHECK-NEXT:    min.f32 %r12, %r3, %r1;
++; CHECK-NEXT:    min.f32 %r13, %r8, %r6;
+ ; CHECK-NEXT:    min.f32 %r14, %r13, %r12;
+ ; CHECK-NEXT:    min.f32 %r15, %r14, %r11;
+ ; CHECK-NEXT:    st.param.b32 [func_retval0], %r15;
+@@ -651,13 +679,17 @@
+ ; CHECK-NEXT:    .reg .b64 %rd<5>;
+ ; CHECK-EMPTY:
+ ; CHECK-NEXT:  // %bb.0:
+-; CHECK-NEXT:    ld.param.v4.b32 {%r1, %r2, %r3, %r4}, [reduce_fmin_float_reassoc_param_0+16];
+-; CHECK-NEXT:    ld.param.v4.b32 {%r5, %r6, %r7, %r8}, [reduce_fmin_float_reassoc_param_0];
+-; CHECK-NEXT:    min.f32 %r9, %r8, %r4;
+-; CHECK-NEXT:    min.f32 %r10, %r6, %r2;
+-; CHECK-NEXT:    min.f32 %r11, %r10, %r9;
+-; CHECK-NEXT:    min.f32 %r12, %r7, %r3;
+-; CHECK-NEXT:    min.f32 %r13, %r5, %r1;
++; CHECK-NEXT:    ld.param.v2.b64 {%rd3, %rd4}, [reduce_fmin_float_reassoc_param_0+16];
++; CHECK-NEXT:    ld.param.v2.b64 {%rd1, %rd2}, [reduce_fmin_float_reassoc_param_0];
++; CHECK-NEXT:    mov.b64 {%r1, %r2}, %rd4;
++; CHECK-NEXT:    mov.b64 {%r3, %r4}, %rd2;
++; CHECK-NEXT:    min.f32 %r5, %r4, %r2;
++; CHECK-NEXT:    mov.b64 {%r6, %r7}, %rd3;
++; CHECK-NEXT:    mov.b64 {%r8, %r9}, %rd1;
++; CHECK-NEXT:    min.f32 %r10, %r9, %r7;
++; CHECK-NEXT:    min.f32 %r11, %r10, %r5;
++; CHECK-NEXT:    min.f32 %r12, %r3, %r1;
++; CHECK-NEXT:    min.f32 %r13, %r8, %r6;
+ ; CHECK-NEXT:    min.f32 %r14, %r13, %r12;
+ ; CHECK-NEXT:    min.f32 %r15, %r14, %r11;
+ ; CHECK-NEXT:    st.param.b32 [func_retval0], %r15;
+@@ -762,13 +794,17 @@
+ ; CHECK-NEXT:    .reg .b64 %rd<5>;
+ ; CHECK-EMPTY:
+ ; CHECK-NEXT:  // %bb.0:
+-; CHECK-NEXT:    ld.param.v4.b32 {%r1, %r2, %r3, %r4}, [reduce_fmaximum_float_param_0+16];
+-; CHECK-NEXT:    ld.param.v4.b32 {%r5, %r6, %r7, %r8}, [reduce_fmaximum_float_param_0];
+-; CHECK-NEXT:    max.NaN.f32 %r9, %r8, %r4;
+-; CHECK-NEXT:    max.NaN.f32 %r10, %r6, %r2;
+-; CHECK-NEXT:    max.NaN.f32 %r11, %r10, %r9;
+-; CHECK-NEXT:    max.NaN.f32 %r12, %r7, %r3;
+-; CHECK-NEXT:    max.NaN.f32 %r13, %r5, %r1;
++; CHECK-NEXT:    ld.param.v2.b64 {%rd3, %rd4}, [reduce_fmaximum_float_param_0+16];
++; CHECK-NEXT:    ld.param.v2.b64 {%rd1, %rd2}, [reduce_fmaximum_float_param_0];
++; CHECK-NEXT:    mov.b64 {%r1, %r2}, %rd4;
++; CHECK-NEXT:    mov.b64 {%r3, %r4}, %rd2;
++; CHECK-NEXT:    max.NaN.f32 %r5, %r4, %r2;
++; CHECK-NEXT:    mov.b64 {%r6, %r7}, %rd3;
++; CHECK-NEXT:    mov.b64 {%r8, %r9}, %rd1;
++; CHECK-NEXT:    max.NaN.f32 %r10, %r9, %r7;
++; CHECK-NEXT:    max.NaN.f32 %r11, %r10, %r5;
++; CHECK-NEXT:    max.NaN.f32 %r12, %r3, %r1;
++; CHECK-NEXT:    max.NaN.f32 %r13, %r8, %r6;
+ ; CHECK-NEXT:    max.NaN.f32 %r14, %r13, %r12;
+ ; CHECK-NEXT:    max.NaN.f32 %r15, %r14, %r11;
+ ; CHECK-NEXT:    st.param.b32 [func_retval0], %r15;
+@@ -785,13 +821,17 @@
+ ; CHECK-NEXT:    .reg .b64 %rd<5>;
+ ; CHECK-EMPTY:
+ ; CHECK-NEXT:  // %bb.0:
+-; CHECK-NEXT:    ld.param.v4.b32 {%r1, %r2, %r3, %r4}, [reduce_fmaximum_float_reassoc_param_0+16];
+-; CHECK-NEXT:    ld.param.v4.b32 {%r5, %r6, %r7, %r8}, [reduce_fmaximum_float_reassoc_param_0];
+-; CHECK-NEXT:    max.NaN.f32 %r9, %r8, %r4;
+-; CHECK-NEXT:    max.NaN.f32 %r10, %r6, %r2;
+-; CHECK-NEXT:    max.NaN.f32 %r11, %r10, %r9;
+-; CHECK-NEXT:    max.NaN.f32 %r12, %r7, %r3;
+-; CHECK-NEXT:    max.NaN.f32 %r13, %r5, %r1;
++; CHECK-NEXT:    ld.param.v2.b64 {%rd3, %rd4}, [reduce_fmaximum_float_reassoc_param_0+16];
++; CHECK-NEXT:    ld.param.v2.b64 {%rd1, %rd2}, [reduce_fmaximum_float_reassoc_param_0];
++; CHECK-NEXT:    mov.b64 {%r1, %r2}, %rd4;
++; CHECK-NEXT:    mov.b64 {%r3, %r4}, %rd2;
++; CHECK-NEXT:    max.NaN.f32 %r5, %r4, %r2;
++; CHECK-NEXT:    mov.b64 {%r6, %r7}, %rd3;
++; CHECK-NEXT:    mov.b64 {%r8, %r9}, %rd1;
++; CHECK-NEXT:    max.NaN.f32 %r10, %r9, %r7;
++; CHECK-NEXT:    max.NaN.f32 %r11, %r10, %r5;
++; CHECK-NEXT:    max.NaN.f32 %r12, %r3, %r1;
++; CHECK-NEXT:    max.NaN.f32 %r13, %r8, %r6;
+ ; CHECK-NEXT:    max.NaN.f32 %r14, %r13, %r12;
+ ; CHECK-NEXT:    max.NaN.f32 %r15, %r14, %r11;
+ ; CHECK-NEXT:    st.param.b32 [func_retval0], %r15;
+@@ -896,13 +936,17 @@
+ ; CHECK-NEXT:    .reg .b64 %rd<5>;
+ ; CHECK-EMPTY:
+ ; CHECK-NEXT:  // %bb.0:
+-; CHECK-NEXT:    ld.param.v4.b32 {%r1, %r2, %r3, %r4}, [reduce_fminimum_float_param_0+16];
+-; CHECK-NEXT:    ld.param.v4.b32 {%r5, %r6, %r7, %r8}, [reduce_fminimum_float_param_0];
+-; CHECK-NEXT:    min.NaN.f32 %r9, %r8, %r4;
+-; CHECK-NEXT:    min.NaN.f32 %r10, %r6, %r2;
+-; CHECK-NEXT:    min.NaN.f32 %r11, %r10, %r9;
+-; CHECK-NEXT:    min.NaN.f32 %r12, %r7, %r3;
+-; CHECK-NEXT:    min.NaN.f32 %r13, %r5, %r1;
++; CHECK-NEXT:    ld.param.v2.b64 {%rd3, %rd4}, [reduce_fminimum_float_param_0+16];
++; CHECK-NEXT:    ld.param.v2.b64 {%rd1, %rd2}, [reduce_fminimum_float_param_0];
++; CHECK-NEXT:    mov.b64 {%r1, %r2}, %rd4;
++; CHECK-NEXT:    mov.b64 {%r3, %r4}, %rd2;
++; CHECK-NEXT:    min.NaN.f32 %r5, %r4, %r2;
++; CHECK-NEXT:    mov.b64 {%r6, %r7}, %rd3;
++; CHECK-NEXT:    mov.b64 {%r8, %r9}, %rd1;
++; CHECK-NEXT:    min.NaN.f32 %r10, %r9, %r7;
++; CHECK-NEXT:    min.NaN.f32 %r11, %r10, %r5;
++; CHECK-NEXT:    min.NaN.f32 %r12, %r3, %r1;
++; CHECK-NEXT:    min.NaN.f32 %r13, %r8, %r6;
+ ; CHECK-NEXT:    min.NaN.f32 %r14, %r13, %r12;
+ ; CHECK-NEXT:    min.NaN.f32 %r15, %r14, %r11;
+ ; CHECK-NEXT:    st.param.b32 [func_retval0], %r15;
+@@ -919,13 +963,17 @@
+ ; CHECK-NEXT:    .reg .b64 %rd<5>;
+ ; CHECK-EMPTY:
+ ; CHECK-NEXT:  // %bb.0:
+-; CHECK-NEXT:    ld.param.v4.b32 {%r1, %r2, %r3, %r4}, [reduce_fminimum_float_reassoc_param_0+16];
+-; CHECK-NEXT:    ld.param.v4.b32 {%r5, %r6, %r7, %r8}, [reduce_fminimum_float_reassoc_param_0];
+-; CHECK-NEXT:    min.NaN.f32 %r9, %r8, %r4;
+-; CHECK-NEXT:    min.NaN.f32 %r10, %r6, %r2;
+-; CHECK-NEXT:    min.NaN.f32 %r11, %r10, %r9;
+-; CHECK-NEXT:    min.NaN.f32 %r12, %r7, %r3;
+-; CHECK-NEXT:    min.NaN.f32 %r13, %r5, %r1;
++; CHECK-NEXT:    ld.param.v2.b64 {%rd3, %rd4}, [reduce_fminimum_float_reassoc_param_0+16];
++; CHECK-NEXT:    ld.param.v2.b64 {%rd1, %rd2}, [reduce_fminimum_float_reassoc_param_0];
++; CHECK-NEXT:    mov.b64 {%r1, %r2}, %rd4;
++; CHECK-NEXT:    mov.b64 {%r3, %r4}, %rd2;
++; CHECK-NEXT:    min.NaN.f32 %r5, %r4, %r2;
++; CHECK-NEXT:    mov.b64 {%r6, %r7}, %rd3;
++; CHECK-NEXT:    mov.b64 {%r8, %r9}, %rd1;
++; CHECK-NEXT:    min.NaN.f32 %r10, %r9, %r7;
++; CHECK-NEXT:    min.NaN.f32 %r11, %r10, %r5;
++; CHECK-NEXT:    min.NaN.f32 %r12, %r3, %r1;
++; CHECK-NEXT:    min.NaN.f32 %r13, %r8, %r6;
+ ; CHECK-NEXT:    min.NaN.f32 %r14, %r13, %r12;
+ ; CHECK-NEXT:    min.NaN.f32 %r15, %r14, %r11;
+ ; CHECK-NEXT:    st.param.b32 [func_retval0], %r15;
+diff -ruN --strip-trailing-cr a/llvm/test/CodeGen/X86/pr149841.ll b/llvm/test/CodeGen/X86/pr149841.ll
+--- a/llvm/test/CodeGen/X86/pr149841.ll
++++ b/llvm/test/CodeGen/X86/pr149841.ll
+@@ -0,0 +1,34 @@
++; NOTE: Assertions have been autogenerated by utils/update_llc_test_checks.py UTC_ARGS: --version 5
++; RUN: llc < %s | FileCheck %s
 +
-+// hash_multimap::insert
++target datalayout = "e-m:e-p270:32:32-p271:32:32-p272:64:64-i64:64-i128:128-f80:128-n8:16:32:64-S128"
++target triple = "x86_64-unknown-linux-gnu"
 +
-+#include <cassert>
-+#include <ext/hash_set>
++%struct.bar = type { [5 x ptr] }
 +
-+int main(int, char**) {
-+  __gnu_cxx::hash_multiset<int> map;
++@global = external dso_local global %struct.bar
 +
-+  map.insert(1);
-+  map.insert(1);
-+
-+  assert(map.size() == 2);
-+  assert(map.equal_range(1).first == map.begin());
-+  assert(map.equal_range(1).second == map.end());
-+
-+  int arr[] = {1, 1};
-+
-+  map.insert(arr, arr + 2);
-+
-+  assert(map.size() == 4);
-+  assert(map.equal_range(1).first == map.begin());
-+  assert(map.equal_range(1).second == map.end());
-+
-+  return 0;
++define i1 @foo(ptr %arg, i1 %arg1) {
++; CHECK-LABEL: foo:
++; CHECK:       # %bb.0: # %bb
++; CHECK-NEXT:    cmpq $global+1, %rdi
++; CHECK-NEXT:    setne %al
++; CHECK-NEXT:    andb %sil, %al
++; CHECK-NEXT:    retq
++bb:
++  #dbg_value(ptr @global, !3, !DIExpression(), !5)
++  %icmp = icmp ne ptr %arg, getelementptr inbounds nuw (i8, ptr @global, i64 1)
++  %select = select i1 %arg1, i1 %icmp, i1 false
++  ret i1 %select
 +}
-diff -ruN --strip-trailing-cr a/libcxx/test/std/containers/associative/multimap/incomplete_type.pass.cpp b/libcxx/test/std/containers/associative/multimap/incomplete_type.pass.cpp
---- a/libcxx/test/std/containers/associative/multimap/incomplete_type.pass.cpp
-+++ b/libcxx/test/std/containers/associative/multimap/incomplete_type.pass.cpp
-@@ -13,6 +13,7 @@
- 
- #include <map>
- 
-+#include "min_allocator.h"
- #include "test_macros.h"
- 
- struct A {
-@@ -28,5 +29,8 @@
- int main(int, char**) {
-   A a;
- 
-+  // Make sure that the allocator isn't rebound to and incomplete type
-+  std::multimap<int, int, std::less<int>, complete_type_allocator<std::pair<const int, int> > > m;
 +
-   return 0;
- }
-diff -ruN --strip-trailing-cr a/libcxx/test/std/containers/unord/unord.map/incomplete_type.pass.cpp b/libcxx/test/std/containers/unord/unord.map/incomplete_type.pass.cpp
---- a/libcxx/test/std/containers/unord/unord.map/incomplete_type.pass.cpp
-+++ b/libcxx/test/std/containers/unord/unord.map/incomplete_type.pass.cpp
-@@ -14,6 +14,7 @@
- 
- #include <unordered_map>
- 
-+#include "min_allocator.h"
- #include "test_macros.h"
- 
- template <class Tp>
-@@ -36,5 +37,9 @@
- int main(int, char**) {
-   A a;
- 
-+  // Make sure that the allocator isn't rebound to an incomplete type
-+  std::unordered_map<int, int, std::hash<int>, std::equal_to<int>, complete_type_allocator<std::pair<const int, int> > >
-+      m;
++!llvm.dbg.cu = !{!0}
++!llvm.module.flags = !{!2}
 +
-   return 0;
- }
-diff -ruN --strip-trailing-cr a/libcxx/test/std/containers/unord/unord.multimap/incomplete.pass.cpp b/libcxx/test/std/containers/unord/unord.multimap/incomplete.pass.cpp
---- a/libcxx/test/std/containers/unord/unord.multimap/incomplete.pass.cpp
-+++ b/libcxx/test/std/containers/unord/unord.multimap/incomplete.pass.cpp
-@@ -14,6 +14,7 @@
- 
- #include <unordered_map>
- 
-+#include "min_allocator.h"
- #include "test_macros.h"
- 
- template <class Tp>
-@@ -36,5 +37,13 @@
- int main(int, char**) {
-   A a;
- 
-+  // Make sure that the allocator isn't rebound to an incomplete type
-+  std::unordered_multimap<int,
-+                          int,
-+                          std::hash<int>,
-+                          std::equal_to<int>,
-+                          complete_type_allocator<std::pair<const int, int> > >
-+      m;
++!0 = distinct !DICompileUnit(language: DW_LANG_C11, file: !1, isOptimized: false, runtimeVersion: 0, emissionKind: NoDebug)
++!1 = !DIFile(filename: "x.c", directory: "/proc/self/cwd")
++!2 = !{i32 2, !"Debug Info Version", i32 3}
++!3 = !DILocalVariable(name: "x", arg: 1, scope: !4, file: !1)
++!4 = distinct !DISubprogram(name: "x", scope: null, file: !1, spFlags: DISPFlagDefinition, unit: !0)
++!5 = !DILocation(line: 0, scope: !4)
 +
-   return 0;
- }
-diff -ruN --strip-trailing-cr a/llvm/lib/Transforms/Coroutines/CoroSplit.cpp b/llvm/lib/Transforms/Coroutines/CoroSplit.cpp
---- a/llvm/lib/Transforms/Coroutines/CoroSplit.cpp
-+++ b/llvm/lib/Transforms/Coroutines/CoroSplit.cpp
-@@ -1484,12 +1484,9 @@
-     // If there is no DISubprogram for F, it implies the function is compiled
-     // without debug info. So we also don't generate debug info for the
-     // suspension points.
--    bool AddDebugLabels =
--        (DIS && DIS->getUnit() &&
--         (DIS->getUnit()->getEmissionKind() ==
--              DICompileUnit::DebugEmissionKind::FullDebug ||
--          DIS->getUnit()->getEmissionKind() ==
--              DICompileUnit::DebugEmissionKind::LineTablesOnly));
-+    bool AddDebugLabels = DIS && DIS->getUnit() &&
-+                          (DIS->getUnit()->getEmissionKind() ==
-+                           DICompileUnit::DebugEmissionKind::FullDebug);
- 
-     // resume.entry:
-     //  %index.addr = getelementptr inbounds %f.Frame, %f.Frame* %FramePtr, i32
-diff -ruN --strip-trailing-cr a/llvm/lib/Transforms/Instrumentation/MemorySanitizer.cpp b/llvm/lib/Transforms/Instrumentation/MemorySanitizer.cpp
---- a/llvm/lib/Transforms/Instrumentation/MemorySanitizer.cpp
-+++ b/llvm/lib/Transforms/Instrumentation/MemorySanitizer.cpp
-@@ -4322,8 +4322,9 @@
-     if (isa<Constant>(Idx))
-       return;
- 
-+    auto *IdxShadow = getShadow(Idx);
-     Value *Truncated = IRB.CreateTrunc(
--        Idx,
-+        IdxShadow,
-         FixedVectorType::get(Type::getIntNTy(*MS.C, Log2_64(IdxVectorSize)),
-                              IdxVectorSize));
-     insertCheckShadow(Truncated, getOrigin(Idx), I);
-diff -ruN --strip-trailing-cr a/llvm/test/Instrumentation/MemorySanitizer/i386/avx-intrinsics-i386.ll b/llvm/test/Instrumentation/MemorySanitizer/i386/avx-intrinsics-i386.ll
---- a/llvm/test/Instrumentation/MemorySanitizer/i386/avx-intrinsics-i386.ll
-+++ b/llvm/test/Instrumentation/MemorySanitizer/i386/avx-intrinsics-i386.ll
-@@ -987,20 +987,21 @@
- define <2 x double> @test_x86_avx_vpermilvar_pd(<2 x double> %a0, <2 x i64> %a1) #0 {
- ; CHECK-LABEL: @test_x86_avx_vpermilvar_pd(
- ; CHECK-NEXT:    [[TMP1:%.*]] = load <2 x i64>, ptr @__msan_param_tls, align 8
-+; CHECK-NEXT:    [[A1:%.*]] = load <2 x i64>, ptr inttoptr (i64 add (i64 ptrtoint (ptr @__msan_param_tls to i64), i64 16) to ptr), align 8
- ; CHECK-NEXT:    [[TMP5:%.*]] = load i64, ptr @__msan_va_arg_overflow_size_tls, align 8
- ; CHECK-NEXT:    call void @llvm.donothing()
--; CHECK-NEXT:    [[TMP3:%.*]] = trunc <2 x i64> [[A1:%.*]] to <2 x i1>
-+; CHECK-NEXT:    [[TMP3:%.*]] = trunc <2 x i64> [[A1]] to <2 x i1>
- ; CHECK-NEXT:    [[A0:%.*]] = bitcast <2 x i64> [[TMP1]] to <2 x double>
--; CHECK-NEXT:    [[RES:%.*]] = call <2 x double> @llvm.x86.avx.vpermilvar.pd(<2 x double> [[A0]], <2 x i64> [[A1]])
-+; CHECK-NEXT:    [[RES:%.*]] = call <2 x double> @llvm.x86.avx.vpermilvar.pd(<2 x double> [[A0]], <2 x i64> [[A2:%.*]])
- ; CHECK-NEXT:    [[TMP6:%.*]] = bitcast <2 x double> [[RES]] to <2 x i64>
- ; CHECK-NEXT:    [[TMP7:%.*]] = bitcast <2 x i1> [[TMP3]] to i2
- ; CHECK-NEXT:    [[_MSCMP:%.*]] = icmp ne i2 [[TMP7]], 0
--; CHECK-NEXT:    br i1 [[_MSCMP]], label [[TMP8:%.*]], label [[TMP9:%.*]], !prof [[PROF1]]
--; CHECK:       8:
-+; CHECK-NEXT:    br i1 [[_MSCMP]], label [[TMP9:%.*]], label [[TMP10:%.*]], !prof [[PROF1]]
-+; CHECK:       9:
- ; CHECK-NEXT:    call void @__msan_warning_noreturn()
- ; CHECK-NEXT:    unreachable
--; CHECK:       9:
--; CHECK-NEXT:    [[RES1:%.*]] = call <2 x double> @llvm.x86.avx.vpermilvar.pd(<2 x double> [[A2:%.*]], <2 x i64> [[A1]])
-+; CHECK:       10:
-+; CHECK-NEXT:    [[RES1:%.*]] = call <2 x double> @llvm.x86.avx.vpermilvar.pd(<2 x double> [[A3:%.*]], <2 x i64> [[A2]])
- ; CHECK-NEXT:    store <2 x i64> [[TMP6]], ptr @__msan_retval_tls, align 8
- ; CHECK-NEXT:    ret <2 x double> [[RES1]]
- ;
-@@ -1013,20 +1014,21 @@
- define <4 x double> @test_x86_avx_vpermilvar_pd_256(<4 x double> %a0, <4 x i64> %a1) #0 {
- ; CHECK-LABEL: @test_x86_avx_vpermilvar_pd_256(
- ; CHECK-NEXT:    [[TMP1:%.*]] = load <4 x i64>, ptr @__msan_param_tls, align 8
-+; CHECK-NEXT:    [[A1:%.*]] = load <4 x i64>, ptr inttoptr (i64 add (i64 ptrtoint (ptr @__msan_param_tls to i64), i64 32) to ptr), align 8
- ; CHECK-NEXT:    [[TMP5:%.*]] = load i64, ptr @__msan_va_arg_overflow_size_tls, align 8
- ; CHECK-NEXT:    call void @llvm.donothing()
--; CHECK-NEXT:    [[TMP3:%.*]] = trunc <4 x i64> [[A1:%.*]] to <4 x i2>
-+; CHECK-NEXT:    [[TMP3:%.*]] = trunc <4 x i64> [[A1]] to <4 x i2>
- ; CHECK-NEXT:    [[A0:%.*]] = bitcast <4 x i64> [[TMP1]] to <4 x double>
--; CHECK-NEXT:    [[RES:%.*]] = call <4 x double> @llvm.x86.avx.vpermilvar.pd.256(<4 x double> [[A0]], <4 x i64> [[A1]])
-+; CHECK-NEXT:    [[RES:%.*]] = call <4 x double> @llvm.x86.avx.vpermilvar.pd.256(<4 x double> [[A0]], <4 x i64> [[A2:%.*]])
- ; CHECK-NEXT:    [[TMP6:%.*]] = bitcast <4 x double> [[RES]] to <4 x i64>
- ; CHECK-NEXT:    [[TMP7:%.*]] = bitcast <4 x i2> [[TMP3]] to i8
- ; CHECK-NEXT:    [[_MSCMP:%.*]] = icmp ne i8 [[TMP7]], 0
--; CHECK-NEXT:    br i1 [[_MSCMP]], label [[TMP8:%.*]], label [[TMP9:%.*]], !prof [[PROF1]]
--; CHECK:       8:
-+; CHECK-NEXT:    br i1 [[_MSCMP]], label [[TMP9:%.*]], label [[TMP10:%.*]], !prof [[PROF1]]
-+; CHECK:       9:
- ; CHECK-NEXT:    call void @__msan_warning_noreturn()
- ; CHECK-NEXT:    unreachable
--; CHECK:       9:
--; CHECK-NEXT:    [[RES1:%.*]] = call <4 x double> @llvm.x86.avx.vpermilvar.pd.256(<4 x double> [[A2:%.*]], <4 x i64> [[A1]])
-+; CHECK:       10:
-+; CHECK-NEXT:    [[RES1:%.*]] = call <4 x double> @llvm.x86.avx.vpermilvar.pd.256(<4 x double> [[A3:%.*]], <4 x i64> [[A2]])
- ; CHECK-NEXT:    store <4 x i64> [[TMP6]], ptr @__msan_retval_tls, align 8
- ; CHECK-NEXT:    ret <4 x double> [[RES1]]
- ;
-@@ -1054,20 +1056,21 @@
- define <4 x float> @test_x86_avx_vpermilvar_ps(<4 x float> %a0, <4 x i32> %a1) #0 {
- ; CHECK-LABEL: @test_x86_avx_vpermilvar_ps(
- ; CHECK-NEXT:    [[TMP1:%.*]] = load <4 x i32>, ptr @__msan_param_tls, align 8
-+; CHECK-NEXT:    [[A1:%.*]] = load <4 x i32>, ptr inttoptr (i64 add (i64 ptrtoint (ptr @__msan_param_tls to i64), i64 16) to ptr), align 8
- ; CHECK-NEXT:    [[TMP5:%.*]] = load i64, ptr @__msan_va_arg_overflow_size_tls, align 8
- ; CHECK-NEXT:    call void @llvm.donothing()
--; CHECK-NEXT:    [[TMP3:%.*]] = trunc <4 x i32> [[A1:%.*]] to <4 x i2>
-+; CHECK-NEXT:    [[TMP3:%.*]] = trunc <4 x i32> [[A1]] to <4 x i2>
- ; CHECK-NEXT:    [[A0:%.*]] = bitcast <4 x i32> [[TMP1]] to <4 x float>
--; CHECK-NEXT:    [[RES:%.*]] = call <4 x float> @llvm.x86.avx.vpermilvar.ps(<4 x float> [[A0]], <4 x i32> [[A1]])
-+; CHECK-NEXT:    [[RES:%.*]] = call <4 x float> @llvm.x86.avx.vpermilvar.ps(<4 x float> [[A0]], <4 x i32> [[A2:%.*]])
- ; CHECK-NEXT:    [[TMP6:%.*]] = bitcast <4 x float> [[RES]] to <4 x i32>
- ; CHECK-NEXT:    [[TMP7:%.*]] = bitcast <4 x i2> [[TMP3]] to i8
- ; CHECK-NEXT:    [[_MSCMP:%.*]] = icmp ne i8 [[TMP7]], 0
--; CHECK-NEXT:    br i1 [[_MSCMP]], label [[TMP8:%.*]], label [[TMP9:%.*]], !prof [[PROF1]]
--; CHECK:       8:
-+; CHECK-NEXT:    br i1 [[_MSCMP]], label [[TMP9:%.*]], label [[TMP10:%.*]], !prof [[PROF1]]
-+; CHECK:       9:
- ; CHECK-NEXT:    call void @__msan_warning_noreturn()
- ; CHECK-NEXT:    unreachable
--; CHECK:       9:
--; CHECK-NEXT:    [[RES1:%.*]] = call <4 x float> @llvm.x86.avx.vpermilvar.ps(<4 x float> [[A2:%.*]], <4 x i32> [[A1]])
-+; CHECK:       10:
-+; CHECK-NEXT:    [[RES1:%.*]] = call <4 x float> @llvm.x86.avx.vpermilvar.ps(<4 x float> [[A3:%.*]], <4 x i32> [[A2]])
- ; CHECK-NEXT:    store <4 x i32> [[TMP6]], ptr @__msan_retval_tls, align 8
- ; CHECK-NEXT:    ret <4 x float> [[RES1]]
- ;
-@@ -1091,7 +1094,7 @@
- ; CHECK-NEXT:    [[TMP6:%.*]] = and i64 [[TMP5]], -2147483649
- ; CHECK-NEXT:    [[TMP7:%.*]] = inttoptr i64 [[TMP6]] to ptr
- ; CHECK-NEXT:    [[_MSLD:%.*]] = load <4 x i32>, ptr [[TMP7]], align 16
--; CHECK-NEXT:    [[TMP9:%.*]] = trunc <4 x i32> [[A2]] to <4 x i2>
-+; CHECK-NEXT:    [[TMP9:%.*]] = trunc <4 x i32> [[_MSLD]] to <4 x i2>
- ; CHECK-NEXT:    [[A0:%.*]] = bitcast <4 x i32> [[TMP2]] to <4 x float>
- ; CHECK-NEXT:    [[RES:%.*]] = call <4 x float> @llvm.x86.avx.vpermilvar.ps(<4 x float> [[A0]], <4 x i32> [[A2]])
- ; CHECK-NEXT:    [[TMP11:%.*]] = bitcast <4 x float> [[RES]] to <4 x i32>
-@@ -1116,20 +1119,21 @@
- define <8 x float> @test_x86_avx_vpermilvar_ps_256(<8 x float> %a0, <8 x i32> %a1) #0 {
- ; CHECK-LABEL: @test_x86_avx_vpermilvar_ps_256(
- ; CHECK-NEXT:    [[TMP1:%.*]] = load <8 x i32>, ptr @__msan_param_tls, align 8
-+; CHECK-NEXT:    [[A1:%.*]] = load <8 x i32>, ptr inttoptr (i64 add (i64 ptrtoint (ptr @__msan_param_tls to i64), i64 32) to ptr), align 8
- ; CHECK-NEXT:    [[TMP5:%.*]] = load i64, ptr @__msan_va_arg_overflow_size_tls, align 8
- ; CHECK-NEXT:    call void @llvm.donothing()
--; CHECK-NEXT:    [[TMP3:%.*]] = trunc <8 x i32> [[A1:%.*]] to <8 x i3>
-+; CHECK-NEXT:    [[TMP3:%.*]] = trunc <8 x i32> [[A1]] to <8 x i3>
- ; CHECK-NEXT:    [[A0:%.*]] = bitcast <8 x i32> [[TMP1]] to <8 x float>
--; CHECK-NEXT:    [[RES:%.*]] = call <8 x float> @llvm.x86.avx.vpermilvar.ps.256(<8 x float> [[A0]], <8 x i32> [[A1]])
-+; CHECK-NEXT:    [[RES:%.*]] = call <8 x float> @llvm.x86.avx.vpermilvar.ps.256(<8 x float> [[A0]], <8 x i32> [[A2:%.*]])
- ; CHECK-NEXT:    [[TMP6:%.*]] = bitcast <8 x float> [[RES]] to <8 x i32>
- ; CHECK-NEXT:    [[TMP7:%.*]] = bitcast <8 x i3> [[TMP3]] to i24
- ; CHECK-NEXT:    [[_MSCMP:%.*]] = icmp ne i24 [[TMP7]], 0
--; CHECK-NEXT:    br i1 [[_MSCMP]], label [[TMP8:%.*]], label [[TMP9:%.*]], !prof [[PROF1]]
--; CHECK:       8:
-+; CHECK-NEXT:    br i1 [[_MSCMP]], label [[TMP9:%.*]], label [[TMP10:%.*]], !prof [[PROF1]]
-+; CHECK:       9:
- ; CHECK-NEXT:    call void @__msan_warning_noreturn()
- ; CHECK-NEXT:    unreachable
--; CHECK:       9:
--; CHECK-NEXT:    [[RES1:%.*]] = call <8 x float> @llvm.x86.avx.vpermilvar.ps.256(<8 x float> [[A2:%.*]], <8 x i32> [[A1]])
-+; CHECK:       10:
-+; CHECK-NEXT:    [[RES1:%.*]] = call <8 x float> @llvm.x86.avx.vpermilvar.ps.256(<8 x float> [[A3:%.*]], <8 x i32> [[A2]])
- ; CHECK-NEXT:    store <8 x i32> [[TMP6]], ptr @__msan_retval_tls, align 8
- ; CHECK-NEXT:    ret <8 x float> [[RES1]]
- ;
-diff -ruN --strip-trailing-cr a/llvm/test/Instrumentation/MemorySanitizer/X86/avx512bw-intrinsics.ll b/llvm/test/Instrumentation/MemorySanitizer/X86/avx512bw-intrinsics.ll
---- a/llvm/test/Instrumentation/MemorySanitizer/X86/avx512bw-intrinsics.ll
-+++ b/llvm/test/Instrumentation/MemorySanitizer/X86/avx512bw-intrinsics.ll
-@@ -1477,17 +1477,18 @@
- ; CHECK-LABEL: @test_int_x86_avx512_vpermt2var_hi_512(
- ; CHECK-NEXT:    [[TMP1:%.*]] = load <32 x i16>, ptr inttoptr (i64 add (i64 ptrtoint (ptr @__msan_param_tls to i64), i64 64) to ptr), align 8
- ; CHECK-NEXT:    [[TMP2:%.*]] = load <32 x i16>, ptr inttoptr (i64 add (i64 ptrtoint (ptr @__msan_param_tls to i64), i64 128) to ptr), align 8
-+; CHECK-NEXT:    [[X0:%.*]] = load <32 x i16>, ptr @__msan_param_tls, align 8
- ; CHECK-NEXT:    call void @llvm.donothing()
--; CHECK-NEXT:    [[TMP3:%.*]] = trunc <32 x i16> [[X0:%.*]] to <32 x i5>
--; CHECK-NEXT:    [[TMP100:%.*]] = call <32 x i16> @llvm.x86.avx512.vpermi2var.hi.512(<32 x i16> [[TMP1]], <32 x i16> [[X0]], <32 x i16> [[TMP2]])
-+; CHECK-NEXT:    [[TMP3:%.*]] = trunc <32 x i16> [[X0]] to <32 x i5>
-+; CHECK-NEXT:    [[TMP100:%.*]] = call <32 x i16> @llvm.x86.avx512.vpermi2var.hi.512(<32 x i16> [[TMP1]], <32 x i16> [[X3:%.*]], <32 x i16> [[TMP2]])
- ; CHECK-NEXT:    [[TMP5:%.*]] = bitcast <32 x i5> [[TMP3]] to i160
- ; CHECK-NEXT:    [[_MSCMP:%.*]] = icmp ne i160 [[TMP5]], 0
--; CHECK-NEXT:    br i1 [[_MSCMP]], label [[TMP6:%.*]], label [[TMP7:%.*]], !prof [[PROF1]]
--; CHECK:       6:
-+; CHECK-NEXT:    br i1 [[_MSCMP]], label [[TMP7:%.*]], label [[TMP8:%.*]], !prof [[PROF1]]
-+; CHECK:       7:
- ; CHECK-NEXT:    call void @__msan_warning_noreturn() #[[ATTR8]]
- ; CHECK-NEXT:    unreachable
--; CHECK:       7:
--; CHECK-NEXT:    [[TMP103:%.*]] = call <32 x i16> @llvm.x86.avx512.vpermi2var.hi.512(<32 x i16> [[X1:%.*]], <32 x i16> [[X0]], <32 x i16> [[X2:%.*]])
-+; CHECK:       8:
-+; CHECK-NEXT:    [[TMP103:%.*]] = call <32 x i16> @llvm.x86.avx512.vpermi2var.hi.512(<32 x i16> [[X1:%.*]], <32 x i16> [[X3]], <32 x i16> [[X2:%.*]])
- ; CHECK-NEXT:    store <32 x i16> [[TMP100]], ptr @__msan_retval_tls, align 8
- ; CHECK-NEXT:    ret <32 x i16> [[TMP103]]
- ;
-@@ -1499,18 +1500,19 @@
- ; CHECK-LABEL: @test_int_x86_avx512_mask_vpermt2var_hi_512(
- ; CHECK-NEXT:    [[TMP1:%.*]] = load <32 x i16>, ptr inttoptr (i64 add (i64 ptrtoint (ptr @__msan_param_tls to i64), i64 64) to ptr), align 8
- ; CHECK-NEXT:    [[TMP2:%.*]] = load <32 x i16>, ptr inttoptr (i64 add (i64 ptrtoint (ptr @__msan_param_tls to i64), i64 128) to ptr), align 8
-+; CHECK-NEXT:    [[X0:%.*]] = load <32 x i16>, ptr @__msan_param_tls, align 8
- ; CHECK-NEXT:    [[TMP4:%.*]] = load i32, ptr inttoptr (i64 add (i64 ptrtoint (ptr @__msan_param_tls to i64), i64 192) to ptr), align 8
- ; CHECK-NEXT:    call void @llvm.donothing()
--; CHECK-NEXT:    [[TMP5:%.*]] = trunc <32 x i16> [[X0:%.*]] to <32 x i5>
--; CHECK-NEXT:    [[TMP101:%.*]] = call <32 x i16> @llvm.x86.avx512.vpermi2var.hi.512(<32 x i16> [[TMP1]], <32 x i16> [[X0]], <32 x i16> [[TMP2]])
-+; CHECK-NEXT:    [[TMP5:%.*]] = trunc <32 x i16> [[X0]] to <32 x i5>
-+; CHECK-NEXT:    [[TMP101:%.*]] = call <32 x i16> @llvm.x86.avx512.vpermi2var.hi.512(<32 x i16> [[TMP1]], <32 x i16> [[X4:%.*]], <32 x i16> [[TMP2]])
- ; CHECK-NEXT:    [[TMP6:%.*]] = bitcast <32 x i5> [[TMP5]] to i160
- ; CHECK-NEXT:    [[_MSCMP:%.*]] = icmp ne i160 [[TMP6]], 0
--; CHECK-NEXT:    br i1 [[_MSCMP]], label [[TMP7:%.*]], label [[TMP8:%.*]], !prof [[PROF1]]
--; CHECK:       7:
-+; CHECK-NEXT:    br i1 [[_MSCMP]], label [[TMP8:%.*]], label [[TMP9:%.*]], !prof [[PROF1]]
-+; CHECK:       8:
- ; CHECK-NEXT:    call void @__msan_warning_noreturn() #[[ATTR8]]
- ; CHECK-NEXT:    unreachable
--; CHECK:       8:
--; CHECK-NEXT:    [[TMP104:%.*]] = call <32 x i16> @llvm.x86.avx512.vpermi2var.hi.512(<32 x i16> [[X1:%.*]], <32 x i16> [[X0]], <32 x i16> [[X2:%.*]])
-+; CHECK:       9:
-+; CHECK-NEXT:    [[TMP104:%.*]] = call <32 x i16> @llvm.x86.avx512.vpermi2var.hi.512(<32 x i16> [[X1:%.*]], <32 x i16> [[X4]], <32 x i16> [[X2:%.*]])
- ; CHECK-NEXT:    [[TMP105:%.*]] = bitcast i32 [[TMP4]] to <32 x i1>
- ; CHECK-NEXT:    [[TMP106:%.*]] = bitcast i32 [[X3:%.*]] to <32 x i1>
- ; CHECK-NEXT:    [[TMP107:%.*]] = select <32 x i1> [[TMP106]], <32 x i16> [[TMP101]], <32 x i16> [[TMP1]]
-@@ -1532,18 +1534,19 @@
- ; CHECK-LABEL: @test_int_x86_avx512_maskz_vpermt2var_hi_512(
- ; CHECK-NEXT:    [[TMP1:%.*]] = load <32 x i16>, ptr inttoptr (i64 add (i64 ptrtoint (ptr @__msan_param_tls to i64), i64 64) to ptr), align 8
- ; CHECK-NEXT:    [[TMP2:%.*]] = load <32 x i16>, ptr inttoptr (i64 add (i64 ptrtoint (ptr @__msan_param_tls to i64), i64 128) to ptr), align 8
-+; CHECK-NEXT:    [[X0:%.*]] = load <32 x i16>, ptr @__msan_param_tls, align 8
- ; CHECK-NEXT:    [[TMP4:%.*]] = load i32, ptr inttoptr (i64 add (i64 ptrtoint (ptr @__msan_param_tls to i64), i64 192) to ptr), align 8
- ; CHECK-NEXT:    call void @llvm.donothing()
--; CHECK-NEXT:    [[TMP5:%.*]] = trunc <32 x i16> [[X0:%.*]] to <32 x i5>
--; CHECK-NEXT:    [[TMP101:%.*]] = call <32 x i16> @llvm.x86.avx512.vpermi2var.hi.512(<32 x i16> [[TMP1]], <32 x i16> [[X0]], <32 x i16> [[TMP2]])
-+; CHECK-NEXT:    [[TMP5:%.*]] = trunc <32 x i16> [[X0]] to <32 x i5>
-+; CHECK-NEXT:    [[TMP101:%.*]] = call <32 x i16> @llvm.x86.avx512.vpermi2var.hi.512(<32 x i16> [[TMP1]], <32 x i16> [[X4:%.*]], <32 x i16> [[TMP2]])
- ; CHECK-NEXT:    [[TMP6:%.*]] = bitcast <32 x i5> [[TMP5]] to i160
- ; CHECK-NEXT:    [[_MSCMP:%.*]] = icmp ne i160 [[TMP6]], 0
--; CHECK-NEXT:    br i1 [[_MSCMP]], label [[TMP7:%.*]], label [[TMP8:%.*]], !prof [[PROF1]]
--; CHECK:       7:
-+; CHECK-NEXT:    br i1 [[_MSCMP]], label [[TMP8:%.*]], label [[TMP9:%.*]], !prof [[PROF1]]
-+; CHECK:       8:
- ; CHECK-NEXT:    call void @__msan_warning_noreturn() #[[ATTR8]]
- ; CHECK-NEXT:    unreachable
--; CHECK:       8:
--; CHECK-NEXT:    [[TMP104:%.*]] = call <32 x i16> @llvm.x86.avx512.vpermi2var.hi.512(<32 x i16> [[X1:%.*]], <32 x i16> [[X0]], <32 x i16> [[X2:%.*]])
-+; CHECK:       9:
-+; CHECK-NEXT:    [[TMP104:%.*]] = call <32 x i16> @llvm.x86.avx512.vpermi2var.hi.512(<32 x i16> [[X1:%.*]], <32 x i16> [[X4]], <32 x i16> [[X2:%.*]])
- ; CHECK-NEXT:    [[TMP105:%.*]] = bitcast i32 [[TMP4]] to <32 x i1>
- ; CHECK-NEXT:    [[TMP106:%.*]] = bitcast i32 [[X3:%.*]] to <32 x i1>
- ; CHECK-NEXT:    [[TMP107:%.*]] = select <32 x i1> [[TMP106]], <32 x i16> [[TMP101]], <32 x i16> zeroinitializer
-@@ -1567,17 +1570,18 @@
- ; CHECK-LABEL: @test_int_x86_avx512_vpermi2var_hi_512(
- ; CHECK-NEXT:    [[TMP1:%.*]] = load <32 x i16>, ptr @__msan_param_tls, align 8
- ; CHECK-NEXT:    [[TMP2:%.*]] = load <32 x i16>, ptr inttoptr (i64 add (i64 ptrtoint (ptr @__msan_param_tls to i64), i64 128) to ptr), align 8
-+; CHECK-NEXT:    [[X1:%.*]] = load <32 x i16>, ptr inttoptr (i64 add (i64 ptrtoint (ptr @__msan_param_tls to i64), i64 64) to ptr), align 8
- ; CHECK-NEXT:    call void @llvm.donothing()
--; CHECK-NEXT:    [[TMP3:%.*]] = trunc <32 x i16> [[X1:%.*]] to <32 x i5>
--; CHECK-NEXT:    [[TMP100:%.*]] = call <32 x i16> @llvm.x86.avx512.vpermi2var.hi.512(<32 x i16> [[TMP1]], <32 x i16> [[X1]], <32 x i16> [[TMP2]])
-+; CHECK-NEXT:    [[TMP3:%.*]] = trunc <32 x i16> [[X1]] to <32 x i5>
-+; CHECK-NEXT:    [[TMP100:%.*]] = call <32 x i16> @llvm.x86.avx512.vpermi2var.hi.512(<32 x i16> [[TMP1]], <32 x i16> [[X3:%.*]], <32 x i16> [[TMP2]])
- ; CHECK-NEXT:    [[TMP5:%.*]] = bitcast <32 x i5> [[TMP3]] to i160
- ; CHECK-NEXT:    [[_MSCMP:%.*]] = icmp ne i160 [[TMP5]], 0
--; CHECK-NEXT:    br i1 [[_MSCMP]], label [[TMP6:%.*]], label [[TMP7:%.*]], !prof [[PROF1]]
--; CHECK:       6:
-+; CHECK-NEXT:    br i1 [[_MSCMP]], label [[TMP7:%.*]], label [[TMP8:%.*]], !prof [[PROF1]]
-+; CHECK:       7:
- ; CHECK-NEXT:    call void @__msan_warning_noreturn() #[[ATTR8]]
- ; CHECK-NEXT:    unreachable
--; CHECK:       7:
--; CHECK-NEXT:    [[TMP103:%.*]] = call <32 x i16> @llvm.x86.avx512.vpermi2var.hi.512(<32 x i16> [[X0:%.*]], <32 x i16> [[X1]], <32 x i16> [[X2:%.*]])
-+; CHECK:       8:
-+; CHECK-NEXT:    [[TMP103:%.*]] = call <32 x i16> @llvm.x86.avx512.vpermi2var.hi.512(<32 x i16> [[X0:%.*]], <32 x i16> [[X3]], <32 x i16> [[X2:%.*]])
- ; CHECK-NEXT:    store <32 x i16> [[TMP100]], ptr @__msan_retval_tls, align 8
- ; CHECK-NEXT:    ret <32 x i16> [[TMP103]]
- ;
-@@ -1589,11 +1593,11 @@
- ; CHECK-LABEL: @test_int_x86_avx512_mask_vpermi2var_hi_512(
- ; CHECK-NEXT:    [[TMP1:%.*]] = load <32 x i16>, ptr @__msan_param_tls, align 8
- ; CHECK-NEXT:    [[TMP2:%.*]] = load <32 x i16>, ptr inttoptr (i64 add (i64 ptrtoint (ptr @__msan_param_tls to i64), i64 128) to ptr), align 8
--; CHECK-NEXT:    [[TMP4:%.*]] = load i32, ptr inttoptr (i64 add (i64 ptrtoint (ptr @__msan_param_tls to i64), i64 192) to ptr), align 8
- ; CHECK-NEXT:    [[TMP3:%.*]] = load <32 x i16>, ptr inttoptr (i64 add (i64 ptrtoint (ptr @__msan_param_tls to i64), i64 64) to ptr), align 8
-+; CHECK-NEXT:    [[TMP4:%.*]] = load i32, ptr inttoptr (i64 add (i64 ptrtoint (ptr @__msan_param_tls to i64), i64 192) to ptr), align 8
- ; CHECK-NEXT:    call void @llvm.donothing()
--; CHECK-NEXT:    [[TMP5:%.*]] = trunc <32 x i16> [[X1:%.*]] to <32 x i5>
--; CHECK-NEXT:    [[TMP101:%.*]] = call <32 x i16> @llvm.x86.avx512.vpermi2var.hi.512(<32 x i16> [[TMP1]], <32 x i16> [[X1]], <32 x i16> [[TMP2]])
-+; CHECK-NEXT:    [[TMP5:%.*]] = trunc <32 x i16> [[TMP3]] to <32 x i5>
-+; CHECK-NEXT:    [[TMP101:%.*]] = call <32 x i16> @llvm.x86.avx512.vpermi2var.hi.512(<32 x i16> [[TMP1]], <32 x i16> [[X1:%.*]], <32 x i16> [[TMP2]])
- ; CHECK-NEXT:    [[TMP7:%.*]] = bitcast <32 x i5> [[TMP5]] to i160
- ; CHECK-NEXT:    [[_MSCMP:%.*]] = icmp ne i160 [[TMP7]], 0
- ; CHECK-NEXT:    br i1 [[_MSCMP]], label [[TMP8:%.*]], label [[TMP9:%.*]], !prof [[PROF1]]
-diff -ruN --strip-trailing-cr a/llvm/test/Instrumentation/MemorySanitizer/X86/avx512bw-intrinsics-upgrade.ll b/llvm/test/Instrumentation/MemorySanitizer/X86/avx512bw-intrinsics-upgrade.ll
---- a/llvm/test/Instrumentation/MemorySanitizer/X86/avx512bw-intrinsics-upgrade.ll
-+++ b/llvm/test/Instrumentation/MemorySanitizer/X86/avx512bw-intrinsics-upgrade.ll
-@@ -5108,17 +5108,18 @@
- ; CHECK-LABEL: @test_int_x86_avx512_vpermt2var_hi_512(
- ; CHECK-NEXT:    [[TMP1:%.*]] = load <32 x i16>, ptr inttoptr (i64 add (i64 ptrtoint (ptr @__msan_param_tls to i64), i64 64) to ptr), align 8
- ; CHECK-NEXT:    [[TMP2:%.*]] = load <32 x i16>, ptr inttoptr (i64 add (i64 ptrtoint (ptr @__msan_param_tls to i64), i64 128) to ptr), align 8
-+; CHECK-NEXT:    [[X0:%.*]] = load <32 x i16>, ptr @__msan_param_tls, align 8
- ; CHECK-NEXT:    call void @llvm.donothing()
--; CHECK-NEXT:    [[TMP3:%.*]] = trunc <32 x i16> [[X0:%.*]] to <32 x i5>
--; CHECK-NEXT:    [[TMP100:%.*]] = call <32 x i16> @llvm.x86.avx512.vpermi2var.hi.512(<32 x i16> [[TMP1]], <32 x i16> [[X0]], <32 x i16> [[TMP2]])
-+; CHECK-NEXT:    [[TMP3:%.*]] = trunc <32 x i16> [[X0]] to <32 x i5>
-+; CHECK-NEXT:    [[TMP100:%.*]] = call <32 x i16> @llvm.x86.avx512.vpermi2var.hi.512(<32 x i16> [[TMP1]], <32 x i16> [[X3:%.*]], <32 x i16> [[TMP2]])
- ; CHECK-NEXT:    [[TMP5:%.*]] = bitcast <32 x i5> [[TMP3]] to i160
- ; CHECK-NEXT:    [[_MSCMP:%.*]] = icmp ne i160 [[TMP5]], 0
--; CHECK-NEXT:    br i1 [[_MSCMP]], label [[TMP6:%.*]], label [[TMP7:%.*]], !prof [[PROF1]]
--; CHECK:       6:
-+; CHECK-NEXT:    br i1 [[_MSCMP]], label [[TMP7:%.*]], label [[TMP8:%.*]], !prof [[PROF1]]
-+; CHECK:       7:
- ; CHECK-NEXT:    call void @__msan_warning_noreturn() #[[ATTR7]]
- ; CHECK-NEXT:    unreachable
--; CHECK:       7:
--; CHECK-NEXT:    [[TMP103:%.*]] = call <32 x i16> @llvm.x86.avx512.vpermi2var.hi.512(<32 x i16> [[X1:%.*]], <32 x i16> [[X0]], <32 x i16> [[X2:%.*]])
-+; CHECK:       8:
-+; CHECK-NEXT:    [[TMP103:%.*]] = call <32 x i16> @llvm.x86.avx512.vpermi2var.hi.512(<32 x i16> [[X1:%.*]], <32 x i16> [[X3]], <32 x i16> [[X2:%.*]])
- ; CHECK-NEXT:    store <32 x i16> [[TMP100]], ptr @__msan_retval_tls, align 8
- ; CHECK-NEXT:    ret <32 x i16> [[TMP103]]
- ;
-@@ -5130,18 +5131,19 @@
- ; CHECK-LABEL: @test_int_x86_avx512_mask_vpermt2var_hi_512(
- ; CHECK-NEXT:    [[TMP1:%.*]] = load <32 x i16>, ptr inttoptr (i64 add (i64 ptrtoint (ptr @__msan_param_tls to i64), i64 64) to ptr), align 8
- ; CHECK-NEXT:    [[TMP2:%.*]] = load <32 x i16>, ptr inttoptr (i64 add (i64 ptrtoint (ptr @__msan_param_tls to i64), i64 128) to ptr), align 8
-+; CHECK-NEXT:    [[X0:%.*]] = load <32 x i16>, ptr @__msan_param_tls, align 8
- ; CHECK-NEXT:    [[TMP4:%.*]] = load i32, ptr inttoptr (i64 add (i64 ptrtoint (ptr @__msan_param_tls to i64), i64 192) to ptr), align 8
- ; CHECK-NEXT:    call void @llvm.donothing()
--; CHECK-NEXT:    [[TMP5:%.*]] = trunc <32 x i16> [[X0:%.*]] to <32 x i5>
--; CHECK-NEXT:    [[TMP101:%.*]] = call <32 x i16> @llvm.x86.avx512.vpermi2var.hi.512(<32 x i16> [[TMP1]], <32 x i16> [[X0]], <32 x i16> [[TMP2]])
-+; CHECK-NEXT:    [[TMP5:%.*]] = trunc <32 x i16> [[X0]] to <32 x i5>
-+; CHECK-NEXT:    [[TMP101:%.*]] = call <32 x i16> @llvm.x86.avx512.vpermi2var.hi.512(<32 x i16> [[TMP1]], <32 x i16> [[X4:%.*]], <32 x i16> [[TMP2]])
- ; CHECK-NEXT:    [[TMP6:%.*]] = bitcast <32 x i5> [[TMP5]] to i160
- ; CHECK-NEXT:    [[_MSCMP:%.*]] = icmp ne i160 [[TMP6]], 0
--; CHECK-NEXT:    br i1 [[_MSCMP]], label [[TMP7:%.*]], label [[TMP8:%.*]], !prof [[PROF1]]
--; CHECK:       7:
-+; CHECK-NEXT:    br i1 [[_MSCMP]], label [[TMP8:%.*]], label [[TMP9:%.*]], !prof [[PROF1]]
-+; CHECK:       8:
- ; CHECK-NEXT:    call void @__msan_warning_noreturn() #[[ATTR7]]
- ; CHECK-NEXT:    unreachable
--; CHECK:       8:
--; CHECK-NEXT:    [[TMP104:%.*]] = call <32 x i16> @llvm.x86.avx512.vpermi2var.hi.512(<32 x i16> [[X1:%.*]], <32 x i16> [[X0]], <32 x i16> [[X2:%.*]])
-+; CHECK:       9:
-+; CHECK-NEXT:    [[TMP104:%.*]] = call <32 x i16> @llvm.x86.avx512.vpermi2var.hi.512(<32 x i16> [[X1:%.*]], <32 x i16> [[X4]], <32 x i16> [[X2:%.*]])
- ; CHECK-NEXT:    [[TMP105:%.*]] = bitcast i32 [[TMP4]] to <32 x i1>
- ; CHECK-NEXT:    [[TMP106:%.*]] = bitcast i32 [[X3:%.*]] to <32 x i1>
- ; CHECK-NEXT:    [[TMP107:%.*]] = select <32 x i1> [[TMP106]], <32 x i16> [[TMP101]], <32 x i16> [[TMP1]]
-@@ -5163,18 +5165,19 @@
- ; CHECK-LABEL: @test_int_x86_avx512_maskz_vpermt2var_hi_512(
- ; CHECK-NEXT:    [[TMP1:%.*]] = load <32 x i16>, ptr inttoptr (i64 add (i64 ptrtoint (ptr @__msan_param_tls to i64), i64 64) to ptr), align 8
- ; CHECK-NEXT:    [[TMP2:%.*]] = load <32 x i16>, ptr inttoptr (i64 add (i64 ptrtoint (ptr @__msan_param_tls to i64), i64 128) to ptr), align 8
-+; CHECK-NEXT:    [[X0:%.*]] = load <32 x i16>, ptr @__msan_param_tls, align 8
- ; CHECK-NEXT:    [[TMP4:%.*]] = load i32, ptr inttoptr (i64 add (i64 ptrtoint (ptr @__msan_param_tls to i64), i64 192) to ptr), align 8
- ; CHECK-NEXT:    call void @llvm.donothing()
--; CHECK-NEXT:    [[TMP5:%.*]] = trunc <32 x i16> [[X0:%.*]] to <32 x i5>
--; CHECK-NEXT:    [[TMP101:%.*]] = call <32 x i16> @llvm.x86.avx512.vpermi2var.hi.512(<32 x i16> [[TMP1]], <32 x i16> [[X0]], <32 x i16> [[TMP2]])
-+; CHECK-NEXT:    [[TMP5:%.*]] = trunc <32 x i16> [[X0]] to <32 x i5>
-+; CHECK-NEXT:    [[TMP101:%.*]] = call <32 x i16> @llvm.x86.avx512.vpermi2var.hi.512(<32 x i16> [[TMP1]], <32 x i16> [[X4:%.*]], <32 x i16> [[TMP2]])
- ; CHECK-NEXT:    [[TMP6:%.*]] = bitcast <32 x i5> [[TMP5]] to i160
- ; CHECK-NEXT:    [[_MSCMP:%.*]] = icmp ne i160 [[TMP6]], 0
--; CHECK-NEXT:    br i1 [[_MSCMP]], label [[TMP7:%.*]], label [[TMP8:%.*]], !prof [[PROF1]]
--; CHECK:       7:
-+; CHECK-NEXT:    br i1 [[_MSCMP]], label [[TMP8:%.*]], label [[TMP9:%.*]], !prof [[PROF1]]
-+; CHECK:       8:
- ; CHECK-NEXT:    call void @__msan_warning_noreturn() #[[ATTR7]]
- ; CHECK-NEXT:    unreachable
--; CHECK:       8:
--; CHECK-NEXT:    [[TMP104:%.*]] = call <32 x i16> @llvm.x86.avx512.vpermi2var.hi.512(<32 x i16> [[X1:%.*]], <32 x i16> [[X0]], <32 x i16> [[X2:%.*]])
-+; CHECK:       9:
-+; CHECK-NEXT:    [[TMP104:%.*]] = call <32 x i16> @llvm.x86.avx512.vpermi2var.hi.512(<32 x i16> [[X1:%.*]], <32 x i16> [[X4]], <32 x i16> [[X2:%.*]])
- ; CHECK-NEXT:    [[TMP105:%.*]] = bitcast i32 [[TMP4]] to <32 x i1>
- ; CHECK-NEXT:    [[TMP106:%.*]] = bitcast i32 [[X3:%.*]] to <32 x i1>
- ; CHECK-NEXT:    [[TMP107:%.*]] = select <32 x i1> [[TMP106]], <32 x i16> [[TMP101]], <32 x i16> zeroinitializer
-@@ -5196,17 +5199,18 @@
- ; CHECK-LABEL: @test_int_x86_avx512_vpermi2var_hi_512(
- ; CHECK-NEXT:    [[TMP1:%.*]] = load <32 x i16>, ptr @__msan_param_tls, align 8
- ; CHECK-NEXT:    [[TMP2:%.*]] = load <32 x i16>, ptr inttoptr (i64 add (i64 ptrtoint (ptr @__msan_param_tls to i64), i64 128) to ptr), align 8
-+; CHECK-NEXT:    [[X1:%.*]] = load <32 x i16>, ptr inttoptr (i64 add (i64 ptrtoint (ptr @__msan_param_tls to i64), i64 64) to ptr), align 8
- ; CHECK-NEXT:    call void @llvm.donothing()
--; CHECK-NEXT:    [[TMP3:%.*]] = trunc <32 x i16> [[X1:%.*]] to <32 x i5>
--; CHECK-NEXT:    [[TMP100:%.*]] = call <32 x i16> @llvm.x86.avx512.vpermi2var.hi.512(<32 x i16> [[TMP1]], <32 x i16> [[X1]], <32 x i16> [[TMP2]])
-+; CHECK-NEXT:    [[TMP3:%.*]] = trunc <32 x i16> [[X1]] to <32 x i5>
-+; CHECK-NEXT:    [[TMP100:%.*]] = call <32 x i16> @llvm.x86.avx512.vpermi2var.hi.512(<32 x i16> [[TMP1]], <32 x i16> [[X3:%.*]], <32 x i16> [[TMP2]])
- ; CHECK-NEXT:    [[TMP5:%.*]] = bitcast <32 x i5> [[TMP3]] to i160
- ; CHECK-NEXT:    [[_MSCMP:%.*]] = icmp ne i160 [[TMP5]], 0
--; CHECK-NEXT:    br i1 [[_MSCMP]], label [[TMP6:%.*]], label [[TMP7:%.*]], !prof [[PROF1]]
--; CHECK:       6:
-+; CHECK-NEXT:    br i1 [[_MSCMP]], label [[TMP7:%.*]], label [[TMP8:%.*]], !prof [[PROF1]]
-+; CHECK:       7:
- ; CHECK-NEXT:    call void @__msan_warning_noreturn() #[[ATTR7]]
- ; CHECK-NEXT:    unreachable
--; CHECK:       7:
--; CHECK-NEXT:    [[TMP103:%.*]] = call <32 x i16> @llvm.x86.avx512.vpermi2var.hi.512(<32 x i16> [[X0:%.*]], <32 x i16> [[X1]], <32 x i16> [[X2:%.*]])
-+; CHECK:       8:
-+; CHECK-NEXT:    [[TMP103:%.*]] = call <32 x i16> @llvm.x86.avx512.vpermi2var.hi.512(<32 x i16> [[X0:%.*]], <32 x i16> [[X3]], <32 x i16> [[X2:%.*]])
- ; CHECK-NEXT:    store <32 x i16> [[TMP100]], ptr @__msan_retval_tls, align 8
- ; CHECK-NEXT:    ret <32 x i16> [[TMP103]]
- ;
-@@ -5218,11 +5222,11 @@
- ; CHECK-LABEL: @test_int_x86_avx512_mask_vpermi2var_hi_512(
- ; CHECK-NEXT:    [[TMP1:%.*]] = load <32 x i16>, ptr @__msan_param_tls, align 8
- ; CHECK-NEXT:    [[TMP2:%.*]] = load <32 x i16>, ptr inttoptr (i64 add (i64 ptrtoint (ptr @__msan_param_tls to i64), i64 128) to ptr), align 8
--; CHECK-NEXT:    [[TMP4:%.*]] = load i32, ptr inttoptr (i64 add (i64 ptrtoint (ptr @__msan_param_tls to i64), i64 192) to ptr), align 8
- ; CHECK-NEXT:    [[TMP3:%.*]] = load <32 x i16>, ptr inttoptr (i64 add (i64 ptrtoint (ptr @__msan_param_tls to i64), i64 64) to ptr), align 8
-+; CHECK-NEXT:    [[TMP4:%.*]] = load i32, ptr inttoptr (i64 add (i64 ptrtoint (ptr @__msan_param_tls to i64), i64 192) to ptr), align 8
- ; CHECK-NEXT:    call void @llvm.donothing()
--; CHECK-NEXT:    [[TMP5:%.*]] = trunc <32 x i16> [[X1:%.*]] to <32 x i5>
--; CHECK-NEXT:    [[TMP101:%.*]] = call <32 x i16> @llvm.x86.avx512.vpermi2var.hi.512(<32 x i16> [[TMP1]], <32 x i16> [[X1]], <32 x i16> [[TMP2]])
-+; CHECK-NEXT:    [[TMP5:%.*]] = trunc <32 x i16> [[TMP3]] to <32 x i5>
-+; CHECK-NEXT:    [[TMP101:%.*]] = call <32 x i16> @llvm.x86.avx512.vpermi2var.hi.512(<32 x i16> [[TMP1]], <32 x i16> [[X1:%.*]], <32 x i16> [[TMP2]])
- ; CHECK-NEXT:    [[TMP7:%.*]] = bitcast <32 x i5> [[TMP5]] to i160
- ; CHECK-NEXT:    [[_MSCMP:%.*]] = icmp ne i160 [[TMP7]], 0
- ; CHECK-NEXT:    br i1 [[_MSCMP]], label [[TMP8:%.*]], label [[TMP9:%.*]], !prof [[PROF1]]
-diff -ruN --strip-trailing-cr a/llvm/test/Instrumentation/MemorySanitizer/X86/avx512-intrinsics.ll b/llvm/test/Instrumentation/MemorySanitizer/X86/avx512-intrinsics.ll
---- a/llvm/test/Instrumentation/MemorySanitizer/X86/avx512-intrinsics.ll
-+++ b/llvm/test/Instrumentation/MemorySanitizer/X86/avx512-intrinsics.ll
-@@ -5495,28 +5495,29 @@
- ; CHECK-LABEL: @test_int_x86_avx512_vpermi2var_d_512(
- ; CHECK-NEXT:    [[TMP1:%.*]] = load i64, ptr inttoptr (i64 add (i64 ptrtoint (ptr @__msan_param_tls to i64), i64 128) to ptr), align 8
- ; CHECK-NEXT:    [[TMP2:%.*]] = load <16 x i32>, ptr @__msan_param_tls, align 8
-+; CHECK-NEXT:    [[X1:%.*]] = load <16 x i32>, ptr inttoptr (i64 add (i64 ptrtoint (ptr @__msan_param_tls to i64), i64 64) to ptr), align 8
- ; CHECK-NEXT:    call void @llvm.donothing()
- ; CHECK-NEXT:    [[_MSCMP:%.*]] = icmp ne i64 [[TMP1]], 0
--; CHECK-NEXT:    br i1 [[_MSCMP]], label [[TMP3:%.*]], label [[TMP4:%.*]], !prof [[PROF1]]
--; CHECK:       3:
-+; CHECK-NEXT:    br i1 [[_MSCMP]], label [[TMP4:%.*]], label [[TMP5:%.*]], !prof [[PROF1]]
-+; CHECK:       4:
- ; CHECK-NEXT:    call void @__msan_warning_noreturn() #[[ATTR10]]
- ; CHECK-NEXT:    unreachable
--; CHECK:       4:
-+; CHECK:       5:
- ; CHECK-NEXT:    [[X2:%.*]] = load <16 x i32>, ptr [[X2P:%.*]], align 64
- ; CHECK-NEXT:    [[TMP6:%.*]] = ptrtoint ptr [[X2P]] to i64
- ; CHECK-NEXT:    [[TMP7:%.*]] = xor i64 [[TMP6]], 87960930222080
- ; CHECK-NEXT:    [[TMP8:%.*]] = inttoptr i64 [[TMP7]] to ptr
- ; CHECK-NEXT:    [[_MSLD:%.*]] = load <16 x i32>, ptr [[TMP8]], align 64
--; CHECK-NEXT:    [[TMP13:%.*]] = trunc <16 x i32> [[X1:%.*]] to <16 x i4>
--; CHECK-NEXT:    [[_MSPROP1:%.*]] = call <16 x i32> @llvm.x86.avx512.vpermi2var.d.512(<16 x i32> [[TMP2]], <16 x i32> [[X1]], <16 x i32> [[_MSLD]])
-+; CHECK-NEXT:    [[TMP13:%.*]] = trunc <16 x i32> [[X1]] to <16 x i4>
-+; CHECK-NEXT:    [[_MSPROP1:%.*]] = call <16 x i32> @llvm.x86.avx512.vpermi2var.d.512(<16 x i32> [[TMP2]], <16 x i32> [[X3:%.*]], <16 x i32> [[_MSLD]])
- ; CHECK-NEXT:    [[TMP10:%.*]] = bitcast <16 x i4> [[TMP13]] to i64
- ; CHECK-NEXT:    [[_MSCMP1:%.*]] = icmp ne i64 [[TMP10]], 0
--; CHECK-NEXT:    br i1 [[_MSCMP1]], label [[TMP11:%.*]], label [[TMP12:%.*]], !prof [[PROF1]]
--; CHECK:       11:
-+; CHECK-NEXT:    br i1 [[_MSCMP1]], label [[TMP12:%.*]], label [[TMP14:%.*]], !prof [[PROF1]]
-+; CHECK:       12:
- ; CHECK-NEXT:    call void @__msan_warning_noreturn() #[[ATTR10]]
- ; CHECK-NEXT:    unreachable
--; CHECK:       12:
--; CHECK-NEXT:    [[TMP9:%.*]] = call <16 x i32> @llvm.x86.avx512.vpermi2var.d.512(<16 x i32> [[X0:%.*]], <16 x i32> [[X1]], <16 x i32> [[X2]])
-+; CHECK:       13:
-+; CHECK-NEXT:    [[TMP9:%.*]] = call <16 x i32> @llvm.x86.avx512.vpermi2var.d.512(<16 x i32> [[X0:%.*]], <16 x i32> [[X3]], <16 x i32> [[X2]])
- ; CHECK-NEXT:    store <16 x i32> [[_MSPROP1]], ptr @__msan_retval_tls, align 8
- ; CHECK-NEXT:    ret <16 x i32> [[TMP9]]
- ;
-@@ -5529,8 +5530,8 @@
- ; CHECK-LABEL: @test_int_x86_avx512_mask_vpermi2var_d_512(
- ; CHECK-NEXT:    [[TMP1:%.*]] = load i64, ptr inttoptr (i64 add (i64 ptrtoint (ptr @__msan_param_tls to i64), i64 128) to ptr), align 8
- ; CHECK-NEXT:    [[TMP2:%.*]] = load <16 x i32>, ptr @__msan_param_tls, align 8
--; CHECK-NEXT:    [[TMP4:%.*]] = load i16, ptr inttoptr (i64 add (i64 ptrtoint (ptr @__msan_param_tls to i64), i64 136) to ptr), align 8
- ; CHECK-NEXT:    [[TMP3:%.*]] = load <16 x i32>, ptr inttoptr (i64 add (i64 ptrtoint (ptr @__msan_param_tls to i64), i64 64) to ptr), align 8
-+; CHECK-NEXT:    [[TMP4:%.*]] = load i16, ptr inttoptr (i64 add (i64 ptrtoint (ptr @__msan_param_tls to i64), i64 136) to ptr), align 8
- ; CHECK-NEXT:    call void @llvm.donothing()
- ; CHECK-NEXT:    [[_MSCMP:%.*]] = icmp ne i64 [[TMP1]], 0
- ; CHECK-NEXT:    br i1 [[_MSCMP]], label [[TMP5:%.*]], label [[TMP6:%.*]], !prof [[PROF1]]
-@@ -5543,8 +5544,8 @@
- ; CHECK-NEXT:    [[TMP8:%.*]] = xor i64 [[TMP7]], 87960930222080
- ; CHECK-NEXT:    [[TMP9:%.*]] = inttoptr i64 [[TMP8]] to ptr
- ; CHECK-NEXT:    [[_MSLD:%.*]] = load <16 x i32>, ptr [[TMP9]], align 64
--; CHECK-NEXT:    [[TMP18:%.*]] = trunc <16 x i32> [[X1:%.*]] to <16 x i4>
--; CHECK-NEXT:    [[_MSPROP1:%.*]] = call <16 x i32> @llvm.x86.avx512.vpermi2var.d.512(<16 x i32> [[TMP2]], <16 x i32> [[X1]], <16 x i32> [[_MSLD]])
-+; CHECK-NEXT:    [[TMP18:%.*]] = trunc <16 x i32> [[TMP3]] to <16 x i4>
-+; CHECK-NEXT:    [[_MSPROP1:%.*]] = call <16 x i32> @llvm.x86.avx512.vpermi2var.d.512(<16 x i32> [[TMP2]], <16 x i32> [[X1:%.*]], <16 x i32> [[_MSLD]])
- ; CHECK-NEXT:    [[TMP19:%.*]] = bitcast <16 x i4> [[TMP18]] to i64
- ; CHECK-NEXT:    [[_MSCMP1:%.*]] = icmp ne i64 [[TMP19]], 0
- ; CHECK-NEXT:    br i1 [[_MSCMP1]], label [[TMP20:%.*]], label [[TMP21:%.*]], !prof [[PROF1]]
-@@ -5577,20 +5578,21 @@
- ; CHECK-LABEL: @test_int_x86_avx512_vpermi2var_pd_512(
- ; CHECK-NEXT:    [[TMP1:%.*]] = load <8 x i64>, ptr @__msan_param_tls, align 8
- ; CHECK-NEXT:    [[TMP3:%.*]] = load <8 x i64>, ptr inttoptr (i64 add (i64 ptrtoint (ptr @__msan_param_tls to i64), i64 128) to ptr), align 8
-+; CHECK-NEXT:    [[X1:%.*]] = load <8 x i64>, ptr inttoptr (i64 add (i64 ptrtoint (ptr @__msan_param_tls to i64), i64 64) to ptr), align 8
- ; CHECK-NEXT:    call void @llvm.donothing()
--; CHECK-NEXT:    [[TMP6:%.*]] = trunc <8 x i64> [[X1:%.*]] to <8 x i3>
-+; CHECK-NEXT:    [[TMP6:%.*]] = trunc <8 x i64> [[X1]] to <8 x i3>
- ; CHECK-NEXT:    [[TMP4:%.*]] = bitcast <8 x i64> [[TMP1]] to <8 x double>
- ; CHECK-NEXT:    [[TMP5:%.*]] = bitcast <8 x i64> [[TMP3]] to <8 x double>
--; CHECK-NEXT:    [[TMP11:%.*]] = call <8 x double> @llvm.x86.avx512.vpermi2var.pd.512(<8 x double> [[TMP4]], <8 x i64> [[X1]], <8 x double> [[TMP5]])
-+; CHECK-NEXT:    [[TMP11:%.*]] = call <8 x double> @llvm.x86.avx512.vpermi2var.pd.512(<8 x double> [[TMP4]], <8 x i64> [[X3:%.*]], <8 x double> [[TMP5]])
- ; CHECK-NEXT:    [[TMP7:%.*]] = bitcast <8 x double> [[TMP11]] to <8 x i64>
- ; CHECK-NEXT:    [[TMP8:%.*]] = bitcast <8 x i3> [[TMP6]] to i24
- ; CHECK-NEXT:    [[_MSCMP:%.*]] = icmp ne i24 [[TMP8]], 0
--; CHECK-NEXT:    br i1 [[_MSCMP]], label [[TMP12:%.*]], label [[TMP10:%.*]], !prof [[PROF1]]
--; CHECK:       9:
-+; CHECK-NEXT:    br i1 [[_MSCMP]], label [[TMP10:%.*]], label [[TMP12:%.*]], !prof [[PROF1]]
-+; CHECK:       10:
- ; CHECK-NEXT:    call void @__msan_warning_noreturn() #[[ATTR10]]
- ; CHECK-NEXT:    unreachable
--; CHECK:       10:
--; CHECK-NEXT:    [[TMP9:%.*]] = call <8 x double> @llvm.x86.avx512.vpermi2var.pd.512(<8 x double> [[X0:%.*]], <8 x i64> [[X1]], <8 x double> [[X2:%.*]])
-+; CHECK:       11:
-+; CHECK-NEXT:    [[TMP9:%.*]] = call <8 x double> @llvm.x86.avx512.vpermi2var.pd.512(<8 x double> [[X0:%.*]], <8 x i64> [[X3]], <8 x double> [[X2:%.*]])
- ; CHECK-NEXT:    store <8 x i64> [[TMP7]], ptr @__msan_retval_tls, align 8
- ; CHECK-NEXT:    ret <8 x double> [[TMP9]]
- ;
-@@ -5605,10 +5607,10 @@
- ; CHECK-NEXT:    [[TMP2:%.*]] = load <8 x i64>, ptr inttoptr (i64 add (i64 ptrtoint (ptr @__msan_param_tls to i64), i64 64) to ptr), align 8
- ; CHECK-NEXT:    [[TMP4:%.*]] = load i8, ptr inttoptr (i64 add (i64 ptrtoint (ptr @__msan_param_tls to i64), i64 192) to ptr), align 8
- ; CHECK-NEXT:    call void @llvm.donothing()
--; CHECK-NEXT:    [[TMP7:%.*]] = trunc <8 x i64> [[X1:%.*]] to <8 x i3>
-+; CHECK-NEXT:    [[TMP7:%.*]] = trunc <8 x i64> [[TMP2]] to <8 x i3>
- ; CHECK-NEXT:    [[TMP5:%.*]] = bitcast <8 x i64> [[TMP1]] to <8 x double>
- ; CHECK-NEXT:    [[TMP6:%.*]] = bitcast <8 x i64> [[TMP3]] to <8 x double>
--; CHECK-NEXT:    [[TMP9:%.*]] = call <8 x double> @llvm.x86.avx512.vpermi2var.pd.512(<8 x double> [[TMP5]], <8 x i64> [[X1]], <8 x double> [[TMP6]])
-+; CHECK-NEXT:    [[TMP9:%.*]] = call <8 x double> @llvm.x86.avx512.vpermi2var.pd.512(<8 x double> [[TMP5]], <8 x i64> [[X1:%.*]], <8 x double> [[TMP6]])
- ; CHECK-NEXT:    [[TMP8:%.*]] = bitcast <8 x double> [[TMP9]] to <8 x i64>
- ; CHECK-NEXT:    [[TMP21:%.*]] = bitcast <8 x i3> [[TMP7]] to i24
- ; CHECK-NEXT:    [[_MSCMP:%.*]] = icmp ne i24 [[TMP21]], 0
-@@ -5645,20 +5647,21 @@
- ; CHECK-LABEL: @test_int_x86_avx512_vpermi2var_ps_512(
- ; CHECK-NEXT:    [[TMP1:%.*]] = load <16 x i32>, ptr @__msan_param_tls, align 8
- ; CHECK-NEXT:    [[TMP3:%.*]] = load <16 x i32>, ptr inttoptr (i64 add (i64 ptrtoint (ptr @__msan_param_tls to i64), i64 128) to ptr), align 8
-+; CHECK-NEXT:    [[X1:%.*]] = load <16 x i32>, ptr inttoptr (i64 add (i64 ptrtoint (ptr @__msan_param_tls to i64), i64 64) to ptr), align 8
- ; CHECK-NEXT:    call void @llvm.donothing()
--; CHECK-NEXT:    [[TMP6:%.*]] = trunc <16 x i32> [[X1:%.*]] to <16 x i4>
-+; CHECK-NEXT:    [[TMP6:%.*]] = trunc <16 x i32> [[X1]] to <16 x i4>
- ; CHECK-NEXT:    [[TMP4:%.*]] = bitcast <16 x i32> [[TMP1]] to <16 x float>
- ; CHECK-NEXT:    [[TMP5:%.*]] = bitcast <16 x i32> [[TMP3]] to <16 x float>
--; CHECK-NEXT:    [[TMP11:%.*]] = call <16 x float> @llvm.x86.avx512.vpermi2var.ps.512(<16 x float> [[TMP4]], <16 x i32> [[X1]], <16 x float> [[TMP5]])
-+; CHECK-NEXT:    [[TMP11:%.*]] = call <16 x float> @llvm.x86.avx512.vpermi2var.ps.512(<16 x float> [[TMP4]], <16 x i32> [[X3:%.*]], <16 x float> [[TMP5]])
- ; CHECK-NEXT:    [[TMP7:%.*]] = bitcast <16 x float> [[TMP11]] to <16 x i32>
- ; CHECK-NEXT:    [[TMP8:%.*]] = bitcast <16 x i4> [[TMP6]] to i64
- ; CHECK-NEXT:    [[_MSCMP:%.*]] = icmp ne i64 [[TMP8]], 0
--; CHECK-NEXT:    br i1 [[_MSCMP]], label [[TMP12:%.*]], label [[TMP10:%.*]], !prof [[PROF1]]
--; CHECK:       9:
-+; CHECK-NEXT:    br i1 [[_MSCMP]], label [[TMP10:%.*]], label [[TMP12:%.*]], !prof [[PROF1]]
-+; CHECK:       10:
- ; CHECK-NEXT:    call void @__msan_warning_noreturn() #[[ATTR10]]
- ; CHECK-NEXT:    unreachable
--; CHECK:       10:
--; CHECK-NEXT:    [[TMP9:%.*]] = call <16 x float> @llvm.x86.avx512.vpermi2var.ps.512(<16 x float> [[X0:%.*]], <16 x i32> [[X1]], <16 x float> [[X2:%.*]])
-+; CHECK:       11:
-+; CHECK-NEXT:    [[TMP9:%.*]] = call <16 x float> @llvm.x86.avx512.vpermi2var.ps.512(<16 x float> [[X0:%.*]], <16 x i32> [[X3]], <16 x float> [[X2:%.*]])
- ; CHECK-NEXT:    store <16 x i32> [[TMP7]], ptr @__msan_retval_tls, align 8
- ; CHECK-NEXT:    ret <16 x float> [[TMP9]]
- ;
-@@ -5673,10 +5676,10 @@
- ; CHECK-NEXT:    [[TMP2:%.*]] = load <16 x i32>, ptr inttoptr (i64 add (i64 ptrtoint (ptr @__msan_param_tls to i64), i64 64) to ptr), align 8
- ; CHECK-NEXT:    [[TMP4:%.*]] = load i16, ptr inttoptr (i64 add (i64 ptrtoint (ptr @__msan_param_tls to i64), i64 192) to ptr), align 8
- ; CHECK-NEXT:    call void @llvm.donothing()
--; CHECK-NEXT:    [[TMP7:%.*]] = trunc <16 x i32> [[X1:%.*]] to <16 x i4>
-+; CHECK-NEXT:    [[TMP7:%.*]] = trunc <16 x i32> [[TMP2]] to <16 x i4>
- ; CHECK-NEXT:    [[TMP5:%.*]] = bitcast <16 x i32> [[TMP1]] to <16 x float>
- ; CHECK-NEXT:    [[TMP6:%.*]] = bitcast <16 x i32> [[TMP3]] to <16 x float>
--; CHECK-NEXT:    [[TMP9:%.*]] = call <16 x float> @llvm.x86.avx512.vpermi2var.ps.512(<16 x float> [[TMP5]], <16 x i32> [[X1]], <16 x float> [[TMP6]])
-+; CHECK-NEXT:    [[TMP9:%.*]] = call <16 x float> @llvm.x86.avx512.vpermi2var.ps.512(<16 x float> [[TMP5]], <16 x i32> [[X1:%.*]], <16 x float> [[TMP6]])
- ; CHECK-NEXT:    [[TMP8:%.*]] = bitcast <16 x float> [[TMP9]] to <16 x i32>
- ; CHECK-NEXT:    [[TMP21:%.*]] = bitcast <16 x i4> [[TMP7]] to i64
- ; CHECK-NEXT:    [[_MSCMP:%.*]] = icmp ne i64 [[TMP21]], 0
-@@ -5713,17 +5716,18 @@
- ; CHECK-LABEL: @test_int_x86_avx512_vpermi2var_q_512(
- ; CHECK-NEXT:    [[TMP1:%.*]] = load <8 x i64>, ptr @__msan_param_tls, align 8
- ; CHECK-NEXT:    [[TMP3:%.*]] = load <8 x i64>, ptr inttoptr (i64 add (i64 ptrtoint (ptr @__msan_param_tls to i64), i64 128) to ptr), align 8
-+; CHECK-NEXT:    [[X1:%.*]] = load <8 x i64>, ptr inttoptr (i64 add (i64 ptrtoint (ptr @__msan_param_tls to i64), i64 64) to ptr), align 8
- ; CHECK-NEXT:    call void @llvm.donothing()
--; CHECK-NEXT:    [[TMP8:%.*]] = trunc <8 x i64> [[X1:%.*]] to <8 x i3>
--; CHECK-NEXT:    [[_MSPROP1:%.*]] = call <8 x i64> @llvm.x86.avx512.vpermi2var.q.512(<8 x i64> [[TMP1]], <8 x i64> [[X1]], <8 x i64> [[TMP3]])
-+; CHECK-NEXT:    [[TMP8:%.*]] = trunc <8 x i64> [[X1]] to <8 x i3>
-+; CHECK-NEXT:    [[_MSPROP1:%.*]] = call <8 x i64> @llvm.x86.avx512.vpermi2var.q.512(<8 x i64> [[TMP1]], <8 x i64> [[X3:%.*]], <8 x i64> [[TMP3]])
- ; CHECK-NEXT:    [[TMP5:%.*]] = bitcast <8 x i3> [[TMP8]] to i24
- ; CHECK-NEXT:    [[_MSCMP:%.*]] = icmp ne i24 [[TMP5]], 0
--; CHECK-NEXT:    br i1 [[_MSCMP]], label [[TMP6:%.*]], label [[TMP7:%.*]], !prof [[PROF1]]
--; CHECK:       6:
-+; CHECK-NEXT:    br i1 [[_MSCMP]], label [[TMP7:%.*]], label [[TMP9:%.*]], !prof [[PROF1]]
-+; CHECK:       7:
- ; CHECK-NEXT:    call void @__msan_warning_noreturn() #[[ATTR10]]
- ; CHECK-NEXT:    unreachable
--; CHECK:       7:
--; CHECK-NEXT:    [[TMP4:%.*]] = call <8 x i64> @llvm.x86.avx512.vpermi2var.q.512(<8 x i64> [[X0:%.*]], <8 x i64> [[X1]], <8 x i64> [[X2:%.*]])
-+; CHECK:       8:
-+; CHECK-NEXT:    [[TMP4:%.*]] = call <8 x i64> @llvm.x86.avx512.vpermi2var.q.512(<8 x i64> [[X0:%.*]], <8 x i64> [[X3]], <8 x i64> [[X2:%.*]])
- ; CHECK-NEXT:    store <8 x i64> [[_MSPROP1]], ptr @__msan_retval_tls, align 8
- ; CHECK-NEXT:    ret <8 x i64> [[TMP4]]
- ;
-@@ -5735,11 +5739,11 @@
- ; CHECK-LABEL: @test_int_x86_avx512_mask_vpermi2var_q_512(
- ; CHECK-NEXT:    [[TMP1:%.*]] = load <8 x i64>, ptr @__msan_param_tls, align 8
- ; CHECK-NEXT:    [[TMP3:%.*]] = load <8 x i64>, ptr inttoptr (i64 add (i64 ptrtoint (ptr @__msan_param_tls to i64), i64 128) to ptr), align 8
--; CHECK-NEXT:    [[TMP4:%.*]] = load i8, ptr inttoptr (i64 add (i64 ptrtoint (ptr @__msan_param_tls to i64), i64 192) to ptr), align 8
- ; CHECK-NEXT:    [[TMP2:%.*]] = load <8 x i64>, ptr inttoptr (i64 add (i64 ptrtoint (ptr @__msan_param_tls to i64), i64 64) to ptr), align 8
-+; CHECK-NEXT:    [[TMP4:%.*]] = load i8, ptr inttoptr (i64 add (i64 ptrtoint (ptr @__msan_param_tls to i64), i64 192) to ptr), align 8
- ; CHECK-NEXT:    call void @llvm.donothing()
--; CHECK-NEXT:    [[TMP13:%.*]] = trunc <8 x i64> [[X1:%.*]] to <8 x i3>
--; CHECK-NEXT:    [[_MSPROP1:%.*]] = call <8 x i64> @llvm.x86.avx512.vpermi2var.q.512(<8 x i64> [[TMP1]], <8 x i64> [[X1]], <8 x i64> [[TMP3]])
-+; CHECK-NEXT:    [[TMP13:%.*]] = trunc <8 x i64> [[TMP2]] to <8 x i3>
-+; CHECK-NEXT:    [[_MSPROP1:%.*]] = call <8 x i64> @llvm.x86.avx512.vpermi2var.q.512(<8 x i64> [[TMP1]], <8 x i64> [[X1:%.*]], <8 x i64> [[TMP3]])
- ; CHECK-NEXT:    [[TMP14:%.*]] = bitcast <8 x i3> [[TMP13]] to i24
- ; CHECK-NEXT:    [[_MSCMP:%.*]] = icmp ne i24 [[TMP14]], 0
- ; CHECK-NEXT:    br i1 [[_MSCMP]], label [[TMP15:%.*]], label [[TMP16:%.*]], !prof [[PROF1]]
-@@ -5769,29 +5773,30 @@
- ; CHECK-LABEL: @test_int_x86_avx512_maskz_vpermt2var_d_512(
- ; CHECK-NEXT:    [[TMP1:%.*]] = load i64, ptr inttoptr (i64 add (i64 ptrtoint (ptr @__msan_param_tls to i64), i64 128) to ptr), align 8
- ; CHECK-NEXT:    [[TMP2:%.*]] = load <16 x i32>, ptr inttoptr (i64 add (i64 ptrtoint (ptr @__msan_param_tls to i64), i64 64) to ptr), align 8
-+; CHECK-NEXT:    [[X0:%.*]] = load <16 x i32>, ptr @__msan_param_tls, align 8
- ; CHECK-NEXT:    [[TMP4:%.*]] = load i16, ptr inttoptr (i64 add (i64 ptrtoint (ptr @__msan_param_tls to i64), i64 136) to ptr), align 8
- ; CHECK-NEXT:    call void @llvm.donothing()
- ; CHECK-NEXT:    [[_MSCMP:%.*]] = icmp ne i64 [[TMP1]], 0
--; CHECK-NEXT:    br i1 [[_MSCMP]], label [[TMP6:%.*]], label [[TMP5:%.*]], !prof [[PROF1]]
--; CHECK:       4:
-+; CHECK-NEXT:    br i1 [[_MSCMP]], label [[TMP5:%.*]], label [[TMP6:%.*]], !prof [[PROF1]]
-+; CHECK:       5:
- ; CHECK-NEXT:    call void @__msan_warning_noreturn() #[[ATTR10]]
- ; CHECK-NEXT:    unreachable
--; CHECK:       5:
-+; CHECK:       6:
- ; CHECK-NEXT:    [[X2:%.*]] = load <16 x i32>, ptr [[X2P:%.*]], align 64
- ; CHECK-NEXT:    [[TMP7:%.*]] = ptrtoint ptr [[X2P]] to i64
- ; CHECK-NEXT:    [[TMP8:%.*]] = xor i64 [[TMP7]], 87960930222080
- ; CHECK-NEXT:    [[TMP9:%.*]] = inttoptr i64 [[TMP8]] to ptr
- ; CHECK-NEXT:    [[_MSLD:%.*]] = load <16 x i32>, ptr [[TMP9]], align 64
--; CHECK-NEXT:    [[TMP18:%.*]] = trunc <16 x i32> [[X0:%.*]] to <16 x i4>
--; CHECK-NEXT:    [[_MSPROP1:%.*]] = call <16 x i32> @llvm.x86.avx512.vpermi2var.d.512(<16 x i32> [[TMP2]], <16 x i32> [[X0]], <16 x i32> [[_MSLD]])
-+; CHECK-NEXT:    [[TMP18:%.*]] = trunc <16 x i32> [[X0]] to <16 x i4>
-+; CHECK-NEXT:    [[_MSPROP1:%.*]] = call <16 x i32> @llvm.x86.avx512.vpermi2var.d.512(<16 x i32> [[TMP2]], <16 x i32> [[X4:%.*]], <16 x i32> [[_MSLD]])
- ; CHECK-NEXT:    [[TMP19:%.*]] = bitcast <16 x i4> [[TMP18]] to i64
- ; CHECK-NEXT:    [[_MSCMP1:%.*]] = icmp ne i64 [[TMP19]], 0
- ; CHECK-NEXT:    br i1 [[_MSCMP1]], label [[TMP20:%.*]], label [[TMP21:%.*]], !prof [[PROF1]]
--; CHECK:       12:
-+; CHECK:       13:
- ; CHECK-NEXT:    call void @__msan_warning_noreturn() #[[ATTR10]]
- ; CHECK-NEXT:    unreachable
--; CHECK:       13:
--; CHECK-NEXT:    [[TMP10:%.*]] = call <16 x i32> @llvm.x86.avx512.vpermi2var.d.512(<16 x i32> [[X1:%.*]], <16 x i32> [[X0]], <16 x i32> [[X2]])
-+; CHECK:       14:
-+; CHECK-NEXT:    [[TMP10:%.*]] = call <16 x i32> @llvm.x86.avx512.vpermi2var.d.512(<16 x i32> [[X1:%.*]], <16 x i32> [[X4]], <16 x i32> [[X2]])
- ; CHECK-NEXT:    [[TMP11:%.*]] = bitcast i16 [[TMP4]] to <16 x i1>
- ; CHECK-NEXT:    [[TMP12:%.*]] = bitcast i16 [[X3:%.*]] to <16 x i1>
- ; CHECK-NEXT:    [[TMP13:%.*]] = select <16 x i1> [[TMP12]], <16 x i32> [[_MSPROP1]], <16 x i32> zeroinitializer
-@@ -5816,14 +5821,15 @@
- ; CHECK-NEXT:    [[TMP5:%.*]] = load <8 x i64>, ptr inttoptr (i64 add (i64 ptrtoint (ptr @__msan_param_tls to i64), i64 144) to ptr), align 8
- ; CHECK-NEXT:    [[TMP6:%.*]] = load <8 x i64>, ptr inttoptr (i64 add (i64 ptrtoint (ptr @__msan_param_tls to i64), i64 208) to ptr), align 8
- ; CHECK-NEXT:    [[TMP2:%.*]] = load <8 x i64>, ptr inttoptr (i64 add (i64 ptrtoint (ptr @__msan_param_tls to i64), i64 64) to ptr), align 8
-+; CHECK-NEXT:    [[X0:%.*]] = load <8 x i64>, ptr @__msan_param_tls, align 8
- ; CHECK-NEXT:    [[TMP4:%.*]] = load i8, ptr inttoptr (i64 add (i64 ptrtoint (ptr @__msan_param_tls to i64), i64 136) to ptr), align 8
- ; CHECK-NEXT:    call void @llvm.donothing()
- ; CHECK-NEXT:    [[_MSCMP:%.*]] = icmp ne i64 [[TMP1]], 0
- ; CHECK-NEXT:    br i1 [[_MSCMP]], label [[TMP10:%.*]], label [[TMP12:%.*]], !prof [[PROF1]]
--; CHECK:       6:
-+; CHECK:       7:
- ; CHECK-NEXT:    call void @__msan_warning_noreturn() #[[ATTR10]]
- ; CHECK-NEXT:    unreachable
--; CHECK:       7:
-+; CHECK:       8:
- ; CHECK-NEXT:    [[X2S:%.*]] = load double, ptr [[X2PTR:%.*]], align 8
- ; CHECK-NEXT:    [[TMP7:%.*]] = ptrtoint ptr [[X2PTR]] to i64
- ; CHECK-NEXT:    [[TMP8:%.*]] = xor i64 [[TMP7]], 87960930222080
-@@ -5833,19 +5839,19 @@
- ; CHECK-NEXT:    [[X2INS:%.*]] = insertelement <8 x double> [[EXTRA_PARAM:%.*]], double [[X2S]], i32 0
- ; CHECK-NEXT:    [[_MSPROP1:%.*]] = shufflevector <8 x i64> [[_MSPROP]], <8 x i64> [[TMP6]], <8 x i32> zeroinitializer
- ; CHECK-NEXT:    [[X2:%.*]] = shufflevector <8 x double> [[X2INS]], <8 x double> [[EXTRA_PARAM2:%.*]], <8 x i32> zeroinitializer
--; CHECK-NEXT:    [[TMP11:%.*]] = trunc <8 x i64> [[X0:%.*]] to <8 x i3>
-+; CHECK-NEXT:    [[TMP11:%.*]] = trunc <8 x i64> [[X0]] to <8 x i3>
- ; CHECK-NEXT:    [[TMP24:%.*]] = bitcast <8 x i64> [[TMP2]] to <8 x double>
- ; CHECK-NEXT:    [[TMP13:%.*]] = bitcast <8 x i64> [[_MSPROP1]] to <8 x double>
--; CHECK-NEXT:    [[TMP14:%.*]] = call <8 x double> @llvm.x86.avx512.vpermi2var.pd.512(<8 x double> [[TMP24]], <8 x i64> [[X0]], <8 x double> [[TMP13]])
-+; CHECK-NEXT:    [[TMP14:%.*]] = call <8 x double> @llvm.x86.avx512.vpermi2var.pd.512(<8 x double> [[TMP24]], <8 x i64> [[X4:%.*]], <8 x double> [[TMP13]])
- ; CHECK-NEXT:    [[TMP25:%.*]] = bitcast <8 x double> [[TMP14]] to <8 x i64>
- ; CHECK-NEXT:    [[TMP26:%.*]] = bitcast <8 x i3> [[TMP11]] to i24
- ; CHECK-NEXT:    [[_MSCMP2:%.*]] = icmp ne i24 [[TMP26]], 0
- ; CHECK-NEXT:    br i1 [[_MSCMP2]], label [[TMP27:%.*]], label [[TMP28:%.*]], !prof [[PROF1]]
--; CHECK:       17:
-+; CHECK:       18:
- ; CHECK-NEXT:    call void @__msan_warning_noreturn() #[[ATTR10]]
- ; CHECK-NEXT:    unreachable
--; CHECK:       18:
--; CHECK-NEXT:    [[TMP15:%.*]] = call <8 x double> @llvm.x86.avx512.vpermi2var.pd.512(<8 x double> [[X1:%.*]], <8 x i64> [[X0]], <8 x double> [[X2]])
-+; CHECK:       19:
-+; CHECK-NEXT:    [[TMP15:%.*]] = call <8 x double> @llvm.x86.avx512.vpermi2var.pd.512(<8 x double> [[X1:%.*]], <8 x i64> [[X4]], <8 x double> [[X2]])
- ; CHECK-NEXT:    [[TMP16:%.*]] = bitcast i8 [[TMP4]] to <8 x i1>
- ; CHECK-NEXT:    [[TMP17:%.*]] = bitcast i8 [[X3:%.*]] to <8 x i1>
- ; CHECK-NEXT:    [[TMP18:%.*]] = select <8 x i1> [[TMP17]], <8 x i64> [[TMP25]], <8 x i64> zeroinitializer
-@@ -5871,21 +5877,22 @@
- ; CHECK-LABEL: @test_int_x86_avx512_maskz_vpermt2var_ps_512(
- ; CHECK-NEXT:    [[TMP1:%.*]] = load <16 x i32>, ptr inttoptr (i64 add (i64 ptrtoint (ptr @__msan_param_tls to i64), i64 64) to ptr), align 8
- ; CHECK-NEXT:    [[TMP3:%.*]] = load <16 x i32>, ptr inttoptr (i64 add (i64 ptrtoint (ptr @__msan_param_tls to i64), i64 128) to ptr), align 8
-+; CHECK-NEXT:    [[X0:%.*]] = load <16 x i32>, ptr @__msan_param_tls, align 8
- ; CHECK-NEXT:    [[TMP4:%.*]] = load i16, ptr inttoptr (i64 add (i64 ptrtoint (ptr @__msan_param_tls to i64), i64 192) to ptr), align 8
- ; CHECK-NEXT:    call void @llvm.donothing()
--; CHECK-NEXT:    [[TMP7:%.*]] = trunc <16 x i32> [[X0:%.*]] to <16 x i4>
-+; CHECK-NEXT:    [[TMP7:%.*]] = trunc <16 x i32> [[X0]] to <16 x i4>
- ; CHECK-NEXT:    [[TMP5:%.*]] = bitcast <16 x i32> [[TMP1]] to <16 x float>
- ; CHECK-NEXT:    [[TMP6:%.*]] = bitcast <16 x i32> [[TMP3]] to <16 x float>
--; CHECK-NEXT:    [[TMP19:%.*]] = call <16 x float> @llvm.x86.avx512.vpermi2var.ps.512(<16 x float> [[TMP5]], <16 x i32> [[X0]], <16 x float> [[TMP6]])
-+; CHECK-NEXT:    [[TMP19:%.*]] = call <16 x float> @llvm.x86.avx512.vpermi2var.ps.512(<16 x float> [[TMP5]], <16 x i32> [[X4:%.*]], <16 x float> [[TMP6]])
- ; CHECK-NEXT:    [[TMP8:%.*]] = bitcast <16 x float> [[TMP19]] to <16 x i32>
- ; CHECK-NEXT:    [[TMP9:%.*]] = bitcast <16 x i4> [[TMP7]] to i64
- ; CHECK-NEXT:    [[_MSCMP:%.*]] = icmp ne i64 [[TMP9]], 0
- ; CHECK-NEXT:    br i1 [[_MSCMP]], label [[TMP20:%.*]], label [[TMP21:%.*]], !prof [[PROF1]]
--; CHECK:       10:
-+; CHECK:       11:
- ; CHECK-NEXT:    call void @__msan_warning_noreturn() #[[ATTR10]]
- ; CHECK-NEXT:    unreachable
--; CHECK:       11:
--; CHECK-NEXT:    [[TMP10:%.*]] = call <16 x float> @llvm.x86.avx512.vpermi2var.ps.512(<16 x float> [[X1:%.*]], <16 x i32> [[X0]], <16 x float> [[X2:%.*]])
-+; CHECK:       12:
-+; CHECK-NEXT:    [[TMP10:%.*]] = call <16 x float> @llvm.x86.avx512.vpermi2var.ps.512(<16 x float> [[X1:%.*]], <16 x i32> [[X4]], <16 x float> [[X2:%.*]])
- ; CHECK-NEXT:    [[TMP11:%.*]] = bitcast i16 [[TMP4]] to <16 x i1>
- ; CHECK-NEXT:    [[TMP12:%.*]] = bitcast i16 [[X3:%.*]] to <16 x i1>
- ; CHECK-NEXT:    [[TMP13:%.*]] = select <16 x i1> [[TMP12]], <16 x i32> [[TMP8]], <16 x i32> zeroinitializer
-@@ -5908,18 +5915,19 @@
- ; CHECK-LABEL: @test_int_x86_avx512_maskz_vpermt2var_q_512(
- ; CHECK-NEXT:    [[TMP1:%.*]] = load <8 x i64>, ptr inttoptr (i64 add (i64 ptrtoint (ptr @__msan_param_tls to i64), i64 64) to ptr), align 8
- ; CHECK-NEXT:    [[TMP3:%.*]] = load <8 x i64>, ptr inttoptr (i64 add (i64 ptrtoint (ptr @__msan_param_tls to i64), i64 128) to ptr), align 8
-+; CHECK-NEXT:    [[X0:%.*]] = load <8 x i64>, ptr @__msan_param_tls, align 8
- ; CHECK-NEXT:    [[TMP4:%.*]] = load i8, ptr inttoptr (i64 add (i64 ptrtoint (ptr @__msan_param_tls to i64), i64 192) to ptr), align 8
- ; CHECK-NEXT:    call void @llvm.donothing()
--; CHECK-NEXT:    [[TMP13:%.*]] = trunc <8 x i64> [[X0:%.*]] to <8 x i3>
--; CHECK-NEXT:    [[_MSPROP1:%.*]] = call <8 x i64> @llvm.x86.avx512.vpermi2var.q.512(<8 x i64> [[TMP1]], <8 x i64> [[X0]], <8 x i64> [[TMP3]])
-+; CHECK-NEXT:    [[TMP13:%.*]] = trunc <8 x i64> [[X0]] to <8 x i3>
-+; CHECK-NEXT:    [[_MSPROP1:%.*]] = call <8 x i64> @llvm.x86.avx512.vpermi2var.q.512(<8 x i64> [[TMP1]], <8 x i64> [[X4:%.*]], <8 x i64> [[TMP3]])
- ; CHECK-NEXT:    [[TMP14:%.*]] = bitcast <8 x i3> [[TMP13]] to i24
- ; CHECK-NEXT:    [[_MSCMP:%.*]] = icmp ne i24 [[TMP14]], 0
- ; CHECK-NEXT:    br i1 [[_MSCMP]], label [[TMP15:%.*]], label [[TMP16:%.*]], !prof [[PROF1]]
--; CHECK:       7:
-+; CHECK:       8:
- ; CHECK-NEXT:    call void @__msan_warning_noreturn() #[[ATTR10]]
- ; CHECK-NEXT:    unreachable
--; CHECK:       8:
--; CHECK-NEXT:    [[TMP5:%.*]] = call <8 x i64> @llvm.x86.avx512.vpermi2var.q.512(<8 x i64> [[X1:%.*]], <8 x i64> [[X0]], <8 x i64> [[X2:%.*]])
-+; CHECK:       9:
-+; CHECK-NEXT:    [[TMP5:%.*]] = call <8 x i64> @llvm.x86.avx512.vpermi2var.q.512(<8 x i64> [[X1:%.*]], <8 x i64> [[X4]], <8 x i64> [[X2:%.*]])
- ; CHECK-NEXT:    [[TMP6:%.*]] = bitcast i8 [[TMP4]] to <8 x i1>
- ; CHECK-NEXT:    [[TMP7:%.*]] = bitcast i8 [[X3:%.*]] to <8 x i1>
- ; CHECK-NEXT:    [[TMP8:%.*]] = select <8 x i1> [[TMP7]], <8 x i64> [[_MSPROP1]], <8 x i64> zeroinitializer
-@@ -5941,17 +5949,18 @@
- ; CHECK-LABEL: @test_int_x86_avx512_vpermt2var_d_512(
- ; CHECK-NEXT:    [[TMP1:%.*]] = load <16 x i32>, ptr inttoptr (i64 add (i64 ptrtoint (ptr @__msan_param_tls to i64), i64 64) to ptr), align 8
- ; CHECK-NEXT:    [[TMP3:%.*]] = load <16 x i32>, ptr inttoptr (i64 add (i64 ptrtoint (ptr @__msan_param_tls to i64), i64 128) to ptr), align 8
-+; CHECK-NEXT:    [[X0:%.*]] = load <16 x i32>, ptr @__msan_param_tls, align 8
- ; CHECK-NEXT:    call void @llvm.donothing()
--; CHECK-NEXT:    [[TMP8:%.*]] = trunc <16 x i32> [[X0:%.*]] to <16 x i4>
--; CHECK-NEXT:    [[_MSPROP1:%.*]] = call <16 x i32> @llvm.x86.avx512.vpermi2var.d.512(<16 x i32> [[TMP1]], <16 x i32> [[X0]], <16 x i32> [[TMP3]])
-+; CHECK-NEXT:    [[TMP8:%.*]] = trunc <16 x i32> [[X0]] to <16 x i4>
-+; CHECK-NEXT:    [[_MSPROP1:%.*]] = call <16 x i32> @llvm.x86.avx512.vpermi2var.d.512(<16 x i32> [[TMP1]], <16 x i32> [[X3:%.*]], <16 x i32> [[TMP3]])
- ; CHECK-NEXT:    [[TMP5:%.*]] = bitcast <16 x i4> [[TMP8]] to i64
- ; CHECK-NEXT:    [[_MSCMP:%.*]] = icmp ne i64 [[TMP5]], 0
--; CHECK-NEXT:    br i1 [[_MSCMP]], label [[TMP6:%.*]], label [[TMP7:%.*]], !prof [[PROF1]]
--; CHECK:       6:
-+; CHECK-NEXT:    br i1 [[_MSCMP]], label [[TMP7:%.*]], label [[TMP9:%.*]], !prof [[PROF1]]
-+; CHECK:       7:
- ; CHECK-NEXT:    call void @__msan_warning_noreturn() #[[ATTR10]]
- ; CHECK-NEXT:    unreachable
--; CHECK:       7:
--; CHECK-NEXT:    [[TMP4:%.*]] = call <16 x i32> @llvm.x86.avx512.vpermi2var.d.512(<16 x i32> [[X1:%.*]], <16 x i32> [[X0]], <16 x i32> [[X2:%.*]])
-+; CHECK:       8:
-+; CHECK-NEXT:    [[TMP4:%.*]] = call <16 x i32> @llvm.x86.avx512.vpermi2var.d.512(<16 x i32> [[X1:%.*]], <16 x i32> [[X3]], <16 x i32> [[X2:%.*]])
- ; CHECK-NEXT:    store <16 x i32> [[_MSPROP1]], ptr @__msan_retval_tls, align 8
- ; CHECK-NEXT:    ret <16 x i32> [[TMP4]]
- ;
-@@ -5963,18 +5972,19 @@
- ; CHECK-LABEL: @test_int_x86_avx512_mask_vpermt2var_d_512(
- ; CHECK-NEXT:    [[TMP1:%.*]] = load <16 x i32>, ptr inttoptr (i64 add (i64 ptrtoint (ptr @__msan_param_tls to i64), i64 64) to ptr), align 8
- ; CHECK-NEXT:    [[TMP3:%.*]] = load <16 x i32>, ptr inttoptr (i64 add (i64 ptrtoint (ptr @__msan_param_tls to i64), i64 128) to ptr), align 8
-+; CHECK-NEXT:    [[X0:%.*]] = load <16 x i32>, ptr @__msan_param_tls, align 8
- ; CHECK-NEXT:    [[TMP4:%.*]] = load i16, ptr inttoptr (i64 add (i64 ptrtoint (ptr @__msan_param_tls to i64), i64 192) to ptr), align 8
- ; CHECK-NEXT:    call void @llvm.donothing()
--; CHECK-NEXT:    [[TMP13:%.*]] = trunc <16 x i32> [[X0:%.*]] to <16 x i4>
--; CHECK-NEXT:    [[_MSPROP1:%.*]] = call <16 x i32> @llvm.x86.avx512.vpermi2var.d.512(<16 x i32> [[TMP1]], <16 x i32> [[X0]], <16 x i32> [[TMP3]])
-+; CHECK-NEXT:    [[TMP13:%.*]] = trunc <16 x i32> [[X0]] to <16 x i4>
-+; CHECK-NEXT:    [[_MSPROP1:%.*]] = call <16 x i32> @llvm.x86.avx512.vpermi2var.d.512(<16 x i32> [[TMP1]], <16 x i32> [[X4:%.*]], <16 x i32> [[TMP3]])
- ; CHECK-NEXT:    [[TMP14:%.*]] = bitcast <16 x i4> [[TMP13]] to i64
- ; CHECK-NEXT:    [[_MSCMP:%.*]] = icmp ne i64 [[TMP14]], 0
- ; CHECK-NEXT:    br i1 [[_MSCMP]], label [[TMP15:%.*]], label [[TMP16:%.*]], !prof [[PROF1]]
--; CHECK:       7:
-+; CHECK:       8:
- ; CHECK-NEXT:    call void @__msan_warning_noreturn() #[[ATTR10]]
- ; CHECK-NEXT:    unreachable
--; CHECK:       8:
--; CHECK-NEXT:    [[TMP5:%.*]] = call <16 x i32> @llvm.x86.avx512.vpermi2var.d.512(<16 x i32> [[X1:%.*]], <16 x i32> [[X0]], <16 x i32> [[X2:%.*]])
-+; CHECK:       9:
-+; CHECK-NEXT:    [[TMP5:%.*]] = call <16 x i32> @llvm.x86.avx512.vpermi2var.d.512(<16 x i32> [[X1:%.*]], <16 x i32> [[X4]], <16 x i32> [[X2:%.*]])
- ; CHECK-NEXT:    [[TMP6:%.*]] = bitcast i16 [[TMP4]] to <16 x i1>
- ; CHECK-NEXT:    [[TMP7:%.*]] = bitcast i16 [[X3:%.*]] to <16 x i1>
- ; CHECK-NEXT:    [[TMP8:%.*]] = select <16 x i1> [[TMP7]], <16 x i32> [[_MSPROP1]], <16 x i32> [[TMP1]]
-@@ -8478,19 +8488,20 @@
- define <8 x double>@test_int_x86_avx512_vpermilvar_pd_512(<8 x double> %x0, <8 x i64> %x1) #0 {
- ; CHECK-LABEL: @test_int_x86_avx512_vpermilvar_pd_512(
- ; CHECK-NEXT:    [[TMP1:%.*]] = load <8 x i64>, ptr @__msan_param_tls, align 8
-+; CHECK-NEXT:    [[X1:%.*]] = load <8 x i64>, ptr inttoptr (i64 add (i64 ptrtoint (ptr @__msan_param_tls to i64), i64 64) to ptr), align 8
- ; CHECK-NEXT:    call void @llvm.donothing()
--; CHECK-NEXT:    [[TMP2:%.*]] = trunc <8 x i64> [[X1:%.*]] to <8 x i3>
-+; CHECK-NEXT:    [[TMP2:%.*]] = trunc <8 x i64> [[X1]] to <8 x i3>
- ; CHECK-NEXT:    [[X0:%.*]] = bitcast <8 x i64> [[TMP1]] to <8 x double>
--; CHECK-NEXT:    [[RES:%.*]] = call <8 x double> @llvm.x86.avx512.vpermilvar.pd.512(<8 x double> [[X0]], <8 x i64> [[X1]])
-+; CHECK-NEXT:    [[RES:%.*]] = call <8 x double> @llvm.x86.avx512.vpermilvar.pd.512(<8 x double> [[X0]], <8 x i64> [[X2:%.*]])
- ; CHECK-NEXT:    [[TMP4:%.*]] = bitcast <8 x double> [[RES]] to <8 x i64>
- ; CHECK-NEXT:    [[TMP6:%.*]] = bitcast <8 x i3> [[TMP2]] to i24
- ; CHECK-NEXT:    [[_MSCMP:%.*]] = icmp ne i24 [[TMP6]], 0
--; CHECK-NEXT:    br i1 [[_MSCMP]], label [[TMP7:%.*]], label [[TMP8:%.*]], !prof [[PROF1]]
--; CHECK:       7:
-+; CHECK-NEXT:    br i1 [[_MSCMP]], label [[TMP8:%.*]], label [[TMP9:%.*]], !prof [[PROF1]]
-+; CHECK:       8:
- ; CHECK-NEXT:    call void @__msan_warning_noreturn() #[[ATTR10]]
- ; CHECK-NEXT:    unreachable
--; CHECK:       8:
--; CHECK-NEXT:    [[RES1:%.*]] = call <8 x double> @llvm.x86.avx512.vpermilvar.pd.512(<8 x double> [[X2:%.*]], <8 x i64> [[X1]])
-+; CHECK:       9:
-+; CHECK-NEXT:    [[RES1:%.*]] = call <8 x double> @llvm.x86.avx512.vpermilvar.pd.512(<8 x double> [[X3:%.*]], <8 x i64> [[X2]])
- ; CHECK-NEXT:    store <8 x i64> [[TMP4]], ptr @__msan_retval_tls, align 8
- ; CHECK-NEXT:    ret <8 x double> [[RES1]]
- ;
-@@ -8501,21 +8512,22 @@
- define <8 x double>@test_int_x86_avx512_vpermilvar_pd_512_mask(<8 x double> %x0, <8 x i64> %x1, <8 x double> %x2, i8 %mask) #0 {
- ; CHECK-LABEL: @test_int_x86_avx512_vpermilvar_pd_512_mask(
- ; CHECK-NEXT:    [[TMP1:%.*]] = load <8 x i64>, ptr @__msan_param_tls, align 8
-+; CHECK-NEXT:    [[X1:%.*]] = load <8 x i64>, ptr inttoptr (i64 add (i64 ptrtoint (ptr @__msan_param_tls to i64), i64 64) to ptr), align 8
- ; CHECK-NEXT:    [[TMP3:%.*]] = load i8, ptr inttoptr (i64 add (i64 ptrtoint (ptr @__msan_param_tls to i64), i64 192) to ptr), align 8
- ; CHECK-NEXT:    [[TMP4:%.*]] = load <8 x i64>, ptr inttoptr (i64 add (i64 ptrtoint (ptr @__msan_param_tls to i64), i64 128) to ptr), align 8
- ; CHECK-NEXT:    call void @llvm.donothing()
--; CHECK-NEXT:    [[TMP5:%.*]] = trunc <8 x i64> [[X1:%.*]] to <8 x i3>
-+; CHECK-NEXT:    [[TMP5:%.*]] = trunc <8 x i64> [[X1]] to <8 x i3>
- ; CHECK-NEXT:    [[X0:%.*]] = bitcast <8 x i64> [[TMP1]] to <8 x double>
--; CHECK-NEXT:    [[RES:%.*]] = call <8 x double> @llvm.x86.avx512.vpermilvar.pd.512(<8 x double> [[X0]], <8 x i64> [[X1]])
-+; CHECK-NEXT:    [[RES:%.*]] = call <8 x double> @llvm.x86.avx512.vpermilvar.pd.512(<8 x double> [[X0]], <8 x i64> [[X3:%.*]])
- ; CHECK-NEXT:    [[TMP6:%.*]] = bitcast <8 x double> [[RES]] to <8 x i64>
- ; CHECK-NEXT:    [[TMP8:%.*]] = bitcast <8 x i3> [[TMP5]] to i24
- ; CHECK-NEXT:    [[_MSCMP:%.*]] = icmp ne i24 [[TMP8]], 0
- ; CHECK-NEXT:    br i1 [[_MSCMP]], label [[TMP16:%.*]], label [[TMP17:%.*]], !prof [[PROF1]]
--; CHECK:       9:
-+; CHECK:       10:
- ; CHECK-NEXT:    call void @__msan_warning_noreturn() #[[ATTR10]]
- ; CHECK-NEXT:    unreachable
--; CHECK:       10:
--; CHECK-NEXT:    [[RES1:%.*]] = call <8 x double> @llvm.x86.avx512.vpermilvar.pd.512(<8 x double> [[X3:%.*]], <8 x i64> [[X1]])
-+; CHECK:       11:
-+; CHECK-NEXT:    [[RES1:%.*]] = call <8 x double> @llvm.x86.avx512.vpermilvar.pd.512(<8 x double> [[X4:%.*]], <8 x i64> [[X3]])
- ; CHECK-NEXT:    [[TMP9:%.*]] = bitcast i8 [[TMP3]] to <8 x i1>
- ; CHECK-NEXT:    [[MASK_CAST:%.*]] = bitcast i8 [[MASK:%.*]] to <8 x i1>
- ; CHECK-NEXT:    [[TMP10:%.*]] = select <8 x i1> [[MASK_CAST]], <8 x i64> [[TMP6]], <8 x i64> [[TMP4]]
-@@ -8538,20 +8550,21 @@
- define <8 x double>@test_int_x86_avx512_vpermilvar_pd_512_maskz(<8 x double> %x0, <8 x i64> %x1, i8 %mask) #0 {
- ; CHECK-LABEL: @test_int_x86_avx512_vpermilvar_pd_512_maskz(
- ; CHECK-NEXT:    [[TMP1:%.*]] = load <8 x i64>, ptr @__msan_param_tls, align 8
-+; CHECK-NEXT:    [[X1:%.*]] = load <8 x i64>, ptr inttoptr (i64 add (i64 ptrtoint (ptr @__msan_param_tls to i64), i64 64) to ptr), align 8
- ; CHECK-NEXT:    [[TMP3:%.*]] = load i8, ptr inttoptr (i64 add (i64 ptrtoint (ptr @__msan_param_tls to i64), i64 128) to ptr), align 8
- ; CHECK-NEXT:    call void @llvm.donothing()
--; CHECK-NEXT:    [[TMP4:%.*]] = trunc <8 x i64> [[X1:%.*]] to <8 x i3>
-+; CHECK-NEXT:    [[TMP4:%.*]] = trunc <8 x i64> [[X1]] to <8 x i3>
- ; CHECK-NEXT:    [[X0:%.*]] = bitcast <8 x i64> [[TMP1]] to <8 x double>
--; CHECK-NEXT:    [[RES:%.*]] = call <8 x double> @llvm.x86.avx512.vpermilvar.pd.512(<8 x double> [[X0]], <8 x i64> [[X1]])
-+; CHECK-NEXT:    [[RES:%.*]] = call <8 x double> @llvm.x86.avx512.vpermilvar.pd.512(<8 x double> [[X0]], <8 x i64> [[X2:%.*]])
- ; CHECK-NEXT:    [[TMP5:%.*]] = bitcast <8 x double> [[RES]] to <8 x i64>
- ; CHECK-NEXT:    [[TMP7:%.*]] = bitcast <8 x i3> [[TMP4]] to i24
- ; CHECK-NEXT:    [[_MSCMP:%.*]] = icmp ne i24 [[TMP7]], 0
- ; CHECK-NEXT:    br i1 [[_MSCMP]], label [[TMP14:%.*]], label [[TMP15:%.*]], !prof [[PROF1]]
--; CHECK:       8:
-+; CHECK:       9:
- ; CHECK-NEXT:    call void @__msan_warning_noreturn() #[[ATTR10]]
- ; CHECK-NEXT:    unreachable
--; CHECK:       9:
--; CHECK-NEXT:    [[RES1:%.*]] = call <8 x double> @llvm.x86.avx512.vpermilvar.pd.512(<8 x double> [[X2:%.*]], <8 x i64> [[X1]])
-+; CHECK:       10:
-+; CHECK-NEXT:    [[RES1:%.*]] = call <8 x double> @llvm.x86.avx512.vpermilvar.pd.512(<8 x double> [[X3:%.*]], <8 x i64> [[X2]])
- ; CHECK-NEXT:    [[TMP8:%.*]] = bitcast i8 [[TMP3]] to <8 x i1>
- ; CHECK-NEXT:    [[MASK_CAST:%.*]] = bitcast i8 [[MASK:%.*]] to <8 x i1>
- ; CHECK-NEXT:    [[TMP9:%.*]] = select <8 x i1> [[MASK_CAST]], <8 x i64> [[TMP5]], <8 x i64> zeroinitializer
-@@ -8575,19 +8588,20 @@
- define <16 x float>@test_int_x86_avx512_vpermilvar_ps_512(<16 x float> %x0, <16 x i32> %x1) #0 {
- ; CHECK-LABEL: @test_int_x86_avx512_vpermilvar_ps_512(
- ; CHECK-NEXT:    [[TMP1:%.*]] = load <16 x i32>, ptr @__msan_param_tls, align 8
-+; CHECK-NEXT:    [[X1:%.*]] = load <16 x i32>, ptr inttoptr (i64 add (i64 ptrtoint (ptr @__msan_param_tls to i64), i64 64) to ptr), align 8
- ; CHECK-NEXT:    call void @llvm.donothing()
--; CHECK-NEXT:    [[TMP2:%.*]] = trunc <16 x i32> [[X1:%.*]] to <16 x i4>
-+; CHECK-NEXT:    [[TMP2:%.*]] = trunc <16 x i32> [[X1]] to <16 x i4>
- ; CHECK-NEXT:    [[X0:%.*]] = bitcast <16 x i32> [[TMP1]] to <16 x float>
--; CHECK-NEXT:    [[RES:%.*]] = call <16 x float> @llvm.x86.avx512.vpermilvar.ps.512(<16 x float> [[X0]], <16 x i32> [[X1]])
-+; CHECK-NEXT:    [[RES:%.*]] = call <16 x float> @llvm.x86.avx512.vpermilvar.ps.512(<16 x float> [[X0]], <16 x i32> [[X2:%.*]])
- ; CHECK-NEXT:    [[TMP4:%.*]] = bitcast <16 x float> [[RES]] to <16 x i32>
- ; CHECK-NEXT:    [[TMP6:%.*]] = bitcast <16 x i4> [[TMP2]] to i64
- ; CHECK-NEXT:    [[_MSCMP:%.*]] = icmp ne i64 [[TMP6]], 0
--; CHECK-NEXT:    br i1 [[_MSCMP]], label [[TMP7:%.*]], label [[TMP8:%.*]], !prof [[PROF1]]
--; CHECK:       7:
-+; CHECK-NEXT:    br i1 [[_MSCMP]], label [[TMP8:%.*]], label [[TMP9:%.*]], !prof [[PROF1]]
-+; CHECK:       8:
- ; CHECK-NEXT:    call void @__msan_warning_noreturn() #[[ATTR10]]
- ; CHECK-NEXT:    unreachable
--; CHECK:       8:
--; CHECK-NEXT:    [[RES1:%.*]] = call <16 x float> @llvm.x86.avx512.vpermilvar.ps.512(<16 x float> [[X2:%.*]], <16 x i32> [[X1]])
-+; CHECK:       9:
-+; CHECK-NEXT:    [[RES1:%.*]] = call <16 x float> @llvm.x86.avx512.vpermilvar.ps.512(<16 x float> [[X3:%.*]], <16 x i32> [[X2]])
- ; CHECK-NEXT:    store <16 x i32> [[TMP4]], ptr @__msan_retval_tls, align 8
- ; CHECK-NEXT:    ret <16 x float> [[RES1]]
- ;
-@@ -8598,21 +8612,22 @@
- define <16 x float>@test_int_x86_avx512_vpermilvar_ps_512_mask(<16 x float> %x0, <16 x i32> %x1, <16 x float> %x2, i16 %mask) #0 {
- ; CHECK-LABEL: @test_int_x86_avx512_vpermilvar_ps_512_mask(
- ; CHECK-NEXT:    [[TMP1:%.*]] = load <16 x i32>, ptr @__msan_param_tls, align 8
-+; CHECK-NEXT:    [[X1:%.*]] = load <16 x i32>, ptr inttoptr (i64 add (i64 ptrtoint (ptr @__msan_param_tls to i64), i64 64) to ptr), align 8
- ; CHECK-NEXT:    [[TMP3:%.*]] = load i16, ptr inttoptr (i64 add (i64 ptrtoint (ptr @__msan_param_tls to i64), i64 192) to ptr), align 8
- ; CHECK-NEXT:    [[TMP4:%.*]] = load <16 x i32>, ptr inttoptr (i64 add (i64 ptrtoint (ptr @__msan_param_tls to i64), i64 128) to ptr), align 8
- ; CHECK-NEXT:    call void @llvm.donothing()
--; CHECK-NEXT:    [[TMP5:%.*]] = trunc <16 x i32> [[X1:%.*]] to <16 x i4>
-+; CHECK-NEXT:    [[TMP5:%.*]] = trunc <16 x i32> [[X1]] to <16 x i4>
- ; CHECK-NEXT:    [[X0:%.*]] = bitcast <16 x i32> [[TMP1]] to <16 x float>
--; CHECK-NEXT:    [[RES:%.*]] = call <16 x float> @llvm.x86.avx512.vpermilvar.ps.512(<16 x float> [[X0]], <16 x i32> [[X1]])
-+; CHECK-NEXT:    [[RES:%.*]] = call <16 x float> @llvm.x86.avx512.vpermilvar.ps.512(<16 x float> [[X0]], <16 x i32> [[X3:%.*]])
- ; CHECK-NEXT:    [[TMP6:%.*]] = bitcast <16 x float> [[RES]] to <16 x i32>
- ; CHECK-NEXT:    [[TMP8:%.*]] = bitcast <16 x i4> [[TMP5]] to i64
- ; CHECK-NEXT:    [[_MSCMP:%.*]] = icmp ne i64 [[TMP8]], 0
- ; CHECK-NEXT:    br i1 [[_MSCMP]], label [[TMP16:%.*]], label [[TMP17:%.*]], !prof [[PROF1]]
--; CHECK:       9:
-+; CHECK:       10:
- ; CHECK-NEXT:    call void @__msan_warning_noreturn() #[[ATTR10]]
- ; CHECK-NEXT:    unreachable
--; CHECK:       10:
--; CHECK-NEXT:    [[RES1:%.*]] = call <16 x float> @llvm.x86.avx512.vpermilvar.ps.512(<16 x float> [[X3:%.*]], <16 x i32> [[X1]])
-+; CHECK:       11:
-+; CHECK-NEXT:    [[RES1:%.*]] = call <16 x float> @llvm.x86.avx512.vpermilvar.ps.512(<16 x float> [[X4:%.*]], <16 x i32> [[X3]])
- ; CHECK-NEXT:    [[TMP9:%.*]] = bitcast i16 [[TMP3]] to <16 x i1>
- ; CHECK-NEXT:    [[MASK_CAST:%.*]] = bitcast i16 [[MASK:%.*]] to <16 x i1>
- ; CHECK-NEXT:    [[TMP10:%.*]] = select <16 x i1> [[MASK_CAST]], <16 x i32> [[TMP6]], <16 x i32> [[TMP4]]
-@@ -8635,20 +8650,21 @@
- define <16 x float>@test_int_x86_avx512_vpermilvar_ps_512_maskz(<16 x float> %x0, <16 x i32> %x1, i16 %mask) #0 {
- ; CHECK-LABEL: @test_int_x86_avx512_vpermilvar_ps_512_maskz(
- ; CHECK-NEXT:    [[TMP1:%.*]] = load <16 x i32>, ptr @__msan_param_tls, align 8
-+; CHECK-NEXT:    [[X1:%.*]] = load <16 x i32>, ptr inttoptr (i64 add (i64 ptrtoint (ptr @__msan_param_tls to i64), i64 64) to ptr), align 8
- ; CHECK-NEXT:    [[TMP3:%.*]] = load i16, ptr inttoptr (i64 add (i64 ptrtoint (ptr @__msan_param_tls to i64), i64 128) to ptr), align 8
- ; CHECK-NEXT:    call void @llvm.donothing()
--; CHECK-NEXT:    [[TMP4:%.*]] = trunc <16 x i32> [[X1:%.*]] to <16 x i4>
-+; CHECK-NEXT:    [[TMP4:%.*]] = trunc <16 x i32> [[X1]] to <16 x i4>
- ; CHECK-NEXT:    [[X0:%.*]] = bitcast <16 x i32> [[TMP1]] to <16 x float>
--; CHECK-NEXT:    [[RES:%.*]] = call <16 x float> @llvm.x86.avx512.vpermilvar.ps.512(<16 x float> [[X0]], <16 x i32> [[X1]])
-+; CHECK-NEXT:    [[RES:%.*]] = call <16 x float> @llvm.x86.avx512.vpermilvar.ps.512(<16 x float> [[X0]], <16 x i32> [[X2:%.*]])
- ; CHECK-NEXT:    [[TMP5:%.*]] = bitcast <16 x float> [[RES]] to <16 x i32>
- ; CHECK-NEXT:    [[TMP7:%.*]] = bitcast <16 x i4> [[TMP4]] to i64
- ; CHECK-NEXT:    [[_MSCMP:%.*]] = icmp ne i64 [[TMP7]], 0
- ; CHECK-NEXT:    br i1 [[_MSCMP]], label [[TMP14:%.*]], label [[TMP15:%.*]], !prof [[PROF1]]
--; CHECK:       8:
-+; CHECK:       9:
- ; CHECK-NEXT:    call void @__msan_warning_noreturn() #[[ATTR10]]
- ; CHECK-NEXT:    unreachable
--; CHECK:       9:
--; CHECK-NEXT:    [[RES1:%.*]] = call <16 x float> @llvm.x86.avx512.vpermilvar.ps.512(<16 x float> [[X2:%.*]], <16 x i32> [[X1]])
-+; CHECK:       10:
-+; CHECK-NEXT:    [[RES1:%.*]] = call <16 x float> @llvm.x86.avx512.vpermilvar.ps.512(<16 x float> [[X3:%.*]], <16 x i32> [[X2]])
- ; CHECK-NEXT:    [[TMP8:%.*]] = bitcast i16 [[TMP3]] to <16 x i1>
- ; CHECK-NEXT:    [[MASK_CAST:%.*]] = bitcast i16 [[MASK:%.*]] to <16 x i1>
- ; CHECK-NEXT:    [[TMP9:%.*]] = select <16 x i1> [[MASK_CAST]], <16 x i32> [[TMP5]], <16 x i32> zeroinitializer
-diff -ruN --strip-trailing-cr a/llvm/test/Instrumentation/MemorySanitizer/X86/avx512-intrinsics-upgrade.ll b/llvm/test/Instrumentation/MemorySanitizer/X86/avx512-intrinsics-upgrade.ll
---- a/llvm/test/Instrumentation/MemorySanitizer/X86/avx512-intrinsics-upgrade.ll
-+++ b/llvm/test/Instrumentation/MemorySanitizer/X86/avx512-intrinsics-upgrade.ll
-@@ -8141,19 +8141,20 @@
- define <8 x double>@test_int_x86_avx512_vpermilvar_pd_512(<8 x double> %x0, <8 x i64> %x1, <8 x double> %x2)  #0 {
- ; CHECK-LABEL: @test_int_x86_avx512_vpermilvar_pd_512(
- ; CHECK-NEXT:    [[TMP1:%.*]] = load <8 x i64>, ptr @__msan_param_tls, align 8
-+; CHECK-NEXT:    [[X1:%.*]] = load <8 x i64>, ptr inttoptr (i64 add (i64 ptrtoint (ptr @__msan_param_tls to i64), i64 64) to ptr), align 8
- ; CHECK-NEXT:    call void @llvm.donothing()
--; CHECK-NEXT:    [[TMP2:%.*]] = trunc <8 x i64> [[X1:%.*]] to <8 x i3>
-+; CHECK-NEXT:    [[TMP2:%.*]] = trunc <8 x i64> [[X1]] to <8 x i3>
- ; CHECK-NEXT:    [[X0:%.*]] = bitcast <8 x i64> [[TMP1]] to <8 x double>
--; CHECK-NEXT:    [[TMP7:%.*]] = call <8 x double> @llvm.x86.avx512.vpermilvar.pd.512(<8 x double> [[X0]], <8 x i64> [[X1]])
-+; CHECK-NEXT:    [[TMP7:%.*]] = call <8 x double> @llvm.x86.avx512.vpermilvar.pd.512(<8 x double> [[X0]], <8 x i64> [[X2:%.*]])
- ; CHECK-NEXT:    [[TMP4:%.*]] = bitcast <8 x double> [[TMP7]] to <8 x i64>
- ; CHECK-NEXT:    [[TMP6:%.*]] = bitcast <8 x i3> [[TMP2]] to i24
- ; CHECK-NEXT:    [[_MSCMP:%.*]] = icmp ne i24 [[TMP6]], 0
--; CHECK-NEXT:    br i1 [[_MSCMP]], label [[TMP9:%.*]], label [[TMP8:%.*]], !prof [[PROF1]]
--; CHECK:       7:
-+; CHECK-NEXT:    br i1 [[_MSCMP]], label [[TMP8:%.*]], label [[TMP9:%.*]], !prof [[PROF1]]
-+; CHECK:       8:
- ; CHECK-NEXT:    call void @__msan_warning_noreturn() #[[ATTR8]]
- ; CHECK-NEXT:    unreachable
--; CHECK:       8:
--; CHECK-NEXT:    [[TMP5:%.*]] = call <8 x double> @llvm.x86.avx512.vpermilvar.pd.512(<8 x double> [[X2:%.*]], <8 x i64> [[X1]])
-+; CHECK:       9:
-+; CHECK-NEXT:    [[TMP5:%.*]] = call <8 x double> @llvm.x86.avx512.vpermilvar.pd.512(<8 x double> [[X3:%.*]], <8 x i64> [[X2]])
- ; CHECK-NEXT:    store <8 x i64> [[TMP4]], ptr @__msan_retval_tls, align 8
- ; CHECK-NEXT:    ret <8 x double> [[TMP5]]
- ;
-@@ -8165,21 +8166,22 @@
- ;
- ; CHECK-LABEL: @test_int_x86_avx512_mask_vpermilvar_pd_512(
- ; CHECK-NEXT:    [[TMP1:%.*]] = load <8 x i64>, ptr @__msan_param_tls, align 8
-+; CHECK-NEXT:    [[X1:%.*]] = load <8 x i64>, ptr inttoptr (i64 add (i64 ptrtoint (ptr @__msan_param_tls to i64), i64 64) to ptr), align 8
- ; CHECK-NEXT:    [[TMP3:%.*]] = load i8, ptr inttoptr (i64 add (i64 ptrtoint (ptr @__msan_param_tls to i64), i64 192) to ptr), align 8
- ; CHECK-NEXT:    [[TMP4:%.*]] = load <8 x i64>, ptr inttoptr (i64 add (i64 ptrtoint (ptr @__msan_param_tls to i64), i64 128) to ptr), align 8
- ; CHECK-NEXT:    call void @llvm.donothing()
--; CHECK-NEXT:    [[TMP5:%.*]] = trunc <8 x i64> [[X1:%.*]] to <8 x i3>
-+; CHECK-NEXT:    [[TMP5:%.*]] = trunc <8 x i64> [[X1]] to <8 x i3>
- ; CHECK-NEXT:    [[X0:%.*]] = bitcast <8 x i64> [[TMP1]] to <8 x double>
--; CHECK-NEXT:    [[TMP9:%.*]] = call <8 x double> @llvm.x86.avx512.vpermilvar.pd.512(<8 x double> [[X0]], <8 x i64> [[X1]])
-+; CHECK-NEXT:    [[TMP9:%.*]] = call <8 x double> @llvm.x86.avx512.vpermilvar.pd.512(<8 x double> [[X0]], <8 x i64> [[X4:%.*]])
- ; CHECK-NEXT:    [[TMP6:%.*]] = bitcast <8 x double> [[TMP9]] to <8 x i64>
- ; CHECK-NEXT:    [[TMP8:%.*]] = bitcast <8 x i3> [[TMP5]] to i24
- ; CHECK-NEXT:    [[_MSCMP:%.*]] = icmp ne i24 [[TMP8]], 0
- ; CHECK-NEXT:    br i1 [[_MSCMP]], label [[TMP19:%.*]], label [[TMP20:%.*]], !prof [[PROF1]]
--; CHECK:       9:
-+; CHECK:       10:
- ; CHECK-NEXT:    call void @__msan_warning_noreturn() #[[ATTR8]]
- ; CHECK-NEXT:    unreachable
--; CHECK:       10:
--; CHECK-NEXT:    [[TMP7:%.*]] = call <8 x double> @llvm.x86.avx512.vpermilvar.pd.512(<8 x double> [[X4:%.*]], <8 x i64> [[X1]])
-+; CHECK:       11:
-+; CHECK-NEXT:    [[TMP7:%.*]] = call <8 x double> @llvm.x86.avx512.vpermilvar.pd.512(<8 x double> [[X5:%.*]], <8 x i64> [[X4]])
- ; CHECK-NEXT:    [[TMP10:%.*]] = bitcast i8 [[TMP3]] to <8 x i1>
- ; CHECK-NEXT:    [[TMP11:%.*]] = bitcast i8 [[X3:%.*]] to <8 x i1>
- ; CHECK-NEXT:    [[TMP12:%.*]] = select <8 x i1> [[TMP11]], <8 x i64> [[TMP6]], <8 x i64> [[TMP4]]
-@@ -8201,20 +8203,21 @@
- ;
- ; CHECK-LABEL: @test_int_x86_avx512_maskz_vpermilvar_pd_512(
- ; CHECK-NEXT:    [[TMP1:%.*]] = load <8 x i64>, ptr @__msan_param_tls, align 8
-+; CHECK-NEXT:    [[X1:%.*]] = load <8 x i64>, ptr inttoptr (i64 add (i64 ptrtoint (ptr @__msan_param_tls to i64), i64 64) to ptr), align 8
- ; CHECK-NEXT:    [[TMP3:%.*]] = load i8, ptr inttoptr (i64 add (i64 ptrtoint (ptr @__msan_param_tls to i64), i64 192) to ptr), align 8
- ; CHECK-NEXT:    call void @llvm.donothing()
--; CHECK-NEXT:    [[TMP4:%.*]] = trunc <8 x i64> [[X1:%.*]] to <8 x i3>
-+; CHECK-NEXT:    [[TMP4:%.*]] = trunc <8 x i64> [[X1]] to <8 x i3>
- ; CHECK-NEXT:    [[X0:%.*]] = bitcast <8 x i64> [[TMP1]] to <8 x double>
--; CHECK-NEXT:    [[TMP8:%.*]] = call <8 x double> @llvm.x86.avx512.vpermilvar.pd.512(<8 x double> [[X0]], <8 x i64> [[X1]])
-+; CHECK-NEXT:    [[TMP8:%.*]] = call <8 x double> @llvm.x86.avx512.vpermilvar.pd.512(<8 x double> [[X0]], <8 x i64> [[X2:%.*]])
- ; CHECK-NEXT:    [[TMP5:%.*]] = bitcast <8 x double> [[TMP8]] to <8 x i64>
- ; CHECK-NEXT:    [[TMP7:%.*]] = bitcast <8 x i3> [[TMP4]] to i24
- ; CHECK-NEXT:    [[_MSCMP:%.*]] = icmp ne i24 [[TMP7]], 0
- ; CHECK-NEXT:    br i1 [[_MSCMP]], label [[TMP17:%.*]], label [[TMP18:%.*]], !prof [[PROF1]]
--; CHECK:       8:
-+; CHECK:       9:
- ; CHECK-NEXT:    call void @__msan_warning_noreturn() #[[ATTR8]]
- ; CHECK-NEXT:    unreachable
--; CHECK:       9:
--; CHECK-NEXT:    [[TMP6:%.*]] = call <8 x double> @llvm.x86.avx512.vpermilvar.pd.512(<8 x double> [[X2:%.*]], <8 x i64> [[X1]])
-+; CHECK:       10:
-+; CHECK-NEXT:    [[TMP6:%.*]] = call <8 x double> @llvm.x86.avx512.vpermilvar.pd.512(<8 x double> [[X4:%.*]], <8 x i64> [[X2]])
- ; CHECK-NEXT:    [[TMP9:%.*]] = bitcast i8 [[TMP3]] to <8 x i1>
- ; CHECK-NEXT:    [[TMP10:%.*]] = bitcast i8 [[X3:%.*]] to <8 x i1>
- ; CHECK-NEXT:    [[TMP11:%.*]] = select <8 x i1> [[TMP10]], <8 x i64> [[TMP5]], <8 x i64> zeroinitializer
-@@ -8236,19 +8239,20 @@
- define <16 x float>@test_int_x86_avx512_vpermilvar_ps_512(<16 x float> %x0, <16 x i32> %x1, <16 x float> %x2)  #0 {
- ; CHECK-LABEL: @test_int_x86_avx512_vpermilvar_ps_512(
- ; CHECK-NEXT:    [[TMP1:%.*]] = load <16 x i32>, ptr @__msan_param_tls, align 8
-+; CHECK-NEXT:    [[X1:%.*]] = load <16 x i32>, ptr inttoptr (i64 add (i64 ptrtoint (ptr @__msan_param_tls to i64), i64 64) to ptr), align 8
- ; CHECK-NEXT:    call void @llvm.donothing()
--; CHECK-NEXT:    [[TMP2:%.*]] = trunc <16 x i32> [[X1:%.*]] to <16 x i4>
-+; CHECK-NEXT:    [[TMP2:%.*]] = trunc <16 x i32> [[X1]] to <16 x i4>
- ; CHECK-NEXT:    [[X0:%.*]] = bitcast <16 x i32> [[TMP1]] to <16 x float>
--; CHECK-NEXT:    [[TMP7:%.*]] = call <16 x float> @llvm.x86.avx512.vpermilvar.ps.512(<16 x float> [[X0]], <16 x i32> [[X1]])
-+; CHECK-NEXT:    [[TMP7:%.*]] = call <16 x float> @llvm.x86.avx512.vpermilvar.ps.512(<16 x float> [[X0]], <16 x i32> [[X2:%.*]])
- ; CHECK-NEXT:    [[TMP4:%.*]] = bitcast <16 x float> [[TMP7]] to <16 x i32>
- ; CHECK-NEXT:    [[TMP6:%.*]] = bitcast <16 x i4> [[TMP2]] to i64
- ; CHECK-NEXT:    [[_MSCMP:%.*]] = icmp ne i64 [[TMP6]], 0
--; CHECK-NEXT:    br i1 [[_MSCMP]], label [[TMP9:%.*]], label [[TMP8:%.*]], !prof [[PROF1]]
--; CHECK:       7:
-+; CHECK-NEXT:    br i1 [[_MSCMP]], label [[TMP8:%.*]], label [[TMP9:%.*]], !prof [[PROF1]]
-+; CHECK:       8:
- ; CHECK-NEXT:    call void @__msan_warning_noreturn() #[[ATTR8]]
- ; CHECK-NEXT:    unreachable
--; CHECK:       8:
--; CHECK-NEXT:    [[TMP5:%.*]] = call <16 x float> @llvm.x86.avx512.vpermilvar.ps.512(<16 x float> [[X2:%.*]], <16 x i32> [[X1]])
-+; CHECK:       9:
-+; CHECK-NEXT:    [[TMP5:%.*]] = call <16 x float> @llvm.x86.avx512.vpermilvar.ps.512(<16 x float> [[X3:%.*]], <16 x i32> [[X2]])
- ; CHECK-NEXT:    store <16 x i32> [[TMP4]], ptr @__msan_retval_tls, align 8
- ; CHECK-NEXT:    ret <16 x float> [[TMP5]]
- ;
-@@ -8260,21 +8264,22 @@
- ;
- ; CHECK-LABEL: @test_int_x86_avx512_mask_vpermilvar_ps_512(
- ; CHECK-NEXT:    [[TMP1:%.*]] = load <16 x i32>, ptr @__msan_param_tls, align 8
-+; CHECK-NEXT:    [[X1:%.*]] = load <16 x i32>, ptr inttoptr (i64 add (i64 ptrtoint (ptr @__msan_param_tls to i64), i64 64) to ptr), align 8
- ; CHECK-NEXT:    [[TMP3:%.*]] = load i16, ptr inttoptr (i64 add (i64 ptrtoint (ptr @__msan_param_tls to i64), i64 192) to ptr), align 8
- ; CHECK-NEXT:    [[TMP4:%.*]] = load <16 x i32>, ptr inttoptr (i64 add (i64 ptrtoint (ptr @__msan_param_tls to i64), i64 128) to ptr), align 8
- ; CHECK-NEXT:    call void @llvm.donothing()
--; CHECK-NEXT:    [[TMP5:%.*]] = trunc <16 x i32> [[X1:%.*]] to <16 x i4>
-+; CHECK-NEXT:    [[TMP5:%.*]] = trunc <16 x i32> [[X1]] to <16 x i4>
- ; CHECK-NEXT:    [[X0:%.*]] = bitcast <16 x i32> [[TMP1]] to <16 x float>
--; CHECK-NEXT:    [[TMP9:%.*]] = call <16 x float> @llvm.x86.avx512.vpermilvar.ps.512(<16 x float> [[X0]], <16 x i32> [[X1]])
-+; CHECK-NEXT:    [[TMP9:%.*]] = call <16 x float> @llvm.x86.avx512.vpermilvar.ps.512(<16 x float> [[X0]], <16 x i32> [[X4:%.*]])
- ; CHECK-NEXT:    [[TMP6:%.*]] = bitcast <16 x float> [[TMP9]] to <16 x i32>
- ; CHECK-NEXT:    [[TMP8:%.*]] = bitcast <16 x i4> [[TMP5]] to i64
- ; CHECK-NEXT:    [[_MSCMP:%.*]] = icmp ne i64 [[TMP8]], 0
- ; CHECK-NEXT:    br i1 [[_MSCMP]], label [[TMP19:%.*]], label [[TMP20:%.*]], !prof [[PROF1]]
--; CHECK:       9:
-+; CHECK:       10:
- ; CHECK-NEXT:    call void @__msan_warning_noreturn() #[[ATTR8]]
- ; CHECK-NEXT:    unreachable
--; CHECK:       10:
--; CHECK-NEXT:    [[TMP7:%.*]] = call <16 x float> @llvm.x86.avx512.vpermilvar.ps.512(<16 x float> [[X4:%.*]], <16 x i32> [[X1]])
-+; CHECK:       11:
-+; CHECK-NEXT:    [[TMP7:%.*]] = call <16 x float> @llvm.x86.avx512.vpermilvar.ps.512(<16 x float> [[X5:%.*]], <16 x i32> [[X4]])
- ; CHECK-NEXT:    [[TMP10:%.*]] = bitcast i16 [[TMP3]] to <16 x i1>
- ; CHECK-NEXT:    [[TMP11:%.*]] = bitcast i16 [[X3:%.*]] to <16 x i1>
- ; CHECK-NEXT:    [[TMP12:%.*]] = select <16 x i1> [[TMP11]], <16 x i32> [[TMP6]], <16 x i32> [[TMP4]]
-@@ -8297,20 +8302,21 @@
- ;
- ; CHECK-LABEL: @test_int_x86_avx512_maskz_vpermilvar_ps_512(
- ; CHECK-NEXT:    [[TMP1:%.*]] = load <16 x i32>, ptr @__msan_param_tls, align 8
-+; CHECK-NEXT:    [[X1:%.*]] = load <16 x i32>, ptr inttoptr (i64 add (i64 ptrtoint (ptr @__msan_param_tls to i64), i64 64) to ptr), align 8
- ; CHECK-NEXT:    [[TMP3:%.*]] = load i16, ptr inttoptr (i64 add (i64 ptrtoint (ptr @__msan_param_tls to i64), i64 128) to ptr), align 8
- ; CHECK-NEXT:    call void @llvm.donothing()
--; CHECK-NEXT:    [[TMP4:%.*]] = trunc <16 x i32> [[X1:%.*]] to <16 x i4>
-+; CHECK-NEXT:    [[TMP4:%.*]] = trunc <16 x i32> [[X1]] to <16 x i4>
- ; CHECK-NEXT:    [[X0:%.*]] = bitcast <16 x i32> [[TMP1]] to <16 x float>
--; CHECK-NEXT:    [[TMP8:%.*]] = call <16 x float> @llvm.x86.avx512.vpermilvar.ps.512(<16 x float> [[X0]], <16 x i32> [[X1]])
-+; CHECK-NEXT:    [[TMP8:%.*]] = call <16 x float> @llvm.x86.avx512.vpermilvar.ps.512(<16 x float> [[X0]], <16 x i32> [[X2:%.*]])
- ; CHECK-NEXT:    [[TMP5:%.*]] = bitcast <16 x float> [[TMP8]] to <16 x i32>
- ; CHECK-NEXT:    [[TMP7:%.*]] = bitcast <16 x i4> [[TMP4]] to i64
- ; CHECK-NEXT:    [[_MSCMP:%.*]] = icmp ne i64 [[TMP7]], 0
- ; CHECK-NEXT:    br i1 [[_MSCMP]], label [[TMP17:%.*]], label [[TMP18:%.*]], !prof [[PROF1]]
--; CHECK:       8:
-+; CHECK:       9:
- ; CHECK-NEXT:    call void @__msan_warning_noreturn() #[[ATTR8]]
- ; CHECK-NEXT:    unreachable
--; CHECK:       9:
--; CHECK-NEXT:    [[TMP6:%.*]] = call <16 x float> @llvm.x86.avx512.vpermilvar.ps.512(<16 x float> [[X2:%.*]], <16 x i32> [[X1]])
-+; CHECK:       10:
-+; CHECK-NEXT:    [[TMP6:%.*]] = call <16 x float> @llvm.x86.avx512.vpermilvar.ps.512(<16 x float> [[X4:%.*]], <16 x i32> [[X2]])
- ; CHECK-NEXT:    [[TMP9:%.*]] = bitcast i16 [[TMP3]] to <16 x i1>
- ; CHECK-NEXT:    [[TMP10:%.*]] = bitcast i16 [[X3:%.*]] to <16 x i1>
- ; CHECK-NEXT:    [[TMP11:%.*]] = select <16 x i1> [[TMP10]], <16 x i32> [[TMP5]], <16 x i32> zeroinitializer
-@@ -13713,28 +13719,29 @@
- ; CHECK-NEXT:    [[TMP1:%.*]] = load i64, ptr inttoptr (i64 add (i64 ptrtoint (ptr @__msan_param_tls to i64), i64 128) to ptr), align 8
- ; CHECK-NEXT:    [[TMP2:%.*]] = load <16 x i32>, ptr @__msan_param_tls, align 8
- ; CHECK-NEXT:    [[TMP4:%.*]] = load <16 x i32>, ptr inttoptr (i64 add (i64 ptrtoint (ptr @__msan_param_tls to i64), i64 136) to ptr), align 8
-+; CHECK-NEXT:    [[X1:%.*]] = load <16 x i32>, ptr inttoptr (i64 add (i64 ptrtoint (ptr @__msan_param_tls to i64), i64 64) to ptr), align 8
- ; CHECK-NEXT:    call void @llvm.donothing()
- ; CHECK-NEXT:    [[_MSCMP:%.*]] = icmp ne i64 [[TMP1]], 0
--; CHECK-NEXT:    br i1 [[_MSCMP]], label [[TMP6:%.*]], label [[TMP5:%.*]], !prof [[PROF1]]
--; CHECK:       4:
-+; CHECK-NEXT:    br i1 [[_MSCMP]], label [[TMP5:%.*]], label [[TMP6:%.*]], !prof [[PROF1]]
-+; CHECK:       5:
- ; CHECK-NEXT:    call void @__msan_warning_noreturn() #[[ATTR8]]
- ; CHECK-NEXT:    unreachable
--; CHECK:       5:
-+; CHECK:       6:
- ; CHECK-NEXT:    [[X2:%.*]] = load <16 x i32>, ptr [[X2P:%.*]], align 64
- ; CHECK-NEXT:    [[TMP7:%.*]] = ptrtoint ptr [[X2P]] to i64
- ; CHECK-NEXT:    [[TMP8:%.*]] = xor i64 [[TMP7]], 87960930222080
- ; CHECK-NEXT:    [[TMP9:%.*]] = inttoptr i64 [[TMP8]] to ptr
- ; CHECK-NEXT:    [[_MSLD:%.*]] = load <16 x i32>, ptr [[TMP9]], align 64
--; CHECK-NEXT:    [[TMP14:%.*]] = trunc <16 x i32> [[X1:%.*]] to <16 x i4>
--; CHECK-NEXT:    [[_MSPROP1:%.*]] = call <16 x i32> @llvm.x86.avx512.vpermi2var.d.512(<16 x i32> [[TMP2]], <16 x i32> [[X1]], <16 x i32> [[TMP4]])
-+; CHECK-NEXT:    [[TMP14:%.*]] = trunc <16 x i32> [[X1]] to <16 x i4>
-+; CHECK-NEXT:    [[_MSPROP1:%.*]] = call <16 x i32> @llvm.x86.avx512.vpermi2var.d.512(<16 x i32> [[TMP2]], <16 x i32> [[X3:%.*]], <16 x i32> [[TMP4]])
- ; CHECK-NEXT:    [[TMP11:%.*]] = bitcast <16 x i4> [[TMP14]] to i64
- ; CHECK-NEXT:    [[_MSCMP1:%.*]] = icmp ne i64 [[TMP11]], 0
--; CHECK-NEXT:    br i1 [[_MSCMP1]], label [[TMP12:%.*]], label [[TMP13:%.*]], !prof [[PROF1]]
--; CHECK:       12:
-+; CHECK-NEXT:    br i1 [[_MSCMP1]], label [[TMP13:%.*]], label [[TMP15:%.*]], !prof [[PROF1]]
-+; CHECK:       13:
- ; CHECK-NEXT:    call void @__msan_warning_noreturn() #[[ATTR8]]
- ; CHECK-NEXT:    unreachable
--; CHECK:       13:
--; CHECK-NEXT:    [[TMP10:%.*]] = call <16 x i32> @llvm.x86.avx512.vpermi2var.d.512(<16 x i32> [[X0:%.*]], <16 x i32> [[X1]], <16 x i32> [[X4:%.*]])
-+; CHECK:       14:
-+; CHECK-NEXT:    [[TMP10:%.*]] = call <16 x i32> @llvm.x86.avx512.vpermi2var.d.512(<16 x i32> [[X0:%.*]], <16 x i32> [[X3]], <16 x i32> [[X4:%.*]])
- ; CHECK-NEXT:    store <16 x i32> [[_MSPROP1]], ptr @__msan_retval_tls, align 8
- ; CHECK-NEXT:    ret <16 x i32> [[TMP10]]
- ;
-@@ -13748,8 +13755,8 @@
- ; CHECK-LABEL: @test_int_x86_avx512_mask_vpermi2var_d_512(
- ; CHECK-NEXT:    [[TMP1:%.*]] = load i64, ptr inttoptr (i64 add (i64 ptrtoint (ptr @__msan_param_tls to i64), i64 128) to ptr), align 8
- ; CHECK-NEXT:    [[TMP2:%.*]] = load <16 x i32>, ptr @__msan_param_tls, align 8
--; CHECK-NEXT:    [[TMP4:%.*]] = load i16, ptr inttoptr (i64 add (i64 ptrtoint (ptr @__msan_param_tls to i64), i64 200) to ptr), align 8
- ; CHECK-NEXT:    [[TMP3:%.*]] = load <16 x i32>, ptr inttoptr (i64 add (i64 ptrtoint (ptr @__msan_param_tls to i64), i64 64) to ptr), align 8
-+; CHECK-NEXT:    [[TMP4:%.*]] = load i16, ptr inttoptr (i64 add (i64 ptrtoint (ptr @__msan_param_tls to i64), i64 200) to ptr), align 8
- ; CHECK-NEXT:    call void @llvm.donothing()
- ; CHECK-NEXT:    [[_MSCMP:%.*]] = icmp ne i64 [[TMP1]], 0
- ; CHECK-NEXT:    br i1 [[_MSCMP]], label [[TMP5:%.*]], label [[TMP6:%.*]], !prof [[PROF1]]
-@@ -13762,8 +13769,8 @@
- ; CHECK-NEXT:    [[TMP8:%.*]] = xor i64 [[TMP7]], 87960930222080
- ; CHECK-NEXT:    [[TMP9:%.*]] = inttoptr i64 [[TMP8]] to ptr
- ; CHECK-NEXT:    [[_MSLD:%.*]] = load <16 x i32>, ptr [[TMP9]], align 64
--; CHECK-NEXT:    [[TMP18:%.*]] = trunc <16 x i32> [[X1:%.*]] to <16 x i4>
--; CHECK-NEXT:    [[_MSPROP1:%.*]] = call <16 x i32> @llvm.x86.avx512.vpermi2var.d.512(<16 x i32> [[TMP2]], <16 x i32> [[X1]], <16 x i32> [[_MSLD]])
-+; CHECK-NEXT:    [[TMP18:%.*]] = trunc <16 x i32> [[TMP3]] to <16 x i4>
-+; CHECK-NEXT:    [[_MSPROP1:%.*]] = call <16 x i32> @llvm.x86.avx512.vpermi2var.d.512(<16 x i32> [[TMP2]], <16 x i32> [[X1:%.*]], <16 x i32> [[_MSLD]])
- ; CHECK-NEXT:    [[TMP19:%.*]] = bitcast <16 x i4> [[TMP18]] to i64
- ; CHECK-NEXT:    [[_MSCMP1:%.*]] = icmp ne i64 [[TMP19]], 0
- ; CHECK-NEXT:    br i1 [[_MSCMP1]], label [[TMP20:%.*]], label [[TMP21:%.*]], !prof [[PROF1]]
-@@ -13796,10 +13803,10 @@
- ; CHECK-NEXT:    [[TMP3:%.*]] = load <8 x i64>, ptr inttoptr (i64 add (i64 ptrtoint (ptr @__msan_param_tls to i64), i64 128) to ptr), align 8
- ; CHECK-NEXT:    [[TMP8:%.*]] = load <8 x i64>, ptr inttoptr (i64 add (i64 ptrtoint (ptr @__msan_param_tls to i64), i64 64) to ptr), align 8
- ; CHECK-NEXT:    call void @llvm.donothing()
--; CHECK-NEXT:    [[TMP6:%.*]] = trunc <8 x i64> [[X1:%.*]] to <8 x i3>
-+; CHECK-NEXT:    [[TMP6:%.*]] = trunc <8 x i64> [[TMP8]] to <8 x i3>
- ; CHECK-NEXT:    [[TMP4:%.*]] = bitcast <8 x i64> [[TMP1]] to <8 x double>
- ; CHECK-NEXT:    [[TMP5:%.*]] = bitcast <8 x i64> [[TMP3]] to <8 x double>
--; CHECK-NEXT:    [[TMP11:%.*]] = call <8 x double> @llvm.x86.avx512.vpermi2var.pd.512(<8 x double> [[TMP4]], <8 x i64> [[X1]], <8 x double> [[TMP5]])
-+; CHECK-NEXT:    [[TMP11:%.*]] = call <8 x double> @llvm.x86.avx512.vpermi2var.pd.512(<8 x double> [[TMP4]], <8 x i64> [[X1:%.*]], <8 x double> [[TMP5]])
- ; CHECK-NEXT:    [[TMP7:%.*]] = bitcast <8 x double> [[TMP11]] to <8 x i64>
- ; CHECK-NEXT:    [[TMP12:%.*]] = bitcast <8 x i3> [[TMP6]] to i24
- ; CHECK-NEXT:    [[_MSCMP:%.*]] = icmp ne i24 [[TMP12]], 0
-@@ -13825,10 +13832,10 @@
- ; CHECK-NEXT:    [[TMP2:%.*]] = load <8 x i64>, ptr inttoptr (i64 add (i64 ptrtoint (ptr @__msan_param_tls to i64), i64 64) to ptr), align 8
- ; CHECK-NEXT:    [[TMP4:%.*]] = load i8, ptr inttoptr (i64 add (i64 ptrtoint (ptr @__msan_param_tls to i64), i64 192) to ptr), align 8
- ; CHECK-NEXT:    call void @llvm.donothing()
--; CHECK-NEXT:    [[TMP7:%.*]] = trunc <8 x i64> [[X1:%.*]] to <8 x i3>
-+; CHECK-NEXT:    [[TMP7:%.*]] = trunc <8 x i64> [[TMP2]] to <8 x i3>
- ; CHECK-NEXT:    [[TMP5:%.*]] = bitcast <8 x i64> [[TMP1]] to <8 x double>
- ; CHECK-NEXT:    [[TMP6:%.*]] = bitcast <8 x i64> [[TMP3]] to <8 x double>
--; CHECK-NEXT:    [[TMP9:%.*]] = call <8 x double> @llvm.x86.avx512.vpermi2var.pd.512(<8 x double> [[TMP5]], <8 x i64> [[X1]], <8 x double> [[TMP6]])
-+; CHECK-NEXT:    [[TMP9:%.*]] = call <8 x double> @llvm.x86.avx512.vpermi2var.pd.512(<8 x double> [[TMP5]], <8 x i64> [[X1:%.*]], <8 x double> [[TMP6]])
- ; CHECK-NEXT:    [[TMP8:%.*]] = bitcast <8 x double> [[TMP9]] to <8 x i64>
- ; CHECK-NEXT:    [[TMP21:%.*]] = bitcast <8 x i3> [[TMP7]] to i24
- ; CHECK-NEXT:    [[_MSCMP:%.*]] = icmp ne i24 [[TMP21]], 0
-@@ -13864,10 +13871,10 @@
- ; CHECK-NEXT:    [[TMP3:%.*]] = load <16 x i32>, ptr inttoptr (i64 add (i64 ptrtoint (ptr @__msan_param_tls to i64), i64 128) to ptr), align 8
- ; CHECK-NEXT:    [[TMP8:%.*]] = load <16 x i32>, ptr inttoptr (i64 add (i64 ptrtoint (ptr @__msan_param_tls to i64), i64 64) to ptr), align 8
- ; CHECK-NEXT:    call void @llvm.donothing()
--; CHECK-NEXT:    [[TMP6:%.*]] = trunc <16 x i32> [[X1:%.*]] to <16 x i4>
-+; CHECK-NEXT:    [[TMP6:%.*]] = trunc <16 x i32> [[TMP8]] to <16 x i4>
- ; CHECK-NEXT:    [[TMP4:%.*]] = bitcast <16 x i32> [[TMP1]] to <16 x float>
- ; CHECK-NEXT:    [[TMP5:%.*]] = bitcast <16 x i32> [[TMP3]] to <16 x float>
--; CHECK-NEXT:    [[TMP11:%.*]] = call <16 x float> @llvm.x86.avx512.vpermi2var.ps.512(<16 x float> [[TMP4]], <16 x i32> [[X1]], <16 x float> [[TMP5]])
-+; CHECK-NEXT:    [[TMP11:%.*]] = call <16 x float> @llvm.x86.avx512.vpermi2var.ps.512(<16 x float> [[TMP4]], <16 x i32> [[X1:%.*]], <16 x float> [[TMP5]])
- ; CHECK-NEXT:    [[TMP7:%.*]] = bitcast <16 x float> [[TMP11]] to <16 x i32>
- ; CHECK-NEXT:    [[TMP12:%.*]] = bitcast <16 x i4> [[TMP6]] to i64
- ; CHECK-NEXT:    [[_MSCMP:%.*]] = icmp ne i64 [[TMP12]], 0
-@@ -13893,10 +13900,10 @@
- ; CHECK-NEXT:    [[TMP2:%.*]] = load <16 x i32>, ptr inttoptr (i64 add (i64 ptrtoint (ptr @__msan_param_tls to i64), i64 64) to ptr), align 8
- ; CHECK-NEXT:    [[TMP4:%.*]] = load i16, ptr inttoptr (i64 add (i64 ptrtoint (ptr @__msan_param_tls to i64), i64 192) to ptr), align 8
- ; CHECK-NEXT:    call void @llvm.donothing()
--; CHECK-NEXT:    [[TMP7:%.*]] = trunc <16 x i32> [[X1:%.*]] to <16 x i4>
-+; CHECK-NEXT:    [[TMP7:%.*]] = trunc <16 x i32> [[TMP2]] to <16 x i4>
- ; CHECK-NEXT:    [[TMP5:%.*]] = bitcast <16 x i32> [[TMP1]] to <16 x float>
- ; CHECK-NEXT:    [[TMP6:%.*]] = bitcast <16 x i32> [[TMP3]] to <16 x float>
--; CHECK-NEXT:    [[TMP9:%.*]] = call <16 x float> @llvm.x86.avx512.vpermi2var.ps.512(<16 x float> [[TMP5]], <16 x i32> [[X1]], <16 x float> [[TMP6]])
-+; CHECK-NEXT:    [[TMP9:%.*]] = call <16 x float> @llvm.x86.avx512.vpermi2var.ps.512(<16 x float> [[TMP5]], <16 x i32> [[X1:%.*]], <16 x float> [[TMP6]])
- ; CHECK-NEXT:    [[TMP8:%.*]] = bitcast <16 x float> [[TMP9]] to <16 x i32>
- ; CHECK-NEXT:    [[TMP21:%.*]] = bitcast <16 x i4> [[TMP7]] to i64
- ; CHECK-NEXT:    [[_MSCMP:%.*]] = icmp ne i64 [[TMP21]], 0
-@@ -13930,17 +13937,18 @@
- ; CHECK-LABEL: @test_int_x86_avx512_vpermi2var_q_512(
- ; CHECK-NEXT:    [[TMP1:%.*]] = load <8 x i64>, ptr @__msan_param_tls, align 8
- ; CHECK-NEXT:    [[TMP3:%.*]] = load <8 x i64>, ptr inttoptr (i64 add (i64 ptrtoint (ptr @__msan_param_tls to i64), i64 128) to ptr), align 8
-+; CHECK-NEXT:    [[X1:%.*]] = load <8 x i64>, ptr inttoptr (i64 add (i64 ptrtoint (ptr @__msan_param_tls to i64), i64 64) to ptr), align 8
- ; CHECK-NEXT:    call void @llvm.donothing()
--; CHECK-NEXT:    [[TMP8:%.*]] = trunc <8 x i64> [[X1:%.*]] to <8 x i3>
--; CHECK-NEXT:    [[_MSPROP1:%.*]] = call <8 x i64> @llvm.x86.avx512.vpermi2var.q.512(<8 x i64> [[TMP1]], <8 x i64> [[X1]], <8 x i64> [[TMP3]])
-+; CHECK-NEXT:    [[TMP8:%.*]] = trunc <8 x i64> [[X1]] to <8 x i3>
-+; CHECK-NEXT:    [[_MSPROP1:%.*]] = call <8 x i64> @llvm.x86.avx512.vpermi2var.q.512(<8 x i64> [[TMP1]], <8 x i64> [[X3:%.*]], <8 x i64> [[TMP3]])
- ; CHECK-NEXT:    [[TMP5:%.*]] = bitcast <8 x i3> [[TMP8]] to i24
- ; CHECK-NEXT:    [[_MSCMP:%.*]] = icmp ne i24 [[TMP5]], 0
--; CHECK-NEXT:    br i1 [[_MSCMP]], label [[TMP6:%.*]], label [[TMP7:%.*]], !prof [[PROF1]]
--; CHECK:       6:
-+; CHECK-NEXT:    br i1 [[_MSCMP]], label [[TMP7:%.*]], label [[TMP9:%.*]], !prof [[PROF1]]
-+; CHECK:       7:
- ; CHECK-NEXT:    call void @__msan_warning_noreturn() #[[ATTR8]]
- ; CHECK-NEXT:    unreachable
--; CHECK:       7:
--; CHECK-NEXT:    [[TMP4:%.*]] = call <8 x i64> @llvm.x86.avx512.vpermi2var.q.512(<8 x i64> [[X0:%.*]], <8 x i64> [[X1]], <8 x i64> [[X2:%.*]])
-+; CHECK:       8:
-+; CHECK-NEXT:    [[TMP4:%.*]] = call <8 x i64> @llvm.x86.avx512.vpermi2var.q.512(<8 x i64> [[X0:%.*]], <8 x i64> [[X3]], <8 x i64> [[X2:%.*]])
- ; CHECK-NEXT:    store <8 x i64> [[_MSPROP1]], ptr @__msan_retval_tls, align 8
- ; CHECK-NEXT:    ret <8 x i64> [[TMP4]]
- ;
-@@ -13953,11 +13961,11 @@
- ; CHECK-LABEL: @test_int_x86_avx512_mask_vpermi2var_q_512(
- ; CHECK-NEXT:    [[TMP1:%.*]] = load <8 x i64>, ptr @__msan_param_tls, align 8
- ; CHECK-NEXT:    [[TMP3:%.*]] = load <8 x i64>, ptr inttoptr (i64 add (i64 ptrtoint (ptr @__msan_param_tls to i64), i64 128) to ptr), align 8
--; CHECK-NEXT:    [[TMP4:%.*]] = load i8, ptr inttoptr (i64 add (i64 ptrtoint (ptr @__msan_param_tls to i64), i64 192) to ptr), align 8
- ; CHECK-NEXT:    [[TMP2:%.*]] = load <8 x i64>, ptr inttoptr (i64 add (i64 ptrtoint (ptr @__msan_param_tls to i64), i64 64) to ptr), align 8
-+; CHECK-NEXT:    [[TMP4:%.*]] = load i8, ptr inttoptr (i64 add (i64 ptrtoint (ptr @__msan_param_tls to i64), i64 192) to ptr), align 8
- ; CHECK-NEXT:    call void @llvm.donothing()
--; CHECK-NEXT:    [[TMP13:%.*]] = trunc <8 x i64> [[X1:%.*]] to <8 x i3>
--; CHECK-NEXT:    [[_MSPROP1:%.*]] = call <8 x i64> @llvm.x86.avx512.vpermi2var.q.512(<8 x i64> [[TMP1]], <8 x i64> [[X1]], <8 x i64> [[TMP3]])
-+; CHECK-NEXT:    [[TMP13:%.*]] = trunc <8 x i64> [[TMP2]] to <8 x i3>
-+; CHECK-NEXT:    [[_MSPROP1:%.*]] = call <8 x i64> @llvm.x86.avx512.vpermi2var.q.512(<8 x i64> [[TMP1]], <8 x i64> [[X1:%.*]], <8 x i64> [[TMP3]])
- ; CHECK-NEXT:    [[TMP14:%.*]] = bitcast <8 x i3> [[TMP13]] to i24
- ; CHECK-NEXT:    [[_MSCMP:%.*]] = icmp ne i24 [[TMP14]], 0
- ; CHECK-NEXT:    br i1 [[_MSCMP]], label [[TMP15:%.*]], label [[TMP16:%.*]], !prof [[PROF1]]
-@@ -13988,29 +13996,30 @@
- ; CHECK-LABEL: @test_int_x86_avx512_maskz_vpermt2var_d_512(
- ; CHECK-NEXT:    [[TMP1:%.*]] = load i64, ptr inttoptr (i64 add (i64 ptrtoint (ptr @__msan_param_tls to i64), i64 128) to ptr), align 8
- ; CHECK-NEXT:    [[TMP2:%.*]] = load <16 x i32>, ptr inttoptr (i64 add (i64 ptrtoint (ptr @__msan_param_tls to i64), i64 64) to ptr), align 8
-+; CHECK-NEXT:    [[X0:%.*]] = load <16 x i32>, ptr @__msan_param_tls, align 8
- ; CHECK-NEXT:    [[TMP4:%.*]] = load i16, ptr inttoptr (i64 add (i64 ptrtoint (ptr @__msan_param_tls to i64), i64 136) to ptr), align 8
- ; CHECK-NEXT:    call void @llvm.donothing()
- ; CHECK-NEXT:    [[_MSCMP:%.*]] = icmp ne i64 [[TMP1]], 0
--; CHECK-NEXT:    br i1 [[_MSCMP]], label [[TMP6:%.*]], label [[TMP5:%.*]], !prof [[PROF1]]
--; CHECK:       4:
-+; CHECK-NEXT:    br i1 [[_MSCMP]], label [[TMP5:%.*]], label [[TMP6:%.*]], !prof [[PROF1]]
-+; CHECK:       5:
- ; CHECK-NEXT:    call void @__msan_warning_noreturn() #[[ATTR8]]
- ; CHECK-NEXT:    unreachable
--; CHECK:       5:
-+; CHECK:       6:
- ; CHECK-NEXT:    [[X2:%.*]] = load <16 x i32>, ptr [[X2P:%.*]], align 64
- ; CHECK-NEXT:    [[TMP7:%.*]] = ptrtoint ptr [[X2P]] to i64
- ; CHECK-NEXT:    [[TMP8:%.*]] = xor i64 [[TMP7]], 87960930222080
- ; CHECK-NEXT:    [[TMP9:%.*]] = inttoptr i64 [[TMP8]] to ptr
- ; CHECK-NEXT:    [[_MSLD:%.*]] = load <16 x i32>, ptr [[TMP9]], align 64
--; CHECK-NEXT:    [[TMP18:%.*]] = trunc <16 x i32> [[X0:%.*]] to <16 x i4>
--; CHECK-NEXT:    [[_MSPROP1:%.*]] = call <16 x i32> @llvm.x86.avx512.vpermi2var.d.512(<16 x i32> [[TMP2]], <16 x i32> [[X0]], <16 x i32> [[_MSLD]])
-+; CHECK-NEXT:    [[TMP18:%.*]] = trunc <16 x i32> [[X0]] to <16 x i4>
-+; CHECK-NEXT:    [[_MSPROP1:%.*]] = call <16 x i32> @llvm.x86.avx512.vpermi2var.d.512(<16 x i32> [[TMP2]], <16 x i32> [[X4:%.*]], <16 x i32> [[_MSLD]])
- ; CHECK-NEXT:    [[TMP19:%.*]] = bitcast <16 x i4> [[TMP18]] to i64
- ; CHECK-NEXT:    [[_MSCMP1:%.*]] = icmp ne i64 [[TMP19]], 0
- ; CHECK-NEXT:    br i1 [[_MSCMP1]], label [[TMP20:%.*]], label [[TMP21:%.*]], !prof [[PROF1]]
--; CHECK:       12:
-+; CHECK:       13:
- ; CHECK-NEXT:    call void @__msan_warning_noreturn() #[[ATTR8]]
- ; CHECK-NEXT:    unreachable
--; CHECK:       13:
--; CHECK-NEXT:    [[TMP10:%.*]] = call <16 x i32> @llvm.x86.avx512.vpermi2var.d.512(<16 x i32> [[X1:%.*]], <16 x i32> [[X0]], <16 x i32> [[X2]])
-+; CHECK:       14:
-+; CHECK-NEXT:    [[TMP10:%.*]] = call <16 x i32> @llvm.x86.avx512.vpermi2var.d.512(<16 x i32> [[X1:%.*]], <16 x i32> [[X4]], <16 x i32> [[X2]])
- ; CHECK-NEXT:    [[TMP11:%.*]] = bitcast i16 [[TMP4]] to <16 x i1>
- ; CHECK-NEXT:    [[TMP12:%.*]] = bitcast i16 [[X3:%.*]] to <16 x i1>
- ; CHECK-NEXT:    [[TMP13:%.*]] = select <16 x i1> [[TMP12]], <16 x i32> [[_MSPROP1]], <16 x i32> zeroinitializer
-@@ -14035,14 +14044,15 @@
- ; CHECK-NEXT:    [[TMP1:%.*]] = load i64, ptr inttoptr (i64 add (i64 ptrtoint (ptr @__msan_param_tls to i64), i64 128) to ptr), align 8
- ; CHECK-NEXT:    [[TMP5:%.*]] = load <8 x i64>, ptr inttoptr (i64 add (i64 ptrtoint (ptr @__msan_param_tls to i64), i64 144) to ptr), align 8
- ; CHECK-NEXT:    [[TMP2:%.*]] = load <8 x i64>, ptr inttoptr (i64 add (i64 ptrtoint (ptr @__msan_param_tls to i64), i64 64) to ptr), align 8
-+; CHECK-NEXT:    [[X0:%.*]] = load <8 x i64>, ptr @__msan_param_tls, align 8
- ; CHECK-NEXT:    [[TMP4:%.*]] = load i8, ptr inttoptr (i64 add (i64 ptrtoint (ptr @__msan_param_tls to i64), i64 136) to ptr), align 8
- ; CHECK-NEXT:    call void @llvm.donothing()
- ; CHECK-NEXT:    [[_MSCMP:%.*]] = icmp ne i64 [[TMP1]], 0
--; CHECK-NEXT:    br i1 [[_MSCMP]], label [[TMP12:%.*]], label [[TMP6:%.*]], !prof [[PROF1]]
--; CHECK:       5:
-+; CHECK-NEXT:    br i1 [[_MSCMP]], label [[TMP6:%.*]], label [[TMP12:%.*]], !prof [[PROF1]]
-+; CHECK:       6:
- ; CHECK-NEXT:    call void @__msan_warning_noreturn() #[[ATTR8]]
- ; CHECK-NEXT:    unreachable
--; CHECK:       6:
-+; CHECK:       7:
- ; CHECK-NEXT:    [[X2S:%.*]] = load double, ptr [[X2PTR:%.*]], align 8
- ; CHECK-NEXT:    [[TMP7:%.*]] = ptrtoint ptr [[X2PTR]] to i64
- ; CHECK-NEXT:    [[TMP8:%.*]] = xor i64 [[TMP7]], 87960930222080
-@@ -14052,19 +14062,19 @@
- ; CHECK-NEXT:    [[X2INS:%.*]] = insertelement <8 x double> [[EXTRA_PARAM:%.*]], double [[X2S]], i32 0
- ; CHECK-NEXT:    [[_MSPROP1:%.*]] = shufflevector <8 x i64> [[_MSPROP]], <8 x i64> [[TMP5]], <8 x i32> zeroinitializer
- ; CHECK-NEXT:    [[X2:%.*]] = shufflevector <8 x double> [[X2INS]], <8 x double> [[EXTRA_PARAM]], <8 x i32> zeroinitializer
--; CHECK-NEXT:    [[TMP10:%.*]] = trunc <8 x i64> [[X0:%.*]] to <8 x i3>
-+; CHECK-NEXT:    [[TMP10:%.*]] = trunc <8 x i64> [[X0]] to <8 x i3>
- ; CHECK-NEXT:    [[TMP11:%.*]] = bitcast <8 x i64> [[TMP2]] to <8 x double>
- ; CHECK-NEXT:    [[TMP24:%.*]] = bitcast <8 x i64> [[_MSPROP1]] to <8 x double>
--; CHECK-NEXT:    [[TMP13:%.*]] = call <8 x double> @llvm.x86.avx512.vpermi2var.pd.512(<8 x double> [[TMP11]], <8 x i64> [[X0]], <8 x double> [[TMP24]])
-+; CHECK-NEXT:    [[TMP13:%.*]] = call <8 x double> @llvm.x86.avx512.vpermi2var.pd.512(<8 x double> [[TMP11]], <8 x i64> [[X4:%.*]], <8 x double> [[TMP24]])
- ; CHECK-NEXT:    [[TMP14:%.*]] = bitcast <8 x double> [[TMP13]] to <8 x i64>
- ; CHECK-NEXT:    [[TMP25:%.*]] = bitcast <8 x i3> [[TMP10]] to i24
- ; CHECK-NEXT:    [[_MSCMP2:%.*]] = icmp ne i24 [[TMP25]], 0
- ; CHECK-NEXT:    br i1 [[_MSCMP2]], label [[TMP26:%.*]], label [[TMP27:%.*]], !prof [[PROF1]]
--; CHECK:       16:
-+; CHECK:       17:
- ; CHECK-NEXT:    call void @__msan_warning_noreturn() #[[ATTR8]]
- ; CHECK-NEXT:    unreachable
--; CHECK:       17:
--; CHECK-NEXT:    [[TMP15:%.*]] = call <8 x double> @llvm.x86.avx512.vpermi2var.pd.512(<8 x double> [[X1:%.*]], <8 x i64> [[X0]], <8 x double> [[X2]])
-+; CHECK:       18:
-+; CHECK-NEXT:    [[TMP15:%.*]] = call <8 x double> @llvm.x86.avx512.vpermi2var.pd.512(<8 x double> [[X1:%.*]], <8 x i64> [[X4]], <8 x double> [[X2]])
- ; CHECK-NEXT:    [[TMP16:%.*]] = bitcast i8 [[TMP4]] to <8 x i1>
- ; CHECK-NEXT:    [[TMP17:%.*]] = bitcast i8 [[X3:%.*]] to <8 x i1>
- ; CHECK-NEXT:    [[TMP18:%.*]] = select <8 x i1> [[TMP17]], <8 x i64> [[TMP14]], <8 x i64> zeroinitializer
-@@ -14091,21 +14101,22 @@
- ; CHECK-LABEL: @test_int_x86_avx512_maskz_vpermt2var_ps_512(
- ; CHECK-NEXT:    [[TMP1:%.*]] = load <16 x i32>, ptr inttoptr (i64 add (i64 ptrtoint (ptr @__msan_param_tls to i64), i64 64) to ptr), align 8
- ; CHECK-NEXT:    [[TMP3:%.*]] = load <16 x i32>, ptr inttoptr (i64 add (i64 ptrtoint (ptr @__msan_param_tls to i64), i64 128) to ptr), align 8
-+; CHECK-NEXT:    [[X0:%.*]] = load <16 x i32>, ptr @__msan_param_tls, align 8
- ; CHECK-NEXT:    [[TMP4:%.*]] = load i16, ptr inttoptr (i64 add (i64 ptrtoint (ptr @__msan_param_tls to i64), i64 192) to ptr), align 8
- ; CHECK-NEXT:    call void @llvm.donothing()
--; CHECK-NEXT:    [[TMP7:%.*]] = trunc <16 x i32> [[X0:%.*]] to <16 x i4>
-+; CHECK-NEXT:    [[TMP7:%.*]] = trunc <16 x i32> [[X0]] to <16 x i4>
- ; CHECK-NEXT:    [[TMP5:%.*]] = bitcast <16 x i32> [[TMP1]] to <16 x float>
- ; CHECK-NEXT:    [[TMP6:%.*]] = bitcast <16 x i32> [[TMP3]] to <16 x float>
--; CHECK-NEXT:    [[TMP19:%.*]] = call <16 x float> @llvm.x86.avx512.vpermi2var.ps.512(<16 x float> [[TMP5]], <16 x i32> [[X0]], <16 x float> [[TMP6]])
-+; CHECK-NEXT:    [[TMP19:%.*]] = call <16 x float> @llvm.x86.avx512.vpermi2var.ps.512(<16 x float> [[TMP5]], <16 x i32> [[X4:%.*]], <16 x float> [[TMP6]])
- ; CHECK-NEXT:    [[TMP8:%.*]] = bitcast <16 x float> [[TMP19]] to <16 x i32>
- ; CHECK-NEXT:    [[TMP9:%.*]] = bitcast <16 x i4> [[TMP7]] to i64
- ; CHECK-NEXT:    [[_MSCMP:%.*]] = icmp ne i64 [[TMP9]], 0
- ; CHECK-NEXT:    br i1 [[_MSCMP]], label [[TMP20:%.*]], label [[TMP21:%.*]], !prof [[PROF1]]
--; CHECK:       10:
-+; CHECK:       11:
- ; CHECK-NEXT:    call void @__msan_warning_noreturn() #[[ATTR8]]
- ; CHECK-NEXT:    unreachable
--; CHECK:       11:
--; CHECK-NEXT:    [[TMP10:%.*]] = call <16 x float> @llvm.x86.avx512.vpermi2var.ps.512(<16 x float> [[X1:%.*]], <16 x i32> [[X0]], <16 x float> [[X2:%.*]])
-+; CHECK:       12:
-+; CHECK-NEXT:    [[TMP10:%.*]] = call <16 x float> @llvm.x86.avx512.vpermi2var.ps.512(<16 x float> [[X1:%.*]], <16 x i32> [[X4]], <16 x float> [[X2:%.*]])
- ; CHECK-NEXT:    [[TMP11:%.*]] = bitcast i16 [[TMP4]] to <16 x i1>
- ; CHECK-NEXT:    [[TMP12:%.*]] = bitcast i16 [[X3:%.*]] to <16 x i1>
- ; CHECK-NEXT:    [[TMP13:%.*]] = select <16 x i1> [[TMP12]], <16 x i32> [[TMP8]], <16 x i32> zeroinitializer
-@@ -14130,18 +14141,19 @@
- ; CHECK-LABEL: @test_int_x86_avx512_maskz_vpermt2var_q_512(
- ; CHECK-NEXT:    [[TMP1:%.*]] = load <8 x i64>, ptr inttoptr (i64 add (i64 ptrtoint (ptr @__msan_param_tls to i64), i64 64) to ptr), align 8
- ; CHECK-NEXT:    [[TMP3:%.*]] = load <8 x i64>, ptr inttoptr (i64 add (i64 ptrtoint (ptr @__msan_param_tls to i64), i64 128) to ptr), align 8
-+; CHECK-NEXT:    [[X0:%.*]] = load <8 x i64>, ptr @__msan_param_tls, align 8
- ; CHECK-NEXT:    [[TMP4:%.*]] = load i8, ptr inttoptr (i64 add (i64 ptrtoint (ptr @__msan_param_tls to i64), i64 192) to ptr), align 8
- ; CHECK-NEXT:    call void @llvm.donothing()
--; CHECK-NEXT:    [[TMP13:%.*]] = trunc <8 x i64> [[X0:%.*]] to <8 x i3>
--; CHECK-NEXT:    [[_MSPROP1:%.*]] = call <8 x i64> @llvm.x86.avx512.vpermi2var.q.512(<8 x i64> [[TMP1]], <8 x i64> [[X0]], <8 x i64> [[TMP3]])
-+; CHECK-NEXT:    [[TMP13:%.*]] = trunc <8 x i64> [[X0]] to <8 x i3>
-+; CHECK-NEXT:    [[_MSPROP1:%.*]] = call <8 x i64> @llvm.x86.avx512.vpermi2var.q.512(<8 x i64> [[TMP1]], <8 x i64> [[X4:%.*]], <8 x i64> [[TMP3]])
- ; CHECK-NEXT:    [[TMP14:%.*]] = bitcast <8 x i3> [[TMP13]] to i24
- ; CHECK-NEXT:    [[_MSCMP:%.*]] = icmp ne i24 [[TMP14]], 0
- ; CHECK-NEXT:    br i1 [[_MSCMP]], label [[TMP15:%.*]], label [[TMP16:%.*]], !prof [[PROF1]]
--; CHECK:       7:
-+; CHECK:       8:
- ; CHECK-NEXT:    call void @__msan_warning_noreturn() #[[ATTR8]]
- ; CHECK-NEXT:    unreachable
--; CHECK:       8:
--; CHECK-NEXT:    [[TMP5:%.*]] = call <8 x i64> @llvm.x86.avx512.vpermi2var.q.512(<8 x i64> [[X1:%.*]], <8 x i64> [[X0]], <8 x i64> [[X2:%.*]])
-+; CHECK:       9:
-+; CHECK-NEXT:    [[TMP5:%.*]] = call <8 x i64> @llvm.x86.avx512.vpermi2var.q.512(<8 x i64> [[X1:%.*]], <8 x i64> [[X4]], <8 x i64> [[X2:%.*]])
- ; CHECK-NEXT:    [[TMP6:%.*]] = bitcast i8 [[TMP4]] to <8 x i1>
- ; CHECK-NEXT:    [[TMP7:%.*]] = bitcast i8 [[X3:%.*]] to <8 x i1>
- ; CHECK-NEXT:    [[TMP8:%.*]] = select <8 x i1> [[TMP7]], <8 x i64> [[_MSPROP1]], <8 x i64> zeroinitializer
-@@ -14163,17 +14175,18 @@
- ; CHECK-LABEL: @test_int_x86_avx512_vpermt2var_d_512(
- ; CHECK-NEXT:    [[TMP1:%.*]] = load <16 x i32>, ptr inttoptr (i64 add (i64 ptrtoint (ptr @__msan_param_tls to i64), i64 64) to ptr), align 8
- ; CHECK-NEXT:    [[TMP3:%.*]] = load <16 x i32>, ptr inttoptr (i64 add (i64 ptrtoint (ptr @__msan_param_tls to i64), i64 128) to ptr), align 8
-+; CHECK-NEXT:    [[X0:%.*]] = load <16 x i32>, ptr @__msan_param_tls, align 8
- ; CHECK-NEXT:    call void @llvm.donothing()
--; CHECK-NEXT:    [[TMP8:%.*]] = trunc <16 x i32> [[X0:%.*]] to <16 x i4>
--; CHECK-NEXT:    [[_MSPROP1:%.*]] = call <16 x i32> @llvm.x86.avx512.vpermi2var.d.512(<16 x i32> [[TMP1]], <16 x i32> [[X0]], <16 x i32> [[TMP3]])
-+; CHECK-NEXT:    [[TMP8:%.*]] = trunc <16 x i32> [[X0]] to <16 x i4>
-+; CHECK-NEXT:    [[_MSPROP1:%.*]] = call <16 x i32> @llvm.x86.avx512.vpermi2var.d.512(<16 x i32> [[TMP1]], <16 x i32> [[X3:%.*]], <16 x i32> [[TMP3]])
- ; CHECK-NEXT:    [[TMP5:%.*]] = bitcast <16 x i4> [[TMP8]] to i64
- ; CHECK-NEXT:    [[_MSCMP:%.*]] = icmp ne i64 [[TMP5]], 0
--; CHECK-NEXT:    br i1 [[_MSCMP]], label [[TMP6:%.*]], label [[TMP7:%.*]], !prof [[PROF1]]
--; CHECK:       6:
-+; CHECK-NEXT:    br i1 [[_MSCMP]], label [[TMP7:%.*]], label [[TMP9:%.*]], !prof [[PROF1]]
-+; CHECK:       7:
- ; CHECK-NEXT:    call void @__msan_warning_noreturn() #[[ATTR8]]
- ; CHECK-NEXT:    unreachable
--; CHECK:       7:
--; CHECK-NEXT:    [[TMP4:%.*]] = call <16 x i32> @llvm.x86.avx512.vpermi2var.d.512(<16 x i32> [[X1:%.*]], <16 x i32> [[X0]], <16 x i32> [[X2:%.*]])
-+; CHECK:       8:
-+; CHECK-NEXT:    [[TMP4:%.*]] = call <16 x i32> @llvm.x86.avx512.vpermi2var.d.512(<16 x i32> [[X1:%.*]], <16 x i32> [[X3]], <16 x i32> [[X2:%.*]])
- ; CHECK-NEXT:    store <16 x i32> [[_MSPROP1]], ptr @__msan_retval_tls, align 8
- ; CHECK-NEXT:    ret <16 x i32> [[TMP4]]
- ;
-@@ -14186,18 +14199,19 @@
- ; CHECK-LABEL: @test_int_x86_avx512_mask_vpermt2var_d_512(
- ; CHECK-NEXT:    [[TMP1:%.*]] = load <16 x i32>, ptr inttoptr (i64 add (i64 ptrtoint (ptr @__msan_param_tls to i64), i64 64) to ptr), align 8
- ; CHECK-NEXT:    [[TMP3:%.*]] = load <16 x i32>, ptr inttoptr (i64 add (i64 ptrtoint (ptr @__msan_param_tls to i64), i64 128) to ptr), align 8
-+; CHECK-NEXT:    [[X0:%.*]] = load <16 x i32>, ptr @__msan_param_tls, align 8
- ; CHECK-NEXT:    [[TMP4:%.*]] = load i16, ptr inttoptr (i64 add (i64 ptrtoint (ptr @__msan_param_tls to i64), i64 192) to ptr), align 8
- ; CHECK-NEXT:    call void @llvm.donothing()
--; CHECK-NEXT:    [[TMP13:%.*]] = trunc <16 x i32> [[X0:%.*]] to <16 x i4>
--; CHECK-NEXT:    [[_MSPROP1:%.*]] = call <16 x i32> @llvm.x86.avx512.vpermi2var.d.512(<16 x i32> [[TMP1]], <16 x i32> [[X0]], <16 x i32> [[TMP3]])
-+; CHECK-NEXT:    [[TMP13:%.*]] = trunc <16 x i32> [[X0]] to <16 x i4>
-+; CHECK-NEXT:    [[_MSPROP1:%.*]] = call <16 x i32> @llvm.x86.avx512.vpermi2var.d.512(<16 x i32> [[TMP1]], <16 x i32> [[X4:%.*]], <16 x i32> [[TMP3]])
- ; CHECK-NEXT:    [[TMP14:%.*]] = bitcast <16 x i4> [[TMP13]] to i64
- ; CHECK-NEXT:    [[_MSCMP:%.*]] = icmp ne i64 [[TMP14]], 0
- ; CHECK-NEXT:    br i1 [[_MSCMP]], label [[TMP15:%.*]], label [[TMP16:%.*]], !prof [[PROF1]]
--; CHECK:       7:
-+; CHECK:       8:
- ; CHECK-NEXT:    call void @__msan_warning_noreturn() #[[ATTR8]]
- ; CHECK-NEXT:    unreachable
--; CHECK:       8:
--; CHECK-NEXT:    [[TMP5:%.*]] = call <16 x i32> @llvm.x86.avx512.vpermi2var.d.512(<16 x i32> [[X1:%.*]], <16 x i32> [[X0]], <16 x i32> [[X2:%.*]])
-+; CHECK:       9:
-+; CHECK-NEXT:    [[TMP5:%.*]] = call <16 x i32> @llvm.x86.avx512.vpermi2var.d.512(<16 x i32> [[X1:%.*]], <16 x i32> [[X4]], <16 x i32> [[X2:%.*]])
- ; CHECK-NEXT:    [[TMP6:%.*]] = bitcast i16 [[TMP4]] to <16 x i1>
- ; CHECK-NEXT:    [[TMP7:%.*]] = bitcast i16 [[X3:%.*]] to <16 x i1>
- ; CHECK-NEXT:    [[TMP8:%.*]] = select <16 x i1> [[TMP7]], <16 x i32> [[_MSPROP1]], <16 x i32> [[TMP1]]
-diff -ruN --strip-trailing-cr a/llvm/test/Instrumentation/MemorySanitizer/X86/avx512vl-intrinsics.ll b/llvm/test/Instrumentation/MemorySanitizer/X86/avx512vl-intrinsics.ll
---- a/llvm/test/Instrumentation/MemorySanitizer/X86/avx512vl-intrinsics.ll
-+++ b/llvm/test/Instrumentation/MemorySanitizer/X86/avx512vl-intrinsics.ll
-@@ -1902,16 +1902,17 @@
- ; CHECK-SAME: <4 x i32> [[X0:%.*]], <4 x i32> [[X1:%.*]], <4 x i32> [[X2:%.*]]) #[[ATTR0]] {
- ; CHECK-NEXT:    [[TMP6:%.*]] = load <4 x i32>, ptr @__msan_param_tls, align 8
- ; CHECK-NEXT:    [[TMP5:%.*]] = load <4 x i32>, ptr inttoptr (i64 add (i64 ptrtoint (ptr @__msan_param_tls to i64), i64 32) to ptr), align 8
-+; CHECK-NEXT:    [[TMP8:%.*]] = load <4 x i32>, ptr inttoptr (i64 add (i64 ptrtoint (ptr @__msan_param_tls to i64), i64 16) to ptr), align 8
- ; CHECK-NEXT:    call void @llvm.donothing()
--; CHECK-NEXT:    [[TMP3:%.*]] = trunc <4 x i32> [[X1]] to <4 x i2>
-+; CHECK-NEXT:    [[TMP3:%.*]] = trunc <4 x i32> [[TMP8]] to <4 x i2>
- ; CHECK-NEXT:    [[TMP4:%.*]] = call <4 x i32> @llvm.x86.avx512.vpermi2var.d.128(<4 x i32> [[TMP6]], <4 x i32> [[X1]], <4 x i32> [[TMP5]])
- ; CHECK-NEXT:    [[TMP7:%.*]] = bitcast <4 x i2> [[TMP3]] to i8
- ; CHECK-NEXT:    [[_MSCMP:%.*]] = icmp ne i8 [[TMP7]], 0
--; CHECK-NEXT:    br i1 [[_MSCMP]], label %[[BB6:.*]], label %[[BB7:.*]], !prof [[PROF1]]
--; CHECK:       [[BB6]]:
-+; CHECK-NEXT:    br i1 [[_MSCMP]], label %[[BB7:.*]], label %[[BB8:.*]], !prof [[PROF1]]
-+; CHECK:       [[BB7]]:
- ; CHECK-NEXT:    call void @__msan_warning_noreturn() #[[ATTR6]]
- ; CHECK-NEXT:    unreachable
--; CHECK:       [[BB7]]:
-+; CHECK:       [[BB8]]:
- ; CHECK-NEXT:    [[TMP1:%.*]] = call <4 x i32> @llvm.x86.avx512.vpermi2var.d.128(<4 x i32> [[X0]], <4 x i32> [[X1]], <4 x i32> [[X2]])
- ; CHECK-NEXT:    store <4 x i32> [[TMP4]], ptr @__msan_retval_tls, align 8
- ; CHECK-NEXT:    ret <4 x i32> [[TMP1]]
-@@ -1926,10 +1927,10 @@
- ; CHECK-SAME: <4 x i32> [[X0:%.*]], <4 x i32> [[X1:%.*]], <4 x i32> [[X2:%.*]], i8 [[X3:%.*]]) #[[ATTR0]] {
- ; CHECK-NEXT:    [[TMP8:%.*]] = load <4 x i32>, ptr @__msan_param_tls, align 8
- ; CHECK-NEXT:    [[TMP6:%.*]] = load <4 x i32>, ptr inttoptr (i64 add (i64 ptrtoint (ptr @__msan_param_tls to i64), i64 32) to ptr), align 8
--; CHECK-NEXT:    [[TMP11:%.*]] = load i8, ptr inttoptr (i64 add (i64 ptrtoint (ptr @__msan_param_tls to i64), i64 48) to ptr), align 8
- ; CHECK-NEXT:    [[TMP3:%.*]] = load <4 x i32>, ptr inttoptr (i64 add (i64 ptrtoint (ptr @__msan_param_tls to i64), i64 16) to ptr), align 8
-+; CHECK-NEXT:    [[TMP11:%.*]] = load i8, ptr inttoptr (i64 add (i64 ptrtoint (ptr @__msan_param_tls to i64), i64 48) to ptr), align 8
- ; CHECK-NEXT:    call void @llvm.donothing()
--; CHECK-NEXT:    [[TMP9:%.*]] = trunc <4 x i32> [[X1]] to <4 x i2>
-+; CHECK-NEXT:    [[TMP9:%.*]] = trunc <4 x i32> [[TMP3]] to <4 x i2>
- ; CHECK-NEXT:    [[TMP5:%.*]] = call <4 x i32> @llvm.x86.avx512.vpermi2var.d.128(<4 x i32> [[TMP8]], <4 x i32> [[X1]], <4 x i32> [[TMP6]])
- ; CHECK-NEXT:    [[TMP13:%.*]] = bitcast <4 x i2> [[TMP9]] to i8
- ; CHECK-NEXT:    [[_MSCMP:%.*]] = icmp ne i8 [[TMP13]], 0
-@@ -1964,16 +1965,17 @@
- ; CHECK-SAME: <4 x i32> [[X0:%.*]], <4 x i32> [[X1:%.*]], <4 x i32> [[X2:%.*]]) #[[ATTR0]] {
- ; CHECK-NEXT:    [[TMP6:%.*]] = load <4 x i32>, ptr inttoptr (i64 add (i64 ptrtoint (ptr @__msan_param_tls to i64), i64 16) to ptr), align 8
- ; CHECK-NEXT:    [[TMP5:%.*]] = load <4 x i32>, ptr inttoptr (i64 add (i64 ptrtoint (ptr @__msan_param_tls to i64), i64 32) to ptr), align 8
-+; CHECK-NEXT:    [[TMP8:%.*]] = load <4 x i32>, ptr @__msan_param_tls, align 8
- ; CHECK-NEXT:    call void @llvm.donothing()
--; CHECK-NEXT:    [[TMP3:%.*]] = trunc <4 x i32> [[X0]] to <4 x i2>
-+; CHECK-NEXT:    [[TMP3:%.*]] = trunc <4 x i32> [[TMP8]] to <4 x i2>
- ; CHECK-NEXT:    [[TMP4:%.*]] = call <4 x i32> @llvm.x86.avx512.vpermi2var.d.128(<4 x i32> [[TMP6]], <4 x i32> [[X0]], <4 x i32> [[TMP5]])
- ; CHECK-NEXT:    [[TMP7:%.*]] = bitcast <4 x i2> [[TMP3]] to i8
- ; CHECK-NEXT:    [[_MSCMP:%.*]] = icmp ne i8 [[TMP7]], 0
--; CHECK-NEXT:    br i1 [[_MSCMP]], label %[[BB6:.*]], label %[[BB7:.*]], !prof [[PROF1]]
--; CHECK:       [[BB6]]:
-+; CHECK-NEXT:    br i1 [[_MSCMP]], label %[[BB7:.*]], label %[[BB8:.*]], !prof [[PROF1]]
-+; CHECK:       [[BB7]]:
- ; CHECK-NEXT:    call void @__msan_warning_noreturn() #[[ATTR6]]
- ; CHECK-NEXT:    unreachable
--; CHECK:       [[BB7]]:
-+; CHECK:       [[BB8]]:
- ; CHECK-NEXT:    [[TMP1:%.*]] = call <4 x i32> @llvm.x86.avx512.vpermi2var.d.128(<4 x i32> [[X1]], <4 x i32> [[X0]], <4 x i32> [[X2]])
- ; CHECK-NEXT:    store <4 x i32> [[TMP4]], ptr @__msan_retval_tls, align 8
- ; CHECK-NEXT:    ret <4 x i32> [[TMP1]]
-@@ -1988,17 +1990,18 @@
- ; CHECK-SAME: <4 x i32> [[X0:%.*]], <4 x i32> [[X1:%.*]], <4 x i32> [[X2:%.*]], i8 [[X3:%.*]]) #[[ATTR0]] {
- ; CHECK-NEXT:    [[TMP8:%.*]] = load <4 x i32>, ptr inttoptr (i64 add (i64 ptrtoint (ptr @__msan_param_tls to i64), i64 16) to ptr), align 8
- ; CHECK-NEXT:    [[TMP6:%.*]] = load <4 x i32>, ptr inttoptr (i64 add (i64 ptrtoint (ptr @__msan_param_tls to i64), i64 32) to ptr), align 8
-+; CHECK-NEXT:    [[TMP3:%.*]] = load <4 x i32>, ptr @__msan_param_tls, align 8
- ; CHECK-NEXT:    [[TMP11:%.*]] = load i8, ptr inttoptr (i64 add (i64 ptrtoint (ptr @__msan_param_tls to i64), i64 48) to ptr), align 8
- ; CHECK-NEXT:    call void @llvm.donothing()
--; CHECK-NEXT:    [[TMP9:%.*]] = trunc <4 x i32> [[X0]] to <4 x i2>
-+; CHECK-NEXT:    [[TMP9:%.*]] = trunc <4 x i32> [[TMP3]] to <4 x i2>
- ; CHECK-NEXT:    [[TMP5:%.*]] = call <4 x i32> @llvm.x86.avx512.vpermi2var.d.128(<4 x i32> [[TMP8]], <4 x i32> [[X0]], <4 x i32> [[TMP6]])
- ; CHECK-NEXT:    [[TMP13:%.*]] = bitcast <4 x i2> [[TMP9]] to i8
- ; CHECK-NEXT:    [[_MSCMP:%.*]] = icmp ne i8 [[TMP13]], 0
--; CHECK-NEXT:    br i1 [[_MSCMP]], label %[[BB7:.*]], label %[[BB8:.*]], !prof [[PROF1]]
--; CHECK:       [[BB7]]:
-+; CHECK-NEXT:    br i1 [[_MSCMP]], label %[[BB8:.*]], label %[[BB9:.*]], !prof [[PROF1]]
-+; CHECK:       [[BB8]]:
- ; CHECK-NEXT:    call void @__msan_warning_noreturn() #[[ATTR6]]
- ; CHECK-NEXT:    unreachable
--; CHECK:       [[BB8]]:
-+; CHECK:       [[BB9]]:
- ; CHECK-NEXT:    [[TMP1:%.*]] = call <4 x i32> @llvm.x86.avx512.vpermi2var.d.128(<4 x i32> [[X1]], <4 x i32> [[X0]], <4 x i32> [[X2]])
- ; CHECK-NEXT:    [[TMP10:%.*]] = bitcast i8 [[TMP11]] to <8 x i1>
- ; CHECK-NEXT:    [[TMP2:%.*]] = bitcast i8 [[X3]] to <8 x i1>
-@@ -2026,17 +2029,18 @@
- ; CHECK-SAME: <4 x i32> [[X0:%.*]], <4 x i32> [[X1:%.*]], <4 x i32> [[X2:%.*]], i8 [[X3:%.*]]) #[[ATTR0]] {
- ; CHECK-NEXT:    [[TMP8:%.*]] = load <4 x i32>, ptr inttoptr (i64 add (i64 ptrtoint (ptr @__msan_param_tls to i64), i64 16) to ptr), align 8
- ; CHECK-NEXT:    [[TMP9:%.*]] = load <4 x i32>, ptr inttoptr (i64 add (i64 ptrtoint (ptr @__msan_param_tls to i64), i64 32) to ptr), align 8
-+; CHECK-NEXT:    [[TMP3:%.*]] = load <4 x i32>, ptr @__msan_param_tls, align 8
- ; CHECK-NEXT:    [[TMP11:%.*]] = load i8, ptr inttoptr (i64 add (i64 ptrtoint (ptr @__msan_param_tls to i64), i64 48) to ptr), align 8
- ; CHECK-NEXT:    call void @llvm.donothing()
--; CHECK-NEXT:    [[TMP14:%.*]] = trunc <4 x i32> [[X0]] to <4 x i2>
-+; CHECK-NEXT:    [[TMP14:%.*]] = trunc <4 x i32> [[TMP3]] to <4 x i2>
- ; CHECK-NEXT:    [[TMP13:%.*]] = call <4 x i32> @llvm.x86.avx512.vpermi2var.d.128(<4 x i32> [[TMP8]], <4 x i32> [[X0]], <4 x i32> [[TMP9]])
- ; CHECK-NEXT:    [[TMP15:%.*]] = bitcast <4 x i2> [[TMP14]] to i8
- ; CHECK-NEXT:    [[_MSCMP:%.*]] = icmp ne i8 [[TMP15]], 0
--; CHECK-NEXT:    br i1 [[_MSCMP]], label %[[BB7:.*]], label %[[BB8:.*]], !prof [[PROF1]]
--; CHECK:       [[BB7]]:
-+; CHECK-NEXT:    br i1 [[_MSCMP]], label %[[BB8:.*]], label %[[BB9:.*]], !prof [[PROF1]]
-+; CHECK:       [[BB8]]:
- ; CHECK-NEXT:    call void @__msan_warning_noreturn() #[[ATTR6]]
- ; CHECK-NEXT:    unreachable
--; CHECK:       [[BB8]]:
-+; CHECK:       [[BB9]]:
- ; CHECK-NEXT:    [[TMP1:%.*]] = call <4 x i32> @llvm.x86.avx512.vpermi2var.d.128(<4 x i32> [[X1]], <4 x i32> [[X0]], <4 x i32> [[X2]])
- ; CHECK-NEXT:    [[TMP10:%.*]] = bitcast i8 [[TMP11]] to <8 x i1>
- ; CHECK-NEXT:    [[TMP2:%.*]] = bitcast i8 [[X3]] to <8 x i1>
-@@ -2065,16 +2069,17 @@
- ; CHECK-SAME: <8 x i32> [[X0:%.*]], <8 x i32> [[X1:%.*]], <8 x i32> [[X2:%.*]]) #[[ATTR0]] {
- ; CHECK-NEXT:    [[TMP6:%.*]] = load <8 x i32>, ptr @__msan_param_tls, align 8
- ; CHECK-NEXT:    [[TMP5:%.*]] = load <8 x i32>, ptr inttoptr (i64 add (i64 ptrtoint (ptr @__msan_param_tls to i64), i64 64) to ptr), align 8
-+; CHECK-NEXT:    [[TMP8:%.*]] = load <8 x i32>, ptr inttoptr (i64 add (i64 ptrtoint (ptr @__msan_param_tls to i64), i64 32) to ptr), align 8
- ; CHECK-NEXT:    call void @llvm.donothing()
--; CHECK-NEXT:    [[TMP3:%.*]] = trunc <8 x i32> [[X1]] to <8 x i3>
-+; CHECK-NEXT:    [[TMP3:%.*]] = trunc <8 x i32> [[TMP8]] to <8 x i3>
- ; CHECK-NEXT:    [[TMP4:%.*]] = call <8 x i32> @llvm.x86.avx512.vpermi2var.d.256(<8 x i32> [[TMP6]], <8 x i32> [[X1]], <8 x i32> [[TMP5]])
- ; CHECK-NEXT:    [[TMP7:%.*]] = bitcast <8 x i3> [[TMP3]] to i24
- ; CHECK-NEXT:    [[_MSCMP:%.*]] = icmp ne i24 [[TMP7]], 0
--; CHECK-NEXT:    br i1 [[_MSCMP]], label %[[BB6:.*]], label %[[BB7:.*]], !prof [[PROF1]]
--; CHECK:       [[BB6]]:
-+; CHECK-NEXT:    br i1 [[_MSCMP]], label %[[BB7:.*]], label %[[BB8:.*]], !prof [[PROF1]]
-+; CHECK:       [[BB7]]:
- ; CHECK-NEXT:    call void @__msan_warning_noreturn() #[[ATTR6]]
- ; CHECK-NEXT:    unreachable
--; CHECK:       [[BB7]]:
-+; CHECK:       [[BB8]]:
- ; CHECK-NEXT:    [[TMP1:%.*]] = call <8 x i32> @llvm.x86.avx512.vpermi2var.d.256(<8 x i32> [[X0]], <8 x i32> [[X1]], <8 x i32> [[X2]])
- ; CHECK-NEXT:    store <8 x i32> [[TMP4]], ptr @__msan_retval_tls, align 8
- ; CHECK-NEXT:    ret <8 x i32> [[TMP1]]
-@@ -2089,10 +2094,10 @@
- ; CHECK-SAME: <8 x i32> [[X0:%.*]], <8 x i32> [[X1:%.*]], <8 x i32> [[X2:%.*]], i8 [[X3:%.*]]) #[[ATTR0]] {
- ; CHECK-NEXT:    [[TMP8:%.*]] = load <8 x i32>, ptr @__msan_param_tls, align 8
- ; CHECK-NEXT:    [[TMP6:%.*]] = load <8 x i32>, ptr inttoptr (i64 add (i64 ptrtoint (ptr @__msan_param_tls to i64), i64 64) to ptr), align 8
--; CHECK-NEXT:    [[TMP11:%.*]] = load i8, ptr inttoptr (i64 add (i64 ptrtoint (ptr @__msan_param_tls to i64), i64 96) to ptr), align 8
- ; CHECK-NEXT:    [[TMP3:%.*]] = load <8 x i32>, ptr inttoptr (i64 add (i64 ptrtoint (ptr @__msan_param_tls to i64), i64 32) to ptr), align 8
-+; CHECK-NEXT:    [[TMP11:%.*]] = load i8, ptr inttoptr (i64 add (i64 ptrtoint (ptr @__msan_param_tls to i64), i64 96) to ptr), align 8
- ; CHECK-NEXT:    call void @llvm.donothing()
--; CHECK-NEXT:    [[TMP9:%.*]] = trunc <8 x i32> [[X1]] to <8 x i3>
-+; CHECK-NEXT:    [[TMP9:%.*]] = trunc <8 x i32> [[TMP3]] to <8 x i3>
- ; CHECK-NEXT:    [[TMP5:%.*]] = call <8 x i32> @llvm.x86.avx512.vpermi2var.d.256(<8 x i32> [[TMP8]], <8 x i32> [[X1]], <8 x i32> [[TMP6]])
- ; CHECK-NEXT:    [[TMP13:%.*]] = bitcast <8 x i3> [[TMP9]] to i24
- ; CHECK-NEXT:    [[_MSCMP:%.*]] = icmp ne i24 [[TMP13]], 0
-@@ -2124,16 +2129,17 @@
- ; CHECK-SAME: <8 x i32> [[X0:%.*]], <8 x i32> [[X1:%.*]], <8 x i32> [[X2:%.*]]) #[[ATTR0]] {
- ; CHECK-NEXT:    [[TMP6:%.*]] = load <8 x i32>, ptr inttoptr (i64 add (i64 ptrtoint (ptr @__msan_param_tls to i64), i64 32) to ptr), align 8
- ; CHECK-NEXT:    [[TMP5:%.*]] = load <8 x i32>, ptr inttoptr (i64 add (i64 ptrtoint (ptr @__msan_param_tls to i64), i64 64) to ptr), align 8
-+; CHECK-NEXT:    [[TMP8:%.*]] = load <8 x i32>, ptr @__msan_param_tls, align 8
- ; CHECK-NEXT:    call void @llvm.donothing()
--; CHECK-NEXT:    [[TMP3:%.*]] = trunc <8 x i32> [[X0]] to <8 x i3>
-+; CHECK-NEXT:    [[TMP3:%.*]] = trunc <8 x i32> [[TMP8]] to <8 x i3>
- ; CHECK-NEXT:    [[TMP4:%.*]] = call <8 x i32> @llvm.x86.avx512.vpermi2var.d.256(<8 x i32> [[TMP6]], <8 x i32> [[X0]], <8 x i32> [[TMP5]])
- ; CHECK-NEXT:    [[TMP7:%.*]] = bitcast <8 x i3> [[TMP3]] to i24
- ; CHECK-NEXT:    [[_MSCMP:%.*]] = icmp ne i24 [[TMP7]], 0
--; CHECK-NEXT:    br i1 [[_MSCMP]], label %[[BB6:.*]], label %[[BB7:.*]], !prof [[PROF1]]
--; CHECK:       [[BB6]]:
-+; CHECK-NEXT:    br i1 [[_MSCMP]], label %[[BB7:.*]], label %[[BB8:.*]], !prof [[PROF1]]
-+; CHECK:       [[BB7]]:
- ; CHECK-NEXT:    call void @__msan_warning_noreturn() #[[ATTR6]]
- ; CHECK-NEXT:    unreachable
--; CHECK:       [[BB7]]:
-+; CHECK:       [[BB8]]:
- ; CHECK-NEXT:    [[TMP1:%.*]] = call <8 x i32> @llvm.x86.avx512.vpermi2var.d.256(<8 x i32> [[X1]], <8 x i32> [[X0]], <8 x i32> [[X2]])
- ; CHECK-NEXT:    store <8 x i32> [[TMP4]], ptr @__msan_retval_tls, align 8
- ; CHECK-NEXT:    ret <8 x i32> [[TMP1]]
-@@ -2148,17 +2154,18 @@
- ; CHECK-SAME: <8 x i32> [[X0:%.*]], <8 x i32> [[X1:%.*]], <8 x i32> [[X2:%.*]], i8 [[X3:%.*]]) #[[ATTR0]] {
- ; CHECK-NEXT:    [[TMP8:%.*]] = load <8 x i32>, ptr inttoptr (i64 add (i64 ptrtoint (ptr @__msan_param_tls to i64), i64 32) to ptr), align 8
- ; CHECK-NEXT:    [[TMP6:%.*]] = load <8 x i32>, ptr inttoptr (i64 add (i64 ptrtoint (ptr @__msan_param_tls to i64), i64 64) to ptr), align 8
-+; CHECK-NEXT:    [[TMP3:%.*]] = load <8 x i32>, ptr @__msan_param_tls, align 8
- ; CHECK-NEXT:    [[TMP11:%.*]] = load i8, ptr inttoptr (i64 add (i64 ptrtoint (ptr @__msan_param_tls to i64), i64 96) to ptr), align 8
- ; CHECK-NEXT:    call void @llvm.donothing()
--; CHECK-NEXT:    [[TMP9:%.*]] = trunc <8 x i32> [[X0]] to <8 x i3>
-+; CHECK-NEXT:    [[TMP9:%.*]] = trunc <8 x i32> [[TMP3]] to <8 x i3>
- ; CHECK-NEXT:    [[TMP5:%.*]] = call <8 x i32> @llvm.x86.avx512.vpermi2var.d.256(<8 x i32> [[TMP8]], <8 x i32> [[X0]], <8 x i32> [[TMP6]])
- ; CHECK-NEXT:    [[TMP13:%.*]] = bitcast <8 x i3> [[TMP9]] to i24
- ; CHECK-NEXT:    [[_MSCMP:%.*]] = icmp ne i24 [[TMP13]], 0
--; CHECK-NEXT:    br i1 [[_MSCMP]], label %[[BB7:.*]], label %[[BB8:.*]], !prof [[PROF1]]
--; CHECK:       [[BB7]]:
-+; CHECK-NEXT:    br i1 [[_MSCMP]], label %[[BB8:.*]], label %[[BB9:.*]], !prof [[PROF1]]
-+; CHECK:       [[BB8]]:
- ; CHECK-NEXT:    call void @__msan_warning_noreturn() #[[ATTR6]]
- ; CHECK-NEXT:    unreachable
--; CHECK:       [[BB8]]:
-+; CHECK:       [[BB9]]:
- ; CHECK-NEXT:    [[TMP1:%.*]] = call <8 x i32> @llvm.x86.avx512.vpermi2var.d.256(<8 x i32> [[X1]], <8 x i32> [[X0]], <8 x i32> [[X2]])
- ; CHECK-NEXT:    [[TMP10:%.*]] = bitcast i8 [[TMP11]] to <8 x i1>
- ; CHECK-NEXT:    [[TMP2:%.*]] = bitcast i8 [[X3]] to <8 x i1>
-@@ -2183,17 +2190,18 @@
- ; CHECK-SAME: <8 x i32> [[X0:%.*]], <8 x i32> [[X1:%.*]], <8 x i32> [[X2:%.*]], i8 [[X3:%.*]]) #[[ATTR0]] {
- ; CHECK-NEXT:    [[TMP8:%.*]] = load <8 x i32>, ptr inttoptr (i64 add (i64 ptrtoint (ptr @__msan_param_tls to i64), i64 32) to ptr), align 8
- ; CHECK-NEXT:    [[TMP9:%.*]] = load <8 x i32>, ptr inttoptr (i64 add (i64 ptrtoint (ptr @__msan_param_tls to i64), i64 64) to ptr), align 8
-+; CHECK-NEXT:    [[TMP3:%.*]] = load <8 x i32>, ptr @__msan_param_tls, align 8
- ; CHECK-NEXT:    [[TMP11:%.*]] = load i8, ptr inttoptr (i64 add (i64 ptrtoint (ptr @__msan_param_tls to i64), i64 96) to ptr), align 8
- ; CHECK-NEXT:    call void @llvm.donothing()
--; CHECK-NEXT:    [[TMP14:%.*]] = trunc <8 x i32> [[X0]] to <8 x i3>
-+; CHECK-NEXT:    [[TMP14:%.*]] = trunc <8 x i32> [[TMP3]] to <8 x i3>
- ; CHECK-NEXT:    [[TMP13:%.*]] = call <8 x i32> @llvm.x86.avx512.vpermi2var.d.256(<8 x i32> [[TMP8]], <8 x i32> [[X0]], <8 x i32> [[TMP9]])
- ; CHECK-NEXT:    [[TMP15:%.*]] = bitcast <8 x i3> [[TMP14]] to i24
- ; CHECK-NEXT:    [[_MSCMP:%.*]] = icmp ne i24 [[TMP15]], 0
--; CHECK-NEXT:    br i1 [[_MSCMP]], label %[[BB7:.*]], label %[[BB8:.*]], !prof [[PROF1]]
--; CHECK:       [[BB7]]:
-+; CHECK-NEXT:    br i1 [[_MSCMP]], label %[[BB8:.*]], label %[[BB9:.*]], !prof [[PROF1]]
-+; CHECK:       [[BB8]]:
- ; CHECK-NEXT:    call void @__msan_warning_noreturn() #[[ATTR6]]
- ; CHECK-NEXT:    unreachable
--; CHECK:       [[BB8]]:
-+; CHECK:       [[BB9]]:
- ; CHECK-NEXT:    [[TMP1:%.*]] = call <8 x i32> @llvm.x86.avx512.vpermi2var.d.256(<8 x i32> [[X1]], <8 x i32> [[X0]], <8 x i32> [[X2]])
- ; CHECK-NEXT:    [[TMP10:%.*]] = bitcast i8 [[TMP11]] to <8 x i1>
- ; CHECK-NEXT:    [[TMP2:%.*]] = bitcast i8 [[X3]] to <8 x i1>
-@@ -2219,19 +2227,20 @@
- ; CHECK-SAME: <2 x double> [[X0:%.*]], <2 x i64> [[X1:%.*]], <2 x double> [[X2:%.*]]) #[[ATTR0]] {
- ; CHECK-NEXT:    [[TMP9:%.*]] = load <2 x i64>, ptr @__msan_param_tls, align 8
- ; CHECK-NEXT:    [[TMP4:%.*]] = load <2 x i64>, ptr inttoptr (i64 add (i64 ptrtoint (ptr @__msan_param_tls to i64), i64 32) to ptr), align 8
-+; CHECK-NEXT:    [[TMP6:%.*]] = load <2 x i64>, ptr inttoptr (i64 add (i64 ptrtoint (ptr @__msan_param_tls to i64), i64 16) to ptr), align 8
- ; CHECK-NEXT:    call void @llvm.donothing()
--; CHECK-NEXT:    [[TMP3:%.*]] = trunc <2 x i64> [[X1]] to <2 x i1>
-+; CHECK-NEXT:    [[TMP3:%.*]] = trunc <2 x i64> [[TMP6]] to <2 x i1>
- ; CHECK-NEXT:    [[TMP8:%.*]] = bitcast <2 x i64> [[TMP9]] to <2 x double>
- ; CHECK-NEXT:    [[TMP5:%.*]] = bitcast <2 x i64> [[TMP4]] to <2 x double>
- ; CHECK-NEXT:    [[TMP10:%.*]] = call <2 x double> @llvm.x86.avx512.vpermi2var.pd.128(<2 x double> [[TMP8]], <2 x i64> [[X1]], <2 x double> [[TMP5]])
- ; CHECK-NEXT:    [[TMP7:%.*]] = bitcast <2 x double> [[TMP10]] to <2 x i64>
- ; CHECK-NEXT:    [[TMP11:%.*]] = bitcast <2 x i1> [[TMP3]] to i2
- ; CHECK-NEXT:    [[_MSCMP:%.*]] = icmp ne i2 [[TMP11]], 0
--; CHECK-NEXT:    br i1 [[_MSCMP]], label %[[BB9:.*]], label %[[BB10:.*]], !prof [[PROF1]]
--; CHECK:       [[BB9]]:
-+; CHECK-NEXT:    br i1 [[_MSCMP]], label %[[BB10:.*]], label %[[BB11:.*]], !prof [[PROF1]]
-+; CHECK:       [[BB10]]:
- ; CHECK-NEXT:    call void @__msan_warning_noreturn() #[[ATTR6]]
- ; CHECK-NEXT:    unreachable
--; CHECK:       [[BB10]]:
-+; CHECK:       [[BB11]]:
- ; CHECK-NEXT:    [[TMP1:%.*]] = call <2 x double> @llvm.x86.avx512.vpermi2var.pd.128(<2 x double> [[X0]], <2 x i64> [[X1]], <2 x double> [[X2]])
- ; CHECK-NEXT:    store <2 x i64> [[TMP7]], ptr @__msan_retval_tls, align 8
- ; CHECK-NEXT:    ret <2 x double> [[TMP1]]
-@@ -2249,7 +2258,7 @@
- ; CHECK-NEXT:    [[TMP13:%.*]] = load <2 x i64>, ptr inttoptr (i64 add (i64 ptrtoint (ptr @__msan_param_tls to i64), i64 16) to ptr), align 8
- ; CHECK-NEXT:    [[TMP4:%.*]] = load i8, ptr inttoptr (i64 add (i64 ptrtoint (ptr @__msan_param_tls to i64), i64 48) to ptr), align 8
- ; CHECK-NEXT:    call void @llvm.donothing()
--; CHECK-NEXT:    [[TMP15:%.*]] = trunc <2 x i64> [[X1]] to <2 x i1>
-+; CHECK-NEXT:    [[TMP15:%.*]] = trunc <2 x i64> [[TMP13]] to <2 x i1>
- ; CHECK-NEXT:    [[TMP9:%.*]] = bitcast <2 x i64> [[TMP11]] to <2 x double>
- ; CHECK-NEXT:    [[TMP12:%.*]] = bitcast <2 x i64> [[TMP8]] to <2 x double>
- ; CHECK-NEXT:    [[TMP17:%.*]] = call <2 x double> @llvm.x86.avx512.vpermi2var.pd.128(<2 x double> [[TMP9]], <2 x i64> [[X1]], <2 x double> [[TMP12]])
-@@ -2293,19 +2302,20 @@
- ; CHECK-SAME: <4 x double> [[X0:%.*]], <4 x i64> [[X1:%.*]], <4 x double> [[X2:%.*]]) #[[ATTR0]] {
- ; CHECK-NEXT:    [[TMP9:%.*]] = load <4 x i64>, ptr @__msan_param_tls, align 8
- ; CHECK-NEXT:    [[TMP4:%.*]] = load <4 x i64>, ptr inttoptr (i64 add (i64 ptrtoint (ptr @__msan_param_tls to i64), i64 64) to ptr), align 8
-+; CHECK-NEXT:    [[TMP6:%.*]] = load <4 x i64>, ptr inttoptr (i64 add (i64 ptrtoint (ptr @__msan_param_tls to i64), i64 32) to ptr), align 8
- ; CHECK-NEXT:    call void @llvm.donothing()
--; CHECK-NEXT:    [[TMP3:%.*]] = trunc <4 x i64> [[X1]] to <4 x i2>
-+; CHECK-NEXT:    [[TMP3:%.*]] = trunc <4 x i64> [[TMP6]] to <4 x i2>
- ; CHECK-NEXT:    [[TMP8:%.*]] = bitcast <4 x i64> [[TMP9]] to <4 x double>
- ; CHECK-NEXT:    [[TMP5:%.*]] = bitcast <4 x i64> [[TMP4]] to <4 x double>
- ; CHECK-NEXT:    [[TMP10:%.*]] = call <4 x double> @llvm.x86.avx512.vpermi2var.pd.256(<4 x double> [[TMP8]], <4 x i64> [[X1]], <4 x double> [[TMP5]])
- ; CHECK-NEXT:    [[TMP7:%.*]] = bitcast <4 x double> [[TMP10]] to <4 x i64>
- ; CHECK-NEXT:    [[TMP11:%.*]] = bitcast <4 x i2> [[TMP3]] to i8
- ; CHECK-NEXT:    [[_MSCMP:%.*]] = icmp ne i8 [[TMP11]], 0
--; CHECK-NEXT:    br i1 [[_MSCMP]], label %[[BB9:.*]], label %[[BB10:.*]], !prof [[PROF1]]
--; CHECK:       [[BB9]]:
-+; CHECK-NEXT:    br i1 [[_MSCMP]], label %[[BB10:.*]], label %[[BB11:.*]], !prof [[PROF1]]
-+; CHECK:       [[BB10]]:
- ; CHECK-NEXT:    call void @__msan_warning_noreturn() #[[ATTR6]]
- ; CHECK-NEXT:    unreachable
--; CHECK:       [[BB10]]:
-+; CHECK:       [[BB11]]:
- ; CHECK-NEXT:    [[TMP1:%.*]] = call <4 x double> @llvm.x86.avx512.vpermi2var.pd.256(<4 x double> [[X0]], <4 x i64> [[X1]], <4 x double> [[X2]])
- ; CHECK-NEXT:    store <4 x i64> [[TMP7]], ptr @__msan_retval_tls, align 8
- ; CHECK-NEXT:    ret <4 x double> [[TMP1]]
-@@ -2323,7 +2333,7 @@
- ; CHECK-NEXT:    [[TMP13:%.*]] = load <4 x i64>, ptr inttoptr (i64 add (i64 ptrtoint (ptr @__msan_param_tls to i64), i64 32) to ptr), align 8
- ; CHECK-NEXT:    [[TMP4:%.*]] = load i8, ptr inttoptr (i64 add (i64 ptrtoint (ptr @__msan_param_tls to i64), i64 96) to ptr), align 8
- ; CHECK-NEXT:    call void @llvm.donothing()
--; CHECK-NEXT:    [[TMP15:%.*]] = trunc <4 x i64> [[X1]] to <4 x i2>
-+; CHECK-NEXT:    [[TMP15:%.*]] = trunc <4 x i64> [[TMP13]] to <4 x i2>
- ; CHECK-NEXT:    [[TMP9:%.*]] = bitcast <4 x i64> [[TMP11]] to <4 x double>
- ; CHECK-NEXT:    [[TMP12:%.*]] = bitcast <4 x i64> [[TMP8]] to <4 x double>
- ; CHECK-NEXT:    [[TMP17:%.*]] = call <4 x double> @llvm.x86.avx512.vpermi2var.pd.256(<4 x double> [[TMP9]], <4 x i64> [[X1]], <4 x double> [[TMP12]])
-@@ -2367,19 +2377,20 @@
- ; CHECK-SAME: <4 x float> [[X0:%.*]], <4 x i32> [[X1:%.*]], <4 x float> [[X2:%.*]]) #[[ATTR0]] {
- ; CHECK-NEXT:    [[TMP9:%.*]] = load <4 x i32>, ptr @__msan_param_tls, align 8
- ; CHECK-NEXT:    [[TMP4:%.*]] = load <4 x i32>, ptr inttoptr (i64 add (i64 ptrtoint (ptr @__msan_param_tls to i64), i64 32) to ptr), align 8
-+; CHECK-NEXT:    [[TMP6:%.*]] = load <4 x i32>, ptr inttoptr (i64 add (i64 ptrtoint (ptr @__msan_param_tls to i64), i64 16) to ptr), align 8
- ; CHECK-NEXT:    call void @llvm.donothing()
--; CHECK-NEXT:    [[TMP3:%.*]] = trunc <4 x i32> [[X1]] to <4 x i2>
-+; CHECK-NEXT:    [[TMP3:%.*]] = trunc <4 x i32> [[TMP6]] to <4 x i2>
- ; CHECK-NEXT:    [[TMP8:%.*]] = bitcast <4 x i32> [[TMP9]] to <4 x float>
- ; CHECK-NEXT:    [[TMP5:%.*]] = bitcast <4 x i32> [[TMP4]] to <4 x float>
- ; CHECK-NEXT:    [[TMP10:%.*]] = call <4 x float> @llvm.x86.avx512.vpermi2var.ps.128(<4 x float> [[TMP8]], <4 x i32> [[X1]], <4 x float> [[TMP5]])
- ; CHECK-NEXT:    [[TMP7:%.*]] = bitcast <4 x float> [[TMP10]] to <4 x i32>
- ; CHECK-NEXT:    [[TMP11:%.*]] = bitcast <4 x i2> [[TMP3]] to i8
- ; CHECK-NEXT:    [[_MSCMP:%.*]] = icmp ne i8 [[TMP11]], 0
--; CHECK-NEXT:    br i1 [[_MSCMP]], label %[[BB9:.*]], label %[[BB10:.*]], !prof [[PROF1]]
--; CHECK:       [[BB9]]:
-+; CHECK-NEXT:    br i1 [[_MSCMP]], label %[[BB10:.*]], label %[[BB11:.*]], !prof [[PROF1]]
-+; CHECK:       [[BB10]]:
- ; CHECK-NEXT:    call void @__msan_warning_noreturn() #[[ATTR6]]
- ; CHECK-NEXT:    unreachable
--; CHECK:       [[BB10]]:
-+; CHECK:       [[BB11]]:
- ; CHECK-NEXT:    [[TMP1:%.*]] = call <4 x float> @llvm.x86.avx512.vpermi2var.ps.128(<4 x float> [[X0]], <4 x i32> [[X1]], <4 x float> [[X2]])
- ; CHECK-NEXT:    store <4 x i32> [[TMP7]], ptr @__msan_retval_tls, align 8
- ; CHECK-NEXT:    ret <4 x float> [[TMP1]]
-@@ -2397,7 +2408,7 @@
- ; CHECK-NEXT:    [[TMP13:%.*]] = load <4 x i32>, ptr inttoptr (i64 add (i64 ptrtoint (ptr @__msan_param_tls to i64), i64 16) to ptr), align 8
- ; CHECK-NEXT:    [[TMP4:%.*]] = load i8, ptr inttoptr (i64 add (i64 ptrtoint (ptr @__msan_param_tls to i64), i64 48) to ptr), align 8
- ; CHECK-NEXT:    call void @llvm.donothing()
--; CHECK-NEXT:    [[TMP15:%.*]] = trunc <4 x i32> [[X1]] to <4 x i2>
-+; CHECK-NEXT:    [[TMP15:%.*]] = trunc <4 x i32> [[TMP13]] to <4 x i2>
- ; CHECK-NEXT:    [[TMP9:%.*]] = bitcast <4 x i32> [[TMP11]] to <4 x float>
- ; CHECK-NEXT:    [[TMP12:%.*]] = bitcast <4 x i32> [[TMP8]] to <4 x float>
- ; CHECK-NEXT:    [[TMP17:%.*]] = call <4 x float> @llvm.x86.avx512.vpermi2var.ps.128(<4 x float> [[TMP9]], <4 x i32> [[X1]], <4 x float> [[TMP12]])
-@@ -2445,7 +2456,7 @@
- ; CHECK-NEXT:    call void @llvm.donothing()
- ; CHECK-NEXT:    [[TMP14:%.*]] = bitcast <2 x i64> [[TMP11]] to <4 x i32>
- ; CHECK-NEXT:    [[X1CAST:%.*]] = bitcast <2 x i64> [[X1]] to <4 x i32>
--; CHECK-NEXT:    [[TMP8:%.*]] = trunc <4 x i32> [[X1CAST]] to <4 x i2>
-+; CHECK-NEXT:    [[TMP8:%.*]] = trunc <4 x i32> [[TMP14]] to <4 x i2>
- ; CHECK-NEXT:    [[TMP16:%.*]] = bitcast <4 x i32> [[TMP12]] to <4 x float>
- ; CHECK-NEXT:    [[TMP18:%.*]] = bitcast <4 x i32> [[TMP13]] to <4 x float>
- ; CHECK-NEXT:    [[TMP19:%.*]] = call <4 x float> @llvm.x86.avx512.vpermi2var.ps.128(<4 x float> [[TMP16]], <4 x i32> [[X1CAST]], <4 x float> [[TMP18]])
-@@ -2490,19 +2501,20 @@
- ; CHECK-SAME: <8 x float> [[X0:%.*]], <8 x i32> [[X1:%.*]], <8 x float> [[X2:%.*]]) #[[ATTR0]] {
- ; CHECK-NEXT:    [[TMP9:%.*]] = load <8 x i32>, ptr @__msan_param_tls, align 8
- ; CHECK-NEXT:    [[TMP4:%.*]] = load <8 x i32>, ptr inttoptr (i64 add (i64 ptrtoint (ptr @__msan_param_tls to i64), i64 64) to ptr), align 8
-+; CHECK-NEXT:    [[TMP6:%.*]] = load <8 x i32>, ptr inttoptr (i64 add (i64 ptrtoint (ptr @__msan_param_tls to i64), i64 32) to ptr), align 8
- ; CHECK-NEXT:    call void @llvm.donothing()
--; CHECK-NEXT:    [[TMP3:%.*]] = trunc <8 x i32> [[X1]] to <8 x i3>
-+; CHECK-NEXT:    [[TMP3:%.*]] = trunc <8 x i32> [[TMP6]] to <8 x i3>
- ; CHECK-NEXT:    [[TMP8:%.*]] = bitcast <8 x i32> [[TMP9]] to <8 x float>
- ; CHECK-NEXT:    [[TMP5:%.*]] = bitcast <8 x i32> [[TMP4]] to <8 x float>
- ; CHECK-NEXT:    [[TMP10:%.*]] = call <8 x float> @llvm.x86.avx512.vpermi2var.ps.256(<8 x float> [[TMP8]], <8 x i32> [[X1]], <8 x float> [[TMP5]])
- ; CHECK-NEXT:    [[TMP7:%.*]] = bitcast <8 x float> [[TMP10]] to <8 x i32>
- ; CHECK-NEXT:    [[TMP11:%.*]] = bitcast <8 x i3> [[TMP3]] to i24
- ; CHECK-NEXT:    [[_MSCMP:%.*]] = icmp ne i24 [[TMP11]], 0
--; CHECK-NEXT:    br i1 [[_MSCMP]], label %[[BB9:.*]], label %[[BB10:.*]], !prof [[PROF1]]
--; CHECK:       [[BB9]]:
-+; CHECK-NEXT:    br i1 [[_MSCMP]], label %[[BB10:.*]], label %[[BB11:.*]], !prof [[PROF1]]
-+; CHECK:       [[BB10]]:
- ; CHECK-NEXT:    call void @__msan_warning_noreturn() #[[ATTR6]]
- ; CHECK-NEXT:    unreachable
--; CHECK:       [[BB10]]:
-+; CHECK:       [[BB11]]:
- ; CHECK-NEXT:    [[TMP1:%.*]] = call <8 x float> @llvm.x86.avx512.vpermi2var.ps.256(<8 x float> [[X0]], <8 x i32> [[X1]], <8 x float> [[X2]])
- ; CHECK-NEXT:    store <8 x i32> [[TMP7]], ptr @__msan_retval_tls, align 8
- ; CHECK-NEXT:    ret <8 x float> [[TMP1]]
-@@ -2520,7 +2532,7 @@
- ; CHECK-NEXT:    [[TMP13:%.*]] = load <8 x i32>, ptr inttoptr (i64 add (i64 ptrtoint (ptr @__msan_param_tls to i64), i64 32) to ptr), align 8
- ; CHECK-NEXT:    [[TMP4:%.*]] = load i8, ptr inttoptr (i64 add (i64 ptrtoint (ptr @__msan_param_tls to i64), i64 96) to ptr), align 8
- ; CHECK-NEXT:    call void @llvm.donothing()
--; CHECK-NEXT:    [[TMP15:%.*]] = trunc <8 x i32> [[X1]] to <8 x i3>
-+; CHECK-NEXT:    [[TMP15:%.*]] = trunc <8 x i32> [[TMP13]] to <8 x i3>
- ; CHECK-NEXT:    [[TMP9:%.*]] = bitcast <8 x i32> [[TMP11]] to <8 x float>
- ; CHECK-NEXT:    [[TMP12:%.*]] = bitcast <8 x i32> [[TMP8]] to <8 x float>
- ; CHECK-NEXT:    [[TMP17:%.*]] = call <8 x float> @llvm.x86.avx512.vpermi2var.ps.256(<8 x float> [[TMP9]], <8 x i32> [[X1]], <8 x float> [[TMP12]])
-@@ -2561,16 +2573,17 @@
- ; CHECK-SAME: <2 x i64> [[X0:%.*]], <2 x i64> [[X1:%.*]], <2 x i64> [[X2:%.*]]) #[[ATTR0]] {
- ; CHECK-NEXT:    [[TMP6:%.*]] = load <2 x i64>, ptr @__msan_param_tls, align 8
- ; CHECK-NEXT:    [[TMP5:%.*]] = load <2 x i64>, ptr inttoptr (i64 add (i64 ptrtoint (ptr @__msan_param_tls to i64), i64 32) to ptr), align 8
-+; CHECK-NEXT:    [[TMP8:%.*]] = load <2 x i64>, ptr inttoptr (i64 add (i64 ptrtoint (ptr @__msan_param_tls to i64), i64 16) to ptr), align 8
- ; CHECK-NEXT:    call void @llvm.donothing()
--; CHECK-NEXT:    [[TMP3:%.*]] = trunc <2 x i64> [[X1]] to <2 x i1>
-+; CHECK-NEXT:    [[TMP3:%.*]] = trunc <2 x i64> [[TMP8]] to <2 x i1>
- ; CHECK-NEXT:    [[TMP4:%.*]] = call <2 x i64> @llvm.x86.avx512.vpermi2var.q.128(<2 x i64> [[TMP6]], <2 x i64> [[X1]], <2 x i64> [[TMP5]])
- ; CHECK-NEXT:    [[TMP7:%.*]] = bitcast <2 x i1> [[TMP3]] to i2
- ; CHECK-NEXT:    [[_MSCMP:%.*]] = icmp ne i2 [[TMP7]], 0
--; CHECK-NEXT:    br i1 [[_MSCMP]], label %[[BB6:.*]], label %[[BB7:.*]], !prof [[PROF1]]
--; CHECK:       [[BB6]]:
-+; CHECK-NEXT:    br i1 [[_MSCMP]], label %[[BB7:.*]], label %[[BB8:.*]], !prof [[PROF1]]
-+; CHECK:       [[BB7]]:
- ; CHECK-NEXT:    call void @__msan_warning_noreturn() #[[ATTR6]]
- ; CHECK-NEXT:    unreachable
--; CHECK:       [[BB7]]:
-+; CHECK:       [[BB8]]:
- ; CHECK-NEXT:    [[TMP1:%.*]] = call <2 x i64> @llvm.x86.avx512.vpermi2var.q.128(<2 x i64> [[X0]], <2 x i64> [[X1]], <2 x i64> [[X2]])
- ; CHECK-NEXT:    store <2 x i64> [[TMP4]], ptr @__msan_retval_tls, align 8
- ; CHECK-NEXT:    ret <2 x i64> [[TMP1]]
-@@ -2585,10 +2598,10 @@
- ; CHECK-SAME: <2 x i64> [[X0:%.*]], <2 x i64> [[X1:%.*]], <2 x i64> [[X2:%.*]], i8 [[X3:%.*]]) #[[ATTR0]] {
- ; CHECK-NEXT:    [[TMP8:%.*]] = load <2 x i64>, ptr @__msan_param_tls, align 8
- ; CHECK-NEXT:    [[TMP6:%.*]] = load <2 x i64>, ptr inttoptr (i64 add (i64 ptrtoint (ptr @__msan_param_tls to i64), i64 32) to ptr), align 8
--; CHECK-NEXT:    [[TMP11:%.*]] = load i8, ptr inttoptr (i64 add (i64 ptrtoint (ptr @__msan_param_tls to i64), i64 48) to ptr), align 8
- ; CHECK-NEXT:    [[TMP3:%.*]] = load <2 x i64>, ptr inttoptr (i64 add (i64 ptrtoint (ptr @__msan_param_tls to i64), i64 16) to ptr), align 8
-+; CHECK-NEXT:    [[TMP11:%.*]] = load i8, ptr inttoptr (i64 add (i64 ptrtoint (ptr @__msan_param_tls to i64), i64 48) to ptr), align 8
- ; CHECK-NEXT:    call void @llvm.donothing()
--; CHECK-NEXT:    [[TMP9:%.*]] = trunc <2 x i64> [[X1]] to <2 x i1>
-+; CHECK-NEXT:    [[TMP9:%.*]] = trunc <2 x i64> [[TMP3]] to <2 x i1>
- ; CHECK-NEXT:    [[TMP5:%.*]] = call <2 x i64> @llvm.x86.avx512.vpermi2var.q.128(<2 x i64> [[TMP8]], <2 x i64> [[X1]], <2 x i64> [[TMP6]])
- ; CHECK-NEXT:    [[TMP13:%.*]] = bitcast <2 x i1> [[TMP9]] to i2
- ; CHECK-NEXT:    [[_MSCMP:%.*]] = icmp ne i2 [[TMP13]], 0
-@@ -2623,16 +2636,17 @@
- ; CHECK-SAME: <2 x i64> [[X0:%.*]], <2 x i64> [[X1:%.*]], <2 x i64> [[X2:%.*]]) #[[ATTR0]] {
- ; CHECK-NEXT:    [[TMP6:%.*]] = load <2 x i64>, ptr inttoptr (i64 add (i64 ptrtoint (ptr @__msan_param_tls to i64), i64 16) to ptr), align 8
- ; CHECK-NEXT:    [[TMP5:%.*]] = load <2 x i64>, ptr inttoptr (i64 add (i64 ptrtoint (ptr @__msan_param_tls to i64), i64 32) to ptr), align 8
-+; CHECK-NEXT:    [[TMP8:%.*]] = load <2 x i64>, ptr @__msan_param_tls, align 8
- ; CHECK-NEXT:    call void @llvm.donothing()
--; CHECK-NEXT:    [[TMP3:%.*]] = trunc <2 x i64> [[X0]] to <2 x i1>
-+; CHECK-NEXT:    [[TMP3:%.*]] = trunc <2 x i64> [[TMP8]] to <2 x i1>
- ; CHECK-NEXT:    [[TMP4:%.*]] = call <2 x i64> @llvm.x86.avx512.vpermi2var.q.128(<2 x i64> [[TMP6]], <2 x i64> [[X0]], <2 x i64> [[TMP5]])
- ; CHECK-NEXT:    [[TMP7:%.*]] = bitcast <2 x i1> [[TMP3]] to i2
- ; CHECK-NEXT:    [[_MSCMP:%.*]] = icmp ne i2 [[TMP7]], 0
--; CHECK-NEXT:    br i1 [[_MSCMP]], label %[[BB6:.*]], label %[[BB7:.*]], !prof [[PROF1]]
--; CHECK:       [[BB6]]:
-+; CHECK-NEXT:    br i1 [[_MSCMP]], label %[[BB7:.*]], label %[[BB8:.*]], !prof [[PROF1]]
-+; CHECK:       [[BB7]]:
- ; CHECK-NEXT:    call void @__msan_warning_noreturn() #[[ATTR6]]
- ; CHECK-NEXT:    unreachable
--; CHECK:       [[BB7]]:
-+; CHECK:       [[BB8]]:
- ; CHECK-NEXT:    [[TMP1:%.*]] = call <2 x i64> @llvm.x86.avx512.vpermi2var.q.128(<2 x i64> [[X1]], <2 x i64> [[X0]], <2 x i64> [[X2]])
- ; CHECK-NEXT:    store <2 x i64> [[TMP4]], ptr @__msan_retval_tls, align 8
- ; CHECK-NEXT:    ret <2 x i64> [[TMP1]]
-@@ -2647,17 +2661,18 @@
- ; CHECK-SAME: <2 x i64> [[X0:%.*]], <2 x i64> [[X1:%.*]], <2 x i64> [[X2:%.*]], i8 [[X3:%.*]]) #[[ATTR0]] {
- ; CHECK-NEXT:    [[TMP8:%.*]] = load <2 x i64>, ptr inttoptr (i64 add (i64 ptrtoint (ptr @__msan_param_tls to i64), i64 16) to ptr), align 8
- ; CHECK-NEXT:    [[TMP6:%.*]] = load <2 x i64>, ptr inttoptr (i64 add (i64 ptrtoint (ptr @__msan_param_tls to i64), i64 32) to ptr), align 8
-+; CHECK-NEXT:    [[TMP3:%.*]] = load <2 x i64>, ptr @__msan_param_tls, align 8
- ; CHECK-NEXT:    [[TMP11:%.*]] = load i8, ptr inttoptr (i64 add (i64 ptrtoint (ptr @__msan_param_tls to i64), i64 48) to ptr), align 8
- ; CHECK-NEXT:    call void @llvm.donothing()
--; CHECK-NEXT:    [[TMP9:%.*]] = trunc <2 x i64> [[X0]] to <2 x i1>
-+; CHECK-NEXT:    [[TMP9:%.*]] = trunc <2 x i64> [[TMP3]] to <2 x i1>
- ; CHECK-NEXT:    [[TMP5:%.*]] = call <2 x i64> @llvm.x86.avx512.vpermi2var.q.128(<2 x i64> [[TMP8]], <2 x i64> [[X0]], <2 x i64> [[TMP6]])
- ; CHECK-NEXT:    [[TMP13:%.*]] = bitcast <2 x i1> [[TMP9]] to i2
- ; CHECK-NEXT:    [[_MSCMP:%.*]] = icmp ne i2 [[TMP13]], 0
--; CHECK-NEXT:    br i1 [[_MSCMP]], label %[[BB7:.*]], label %[[BB8:.*]], !prof [[PROF1]]
--; CHECK:       [[BB7]]:
-+; CHECK-NEXT:    br i1 [[_MSCMP]], label %[[BB8:.*]], label %[[BB9:.*]], !prof [[PROF1]]
-+; CHECK:       [[BB8]]:
- ; CHECK-NEXT:    call void @__msan_warning_noreturn() #[[ATTR6]]
- ; CHECK-NEXT:    unreachable
--; CHECK:       [[BB8]]:
-+; CHECK:       [[BB9]]:
- ; CHECK-NEXT:    [[TMP1:%.*]] = call <2 x i64> @llvm.x86.avx512.vpermi2var.q.128(<2 x i64> [[X1]], <2 x i64> [[X0]], <2 x i64> [[X2]])
- ; CHECK-NEXT:    [[TMP10:%.*]] = bitcast i8 [[TMP11]] to <8 x i1>
- ; CHECK-NEXT:    [[TMP2:%.*]] = bitcast i8 [[X3]] to <8 x i1>
-@@ -2685,17 +2700,18 @@
- ; CHECK-SAME: <2 x i64> [[X0:%.*]], <2 x i64> [[X1:%.*]], <2 x i64> [[X2:%.*]], i8 [[X3:%.*]]) #[[ATTR0]] {
- ; CHECK-NEXT:    [[TMP8:%.*]] = load <2 x i64>, ptr inttoptr (i64 add (i64 ptrtoint (ptr @__msan_param_tls to i64), i64 16) to ptr), align 8
- ; CHECK-NEXT:    [[TMP9:%.*]] = load <2 x i64>, ptr inttoptr (i64 add (i64 ptrtoint (ptr @__msan_param_tls to i64), i64 32) to ptr), align 8
-+; CHECK-NEXT:    [[TMP3:%.*]] = load <2 x i64>, ptr @__msan_param_tls, align 8
- ; CHECK-NEXT:    [[TMP11:%.*]] = load i8, ptr inttoptr (i64 add (i64 ptrtoint (ptr @__msan_param_tls to i64), i64 48) to ptr), align 8
- ; CHECK-NEXT:    call void @llvm.donothing()
--; CHECK-NEXT:    [[TMP14:%.*]] = trunc <2 x i64> [[X0]] to <2 x i1>
-+; CHECK-NEXT:    [[TMP14:%.*]] = trunc <2 x i64> [[TMP3]] to <2 x i1>
- ; CHECK-NEXT:    [[TMP13:%.*]] = call <2 x i64> @llvm.x86.avx512.vpermi2var.q.128(<2 x i64> [[TMP8]], <2 x i64> [[X0]], <2 x i64> [[TMP9]])
- ; CHECK-NEXT:    [[TMP15:%.*]] = bitcast <2 x i1> [[TMP14]] to i2
- ; CHECK-NEXT:    [[_MSCMP:%.*]] = icmp ne i2 [[TMP15]], 0
--; CHECK-NEXT:    br i1 [[_MSCMP]], label %[[BB7:.*]], label %[[BB8:.*]], !prof [[PROF1]]
--; CHECK:       [[BB7]]:
-+; CHECK-NEXT:    br i1 [[_MSCMP]], label %[[BB8:.*]], label %[[BB9:.*]], !prof [[PROF1]]
-+; CHECK:       [[BB8]]:
- ; CHECK-NEXT:    call void @__msan_warning_noreturn() #[[ATTR6]]
- ; CHECK-NEXT:    unreachable
--; CHECK:       [[BB8]]:
-+; CHECK:       [[BB9]]:
- ; CHECK-NEXT:    [[TMP1:%.*]] = call <2 x i64> @llvm.x86.avx512.vpermi2var.q.128(<2 x i64> [[X1]], <2 x i64> [[X0]], <2 x i64> [[X2]])
- ; CHECK-NEXT:    [[TMP10:%.*]] = bitcast i8 [[TMP11]] to <8 x i1>
- ; CHECK-NEXT:    [[TMP2:%.*]] = bitcast i8 [[X3]] to <8 x i1>
-@@ -2724,16 +2740,17 @@
- ; CHECK-SAME: <4 x i64> [[X0:%.*]], <4 x i64> [[X1:%.*]], <4 x i64> [[X2:%.*]]) #[[ATTR0]] {
- ; CHECK-NEXT:    [[TMP6:%.*]] = load <4 x i64>, ptr @__msan_param_tls, align 8
- ; CHECK-NEXT:    [[TMP5:%.*]] = load <4 x i64>, ptr inttoptr (i64 add (i64 ptrtoint (ptr @__msan_param_tls to i64), i64 64) to ptr), align 8
-+; CHECK-NEXT:    [[TMP8:%.*]] = load <4 x i64>, ptr inttoptr (i64 add (i64 ptrtoint (ptr @__msan_param_tls to i64), i64 32) to ptr), align 8
- ; CHECK-NEXT:    call void @llvm.donothing()
--; CHECK-NEXT:    [[TMP3:%.*]] = trunc <4 x i64> [[X1]] to <4 x i2>
-+; CHECK-NEXT:    [[TMP3:%.*]] = trunc <4 x i64> [[TMP8]] to <4 x i2>
- ; CHECK-NEXT:    [[TMP4:%.*]] = call <4 x i64> @llvm.x86.avx512.vpermi2var.q.256(<4 x i64> [[TMP6]], <4 x i64> [[X1]], <4 x i64> [[TMP5]])
- ; CHECK-NEXT:    [[TMP7:%.*]] = bitcast <4 x i2> [[TMP3]] to i8
- ; CHECK-NEXT:    [[_MSCMP:%.*]] = icmp ne i8 [[TMP7]], 0
--; CHECK-NEXT:    br i1 [[_MSCMP]], label %[[BB6:.*]], label %[[BB7:.*]], !prof [[PROF1]]
--; CHECK:       [[BB6]]:
-+; CHECK-NEXT:    br i1 [[_MSCMP]], label %[[BB7:.*]], label %[[BB8:.*]], !prof [[PROF1]]
-+; CHECK:       [[BB7]]:
- ; CHECK-NEXT:    call void @__msan_warning_noreturn() #[[ATTR6]]
- ; CHECK-NEXT:    unreachable
--; CHECK:       [[BB7]]:
-+; CHECK:       [[BB8]]:
- ; CHECK-NEXT:    [[TMP1:%.*]] = call <4 x i64> @llvm.x86.avx512.vpermi2var.q.256(<4 x i64> [[X0]], <4 x i64> [[X1]], <4 x i64> [[X2]])
- ; CHECK-NEXT:    store <4 x i64> [[TMP4]], ptr @__msan_retval_tls, align 8
- ; CHECK-NEXT:    ret <4 x i64> [[TMP1]]
-@@ -2748,10 +2765,10 @@
- ; CHECK-SAME: <4 x i64> [[X0:%.*]], <4 x i64> [[X1:%.*]], <4 x i64> [[X2:%.*]], i8 [[X3:%.*]]) #[[ATTR0]] {
- ; CHECK-NEXT:    [[TMP8:%.*]] = load <4 x i64>, ptr @__msan_param_tls, align 8
- ; CHECK-NEXT:    [[TMP6:%.*]] = load <4 x i64>, ptr inttoptr (i64 add (i64 ptrtoint (ptr @__msan_param_tls to i64), i64 64) to ptr), align 8
--; CHECK-NEXT:    [[TMP11:%.*]] = load i8, ptr inttoptr (i64 add (i64 ptrtoint (ptr @__msan_param_tls to i64), i64 96) to ptr), align 8
- ; CHECK-NEXT:    [[TMP3:%.*]] = load <4 x i64>, ptr inttoptr (i64 add (i64 ptrtoint (ptr @__msan_param_tls to i64), i64 32) to ptr), align 8
-+; CHECK-NEXT:    [[TMP11:%.*]] = load i8, ptr inttoptr (i64 add (i64 ptrtoint (ptr @__msan_param_tls to i64), i64 96) to ptr), align 8
- ; CHECK-NEXT:    call void @llvm.donothing()
--; CHECK-NEXT:    [[TMP9:%.*]] = trunc <4 x i64> [[X1]] to <4 x i2>
-+; CHECK-NEXT:    [[TMP9:%.*]] = trunc <4 x i64> [[TMP3]] to <4 x i2>
- ; CHECK-NEXT:    [[TMP5:%.*]] = call <4 x i64> @llvm.x86.avx512.vpermi2var.q.256(<4 x i64> [[TMP8]], <4 x i64> [[X1]], <4 x i64> [[TMP6]])
- ; CHECK-NEXT:    [[TMP13:%.*]] = bitcast <4 x i2> [[TMP9]] to i8
- ; CHECK-NEXT:    [[_MSCMP:%.*]] = icmp ne i8 [[TMP13]], 0
-@@ -2786,16 +2803,17 @@
- ; CHECK-SAME: <4 x i64> [[X0:%.*]], <4 x i64> [[X1:%.*]], <4 x i64> [[X2:%.*]]) #[[ATTR0]] {
- ; CHECK-NEXT:    [[TMP6:%.*]] = load <4 x i64>, ptr inttoptr (i64 add (i64 ptrtoint (ptr @__msan_param_tls to i64), i64 32) to ptr), align 8
- ; CHECK-NEXT:    [[TMP5:%.*]] = load <4 x i64>, ptr inttoptr (i64 add (i64 ptrtoint (ptr @__msan_param_tls to i64), i64 64) to ptr), align 8
-+; CHECK-NEXT:    [[TMP8:%.*]] = load <4 x i64>, ptr @__msan_param_tls, align 8
- ; CHECK-NEXT:    call void @llvm.donothing()
--; CHECK-NEXT:    [[TMP3:%.*]] = trunc <4 x i64> [[X0]] to <4 x i2>
-+; CHECK-NEXT:    [[TMP3:%.*]] = trunc <4 x i64> [[TMP8]] to <4 x i2>
- ; CHECK-NEXT:    [[TMP4:%.*]] = call <4 x i64> @llvm.x86.avx512.vpermi2var.q.256(<4 x i64> [[TMP6]], <4 x i64> [[X0]], <4 x i64> [[TMP5]])
- ; CHECK-NEXT:    [[TMP7:%.*]] = bitcast <4 x i2> [[TMP3]] to i8
- ; CHECK-NEXT:    [[_MSCMP:%.*]] = icmp ne i8 [[TMP7]], 0
--; CHECK-NEXT:    br i1 [[_MSCMP]], label %[[BB6:.*]], label %[[BB7:.*]], !prof [[PROF1]]
--; CHECK:       [[BB6]]:
-+; CHECK-NEXT:    br i1 [[_MSCMP]], label %[[BB7:.*]], label %[[BB8:.*]], !prof [[PROF1]]
-+; CHECK:       [[BB7]]:
- ; CHECK-NEXT:    call void @__msan_warning_noreturn() #[[ATTR6]]
- ; CHECK-NEXT:    unreachable
--; CHECK:       [[BB7]]:
-+; CHECK:       [[BB8]]:
- ; CHECK-NEXT:    [[TMP1:%.*]] = call <4 x i64> @llvm.x86.avx512.vpermi2var.q.256(<4 x i64> [[X1]], <4 x i64> [[X0]], <4 x i64> [[X2]])
- ; CHECK-NEXT:    store <4 x i64> [[TMP4]], ptr @__msan_retval_tls, align 8
- ; CHECK-NEXT:    ret <4 x i64> [[TMP1]]
-@@ -2810,17 +2828,18 @@
- ; CHECK-SAME: <4 x i64> [[X0:%.*]], <4 x i64> [[X1:%.*]], <4 x i64> [[X2:%.*]], i8 [[X3:%.*]]) #[[ATTR0]] {
- ; CHECK-NEXT:    [[TMP8:%.*]] = load <4 x i64>, ptr inttoptr (i64 add (i64 ptrtoint (ptr @__msan_param_tls to i64), i64 32) to ptr), align 8
- ; CHECK-NEXT:    [[TMP6:%.*]] = load <4 x i64>, ptr inttoptr (i64 add (i64 ptrtoint (ptr @__msan_param_tls to i64), i64 64) to ptr), align 8
-+; CHECK-NEXT:    [[TMP3:%.*]] = load <4 x i64>, ptr @__msan_param_tls, align 8
- ; CHECK-NEXT:    [[TMP11:%.*]] = load i8, ptr inttoptr (i64 add (i64 ptrtoint (ptr @__msan_param_tls to i64), i64 96) to ptr), align 8
- ; CHECK-NEXT:    call void @llvm.donothing()
--; CHECK-NEXT:    [[TMP9:%.*]] = trunc <4 x i64> [[X0]] to <4 x i2>
-+; CHECK-NEXT:    [[TMP9:%.*]] = trunc <4 x i64> [[TMP3]] to <4 x i2>
- ; CHECK-NEXT:    [[TMP5:%.*]] = call <4 x i64> @llvm.x86.avx512.vpermi2var.q.256(<4 x i64> [[TMP8]], <4 x i64> [[X0]], <4 x i64> [[TMP6]])
- ; CHECK-NEXT:    [[TMP13:%.*]] = bitcast <4 x i2> [[TMP9]] to i8
- ; CHECK-NEXT:    [[_MSCMP:%.*]] = icmp ne i8 [[TMP13]], 0
--; CHECK-NEXT:    br i1 [[_MSCMP]], label %[[BB7:.*]], label %[[BB8:.*]], !prof [[PROF1]]
--; CHECK:       [[BB7]]:
-+; CHECK-NEXT:    br i1 [[_MSCMP]], label %[[BB8:.*]], label %[[BB9:.*]], !prof [[PROF1]]
-+; CHECK:       [[BB8]]:
- ; CHECK-NEXT:    call void @__msan_warning_noreturn() #[[ATTR6]]
- ; CHECK-NEXT:    unreachable
--; CHECK:       [[BB8]]:
-+; CHECK:       [[BB9]]:
- ; CHECK-NEXT:    [[TMP1:%.*]] = call <4 x i64> @llvm.x86.avx512.vpermi2var.q.256(<4 x i64> [[X1]], <4 x i64> [[X0]], <4 x i64> [[X2]])
- ; CHECK-NEXT:    [[TMP10:%.*]] = bitcast i8 [[TMP11]] to <8 x i1>
- ; CHECK-NEXT:    [[TMP2:%.*]] = bitcast i8 [[X3]] to <8 x i1>
-@@ -2848,17 +2867,18 @@
- ; CHECK-SAME: <4 x i64> [[X0:%.*]], <4 x i64> [[X1:%.*]], <4 x i64> [[X2:%.*]], i8 [[X3:%.*]]) #[[ATTR0]] {
- ; CHECK-NEXT:    [[TMP8:%.*]] = load <4 x i64>, ptr inttoptr (i64 add (i64 ptrtoint (ptr @__msan_param_tls to i64), i64 32) to ptr), align 8
- ; CHECK-NEXT:    [[TMP9:%.*]] = load <4 x i64>, ptr inttoptr (i64 add (i64 ptrtoint (ptr @__msan_param_tls to i64), i64 64) to ptr), align 8
-+; CHECK-NEXT:    [[TMP3:%.*]] = load <4 x i64>, ptr @__msan_param_tls, align 8
- ; CHECK-NEXT:    [[TMP11:%.*]] = load i8, ptr inttoptr (i64 add (i64 ptrtoint (ptr @__msan_param_tls to i64), i64 96) to ptr), align 8
- ; CHECK-NEXT:    call void @llvm.donothing()
--; CHECK-NEXT:    [[TMP14:%.*]] = trunc <4 x i64> [[X0]] to <4 x i2>
-+; CHECK-NEXT:    [[TMP14:%.*]] = trunc <4 x i64> [[TMP3]] to <4 x i2>
- ; CHECK-NEXT:    [[TMP13:%.*]] = call <4 x i64> @llvm.x86.avx512.vpermi2var.q.256(<4 x i64> [[TMP8]], <4 x i64> [[X0]], <4 x i64> [[TMP9]])
- ; CHECK-NEXT:    [[TMP15:%.*]] = bitcast <4 x i2> [[TMP14]] to i8
- ; CHECK-NEXT:    [[_MSCMP:%.*]] = icmp ne i8 [[TMP15]], 0
--; CHECK-NEXT:    br i1 [[_MSCMP]], label %[[BB7:.*]], label %[[BB8:.*]], !prof [[PROF1]]
--; CHECK:       [[BB7]]:
-+; CHECK-NEXT:    br i1 [[_MSCMP]], label %[[BB8:.*]], label %[[BB9:.*]], !prof [[PROF1]]
-+; CHECK:       [[BB8]]:
- ; CHECK-NEXT:    call void @__msan_warning_noreturn() #[[ATTR6]]
- ; CHECK-NEXT:    unreachable
--; CHECK:       [[BB8]]:
-+; CHECK:       [[BB9]]:
- ; CHECK-NEXT:    [[TMP1:%.*]] = call <4 x i64> @llvm.x86.avx512.vpermi2var.q.256(<4 x i64> [[X1]], <4 x i64> [[X0]], <4 x i64> [[X2]])
- ; CHECK-NEXT:    [[TMP10:%.*]] = bitcast i8 [[TMP11]] to <8 x i1>
- ; CHECK-NEXT:    [[TMP2:%.*]] = bitcast i8 [[X3]] to <8 x i1>
-diff -ruN --strip-trailing-cr a/llvm/test/Instrumentation/MemorySanitizer/X86/avx-intrinsics-x86.ll b/llvm/test/Instrumentation/MemorySanitizer/X86/avx-intrinsics-x86.ll
---- a/llvm/test/Instrumentation/MemorySanitizer/X86/avx-intrinsics-x86.ll
-+++ b/llvm/test/Instrumentation/MemorySanitizer/X86/avx-intrinsics-x86.ll
-@@ -948,19 +948,20 @@
- define <2 x double> @test_x86_avx_vpermilvar_pd(<2 x double> %a0, <2 x i64> %a1) #0 {
- ; CHECK-LABEL: @test_x86_avx_vpermilvar_pd(
- ; CHECK-NEXT:    [[TMP1:%.*]] = load <2 x i64>, ptr @__msan_param_tls, align 8
-+; CHECK-NEXT:    [[A1:%.*]] = load <2 x i64>, ptr inttoptr (i64 add (i64 ptrtoint (ptr @__msan_param_tls to i64), i64 16) to ptr), align 8
- ; CHECK-NEXT:    call void @llvm.donothing()
--; CHECK-NEXT:    [[TMP2:%.*]] = trunc <2 x i64> [[A1:%.*]] to <2 x i1>
-+; CHECK-NEXT:    [[TMP2:%.*]] = trunc <2 x i64> [[A1]] to <2 x i1>
- ; CHECK-NEXT:    [[A0:%.*]] = bitcast <2 x i64> [[TMP1]] to <2 x double>
--; CHECK-NEXT:    [[RES:%.*]] = call <2 x double> @llvm.x86.avx.vpermilvar.pd(<2 x double> [[A0]], <2 x i64> [[A1]])
-+; CHECK-NEXT:    [[RES:%.*]] = call <2 x double> @llvm.x86.avx.vpermilvar.pd(<2 x double> [[A0]], <2 x i64> [[A2:%.*]])
- ; CHECK-NEXT:    [[TMP4:%.*]] = bitcast <2 x double> [[RES]] to <2 x i64>
- ; CHECK-NEXT:    [[TMP6:%.*]] = bitcast <2 x i1> [[TMP2]] to i2
- ; CHECK-NEXT:    [[_MSCMP:%.*]] = icmp ne i2 [[TMP6]], 0
--; CHECK-NEXT:    br i1 [[_MSCMP]], label [[TMP7:%.*]], label [[TMP8:%.*]], !prof [[PROF1]]
--; CHECK:       7:
-+; CHECK-NEXT:    br i1 [[_MSCMP]], label [[TMP8:%.*]], label [[TMP9:%.*]], !prof [[PROF1]]
-+; CHECK:       8:
- ; CHECK-NEXT:    call void @__msan_warning_noreturn()
- ; CHECK-NEXT:    unreachable
--; CHECK:       8:
--; CHECK-NEXT:    [[RES1:%.*]] = call <2 x double> @llvm.x86.avx.vpermilvar.pd(<2 x double> [[A2:%.*]], <2 x i64> [[A1]])
-+; CHECK:       9:
-+; CHECK-NEXT:    [[RES1:%.*]] = call <2 x double> @llvm.x86.avx.vpermilvar.pd(<2 x double> [[A3:%.*]], <2 x i64> [[A2]])
- ; CHECK-NEXT:    store <2 x i64> [[TMP4]], ptr @__msan_retval_tls, align 8
- ; CHECK-NEXT:    ret <2 x double> [[RES1]]
- ;
-@@ -973,19 +974,20 @@
- define <4 x double> @test_x86_avx_vpermilvar_pd_256(<4 x double> %a0, <4 x i64> %a1) #0 {
- ; CHECK-LABEL: @test_x86_avx_vpermilvar_pd_256(
- ; CHECK-NEXT:    [[TMP1:%.*]] = load <4 x i64>, ptr @__msan_param_tls, align 8
-+; CHECK-NEXT:    [[A1:%.*]] = load <4 x i64>, ptr inttoptr (i64 add (i64 ptrtoint (ptr @__msan_param_tls to i64), i64 32) to ptr), align 8
- ; CHECK-NEXT:    call void @llvm.donothing()
--; CHECK-NEXT:    [[TMP2:%.*]] = trunc <4 x i64> [[A1:%.*]] to <4 x i2>
-+; CHECK-NEXT:    [[TMP2:%.*]] = trunc <4 x i64> [[A1]] to <4 x i2>
- ; CHECK-NEXT:    [[A0:%.*]] = bitcast <4 x i64> [[TMP1]] to <4 x double>
--; CHECK-NEXT:    [[RES:%.*]] = call <4 x double> @llvm.x86.avx.vpermilvar.pd.256(<4 x double> [[A0]], <4 x i64> [[A1]])
-+; CHECK-NEXT:    [[RES:%.*]] = call <4 x double> @llvm.x86.avx.vpermilvar.pd.256(<4 x double> [[A0]], <4 x i64> [[A2:%.*]])
- ; CHECK-NEXT:    [[TMP4:%.*]] = bitcast <4 x double> [[RES]] to <4 x i64>
- ; CHECK-NEXT:    [[TMP6:%.*]] = bitcast <4 x i2> [[TMP2]] to i8
- ; CHECK-NEXT:    [[_MSCMP:%.*]] = icmp ne i8 [[TMP6]], 0
--; CHECK-NEXT:    br i1 [[_MSCMP]], label [[TMP7:%.*]], label [[TMP8:%.*]], !prof [[PROF1]]
--; CHECK:       7:
-+; CHECK-NEXT:    br i1 [[_MSCMP]], label [[TMP8:%.*]], label [[TMP9:%.*]], !prof [[PROF1]]
-+; CHECK:       8:
- ; CHECK-NEXT:    call void @__msan_warning_noreturn()
- ; CHECK-NEXT:    unreachable
--; CHECK:       8:
--; CHECK-NEXT:    [[RES1:%.*]] = call <4 x double> @llvm.x86.avx.vpermilvar.pd.256(<4 x double> [[A2:%.*]], <4 x i64> [[A1]])
-+; CHECK:       9:
-+; CHECK-NEXT:    [[RES1:%.*]] = call <4 x double> @llvm.x86.avx.vpermilvar.pd.256(<4 x double> [[A3:%.*]], <4 x i64> [[A2]])
- ; CHECK-NEXT:    store <4 x i64> [[TMP4]], ptr @__msan_retval_tls, align 8
- ; CHECK-NEXT:    ret <4 x double> [[RES1]]
- ;
-@@ -1012,19 +1014,20 @@
- define <4 x float> @test_x86_avx_vpermilvar_ps(<4 x float> %a0, <4 x i32> %a1) #0 {
- ; CHECK-LABEL: @test_x86_avx_vpermilvar_ps(
- ; CHECK-NEXT:    [[TMP1:%.*]] = load <4 x i32>, ptr @__msan_param_tls, align 8
-+; CHECK-NEXT:    [[A1:%.*]] = load <4 x i32>, ptr inttoptr (i64 add (i64 ptrtoint (ptr @__msan_param_tls to i64), i64 16) to ptr), align 8
- ; CHECK-NEXT:    call void @llvm.donothing()
--; CHECK-NEXT:    [[TMP2:%.*]] = trunc <4 x i32> [[A1:%.*]] to <4 x i2>
-+; CHECK-NEXT:    [[TMP2:%.*]] = trunc <4 x i32> [[A1]] to <4 x i2>
- ; CHECK-NEXT:    [[A0:%.*]] = bitcast <4 x i32> [[TMP1]] to <4 x float>
--; CHECK-NEXT:    [[RES:%.*]] = call <4 x float> @llvm.x86.avx.vpermilvar.ps(<4 x float> [[A0]], <4 x i32> [[A1]])
-+; CHECK-NEXT:    [[RES:%.*]] = call <4 x float> @llvm.x86.avx.vpermilvar.ps(<4 x float> [[A0]], <4 x i32> [[A2:%.*]])
- ; CHECK-NEXT:    [[TMP4:%.*]] = bitcast <4 x float> [[RES]] to <4 x i32>
- ; CHECK-NEXT:    [[TMP6:%.*]] = bitcast <4 x i2> [[TMP2]] to i8
- ; CHECK-NEXT:    [[_MSCMP:%.*]] = icmp ne i8 [[TMP6]], 0
--; CHECK-NEXT:    br i1 [[_MSCMP]], label [[TMP7:%.*]], label [[TMP8:%.*]], !prof [[PROF1]]
--; CHECK:       7:
-+; CHECK-NEXT:    br i1 [[_MSCMP]], label [[TMP8:%.*]], label [[TMP9:%.*]], !prof [[PROF1]]
-+; CHECK:       8:
- ; CHECK-NEXT:    call void @__msan_warning_noreturn()
- ; CHECK-NEXT:    unreachable
--; CHECK:       8:
--; CHECK-NEXT:    [[RES1:%.*]] = call <4 x float> @llvm.x86.avx.vpermilvar.ps(<4 x float> [[A2:%.*]], <4 x i32> [[A1]])
-+; CHECK:       9:
-+; CHECK-NEXT:    [[RES1:%.*]] = call <4 x float> @llvm.x86.avx.vpermilvar.ps(<4 x float> [[A3:%.*]], <4 x i32> [[A2]])
- ; CHECK-NEXT:    store <4 x i32> [[TMP4]], ptr @__msan_retval_tls, align 8
- ; CHECK-NEXT:    ret <4 x float> [[RES1]]
- ;
-@@ -1047,7 +1050,7 @@
- ; CHECK-NEXT:    [[TMP6:%.*]] = xor i64 [[TMP5]], 87960930222080
- ; CHECK-NEXT:    [[TMP7:%.*]] = inttoptr i64 [[TMP6]] to ptr
- ; CHECK-NEXT:    [[_MSLD:%.*]] = load <4 x i32>, ptr [[TMP7]], align 16
--; CHECK-NEXT:    [[TMP8:%.*]] = trunc <4 x i32> [[A2]] to <4 x i2>
-+; CHECK-NEXT:    [[TMP8:%.*]] = trunc <4 x i32> [[_MSLD]] to <4 x i2>
- ; CHECK-NEXT:    [[A0:%.*]] = bitcast <4 x i32> [[TMP2]] to <4 x float>
- ; CHECK-NEXT:    [[RES:%.*]] = call <4 x float> @llvm.x86.avx.vpermilvar.ps(<4 x float> [[A0]], <4 x i32> [[A2]])
- ; CHECK-NEXT:    [[TMP10:%.*]] = bitcast <4 x float> [[RES]] to <4 x i32>
-@@ -1072,19 +1075,20 @@
- define <8 x float> @test_x86_avx_vpermilvar_ps_256(<8 x float> %a0, <8 x i32> %a1) #0 {
- ; CHECK-LABEL: @test_x86_avx_vpermilvar_ps_256(
- ; CHECK-NEXT:    [[TMP1:%.*]] = load <8 x i32>, ptr @__msan_param_tls, align 8
-+; CHECK-NEXT:    [[A1:%.*]] = load <8 x i32>, ptr inttoptr (i64 add (i64 ptrtoint (ptr @__msan_param_tls to i64), i64 32) to ptr), align 8
- ; CHECK-NEXT:    call void @llvm.donothing()
--; CHECK-NEXT:    [[TMP2:%.*]] = trunc <8 x i32> [[A1:%.*]] to <8 x i3>
-+; CHECK-NEXT:    [[TMP2:%.*]] = trunc <8 x i32> [[A1]] to <8 x i3>
- ; CHECK-NEXT:    [[A0:%.*]] = bitcast <8 x i32> [[TMP1]] to <8 x float>
--; CHECK-NEXT:    [[RES:%.*]] = call <8 x float> @llvm.x86.avx.vpermilvar.ps.256(<8 x float> [[A0]], <8 x i32> [[A1]])
-+; CHECK-NEXT:    [[RES:%.*]] = call <8 x float> @llvm.x86.avx.vpermilvar.ps.256(<8 x float> [[A0]], <8 x i32> [[A2:%.*]])
- ; CHECK-NEXT:    [[TMP4:%.*]] = bitcast <8 x float> [[RES]] to <8 x i32>
- ; CHECK-NEXT:    [[TMP6:%.*]] = bitcast <8 x i3> [[TMP2]] to i24
- ; CHECK-NEXT:    [[_MSCMP:%.*]] = icmp ne i24 [[TMP6]], 0
--; CHECK-NEXT:    br i1 [[_MSCMP]], label [[TMP7:%.*]], label [[TMP8:%.*]], !prof [[PROF1]]
--; CHECK:       7:
-+; CHECK-NEXT:    br i1 [[_MSCMP]], label [[TMP8:%.*]], label [[TMP9:%.*]], !prof [[PROF1]]
-+; CHECK:       8:
- ; CHECK-NEXT:    call void @__msan_warning_noreturn()
- ; CHECK-NEXT:    unreachable
--; CHECK:       8:
--; CHECK-NEXT:    [[RES1:%.*]] = call <8 x float> @llvm.x86.avx.vpermilvar.ps.256(<8 x float> [[A2:%.*]], <8 x i32> [[A1]])
-+; CHECK:       9:
-+; CHECK-NEXT:    [[RES1:%.*]] = call <8 x float> @llvm.x86.avx.vpermilvar.ps.256(<8 x float> [[A3:%.*]], <8 x i32> [[A2]])
- ; CHECK-NEXT:    store <8 x i32> [[TMP4]], ptr @__msan_retval_tls, align 8
- ; CHECK-NEXT:    ret <8 x float> [[RES1]]
- ;
-diff -ruN --strip-trailing-cr a/llvm/test/Instrumentation/MemorySanitizer/X86/x86-vpermi2.ll b/llvm/test/Instrumentation/MemorySanitizer/X86/x86-vpermi2.ll
---- a/llvm/test/Instrumentation/MemorySanitizer/X86/x86-vpermi2.ll
-+++ b/llvm/test/Instrumentation/MemorySanitizer/X86/x86-vpermi2.ll
-@@ -53,7 +53,7 @@
- ; CHECK-NEXT:    [[TMP8:%.*]] = or <2 x i64> [[TMP5]], [[TMP2]]
- ; CHECK-NEXT:    [[TMP9:%.*]] = or <2 x i64> [[TMP8]], [[TMP7]]
- ; CHECK-NEXT:    [[T:%.*]] = or <2 x i64> [[M]], <i64 0, i64 4>
--; CHECK-NEXT:    [[TMP10:%.*]] = trunc <2 x i64> [[T]] to <2 x i1>
-+; CHECK-NEXT:    [[TMP10:%.*]] = trunc <2 x i64> [[TMP9]] to <2 x i1>
- ; CHECK-NEXT:    [[_MSPROP1:%.*]] = call <2 x i64> @llvm.x86.avx512.vpermi2var.q.128(<2 x i64> [[TMP6]], <2 x i64> [[T]], <2 x i64> [[TMP3]])
- ; CHECK-NEXT:    [[TMP12:%.*]] = bitcast <2 x i1> [[TMP10]] to i2
- ; CHECK-NEXT:    [[_MSCMP:%.*]] = icmp ne i2 [[TMP12]], 0
-@@ -85,7 +85,7 @@
- ; CHECK-NEXT:    [[TMP8:%.*]] = or <2 x i64> [[TMP5]], [[TMP2]]
- ; CHECK-NEXT:    [[TMP9:%.*]] = or <2 x i64> [[TMP8]], [[TMP7]]
- ; CHECK-NEXT:    [[T:%.*]] = or <2 x i64> [[M]], <i64 0, i64 2>
--; CHECK-NEXT:    [[TMP10:%.*]] = trunc <2 x i64> [[T]] to <2 x i1>
-+; CHECK-NEXT:    [[TMP10:%.*]] = trunc <2 x i64> [[TMP9]] to <2 x i1>
- ; CHECK-NEXT:    [[_MSPROP1:%.*]] = call <2 x i64> @llvm.x86.avx512.vpermi2var.q.128(<2 x i64> [[TMP6]], <2 x i64> [[T]], <2 x i64> [[TMP3]])
- ; CHECK-NEXT:    [[TMP12:%.*]] = bitcast <2 x i1> [[TMP10]] to i2
- ; CHECK-NEXT:    [[_MSCMP:%.*]] = icmp ne i2 [[TMP12]], 0
-@@ -146,7 +146,7 @@
- ; CHECK-NEXT:    [[TMP8:%.*]] = or <4 x i64> [[TMP5]], [[TMP2]]
- ; CHECK-NEXT:    [[TMP9:%.*]] = or <4 x i64> [[TMP8]], [[TMP7]]
- ; CHECK-NEXT:    [[T:%.*]] = or <4 x i64> [[M]], <i64 0, i64 8, i64 16, i64 32>
--; CHECK-NEXT:    [[TMP10:%.*]] = trunc <4 x i64> [[T]] to <4 x i2>
-+; CHECK-NEXT:    [[TMP10:%.*]] = trunc <4 x i64> [[TMP9]] to <4 x i2>
- ; CHECK-NEXT:    [[_MSPROP1:%.*]] = call <4 x i64> @llvm.x86.avx512.vpermi2var.q.256(<4 x i64> [[TMP6]], <4 x i64> [[T]], <4 x i64> [[TMP3]])
- ; CHECK-NEXT:    [[TMP12:%.*]] = bitcast <4 x i2> [[TMP10]] to i8
- ; CHECK-NEXT:    [[_MSCMP:%.*]] = icmp ne i8 [[TMP12]], 0
-@@ -207,7 +207,7 @@
- ; CHECK-NEXT:    [[TMP8:%.*]] = or <8 x i64> [[TMP5]], [[TMP2]]
- ; CHECK-NEXT:    [[TMP9:%.*]] = or <8 x i64> [[TMP8]], [[TMP7]]
- ; CHECK-NEXT:    [[T:%.*]] = or <8 x i64> [[M]], <i64 0, i64 16, i64 32, i64 64, i64 256, i64 512, i64 1024, i64 -16>
--; CHECK-NEXT:    [[TMP10:%.*]] = trunc <8 x i64> [[T]] to <8 x i3>
-+; CHECK-NEXT:    [[TMP10:%.*]] = trunc <8 x i64> [[TMP9]] to <8 x i3>
- ; CHECK-NEXT:    [[_MSPROP1:%.*]] = call <8 x i64> @llvm.x86.avx512.vpermi2var.q.512(<8 x i64> [[TMP6]], <8 x i64> [[T]], <8 x i64> [[TMP3]])
- ; CHECK-NEXT:    [[TMP12:%.*]] = bitcast <8 x i3> [[TMP10]] to i24
- ; CHECK-NEXT:    [[_MSCMP:%.*]] = icmp ne i24 [[TMP12]], 0
-@@ -272,7 +272,7 @@
- ; CHECK-NEXT:    [[TMP8:%.*]] = or <4 x i32> [[TMP5]], [[TMP2]]
- ; CHECK-NEXT:    [[TMP9:%.*]] = or <4 x i32> [[TMP8]], [[TMP7]]
- ; CHECK-NEXT:    [[T:%.*]] = or <4 x i32> [[M]], <i32 0, i32 8, i32 16, i32 32>
--; CHECK-NEXT:    [[TMP10:%.*]] = trunc <4 x i32> [[T]] to <4 x i2>
-+; CHECK-NEXT:    [[TMP10:%.*]] = trunc <4 x i32> [[TMP9]] to <4 x i2>
- ; CHECK-NEXT:    [[_MSPROP1:%.*]] = call <4 x i32> @llvm.x86.avx512.vpermi2var.d.128(<4 x i32> [[TMP6]], <4 x i32> [[T]], <4 x i32> [[TMP3]])
- ; CHECK-NEXT:    [[TMP12:%.*]] = bitcast <4 x i2> [[TMP10]] to i8
- ; CHECK-NEXT:    [[_MSCMP:%.*]] = icmp ne i8 [[TMP12]], 0
-@@ -333,7 +333,7 @@
- ; CHECK-NEXT:    [[TMP8:%.*]] = or <8 x i32> [[TMP5]], [[TMP2]]
- ; CHECK-NEXT:    [[TMP9:%.*]] = or <8 x i32> [[TMP8]], [[TMP7]]
- ; CHECK-NEXT:    [[T:%.*]] = or <8 x i32> [[M]], <i32 0, i32 16, i32 32, i32 64, i32 256, i32 512, i32 -16, i32 -32>
--; CHECK-NEXT:    [[TMP10:%.*]] = trunc <8 x i32> [[T]] to <8 x i3>
-+; CHECK-NEXT:    [[TMP10:%.*]] = trunc <8 x i32> [[TMP9]] to <8 x i3>
- ; CHECK-NEXT:    [[_MSPROP1:%.*]] = call <8 x i32> @llvm.x86.avx512.vpermi2var.d.256(<8 x i32> [[TMP6]], <8 x i32> [[T]], <8 x i32> [[TMP3]])
- ; CHECK-NEXT:    [[TMP12:%.*]] = bitcast <8 x i3> [[TMP10]] to i24
- ; CHECK-NEXT:    [[_MSCMP:%.*]] = icmp ne i24 [[TMP12]], 0
-@@ -394,7 +394,7 @@
- ; CHECK-NEXT:    [[TMP8:%.*]] = or <16 x i32> [[TMP5]], [[TMP2]]
- ; CHECK-NEXT:    [[TMP9:%.*]] = or <16 x i32> [[TMP8]], [[TMP7]]
- ; CHECK-NEXT:    [[T:%.*]] = or <16 x i32> [[M]], <i32 0, i32 32, i32 64, i32 256, i32 512, i32 1024, i32 2048, i32 4096, i32 8192, i32 -32, i32 -64, i32 -128, i32 -256, i32 -512, i32 -1024, i32 -2048>
--; CHECK-NEXT:    [[TMP10:%.*]] = trunc <16 x i32> [[T]] to <16 x i4>
-+; CHECK-NEXT:    [[TMP10:%.*]] = trunc <16 x i32> [[TMP9]] to <16 x i4>
- ; CHECK-NEXT:    [[_MSPROP1:%.*]] = call <16 x i32> @llvm.x86.avx512.vpermi2var.d.512(<16 x i32> [[TMP6]], <16 x i32> [[T]], <16 x i32> [[TMP3]])
- ; CHECK-NEXT:    [[TMP12:%.*]] = bitcast <16 x i4> [[TMP10]] to i64
- ; CHECK-NEXT:    [[_MSCMP:%.*]] = icmp ne i64 [[TMP12]], 0
-@@ -459,7 +459,7 @@
- ; CHECK-NEXT:    [[TMP8:%.*]] = or <8 x i16> [[TMP5]], [[TMP2]]
- ; CHECK-NEXT:    [[TMP9:%.*]] = or <8 x i16> [[TMP8]], [[TMP7]]
- ; CHECK-NEXT:    [[T:%.*]] = or <8 x i16> [[M]], <i16 0, i16 16, i16 32, i16 64, i16 256, i16 512, i16 -16, i16 -32>
--; CHECK-NEXT:    [[TMP10:%.*]] = trunc <8 x i16> [[T]] to <8 x i3>
-+; CHECK-NEXT:    [[TMP10:%.*]] = trunc <8 x i16> [[TMP9]] to <8 x i3>
- ; CHECK-NEXT:    [[_MSPROP1:%.*]] = call <8 x i16> @llvm.x86.avx512.vpermi2var.hi.128(<8 x i16> [[TMP6]], <8 x i16> [[T]], <8 x i16> [[TMP3]])
- ; CHECK-NEXT:    [[TMP12:%.*]] = bitcast <8 x i3> [[TMP10]] to i24
- ; CHECK-NEXT:    [[_MSCMP:%.*]] = icmp ne i24 [[TMP12]], 0
-@@ -520,7 +520,7 @@
- ; CHECK-NEXT:    [[TMP8:%.*]] = or <16 x i16> [[TMP5]], [[TMP2]]
- ; CHECK-NEXT:    [[TMP9:%.*]] = or <16 x i16> [[TMP8]], [[TMP7]]
- ; CHECK-NEXT:    [[T:%.*]] = or <16 x i16> [[M]], <i16 0, i16 32, i16 64, i16 256, i16 512, i16 1024, i16 2048, i16 4096, i16 -32, i16 -64, i16 -128, i16 -256, i16 -512, i16 -1024, i16 -2048, i16 -4096>
--; CHECK-NEXT:    [[TMP10:%.*]] = trunc <16 x i16> [[T]] to <16 x i4>
-+; CHECK-NEXT:    [[TMP10:%.*]] = trunc <16 x i16> [[TMP9]] to <16 x i4>
- ; CHECK-NEXT:    [[_MSPROP1:%.*]] = call <16 x i16> @llvm.x86.avx512.vpermi2var.hi.256(<16 x i16> [[TMP6]], <16 x i16> [[T]], <16 x i16> [[TMP3]])
- ; CHECK-NEXT:    [[TMP12:%.*]] = bitcast <16 x i4> [[TMP10]] to i64
- ; CHECK-NEXT:    [[_MSCMP:%.*]] = icmp ne i64 [[TMP12]], 0
-@@ -581,7 +581,7 @@
- ; CHECK-NEXT:    [[TMP8:%.*]] = or <32 x i16> [[TMP5]], [[TMP2]]
- ; CHECK-NEXT:    [[TMP9:%.*]] = or <32 x i16> [[TMP8]], [[TMP7]]
- ; CHECK-NEXT:    [[T:%.*]] = or <32 x i16> [[M]], <i16 0, i16 64, i16 128, i16 256, i16 512, i16 1024, i16 2048, i16 4096, i16 0, i16 -64, i16 -128, i16 -256, i16 -512, i16 -1024, i16 -2048, i16 -4096, i16 0, i16 64, i16 128, i16 256, i16 512, i16 1024, i16 2048, i16 4096, i16 0, i16 -64, i16 -128, i16 -256, i16 -512, i16 -1024, i16 -2048, i16 -4096>
--; CHECK-NEXT:    [[TMP10:%.*]] = trunc <32 x i16> [[T]] to <32 x i5>
-+; CHECK-NEXT:    [[TMP10:%.*]] = trunc <32 x i16> [[TMP9]] to <32 x i5>
- ; CHECK-NEXT:    [[_MSPROP1:%.*]] = call <32 x i16> @llvm.x86.avx512.vpermi2var.hi.512(<32 x i16> [[TMP6]], <32 x i16> [[T]], <32 x i16> [[TMP3]])
- ; CHECK-NEXT:    [[TMP12:%.*]] = bitcast <32 x i5> [[TMP10]] to i160
- ; CHECK-NEXT:    [[_MSCMP:%.*]] = icmp ne i160 [[TMP12]], 0
-@@ -646,7 +646,7 @@
- ; CHECK-NEXT:    [[TMP8:%.*]] = or <16 x i8> [[TMP5]], [[TMP2]]
- ; CHECK-NEXT:    [[TMP9:%.*]] = or <16 x i8> [[TMP8]], [[TMP7]]
- ; CHECK-NEXT:    [[T:%.*]] = or <16 x i8> [[M]], <i8 0, i8 32, i8 64, i8 -128, i8 0, i8 -32, i8 -64, i8 -128, i8 0, i8 32, i8 64, i8 -128, i8 0, i8 -32, i8 -64, i8 -128>
--; CHECK-NEXT:    [[TMP10:%.*]] = trunc <16 x i8> [[T]] to <16 x i4>
-+; CHECK-NEXT:    [[TMP10:%.*]] = trunc <16 x i8> [[TMP9]] to <16 x i4>
- ; CHECK-NEXT:    [[_MSPROP1:%.*]] = call <16 x i8> @llvm.x86.avx512.vpermi2var.qi.128(<16 x i8> [[TMP6]], <16 x i8> [[T]], <16 x i8> [[TMP3]])
- ; CHECK-NEXT:    [[TMP12:%.*]] = bitcast <16 x i4> [[TMP10]] to i64
- ; CHECK-NEXT:    [[_MSCMP:%.*]] = icmp ne i64 [[TMP12]], 0
-@@ -707,7 +707,7 @@
- ; CHECK-NEXT:    [[TMP8:%.*]] = or <32 x i8> [[TMP5]], [[TMP2]]
- ; CHECK-NEXT:    [[TMP9:%.*]] = or <32 x i8> [[TMP8]], [[TMP7]]
- ; CHECK-NEXT:    [[T:%.*]] = or <32 x i8> [[M]], <i8 0, i8 0, i8 64, i8 -128, i8 0, i8 0, i8 -64, i8 -128, i8 0, i8 0, i8 64, i8 -128, i8 0, i8 0, i8 -64, i8 -128, i8 0, i8 0, i8 64, i8 -128, i8 0, i8 0, i8 -64, i8 -128, i8 0, i8 0, i8 64, i8 -128, i8 0, i8 0, i8 -64, i8 -128>
--; CHECK-NEXT:    [[TMP10:%.*]] = trunc <32 x i8> [[T]] to <32 x i5>
-+; CHECK-NEXT:    [[TMP10:%.*]] = trunc <32 x i8> [[TMP9]] to <32 x i5>
- ; CHECK-NEXT:    [[_MSPROP1:%.*]] = call <32 x i8> @llvm.x86.avx512.vpermi2var.qi.256(<32 x i8> [[TMP6]], <32 x i8> [[T]], <32 x i8> [[TMP3]])
- ; CHECK-NEXT:    [[TMP12:%.*]] = bitcast <32 x i5> [[TMP10]] to i160
- ; CHECK-NEXT:    [[_MSCMP:%.*]] = icmp ne i160 [[TMP12]], 0
-@@ -768,7 +768,7 @@
- ; CHECK-NEXT:    [[TMP8:%.*]] = or <64 x i8> [[TMP5]], [[TMP2]]
- ; CHECK-NEXT:    [[TMP9:%.*]] = or <64 x i8> [[TMP8]], [[TMP7]]
- ; CHECK-NEXT:    [[T:%.*]] = or <64 x i8> [[M]], <i8 0, i8 -128, i8 0, i8 -128, i8 0, i8 -128, i8 0, i8 -128, i8 0, i8 -128, i8 0, i8 -128, i8 0, i8 -128, i8 0, i8 -128, i8 0, i8 -128, i8 0, i8 -128, i8 0, i8 -128, i8 0, i8 -128, i8 0, i8 -128, i8 0, i8 -128, i8 0, i8 -128, i8 0, i8 -128, i8 0, i8 -128, i8 0, i8 -128, i8 0, i8 -128, i8 0, i8 -128, i8 0, i8 -128, i8 0, i8 -128, i8 0, i8 -128, i8 0, i8 -128, i8 0, i8 -128, i8 0, i8 -128, i8 0, i8 -128, i8 0, i8 -128, i8 0, i8 -128, i8 0, i8 -128, i8 0, i8 -128, i8 0, i8 -128>
--; CHECK-NEXT:    [[TMP10:%.*]] = trunc <64 x i8> [[T]] to <64 x i6>
-+; CHECK-NEXT:    [[TMP10:%.*]] = trunc <64 x i8> [[TMP9]] to <64 x i6>
- ; CHECK-NEXT:    [[_MSPROP1:%.*]] = call <64 x i8> @llvm.x86.avx512.vpermi2var.qi.512(<64 x i8> [[TMP6]], <64 x i8> [[T]], <64 x i8> [[TMP3]])
- ; CHECK-NEXT:    [[TMP12:%.*]] = bitcast <64 x i6> [[TMP10]] to i384
- ; CHECK-NEXT:    [[_MSCMP:%.*]] = icmp ne i384 [[TMP12]], 0
-diff -ruN --strip-trailing-cr a/llvm/test/Transforms/Coroutines/coro-split-dbg-labels.ll b/llvm/test/Transforms/Coroutines/coro-split-dbg-labels.ll
---- a/llvm/test/Transforms/Coroutines/coro-split-dbg-labels.ll
-+++ b/llvm/test/Transforms/Coroutines/coro-split-dbg-labels.ll
-@@ -1,14 +1,19 @@
- ; Tests that we add DILabels for the suspend points.
- ;
--; We check both the generated LLVM:
-+; Check the generated LLVM:
- ; RUN: opt < %s -passes='cgscc(coro-split)' -S | FileCheck %s
- ;
--; And the debug info:
-+; Check the generated DWARF debug info:
- ; REQUIRES: object-emission
- ; RUN: opt < %s -passes='cgscc(coro-split),coro-cleanup' \
- ; RUN:   | %llc_dwarf -O0 -filetype=obj -o - \
- ; RUN:   | llvm-dwarfdump - \
- ; RUN:   | FileCheck %s -check-prefix=DWARF
-+;
-+; Check that we don't emit any DILabel if in `LineTablesOnly` mode
-+; RUN: sed -e 's/emissionKind: FullDebug/emissionKind: LineTablesOnly/' %s \
-+; RUN:   | opt -passes='cgscc(coro-split)' -S \
-+; RUN:   | FileCheck %s -check-prefix=LINE-TABLE
- 
- source_filename = "coro.c"
- 
-@@ -83,6 +88,12 @@
- ; CHECK: ![[DESTROY_0]] = !DILabel(scope: !{{[0-9]+}}, name: "__coro_resume_0", file: !{{[0-9]*}}, line: 12, column: 6, isArtificial: true, coroSuspendIdx: 0)
- ; CHECK: ![[DESTROY_1]] = !DILabel(scope: !{{[0-9]+}}, name: "__coro_resume_1", file: !{{[0-9]*}}, line: 14, column: 6, isArtificial: true, coroSuspendIdx: 1)
- 
-+; Check the we do not emit any DILabels in LineTablesOnly mode.
-+; The DWARF emitter cannot handle this and would run into an assertion.
-+; LINE-TABLE: !DICompileUnit{{.*}}LineTablesOnly
-+; LINE-TABLE-NOT: DILabel
-+
-+
- ; DWARF:        {{.*}}DW_TAG_label
- ; DWARF-NEXT:    DW_AT_name ("__coro_resume_0")
- ; DWARF-NEXT:    DW_AT_decl_file
 diff -ruN --strip-trailing-cr a/mlir/lib/Target/IRDLToCpp/TemplatingUtils.h b/mlir/lib/Target/IRDLToCpp/TemplatingUtils.h
 --- a/mlir/lib/Target/IRDLToCpp/TemplatingUtils.h
 +++ b/mlir/lib/Target/IRDLToCpp/TemplatingUtils.h
@@ -2916,87 +3213,11 @@ diff -ruN --strip-trailing-cr a/mlir/lib/Target/IRDLToCpp/TemplatingUtils.h b/ml
  
  namespace mlir::irdl::detail {
  
-diff -ruN --strip-trailing-cr a/utils/bazel/llvm-project-overlay/mlir/BUILD.bazel b/utils/bazel/llvm-project-overlay/mlir/BUILD.bazel
---- a/utils/bazel/llvm-project-overlay/mlir/BUILD.bazel
-+++ b/utils/bazel/llvm-project-overlay/mlir/BUILD.bazel
-@@ -4015,6 +4015,7 @@
-         ":VectorToSCF",
-         ":VectorToSPIRV",
-         ":VectorToXeGPU",
-+        ":XeVMToLLVM",
-     ],
- )
- 
-@@ -4639,6 +4640,7 @@
-         ":VCIXToLLVMIRTranslation",
-         ":VectorToLLVM",
-         ":VectorTransformOps",
-+        ":XeVMToLLVM",
-     ],
- )
- 
-@@ -13644,3 +13646,28 @@
-     td_file = "include/mlir/Dialect/LLVMIR/XeVMOps.td",
-     deps = [":XeVMTdFiles"],
- )
-+
-+cc_library(
-+    name = "XeVMToLLVM",
-+    srcs = glob([
-+        "lib/Conversion/XeVMToLLVM/*.cpp",
-+    ]),
-+    hdrs = glob([
-+        "include/mlir/Conversion/XeVMToLLVM/*.h",
-+    ]),
-+    includes = ["include"],
-+    deps = [
-+        ":XeVMDialect",
-+        ":ConversionPassIncGen",
-+	":ConvertToLLVMInterface",
-+	":GPUDialect",
-+        ":IR",
-+	":LLVMCommonConversion",
-+	":LLVMDialect",
-+        ":Pass",
-+	":Support",
-+        ":TransformUtils",
-+        ":VectorDialect",
-+	"//llvm:Support",
-+    ],
-+)
-diff -ruN --strip-trailing-cr a/utils/bazel/llvm-project-overlay/mlir/python/BUILD.bazel b/utils/bazel/llvm-project-overlay/mlir/python/BUILD.bazel
---- a/utils/bazel/llvm-project-overlay/mlir/python/BUILD.bazel
-+++ b/utils/bazel/llvm-project-overlay/mlir/python/BUILD.bazel
-@@ -701,6 +701,32 @@
- )
- 
- ##---------------------------------------------------------------------------##
-+# Tune dialect.
-+##---------------------------------------------------------------------------##
-+
-+gentbl_filegroup(
-+    name = "TuneTransformOpsPyGen",
-+    tbl_outs = {"mlir/dialects/_transform_tune_extension_ops_gen.py": [
-+        "-gen-python-op-bindings",
-+        "-bind-dialect=transform",
-+        "-dialect-extension=transform_tune_extension",
-+    ]},
-+    tblgen = "//mlir:mlir-tblgen",
-+    td_file = "mlir/dialects/TransformTuneExtensionOps.td",
-+    deps = [
-+        "//mlir:TransformTuneExtensionTdFiles",
-+    ],
-+)
-+
-+filegroup(
-+    name = "TunePyFiles",
-+    srcs = [
-+        "mlir/dialects/transform/tune.py",
-+        ":TuneTransformOpsPyGen",
-+    ],
-+)
-+
-+##---------------------------------------------------------------------------##
- # PythonTest dialect.
- ##---------------------------------------------------------------------------##
+diff -ruN --strip-trailing-cr a/mlir/test/IR/test-pattern-logging-listener.mlir b/mlir/test/IR/test-pattern-logging-listener.mlir
+--- a/mlir/test/IR/test-pattern-logging-listener.mlir
++++ b/mlir/test/IR/test-pattern-logging-listener.mlir
+@@ -1,3 +1,4 @@
++// REQUIRES: asserts
+ // RUN: mlir-opt %s --test-walk-pattern-rewrite-driver \
+ // RUN:   --allow-unregistered-dialect --debug-only=pattern-logging-listener 2>&1 | FileCheck %s
  
diff --git a/third_party/llvm/memcpy.patch b/third_party/llvm/memcpy.patch
deleted file mode 100644
index c6cc824..0000000
--- a/third_party/llvm/memcpy.patch
+++ /dev/null
@@ -1,62 +0,0 @@
-diff --git a/llvm/include/llvm/ADT/Hashing.h b/llvm/include/llvm/ADT/Hashing.h
-index 0093c281aac8..ad131015a7d9 100644
---- a/llvm/include/llvm/ADT/Hashing.h
-+++ b/llvm/include/llvm/ADT/Hashing.h
-@@ -136,7 +136,7 @@ namespace detail {
- 
- inline uint64_t fetch64(const char *p) {
-   uint64_t result;
--  memcpy(&result, p, sizeof(result));
-+  std::memcpy(&result, p, sizeof(result));
-   if (sys::IsBigEndianHost)
-     sys::swapByteOrder(result);
-   return result;
-@@ -144,7 +144,7 @@ inline uint64_t fetch64(const char *p) {
- 
- inline uint32_t fetch32(const char *p) {
-   uint32_t result;
--  memcpy(&result, p, sizeof(result));
-+  std::memcpy(&result, p, sizeof(result));
-   if (sys::IsBigEndianHost)
-     sys::swapByteOrder(result);
-   return result;
-@@ -379,7 +379,7 @@ bool store_and_advance(char *&buffer_ptr, char *buffer_end, const T& value,
-   if (buffer_ptr + store_size > buffer_end)
-     return false;
-   const char *value_data = reinterpret_cast<const char *>(&value);
--  memcpy(buffer_ptr, value_data + offset, store_size);
-+  std::memcpy(buffer_ptr, value_data + offset, store_size);
-   buffer_ptr += store_size;
-   return true;
- }
-@@ -513,7 +513,7 @@ public:
-       // with the variadic combine because that formation can have varying
-       // argument types.
-       size_t partial_store_size = buffer_end - buffer_ptr;
--      memcpy(buffer_ptr, &data, partial_store_size);
-+      std::memcpy(buffer_ptr, &data, partial_store_size);
- 
-       // If the store fails, our buffer is full and ready to hash. We have to
-       // either initialize the hash state (on the first full buffer) or mix
-diff --git a/llvm/include/llvm/ADT/SmallVector.h b/llvm/include/llvm/ADT/SmallVector.h
-index 0b8bb48b8fe5..80f7734b8690 100644
---- a/llvm/include/llvm/ADT/SmallVector.h
-+++ b/llvm/include/llvm/ADT/SmallVector.h
-@@ -518,7 +518,7 @@ protected:
-     // use memcpy here. Note that I and E are iterators and thus might be
-     // invalid for memcpy if they are equal.
-     if (I != E)
--      memcpy(reinterpret_cast<void *>(Dest), I, (E - I) * sizeof(T));
-+      std::memcpy(reinterpret_cast<void *>(Dest), I, (E - I) * sizeof(T));
-   }
- 
-   /// Double the size of the allocated memory, guaranteeing space for at
-@@ -561,7 +561,7 @@ protected:
- public:
-   void push_back(ValueParamT Elt) {
-     const T *EltPtr = reserveForParamAndGetAddress(Elt);
--    memcpy(reinterpret_cast<void *>(this->end()), EltPtr, sizeof(T));
-+    std::memcpy(reinterpret_cast<void *>(this->end()), EltPtr, sizeof(T));
-     this->set_size(this->size() + 1);
-   }
- 
diff --git a/third_party/llvm/workspace.bzl b/third_party/llvm/workspace.bzl
index a338a8f..79fbbfa 100644
--- a/third_party/llvm/workspace.bzl
+++ b/third_party/llvm/workspace.bzl
@@ -4,8 +4,8 @@ load("//third_party:repo.bzl", "tf_http_archive")
 
 def repo(name):
     """Imports LLVM."""
-    LLVM_COMMIT = "0a343098b0ea300b75f16596db2dc32a55007546"
-    LLVM_SHA256 = "7865992af73fceffb9ddb823eea5987698d9e98e8ed7a4a0a214caae8d2771f9"
+    LLVM_COMMIT = "13f7786f72d13a84dfc3d49d87a70e6a05f21fd4"
+    LLVM_SHA256 = "444620f561a7ab1ccaa310b7ba5cdc82c61ff534b6e60b00cb58e779a24cb3bd"
 
     tf_http_archive(
         name = name,
@@ -20,7 +20,6 @@ def repo(name):
             "//third_party/llvm:generated.patch",  # Autogenerated, don't remove.
             "//third_party/llvm:build.patch",
             "//third_party/llvm:mathextras.patch",
-            "//third_party/llvm:memcpy.patch",
             "//third_party/llvm:toolchains.patch",
             "//third_party/llvm:zstd.patch",
         ],
diff --git a/third_party/stablehlo/temporary.patch b/third_party/stablehlo/temporary.patch
index 629bcf2..74a17ba 100755
--- a/third_party/stablehlo/temporary.patch
+++ b/third_party/stablehlo/temporary.patch
@@ -124,6 +124,33 @@ diff --ruN a/stablehlo/stablehlo/dialect/StablehloOps.cpp b/stablehlo/stablehlo/
      locs.push_back(i.getLoc());
    }
  
+diff --ruN a/stablehlo/stablehlo/dialect/StablehloOps.td b/stablehlo/stablehlo/dialect/StablehloOps.td
+--- stablehlo/stablehlo/dialect/StablehloOps.td
++++ stablehlo/stablehlo/dialect/StablehloOps.td
+@@ -1245,11 +1245,6 @@
+   );
+ 
+   let results = (outs HLO_Token);
+-  let builders = [
+-    OpBuilder<(ins
+-      "::mlir::Type":$result_type, "::mlir::Value":$operand,
+-      "::mlir::DenseIntElementsAttr":$source_target_pairs,
+-      "::mlir::stablehlo::ChannelHandleAttr":$channel_handle)>];
+ }
+ 
+ def StableHLO_RecvOp : StableHLO_Op<"recv", [
+@@ -1279,11 +1274,6 @@
+     DefaultValuedOptionalAttr<BoolAttr, "false">:$is_host_transfer, /*recv_i4*/
+     OptionalAttr<I64ElementsAttr>:$source_target_pairs /*recv_i5*/
+   );
+-  let builders = [
+-    OpBuilder<(ins
+-      "::mlir::Type":$result_type, "::mlir::Value":$operand,
+-      "::mlir::DenseIntElementsAttr":$source_target_pairs,
+-      "::mlir::stablehlo::ChannelHandleAttr":$channel_handle)>];
+ 
+   let results = (outs Variadic<HLO_StaticShapeTensorOrPerAxisQuantizedTensorOrToken>);
+   let hasVerifier = 1;
 diff --ruN a/stablehlo/stablehlo/dialect/TypeInference.cpp b/stablehlo/stablehlo/dialect/TypeInference.cpp
 --- stablehlo/stablehlo/dialect/TypeInference.cpp
 +++ stablehlo/stablehlo/dialect/TypeInference.cpp
