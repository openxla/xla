diff --git a/third_party/llvm/generated.patch b/third_party/llvm/generated.patch
index 1f9ec38..9731bbe 100644
--- a/third_party/llvm/generated.patch
+++ b/third_party/llvm/generated.patch
@@ -1,1211 +1,47 @@
 Auto generated patch. Do not edit or delete it, even if empty.
-diff -ruN --strip-trailing-cr a/clang/docs/ReleaseNotes.rst b/clang/docs/ReleaseNotes.rst
---- a/clang/docs/ReleaseNotes.rst
-+++ b/clang/docs/ReleaseNotes.rst
-@@ -340,6 +340,9 @@
-   by template argument deduction.
- - Clang is now better at instantiating the function definition after its use inside
-   of a constexpr lambda. (#GH125747)
-+- Clang no longer crashes when trying to unify the types of arrays with
-+  certain differences in qualifiers (this could happen during template argument
-+  deduction or when building a ternary operator). (#GH97005)
- - The initialization kind of elements of structured bindings
-   direct-list-initialized from an array is corrected to direct-initialization.
- - Clang no longer crashes when a coroutine is declared ``[[noreturn]]``. (#GH127327)
-diff -ruN --strip-trailing-cr a/clang/include/clang/AST/NestedNameSpecifier.h b/clang/include/clang/AST/NestedNameSpecifier.h
---- a/clang/include/clang/AST/NestedNameSpecifier.h
-+++ b/clang/include/clang/AST/NestedNameSpecifier.h
-@@ -201,6 +201,11 @@
-     return nullptr;
-   }
- 
-+  /// Fully translate this nested name specifier to a type.
-+  /// Unlike getAsType, this will convert this entire nested
-+  /// name specifier chain into its equivalent type.
-+  const Type *translateToType(const ASTContext &Context) const;
-+
-   NestedNameSpecifierDependence getDependence() const;
- 
-   /// Whether this nested name specifier refers to a dependent
-diff -ruN --strip-trailing-cr a/clang/lib/AST/ASTContext.cpp b/clang/lib/AST/ASTContext.cpp
---- a/clang/lib/AST/ASTContext.cpp
-+++ b/clang/lib/AST/ASTContext.cpp
-@@ -13650,7 +13650,11 @@
-   QualType EX = X->getElementType(), EY = Y->getElementType();
-   QualType R = Ctx.getCommonSugaredType(EX, EY,
-                                         /*Unqualified=*/true);
-+  // Qualifiers common to both element types.
-   Qualifiers RQ = R.getQualifiers();
-+  // For each side, move to the top level any qualifiers which are not common to
-+  // both element types. The caller must assume top level qualifiers might
-+  // be different, even if they are the same type, and can be treated as sugar.
-   QX += EX.getQualifiers() - RQ;
-   QY += EY.getQualifiers() - RQ;
-   return R;
-@@ -14371,6 +14375,22 @@
-   // necessarily canonical types, as they may still have sugared properties.
-   // QX and QY will store the sum of all qualifiers in Xs and Ys respectively.
-   auto Xs = ::unwrapSugar(SX, QX), Ys = ::unwrapSugar(SY, QY);
-+
-+  // If this is an ArrayType, the element qualifiers are interchangeable with
-+  // the top level qualifiers.
-+  // * In case the canonical nodes are the same, the elements types are already
-+  // the same.
-+  // * Otherwise, the element types will be made the same, and any different
-+  // element qualifiers will be moved up to the top level qualifiers, per
-+  // 'getCommonArrayElementType'.
-+  // In both cases, this means there may be top level qualifiers which differ
-+  // between X and Y. If so, these differing qualifiers are redundant with the
-+  // element qualifiers, and can be removed without changing the canonical type.
-+  // The desired behaviour is the same as for the 'Unqualified' case here:
-+  // treat the redundant qualifiers as sugar, remove the ones which are not
-+  // common to both sides.
-+  bool KeepCommonQualifiers = Unqualified || isa<ArrayType>(SX.Ty);
-+
-   if (SX.Ty != SY.Ty) {
-     // The canonical nodes differ. Build a common canonical node out of the two,
-     // unifying their sugar. This may recurse back here.
-@@ -14386,7 +14406,7 @@
-       SY = Ys.pop_back_val();
-     }
-   }
--  if (Unqualified)
-+  if (KeepCommonQualifiers)
-     QX = Qualifiers::removeCommonQualifiers(QX, QY);
-   else
-     assert(QX == QY);
-diff -ruN --strip-trailing-cr a/clang/lib/AST/NestedNameSpecifier.cpp b/clang/lib/AST/NestedNameSpecifier.cpp
---- a/clang/lib/AST/NestedNameSpecifier.cpp
-+++ b/clang/lib/AST/NestedNameSpecifier.cpp
-@@ -245,6 +245,52 @@
-   return getDependence() & NestedNameSpecifierDependence::Error;
- }
- 
-+const Type *
-+NestedNameSpecifier::translateToType(const ASTContext &Context) const {
-+  NestedNameSpecifier *Prefix = getPrefix();
-+  switch (getKind()) {
-+  case SpecifierKind::Identifier:
-+    return Context
-+        .getDependentNameType(ElaboratedTypeKeyword::None, Prefix,
-+                              getAsIdentifier())
-+        .getTypePtr();
-+  case SpecifierKind::TypeSpec:
-+  case SpecifierKind::TypeSpecWithTemplate: {
-+    const Type *T = getAsType();
-+    switch (T->getTypeClass()) {
-+    case Type::DependentTemplateSpecialization: {
-+      const auto *DT = cast<DependentTemplateSpecializationType>(T);
-+      // FIXME: The type node can't represent the template keyword.
-+      return Context
-+          .getDependentTemplateSpecializationType(ElaboratedTypeKeyword::None,
-+                                                  Prefix, DT->getIdentifier(),
-+                                                  DT->template_arguments())
-+          .getTypePtr();
-+    }
-+    case Type::Record:
-+    case Type::TemplateSpecialization:
-+    case Type::Using:
-+    case Type::Enum:
-+    case Type::Typedef:
-+    case Type::UnresolvedUsing:
-+      return Context
-+          .getElaboratedType(ElaboratedTypeKeyword::None, Prefix,
-+                             QualType(T, 0))
-+          .getTypePtr();
-+    default:
-+      assert(Prefix == nullptr && "unexpected type with elaboration");
-+      return T;
-+    }
-+  }
-+  case SpecifierKind::Global:
-+  case SpecifierKind::Namespace:
-+  case SpecifierKind::NamespaceAlias:
-+  case SpecifierKind::Super:
-+    // These are not representable as types.
-+    return nullptr;
-+  }
-+}
-+
- /// Print this nested name specifier to the given output
- /// stream.
- void NestedNameSpecifier::print(raw_ostream &OS, const PrintingPolicy &Policy,
-diff -ruN --strip-trailing-cr a/clang/lib/Sema/SemaExprCXX.cpp b/clang/lib/Sema/SemaExprCXX.cpp
---- a/clang/lib/Sema/SemaExprCXX.cpp
-+++ b/clang/lib/Sema/SemaExprCXX.cpp
-@@ -60,30 +60,10 @@
-                                               SourceLocation NameLoc,
-                                               const IdentifierInfo &Name) {
-   NestedNameSpecifier *NNS = SS.getScopeRep();
-+  if (const IdentifierInfo *II = NNS->getAsIdentifier())
-+    assert(II == &Name && "not a constructor name");
- 
--  // Convert the nested-name-specifier into a type.
--  QualType Type;
--  switch (NNS->getKind()) {
--  case NestedNameSpecifier::TypeSpec:
--  case NestedNameSpecifier::TypeSpecWithTemplate:
--    Type = QualType(NNS->getAsType(), 0);
--    break;
--
--  case NestedNameSpecifier::Identifier:
--    // Strip off the last layer of the nested-name-specifier and build a
--    // typename type for it.
--    assert(NNS->getAsIdentifier() == &Name && "not a constructor name");
--    Type = Context.getDependentNameType(
--        ElaboratedTypeKeyword::None, NNS->getPrefix(), NNS->getAsIdentifier());
--    break;
--
--  case NestedNameSpecifier::Global:
--  case NestedNameSpecifier::Super:
--  case NestedNameSpecifier::Namespace:
--  case NestedNameSpecifier::NamespaceAlias:
--    llvm_unreachable("Nested name specifier is not a type for inheriting ctor");
--  }
--
-+  QualType Type(NNS->translateToType(Context), 0);
-   // This reference to the type is located entirely at the location of the
-   // final identifier in the qualified-id.
-   return CreateParsedType(Type,
-diff -ruN --strip-trailing-cr a/clang/lib/Sema/SemaLookup.cpp b/clang/lib/Sema/SemaLookup.cpp
---- a/clang/lib/Sema/SemaLookup.cpp
-+++ b/clang/lib/Sema/SemaLookup.cpp
-@@ -3210,8 +3210,8 @@
-     //        X.
-     case Type::MemberPointer: {
-       const MemberPointerType *MemberPtr = cast<MemberPointerType>(T);
--      addAssociatedClassesAndNamespaces(
--          Result, MemberPtr->getMostRecentCXXRecordDecl());
-+      if (CXXRecordDecl *Class = MemberPtr->getMostRecentCXXRecordDecl())
-+        addAssociatedClassesAndNamespaces(Result, Class);
-       T = MemberPtr->getPointeeType().getTypePtr();
-       continue;
-     }
-diff -ruN --strip-trailing-cr a/clang/lib/Sema/SemaTemplateDeduction.cpp b/clang/lib/Sema/SemaTemplateDeduction.cpp
---- a/clang/lib/Sema/SemaTemplateDeduction.cpp
-+++ b/clang/lib/Sema/SemaTemplateDeduction.cpp
-@@ -2127,19 +2127,29 @@
-               /*DeducedFromArrayBound=*/false, HasDeducedAnyParam);
-           Result != TemplateDeductionResult::Success)
-         return Result;
--      const Type *QP = MPP->getQualifier()->getAsType(),
--                 *QA = MPA->getQualifier()->getAsType();
--      CXXRecordDecl *ClsP = MPP->getMostRecentCXXRecordDecl(),
--                    *ClsA = MPA->getMostRecentCXXRecordDecl();
--      // FIXME: Don't drop the rest of the prefixes here.
--      QualType P = !ClsP || declaresSameEntity(QP->getAsCXXRecordDecl(), ClsP)
--                       ? QualType(QP, 0)
--                       : S.Context.getTypeDeclType(ClsP);
--      QualType A = !ClsA || declaresSameEntity(QA->getAsCXXRecordDecl(), ClsA)
--                       ? QualType(QA, 0)
--                       : S.Context.getTypeDeclType(ClsA);
-+
-+      QualType TP;
-+      if (MPP->isSugared()) {
-+        TP = S.Context.getTypeDeclType(MPP->getMostRecentCXXRecordDecl());
-+      } else {
-+        NestedNameSpecifier *QP = MPP->getQualifier();
-+        if (QP->getKind() == NestedNameSpecifier::Identifier)
-+          // Skip translation if it's a non-deduced context anyway.
-+          return TemplateDeductionResult::Success;
-+        TP = QualType(QP->translateToType(S.Context), 0);
+diff -ruN --strip-trailing-cr a/llvm/lib/CodeGen/SelectionDAG/DAGCombiner.cpp b/llvm/lib/CodeGen/SelectionDAG/DAGCombiner.cpp
+--- a/llvm/lib/CodeGen/SelectionDAG/DAGCombiner.cpp
++++ b/llvm/lib/CodeGen/SelectionDAG/DAGCombiner.cpp
+@@ -15964,6 +15964,15 @@
+ 
+     if (TLI.isLoadBitCastBeneficial(N0.getValueType(), VT, DAG,
+                                     *LN0->getMemOperand())) {
++      // If the range metadata type does not match the new memory
++      // operation type, remove the range metadata.
++      if (const MDNode *MD = LN0->getRanges()) {
++        ConstantInt *Lower = mdconst::extract<ConstantInt>(MD->getOperand(0));
++        if (Lower->getBitWidth() != VT.getScalarSizeInBits() ||
++            !VT.isInteger()) {
++          LN0->getMemOperand()->clearRanges();
++        }
 +      }
-+      assert(!TP.isNull() && "member pointer with non-type class");
-+
-+      QualType TA;
-+      if (MPA->isSugared()) {
-+        TA = S.Context.getTypeDeclType(MPA->getMostRecentCXXRecordDecl());
-+      } else {
-+        NestedNameSpecifier *QA = MPA->getQualifier();
-+        TA = QualType(QA->translateToType(S.Context), 0);
-+      }
-+      assert(!TA.isNull() && "member pointer with non-type class");
-       return DeduceTemplateArgumentsByTypeMatch(
--          S, TemplateParams, P, A, Info, Deduced, SubTDF,
-+          S, TemplateParams, TP, TA, Info, Deduced, SubTDF,
-           degradeCallPartialOrderingKind(POK),
-           /*DeducedFromArrayBound=*/false, HasDeducedAnyParam);
-     }
-diff -ruN --strip-trailing-cr a/clang/test/SemaCXX/member-pointer.cpp b/clang/test/SemaCXX/member-pointer.cpp
---- a/clang/test/SemaCXX/member-pointer.cpp
-+++ b/clang/test/SemaCXX/member-pointer.cpp
-@@ -355,3 +355,56 @@
-   };
-   template struct CallableHelper<void (QIODevice::*)()>;
- } // namespace GH132401
-+
-+namespace adl_dependent_class {
-+  struct A {
-+    template <class T> A(T);
-+  };
-+  struct C;
-+  template <class T> void d(void (T::*)());
-+  void f(A);
-+  void g() { f(d<C>); }
-+} // namespace adl_dependent_class
-+
-+namespace deduction1 {
-+  template <typename> struct RunCallImpl;
-+
-+  template <typename Derived>
-+  struct RunCallImpl<int (Derived::Info::*)(Derived *)> {};
-+
-+  template <typename d>
-+  void RunCall(d) {
-+    RunCallImpl<d>();
-+  }
-+
-+  struct Filter {
-+    virtual void MakeCall();
-+    virtual ~Filter() = default;
-+  };
-+
-+  template <typename Derived>
-+  struct ImplementFilter : Filter {
-+    void MakeCall() { RunCall(&Derived::Info::OnStuffHandler); }
-+  };
-+
-+  struct FoobarFilter : ImplementFilter<FoobarFilter> {
-+    struct Info {
-+      int OnStuffHandler(FoobarFilter *);
-+    };
-+  };
-+} // namespace deduction1
-+
-+namespace deduction2 {
-+  template <typename> struct A;
-+  template <typename T>
-+  struct A<void (T::C::*)(int &, T *)> {};
-+  template <typename T> void e(T) {
-+    A<T> f;
-+  }
-+  struct S {
-+    struct C {
-+      void h(int &, S *);
-+    };
-+    void i() { e(&C::h); }
-+  };
-+} // namespace deduction2
-diff -ruN --strip-trailing-cr a/clang/test/SemaCXX/sugar-common-types.cpp b/clang/test/SemaCXX/sugar-common-types.cpp
---- a/clang/test/SemaCXX/sugar-common-types.cpp
-+++ b/clang/test/SemaCXX/sugar-common-types.cpp
-@@ -146,3 +146,43 @@
-   }
-   template void h<int>();
- } // namespace GH67603
-+
-+namespace arrays {
-+  namespace same_canonical {
-+    using ConstB1I = const B1[];
-+    using ConstB1C = const B1[1];
-+    const ConstB1I a = {0};
-+    const ConstB1C b = {0};
-+    N ta = a;
-+    // expected-error@-1 {{lvalue of type 'const B1[1]' (aka 'const int[1]')}}
-+    N tb = b;
-+    // expected-error@-1 {{lvalue of type 'const ConstB1C' (aka 'const const int[1]')}}
-+    N tc = 0 ? a : b;
-+    // expected-error@-1 {{lvalue of type 'const B1[1]' (aka 'const int[1]')}}
-+  } // namespace same_canonical
-+  namespace same_element {
-+    using ConstB1 = const B1;
-+    using ConstB1I = ConstB1[];
-+    using ConstB1C = ConstB1[1];
-+    const ConstB1I a = {0};
-+    const ConstB1C b = {0};
-+    N ta = a;
-+    // expected-error@-1 {{lvalue of type 'const ConstB1[1]' (aka 'const int[1]')}}
-+    N tb = b;
-+    // expected-error@-1 {{lvalue of type 'const ConstB1C' (aka 'const const int[1]')}}
-+    N tc = 0 ? a : b;
-+    // expected-error@-1 {{lvalue of type 'ConstB1[1]' (aka 'const int[1]')}}
-+  } // namespace same_element
-+  namespace balanced_qualifiers {
-+    using ConstX1C = const volatile X1[1];
-+    using Y1C = volatile Y1[1];
-+    extern volatile ConstX1C a;
-+    extern const volatile Y1C b;
-+    N ta = a;
-+    // expected-error@-1 {{lvalue of type 'volatile ConstX1C' (aka 'volatile const volatile int[1]')}}
-+    N tb = b;
-+    // expected-error@-1 {{lvalue of type 'const volatile Y1C' (aka 'const volatile volatile int[1]')}}
-+    N tc = 0 ? a : b;
-+    // expected-error@-1 {{lvalue of type 'const volatile volatile B1[1]' (aka 'const volatile volatile int[1]')}}
-+  } // namespace balanced_qualifiers
-+} // namespace arrays
-diff -ruN --strip-trailing-cr a/clang/test/SemaTemplate/instantiation-backtrace.cpp b/clang/test/SemaTemplate/instantiation-backtrace.cpp
---- a/clang/test/SemaTemplate/instantiation-backtrace.cpp
-+++ b/clang/test/SemaTemplate/instantiation-backtrace.cpp
-@@ -22,7 +22,7 @@
-   (void)sizeof(B<X>); // expected-note{{in instantiation of template class 'B<X>' requested here}}
- }
- 
--template<typename T> 
-+template<typename T>
- struct G : A<T>, // expected-error{{implicit instantiation of undefined template 'A<int>'}}
-   A<T*> // expected-error{{implicit instantiation of undefined template 'A<int *>'}}
-   { };
-@@ -39,13 +39,13 @@
-   template <class T1, class T2>
-     typename ResultTy<T2>::error Deduce( void (T1::*member)(T2) ) {} // \
-     // expected-note {{instantiation of template class 'PR13365::ResultTy<int &>'}} \
--    // expected-note {{substitution failure [with T1 = PR13365::Cls, T2 = int &]}}
-+    // expected-note {{substitution failure [with T1 = Cls, T2 = int &]}}
- 
-   struct Cls {
-     void method(int&);
-   };
-   void test() {
-     Deduce(&Cls::method); // expected-error {{no matching function}} \
--                          // expected-note {{substituting deduced template arguments into function template 'Deduce' [with T1 = PR13365::Cls, T2 = int &]}}
-+                          // expected-note {{substituting deduced template arguments into function template 'Deduce' [with T1 = Cls, T2 = int &]}}
-   }
- }
-diff -ruN --strip-trailing-cr a/llvm/include/llvm/CodeGen/MachineBasicBlock.h b/llvm/include/llvm/CodeGen/MachineBasicBlock.h
---- a/llvm/include/llvm/CodeGen/MachineBasicBlock.h
-+++ b/llvm/include/llvm/CodeGen/MachineBasicBlock.h
-@@ -313,6 +313,15 @@
-   const MachineFunction *getParent() const { return xParent; }
-   MachineFunction *getParent() { return xParent; }
- 
-+  /// Returns true if the original IR terminator is an `indirectbr`. This
-+  /// typically corresponds to a `goto` in C, rather than jump tables.
-+  bool terminatorIsComputedGoto() const {
-+    return back().isIndirectBranch() &&
-+           llvm::all_of(successors(), [](const MachineBasicBlock *Succ) {
-+             return Succ->isIRBlockAddressTaken();
-+           });
-+  }
-+
-   using instr_iterator = Instructions::iterator;
-   using const_instr_iterator = Instructions::const_iterator;
-   using reverse_instr_iterator = Instructions::reverse_iterator;
-diff -ruN --strip-trailing-cr a/llvm/include/llvm/CodeGen/MachineInstr.h b/llvm/include/llvm/CodeGen/MachineInstr.h
---- a/llvm/include/llvm/CodeGen/MachineInstr.h
-+++ b/llvm/include/llvm/CodeGen/MachineInstr.h
-@@ -994,17 +994,8 @@
- 
-   /// Return true if this is an indirect branch, such as a
-   /// branch through a register.
--  bool isIndirectBranch(QueryType Type = AnyInBundle,
--                        bool IncludeJumpTable = true) const {
--    return hasProperty(MCID::IndirectBranch, Type) &&
--           (IncludeJumpTable || !llvm::any_of(operands(), [](const auto &Op) {
--              return Op.isJTI();
--            }));
--  }
--
--  bool isComputedGoto(QueryType Type = AnyInBundle) const {
--    // Jump tables are not considered computed gotos.
--    return isIndirectBranch(Type, /*IncludeJumpTable=*/false);
-+  bool isIndirectBranch(QueryType Type = AnyInBundle) const {
-+    return hasProperty(MCID::IndirectBranch, Type);
-   }
- 
-   /// Return true if this is a branch which may fall
-@@ -2088,6 +2079,9 @@
-                     MCSymbol *PreInstrSymbol, MCSymbol *PostInstrSymbol,
-                     MDNode *HeapAllocMarker, MDNode *PCSections,
-                     uint32_t CFIType, MDNode *MMRAs);
-+
-+  /// Returns true if all successors are IRBlockAddressTaken.
-+  bool jumpToIRBlockAddressTaken() const;
- };
- 
- /// Special DenseMapInfo traits to compare MachineInstr* by *value* of the
-diff -ruN --strip-trailing-cr a/llvm/lib/CodeGen/TailDuplicator.cpp b/llvm/lib/CodeGen/TailDuplicator.cpp
---- a/llvm/lib/CodeGen/TailDuplicator.cpp
-+++ b/llvm/lib/CodeGen/TailDuplicator.cpp
-@@ -604,7 +604,7 @@
-   bool HasComputedGoto = false;
-   if (!TailBB.empty()) {
-     HasIndirectbr = TailBB.back().isIndirectBranch();
--    HasComputedGoto = TailBB.back().isComputedGoto();
-+    HasComputedGoto = TailBB.terminatorIsComputedGoto();
-   }
- 
-   if (HasIndirectbr && PreRegAlloc)
-diff -ruN --strip-trailing-cr a/llvm/lib/ExecutionEngine/RuntimeDyld/RuntimeDyldELF.cpp b/llvm/lib/ExecutionEngine/RuntimeDyld/RuntimeDyldELF.cpp
---- a/llvm/lib/ExecutionEngine/RuntimeDyld/RuntimeDyldELF.cpp
-+++ b/llvm/lib/ExecutionEngine/RuntimeDyld/RuntimeDyldELF.cpp
-@@ -1515,15 +1515,15 @@
-   uint64_t Offset = RelI->getOffset();
-   unsigned RelType = RelI->getType();
-   // Look for an existing stub.
--  auto [It, Inserted] = Stubs.try_emplace(Value);
--  if (!Inserted) {
-+  StubMap::const_iterator i = Stubs.find(Value);
-+  if (i != Stubs.end()) {
-     resolveRelocation(Section, Offset,
--                      Section.getLoadAddressWithOffset(It->second), RelType, 0);
-+                      Section.getLoadAddressWithOffset(i->second), RelType, 0);
-     LLVM_DEBUG(dbgs() << " Stub function found\n");
-   } else if (!resolveAArch64ShortBranch(SectionID, RelI, Value)) {
-     // Create a new stub function.
-     LLVM_DEBUG(dbgs() << " Create a new stub function\n");
--    It->second = Section.getStubOffset();
-+    Stubs[Value] = Section.getStubOffset();
-     uint8_t *StubTargetAddr = createStubFunction(
-         Section.getAddressWithOffset(Section.getStubOffset()));
- 
-@@ -1837,15 +1837,15 @@
-       SectionEntry &Section = Sections[SectionID];
- 
-       //  Look up for existing stub.
--      auto [It, Inserted] = Stubs.try_emplace(Value);
--      if (!Inserted) {
--        RelocationEntry RE(SectionID, Offset, RelType, It->second);
-+      StubMap::const_iterator i = Stubs.find(Value);
-+      if (i != Stubs.end()) {
-+        RelocationEntry RE(SectionID, Offset, RelType, i->second);
-         addRelocationForSection(RE, SectionID);
-         LLVM_DEBUG(dbgs() << " Stub function found\n");
-       } else {
-         // Create a new stub function.
-         LLVM_DEBUG(dbgs() << " Create a new stub function\n");
--        It->second = Section.getStubOffset();
-+        Stubs[Value] = Section.getStubOffset();
- 
-         unsigned AbiVariant = Obj.getPlatformFlags();
- 
-@@ -2075,10 +2075,10 @@
-     SectionEntry &Section = Sections[SectionID];
- 
-     // Look for an existing stub.
--    auto [It, Inserted] = Stubs.try_emplace(Value);
-+    StubMap::const_iterator i = Stubs.find(Value);
-     uintptr_t StubAddress;
--    if (!Inserted) {
--      StubAddress = uintptr_t(Section.getAddressWithOffset(It->second));
-+    if (i != Stubs.end()) {
-+      StubAddress = uintptr_t(Section.getAddressWithOffset(i->second));
-       LLVM_DEBUG(dbgs() << " Stub function found\n");
-     } else {
-       // Create a new stub function.
-@@ -2089,7 +2089,7 @@
-           alignTo(BaseAddress + Section.getStubOffset(), getStubAlignment());
-       unsigned StubOffset = StubAddress - BaseAddress;
- 
--      It->second = StubOffset;
-+      Stubs[Value] = StubOffset;
-       createStubFunction((uint8_t *)StubAddress);
-       RelocationEntry RE(SectionID, StubOffset + 8, ELF::R_390_64,
-                          Value.Offset);
-diff -ruN --strip-trailing-cr a/llvm/lib/ExecutionEngine/RuntimeDyld/Targets/RuntimeDyldMachOARM.h b/llvm/lib/ExecutionEngine/RuntimeDyld/Targets/RuntimeDyldMachOARM.h
---- a/llvm/lib/ExecutionEngine/RuntimeDyld/Targets/RuntimeDyldMachOARM.h
-+++ b/llvm/lib/ExecutionEngine/RuntimeDyld/Targets/RuntimeDyldMachOARM.h
-@@ -307,14 +307,14 @@
-     // This is an ARM branch relocation, need to use a stub function.
-     // Look up for existing stub.
-     SectionEntry &Section = Sections[RE.SectionID];
--    auto [It, Inserted] = Stubs.try_emplace(Value);
-+    RuntimeDyldMachO::StubMap::const_iterator i = Stubs.find(Value);
-     uint8_t *Addr;
--    if (!Inserted) {
--      Addr = Section.getAddressWithOffset(It->second);
-+    if (i != Stubs.end()) {
-+      Addr = Section.getAddressWithOffset(i->second);
-     } else {
-       // Create a new stub function.
-       assert(Section.getStubOffset() % 4 == 0 && "Misaligned stub");
--      It->second = Section.getStubOffset();
-+      Stubs[Value] = Section.getStubOffset();
-       uint32_t StubOpcode = 0;
-       if (RE.RelType == MachO::ARM_RELOC_BR24)
-         StubOpcode = 0xe51ff004; // ldr pc, [pc, #-4]
-diff -ruN --strip-trailing-cr a/llvm/lib/ExecutionEngine/RuntimeDyld/Targets/RuntimeDyldMachOX86_64.h b/llvm/lib/ExecutionEngine/RuntimeDyld/Targets/RuntimeDyldMachOX86_64.h
---- a/llvm/lib/ExecutionEngine/RuntimeDyld/Targets/RuntimeDyldMachOX86_64.h
-+++ b/llvm/lib/ExecutionEngine/RuntimeDyld/Targets/RuntimeDyldMachOX86_64.h
-@@ -131,12 +131,12 @@
-     assert(RE.IsPCRel);
-     assert(RE.Size == 2);
-     Value.Offset -= RE.Addend;
--    auto [It, Inserted] = Stubs.try_emplace(Value);
-+    RuntimeDyldMachO::StubMap::const_iterator i = Stubs.find(Value);
-     uint8_t *Addr;
--    if (!Inserted) {
--      Addr = Section.getAddressWithOffset(It->second);
-+    if (i != Stubs.end()) {
-+      Addr = Section.getAddressWithOffset(i->second);
-     } else {
--      It->second = Section.getStubOffset();
-+      Stubs[Value] = Section.getStubOffset();
-       uint8_t *GOTEntry = Section.getAddressWithOffset(Section.getStubOffset());
-       RelocationEntry GOTRE(RE.SectionID, Section.getStubOffset(),
-                             MachO::X86_64_RELOC_UNSIGNED, Value.Offset, false,
-diff -ruN --strip-trailing-cr a/llvm/test/CodeGen/X86/tail-dup-computed-goto.mir b/llvm/test/CodeGen/X86/tail-dup-computed-goto.mir
---- a/llvm/test/CodeGen/X86/tail-dup-computed-goto.mir
-+++ b/llvm/test/CodeGen/X86/tail-dup-computed-goto.mir
-@@ -2,15 +2,27 @@
- # RUN: llc -mtriple=x86_64-unknown-linux-gnu -run-pass=early-tailduplication -tail-dup-pred-size=1 -tail-dup-succ-size=1 %s -o - | FileCheck %s
- # Check that only the computed goto is not be restrict by tail-dup-pred-size and tail-dup-succ-size.
- --- |
-+  @computed_goto.dispatch = constant [5 x ptr] [ptr null, ptr blockaddress(@computed_goto, %bb1), ptr blockaddress(@computed_goto, %bb2), ptr blockaddress(@computed_goto, %bb3), ptr blockaddress(@computed_goto, %bb4)]
-   declare i64 @f0()
-   declare i64 @f1()
-   declare i64 @f2()
-   declare i64 @f3()
-   declare i64 @f4()
-   declare i64 @f5()
--  @computed_goto.dispatch = external global [5 x ptr]
--  define void @computed_goto() { ret void }
-+  define void @computed_goto() {
-+    start:
-+      ret void
-+    bb1:
-+      ret void
-+    bb2:
-+      ret void
-+    bb3:
-+      ret void
-+    bb4:
-+      ret void
-+  }
-   define void @jump_table() { ret void }
-+  define void @jump_table_pic() { ret void }
- ...
- ---
- name:            computed_goto
-@@ -23,98 +35,88 @@
-   ; CHECK-NEXT:   ADJCALLSTACKDOWN64 0, 0, 0, implicit-def dead $rsp, implicit-def dead $eflags, implicit-def dead $ssp, implicit $rsp, implicit $ssp
-   ; CHECK-NEXT:   CALL64pcrel32 target-flags(x86-plt) @f0, csr_64, implicit $rsp, implicit $ssp, implicit-def $rsp, implicit-def $ssp, implicit-def $rax
-   ; CHECK-NEXT:   ADJCALLSTACKUP64 0, 0, implicit-def dead $rsp, implicit-def dead $eflags, implicit-def dead $ssp, implicit $rsp, implicit $ssp
--  ; CHECK-NEXT:   [[COPY:%[0-9]+]]:gr64 = COPY $rax
-+  ; CHECK-NEXT:   [[COPY:%[0-9]+]]:gr64_nosp = COPY $rax
-   ; CHECK-NEXT:   [[COPY1:%[0-9]+]]:gr64_nosp = COPY [[COPY]]
--  ; CHECK-NEXT:   [[COPY2:%[0-9]+]]:gr64_nosp = COPY [[COPY1]]
--  ; CHECK-NEXT:   JMP64m $noreg, 8, [[COPY1]], @computed_goto.dispatch, $noreg
-+  ; CHECK-NEXT:   JMP64m $noreg, 8, [[COPY]], @computed_goto.dispatch, $noreg
-   ; CHECK-NEXT: {{  $}}
--  ; CHECK-NEXT: bb.1:
-+  ; CHECK-NEXT: bb.1.bb1 (ir-block-address-taken %ir-block.bb1):
-   ; CHECK-NEXT:   successors: %bb.1(0x20000000), %bb.2(0x20000000), %bb.3(0x20000000), %bb.4(0x20000000)
-   ; CHECK-NEXT: {{  $}}
-   ; CHECK-NEXT:   ADJCALLSTACKDOWN64 0, 0, 0, implicit-def dead $rsp, implicit-def dead $eflags, implicit-def dead $ssp, implicit $rsp, implicit $ssp
-   ; CHECK-NEXT:   CALL64pcrel32 target-flags(x86-plt) @f1, csr_64, implicit $rsp, implicit $ssp, implicit-def $rsp, implicit-def $ssp, implicit-def $rax
-   ; CHECK-NEXT:   ADJCALLSTACKUP64 0, 0, implicit-def dead $rsp, implicit-def dead $eflags, implicit-def dead $ssp, implicit $rsp, implicit $ssp
--  ; CHECK-NEXT:   [[COPY3:%[0-9]+]]:gr64 = COPY $rax
--  ; CHECK-NEXT:   [[COPY4:%[0-9]+]]:gr64_nosp = COPY [[COPY3]]
--  ; CHECK-NEXT:   [[COPY5:%[0-9]+]]:gr64_nosp = COPY [[COPY4]]
--  ; CHECK-NEXT:   JMP64m $noreg, 8, [[COPY4]], @computed_goto.dispatch, $noreg
-+  ; CHECK-NEXT:   [[COPY2:%[0-9]+]]:gr64_nosp = COPY $rax
-+  ; CHECK-NEXT:   [[COPY3:%[0-9]+]]:gr64_nosp = COPY [[COPY2]]
-+  ; CHECK-NEXT:   JMP64m $noreg, 8, [[COPY2]], @computed_goto.dispatch, $noreg
-   ; CHECK-NEXT: {{  $}}
--  ; CHECK-NEXT: bb.2:
-+  ; CHECK-NEXT: bb.2.bb2 (ir-block-address-taken %ir-block.bb2):
-   ; CHECK-NEXT:   successors: %bb.1(0x20000000), %bb.2(0x20000000), %bb.3(0x20000000), %bb.4(0x20000000)
-   ; CHECK-NEXT: {{  $}}
-   ; CHECK-NEXT:   ADJCALLSTACKDOWN64 0, 0, 0, implicit-def dead $rsp, implicit-def dead $eflags, implicit-def dead $ssp, implicit $rsp, implicit $ssp
-   ; CHECK-NEXT:   CALL64pcrel32 target-flags(x86-plt) @f2, csr_64, implicit $rsp, implicit $ssp, implicit-def $rsp, implicit-def $ssp, implicit-def $rax
-   ; CHECK-NEXT:   ADJCALLSTACKUP64 0, 0, implicit-def dead $rsp, implicit-def dead $eflags, implicit-def dead $ssp, implicit $rsp, implicit $ssp
--  ; CHECK-NEXT:   [[COPY6:%[0-9]+]]:gr64 = COPY $rax
--  ; CHECK-NEXT:   [[COPY7:%[0-9]+]]:gr64_nosp = COPY [[COPY6]]
--  ; CHECK-NEXT:   [[COPY8:%[0-9]+]]:gr64_nosp = COPY [[COPY7]]
--  ; CHECK-NEXT:   JMP64m $noreg, 8, [[COPY7]], @computed_goto.dispatch, $noreg
-+  ; CHECK-NEXT:   [[COPY4:%[0-9]+]]:gr64_nosp = COPY $rax
-+  ; CHECK-NEXT:   [[COPY5:%[0-9]+]]:gr64_nosp = COPY [[COPY4]]
-+  ; CHECK-NEXT:   JMP64m $noreg, 8, [[COPY4]], @computed_goto.dispatch, $noreg
-   ; CHECK-NEXT: {{  $}}
--  ; CHECK-NEXT: bb.3:
-+  ; CHECK-NEXT: bb.3.bb3 (ir-block-address-taken %ir-block.bb3):
-   ; CHECK-NEXT:   successors: %bb.1(0x20000000), %bb.2(0x20000000), %bb.3(0x20000000), %bb.4(0x20000000)
-   ; CHECK-NEXT: {{  $}}
-   ; CHECK-NEXT:   ADJCALLSTACKDOWN64 0, 0, 0, implicit-def dead $rsp, implicit-def dead $eflags, implicit-def dead $ssp, implicit $rsp, implicit $ssp
-   ; CHECK-NEXT:   CALL64pcrel32 target-flags(x86-plt) @f3, csr_64, implicit $rsp, implicit $ssp, implicit-def $rsp, implicit-def $ssp, implicit-def $rax
-   ; CHECK-NEXT:   ADJCALLSTACKUP64 0, 0, implicit-def dead $rsp, implicit-def dead $eflags, implicit-def dead $ssp, implicit $rsp, implicit $ssp
--  ; CHECK-NEXT:   [[COPY9:%[0-9]+]]:gr64 = COPY $rax
--  ; CHECK-NEXT:   [[COPY10:%[0-9]+]]:gr64_nosp = COPY [[COPY9]]
--  ; CHECK-NEXT:   [[COPY11:%[0-9]+]]:gr64_nosp = COPY [[COPY10]]
--  ; CHECK-NEXT:   JMP64m $noreg, 8, [[COPY10]], @computed_goto.dispatch, $noreg
-+  ; CHECK-NEXT:   [[COPY6:%[0-9]+]]:gr64_nosp = COPY $rax
-+  ; CHECK-NEXT:   [[COPY7:%[0-9]+]]:gr64_nosp = COPY [[COPY6]]
-+  ; CHECK-NEXT:   JMP64m $noreg, 8, [[COPY6]], @computed_goto.dispatch, $noreg
-   ; CHECK-NEXT: {{  $}}
--  ; CHECK-NEXT: bb.4:
-+  ; CHECK-NEXT: bb.4.bb4 (ir-block-address-taken %ir-block.bb4):
-   ; CHECK-NEXT:   successors: %bb.1(0x20000000), %bb.2(0x20000000), %bb.3(0x20000000), %bb.4(0x20000000)
-   ; CHECK-NEXT: {{  $}}
-   ; CHECK-NEXT:   ADJCALLSTACKDOWN64 0, 0, 0, implicit-def dead $rsp, implicit-def dead $eflags, implicit-def dead $ssp, implicit $rsp, implicit $ssp
-   ; CHECK-NEXT:   CALL64pcrel32 target-flags(x86-plt) @f4, csr_64, implicit $rsp, implicit $ssp, implicit-def $rsp, implicit-def $ssp, implicit-def $rax
-   ; CHECK-NEXT:   ADJCALLSTACKUP64 0, 0, implicit-def dead $rsp, implicit-def dead $eflags, implicit-def dead $ssp, implicit $rsp, implicit $ssp
--  ; CHECK-NEXT:   [[COPY12:%[0-9]+]]:gr64 = COPY $rax
--  ; CHECK-NEXT:   [[COPY13:%[0-9]+]]:gr64_nosp = COPY [[COPY12]]
--  ; CHECK-NEXT:   [[COPY14:%[0-9]+]]:gr64_nosp = COPY [[COPY13]]
--  ; CHECK-NEXT:   JMP64m $noreg, 8, [[COPY13]], @computed_goto.dispatch, $noreg
-+  ; CHECK-NEXT:   [[COPY8:%[0-9]+]]:gr64_nosp = COPY $rax
-+  ; CHECK-NEXT:   [[COPY9:%[0-9]+]]:gr64_nosp = COPY [[COPY8]]
-+  ; CHECK-NEXT:   JMP64m $noreg, 8, [[COPY8]], @computed_goto.dispatch, $noreg
-   bb.0:
-     ADJCALLSTACKDOWN64 0, 0, 0, implicit-def dead $rsp, implicit-def dead $eflags, implicit-def dead $ssp, implicit $rsp, implicit $ssp
-     CALL64pcrel32 target-flags(x86-plt) @f0, csr_64, implicit $rsp, implicit $ssp, implicit-def $rsp, implicit-def $ssp, implicit-def $rax
-     ADJCALLSTACKUP64 0, 0, implicit-def dead $rsp, implicit-def dead $eflags, implicit-def dead $ssp, implicit $rsp, implicit $ssp
--    %6:gr64 = COPY $rax
--    %0:gr64 = COPY %6
-+    %1:gr64 = COPY $rax
-     JMP_1 %bb.5
- 
--  bb.1:
-+  bb.1.bb1 (ir-block-address-taken %ir-block.bb1):
-     ADJCALLSTACKDOWN64 0, 0, 0, implicit-def dead $rsp, implicit-def dead $eflags, implicit-def dead $ssp, implicit $rsp, implicit $ssp
-     CALL64pcrel32 target-flags(x86-plt) @f1, csr_64, implicit $rsp, implicit $ssp, implicit-def $rsp, implicit-def $ssp, implicit-def $rax
-     ADJCALLSTACKUP64 0, 0, implicit-def dead $rsp, implicit-def dead $eflags, implicit-def dead $ssp, implicit $rsp, implicit $ssp
--    %10:gr64 = COPY $rax
--    %1:gr64 = COPY %10
-+    %3:gr64 = COPY $rax
-     JMP_1 %bb.5
- 
--  bb.2:
-+  bb.2.bb2 (ir-block-address-taken %ir-block.bb2):
-     ADJCALLSTACKDOWN64 0, 0, 0, implicit-def dead $rsp, implicit-def dead $eflags, implicit-def dead $ssp, implicit $rsp, implicit $ssp
-     CALL64pcrel32 target-flags(x86-plt) @f2, csr_64, implicit $rsp, implicit $ssp, implicit-def $rsp, implicit-def $ssp, implicit-def $rax
-     ADJCALLSTACKUP64 0, 0, implicit-def dead $rsp, implicit-def dead $eflags, implicit-def dead $ssp, implicit $rsp, implicit $ssp
--    %9:gr64 = COPY $rax
--    %2:gr64 = COPY %9
-+    %5:gr64 = COPY $rax
-     JMP_1 %bb.5
- 
--  bb.3:
-+  bb.3.bb3 (ir-block-address-taken %ir-block.bb3):
-     ADJCALLSTACKDOWN64 0, 0, 0, implicit-def dead $rsp, implicit-def dead $eflags, implicit-def dead $ssp, implicit $rsp, implicit $ssp
-     CALL64pcrel32 target-flags(x86-plt) @f3, csr_64, implicit $rsp, implicit $ssp, implicit-def $rsp, implicit-def $ssp, implicit-def $rax
-     ADJCALLSTACKUP64 0, 0, implicit-def dead $rsp, implicit-def dead $eflags, implicit-def dead $ssp, implicit $rsp, implicit $ssp
--    %8:gr64 = COPY $rax
--    %3:gr64 = COPY %8
-+    %7:gr64 = COPY $rax
-     JMP_1 %bb.5
- 
--  bb.4:
-+  bb.4.bb4 (ir-block-address-taken %ir-block.bb4):
-     ADJCALLSTACKDOWN64 0, 0, 0, implicit-def dead $rsp, implicit-def dead $eflags, implicit-def dead $ssp, implicit $rsp, implicit $ssp
-     CALL64pcrel32 target-flags(x86-plt) @f4, csr_64, implicit $rsp, implicit $ssp, implicit-def $rsp, implicit-def $ssp, implicit-def $rax
-     ADJCALLSTACKUP64 0, 0, implicit-def dead $rsp, implicit-def dead $eflags, implicit-def dead $ssp, implicit $rsp, implicit $ssp
--    %7:gr64 = COPY $rax
--    %4:gr64 = COPY %7
-+    %9:gr64 = COPY $rax
- 
-   bb.5:
-     successors: %bb.1, %bb.2, %bb.3, %bb.4
- 
--    %5:gr64_nosp = PHI %0, %bb.0, %4, %bb.4, %3, %bb.3, %2, %bb.2, %1, %bb.1
--    JMP64m $noreg, 8, %5, @computed_goto.dispatch, $noreg
-+    %10:gr64_nosp = PHI %1, %bb.0, %9, %bb.4, %7, %bb.3, %5, %bb.2, %3, %bb.1
-+    JMP64m $noreg, 8, %10, @computed_goto.dispatch, $noreg
- 
- ...
- ---
-@@ -124,7 +126,7 @@
-   kind:            block-address
-   entries:
-     - id:              0
--      blocks:          [ '%bb.2', '%bb.3', '%bb.4', '%bb.5', '%bb.6' ]
-+      blocks:          [ '%bb.3', '%bb.4', '%bb.5', '%bb.6', '%bb.7' ]
- body:             |
-   ; CHECK-LABEL: name: jump_table
-   ; CHECK: bb.0:
-@@ -134,12 +136,11 @@
-   ; CHECK-NEXT:   CALL64pcrel32 target-flags(x86-plt) @f0, csr_64, implicit $rsp, implicit $ssp, implicit-def $rsp, implicit-def $ssp, implicit-def $rax
-   ; CHECK-NEXT:   ADJCALLSTACKUP64 0, 0, implicit-def dead $rsp, implicit-def dead $eflags, implicit-def dead $ssp, implicit $rsp, implicit $ssp
-   ; CHECK-NEXT:   [[COPY:%[0-9]+]]:gr64 = COPY $rax
--  ; CHECK-NEXT:   [[COPY1:%[0-9]+]]:gr64 = COPY [[COPY]]
-   ; CHECK-NEXT: {{  $}}
-   ; CHECK-NEXT: bb.1:
-   ; CHECK-NEXT:   successors: %bb.3(0x1999999a), %bb.4(0x1999999a), %bb.5(0x1999999a), %bb.6(0x1999999a), %bb.7(0x1999999a)
-   ; CHECK-NEXT: {{  $}}
--  ; CHECK-NEXT:   [[PHI:%[0-9]+]]:gr64 = PHI [[COPY1]], %bb.0, %3, %bb.7, %4, %bb.6, %5, %bb.5, %6, %bb.4, %7, %bb.3
-+  ; CHECK-NEXT:   [[PHI:%[0-9]+]]:gr64 = PHI [[COPY]], %bb.0, %2, %bb.7, %3, %bb.6, %4, %bb.5, %5, %bb.4, %6, %bb.3
-   ; CHECK-NEXT:   [[DEC64r:%[0-9]+]]:gr64_nosp = DEC64r [[PHI]], implicit-def dead $eflags
-   ; CHECK-NEXT:   JMP64m $noreg, 8, [[DEC64r]], %jump-table.0, $noreg :: (load (s64) from jump-table)
-   ; CHECK-NEXT: {{  $}}
-@@ -149,8 +150,7 @@
-   ; CHECK-NEXT:   ADJCALLSTACKDOWN64 0, 0, 0, implicit-def dead $rsp, implicit-def dead $eflags, implicit-def dead $ssp, implicit $rsp, implicit $ssp
-   ; CHECK-NEXT:   CALL64pcrel32 target-flags(x86-plt) @f1, csr_64, implicit $rsp, implicit $ssp, implicit-def $rsp, implicit-def $ssp, implicit-def $rax
-   ; CHECK-NEXT:   ADJCALLSTACKUP64 0, 0, implicit-def dead $rsp, implicit-def dead $eflags, implicit-def dead $ssp, implicit $rsp, implicit $ssp
--  ; CHECK-NEXT:   [[COPY2:%[0-9]+]]:gr64 = COPY $rax
--  ; CHECK-NEXT:   [[COPY3:%[0-9]+]]:gr64 = COPY [[COPY2]]
-+  ; CHECK-NEXT:   [[COPY1:%[0-9]+]]:gr64 = COPY $rax
-   ; CHECK-NEXT:   JMP_1 %bb.1
-   ; CHECK-NEXT: {{  $}}
-   ; CHECK-NEXT: bb.4:
-@@ -159,8 +159,7 @@
-   ; CHECK-NEXT:   ADJCALLSTACKDOWN64 0, 0, 0, implicit-def dead $rsp, implicit-def dead $eflags, implicit-def dead $ssp, implicit $rsp, implicit $ssp
-   ; CHECK-NEXT:   CALL64pcrel32 target-flags(x86-plt) @f2, csr_64, implicit $rsp, implicit $ssp, implicit-def $rsp, implicit-def $ssp, implicit-def $rax
-   ; CHECK-NEXT:   ADJCALLSTACKUP64 0, 0, implicit-def dead $rsp, implicit-def dead $eflags, implicit-def dead $ssp, implicit $rsp, implicit $ssp
--  ; CHECK-NEXT:   [[COPY4:%[0-9]+]]:gr64 = COPY $rax
--  ; CHECK-NEXT:   [[COPY5:%[0-9]+]]:gr64 = COPY [[COPY4]]
-+  ; CHECK-NEXT:   [[COPY2:%[0-9]+]]:gr64 = COPY $rax
-   ; CHECK-NEXT:   JMP_1 %bb.1
-   ; CHECK-NEXT: {{  $}}
-   ; CHECK-NEXT: bb.5:
-@@ -169,8 +168,7 @@
-   ; CHECK-NEXT:   ADJCALLSTACKDOWN64 0, 0, 0, implicit-def dead $rsp, implicit-def dead $eflags, implicit-def dead $ssp, implicit $rsp, implicit $ssp
-   ; CHECK-NEXT:   CALL64pcrel32 target-flags(x86-plt) @f3, csr_64, implicit $rsp, implicit $ssp, implicit-def $rsp, implicit-def $ssp, implicit-def $rax
-   ; CHECK-NEXT:   ADJCALLSTACKUP64 0, 0, implicit-def dead $rsp, implicit-def dead $eflags, implicit-def dead $ssp, implicit $rsp, implicit $ssp
--  ; CHECK-NEXT:   [[COPY6:%[0-9]+]]:gr64 = COPY $rax
--  ; CHECK-NEXT:   [[COPY7:%[0-9]+]]:gr64 = COPY [[COPY6]]
-+  ; CHECK-NEXT:   [[COPY3:%[0-9]+]]:gr64 = COPY $rax
-   ; CHECK-NEXT:   JMP_1 %bb.1
-   ; CHECK-NEXT: {{  $}}
-   ; CHECK-NEXT: bb.6:
-@@ -179,8 +177,7 @@
-   ; CHECK-NEXT:   ADJCALLSTACKDOWN64 0, 0, 0, implicit-def dead $rsp, implicit-def dead $eflags, implicit-def dead $ssp, implicit $rsp, implicit $ssp
-   ; CHECK-NEXT:   CALL64pcrel32 target-flags(x86-plt) @f4, csr_64, implicit $rsp, implicit $ssp, implicit-def $rsp, implicit-def $ssp, implicit-def $rax
-   ; CHECK-NEXT:   ADJCALLSTACKUP64 0, 0, implicit-def dead $rsp, implicit-def dead $eflags, implicit-def dead $ssp, implicit $rsp, implicit $ssp
--  ; CHECK-NEXT:   [[COPY8:%[0-9]+]]:gr64 = COPY $rax
--  ; CHECK-NEXT:   [[COPY9:%[0-9]+]]:gr64 = COPY [[COPY8]]
-+  ; CHECK-NEXT:   [[COPY4:%[0-9]+]]:gr64 = COPY $rax
-   ; CHECK-NEXT:   JMP_1 %bb.1
-   ; CHECK-NEXT: {{  $}}
-   ; CHECK-NEXT: bb.7:
-@@ -189,67 +186,181 @@
-   ; CHECK-NEXT:   ADJCALLSTACKDOWN64 0, 0, 0, implicit-def dead $rsp, implicit-def dead $eflags, implicit-def dead $ssp, implicit $rsp, implicit $ssp
-   ; CHECK-NEXT:   CALL64pcrel32 target-flags(x86-plt) @f5, csr_64, implicit $rsp, implicit $ssp, implicit-def $rsp, implicit-def $ssp, implicit-def $rax
-   ; CHECK-NEXT:   ADJCALLSTACKUP64 0, 0, implicit-def dead $rsp, implicit-def dead $eflags, implicit-def dead $ssp, implicit $rsp, implicit $ssp
--  ; CHECK-NEXT:   [[COPY10:%[0-9]+]]:gr64 = COPY $rax
--  ; CHECK-NEXT:   [[COPY11:%[0-9]+]]:gr64 = COPY [[COPY10]]
-+  ; CHECK-NEXT:   [[COPY5:%[0-9]+]]:gr64 = COPY $rax
-   ; CHECK-NEXT:   JMP_1 %bb.1
--  ; CHECK-NEXT: {{  $}}
--  ; CHECK-NEXT: bb.8:
-   bb.0:
-     ADJCALLSTACKDOWN64 0, 0, 0, implicit-def dead $rsp, implicit-def dead $eflags, implicit-def dead $ssp, implicit $rsp, implicit $ssp
-     CALL64pcrel32 target-flags(x86-plt) @f0, csr_64, implicit $rsp, implicit $ssp, implicit-def $rsp, implicit-def $ssp, implicit-def $rax
-     ADJCALLSTACKUP64 0, 0, implicit-def dead $rsp, implicit-def dead $eflags, implicit-def dead $ssp, implicit $rsp, implicit $ssp
--    %7:gr64 = COPY $rax
--    %0:gr64 = COPY %7
-+    %1:gr64 = COPY $rax
- 
-   bb.1:
--    %1:gr64 = PHI %0, %bb.0, %6, %bb.6, %5, %bb.5, %4, %bb.4, %3, %bb.3, %2, %bb.2
--    %8:gr64_nosp = DEC64r %1, implicit-def dead $eflags
-+    %2:gr64 = PHI %1, %bb.0, %3, %bb.7, %4, %bb.6, %5, %bb.5, %6, %bb.4, %7, %bb.3
-+    %8:gr64_nosp = DEC64r %2, implicit-def dead $eflags
- 
--  bb.8:
--    successors: %bb.2(0x1999999a), %bb.3(0x1999999a), %bb.4(0x1999999a), %bb.5(0x1999999a), %bb.6(0x1999999a)
-+  bb.2:
-+    successors: %bb.3(0x1999999a), %bb.4(0x1999999a), %bb.5(0x1999999a), %bb.6(0x1999999a), %bb.7(0x1999999a)
- 
-     JMP64m $noreg, 8, %8, %jump-table.0, $noreg :: (load (s64) from jump-table)
- 
--  bb.2:
-+  bb.3:
-     ADJCALLSTACKDOWN64 0, 0, 0, implicit-def dead $rsp, implicit-def dead $eflags, implicit-def dead $ssp, implicit $rsp, implicit $ssp
-     CALL64pcrel32 target-flags(x86-plt) @f1, csr_64, implicit $rsp, implicit $ssp, implicit-def $rsp, implicit-def $ssp, implicit-def $rax
-     ADJCALLSTACKUP64 0, 0, implicit-def dead $rsp, implicit-def dead $eflags, implicit-def dead $ssp, implicit $rsp, implicit $ssp
--    %13:gr64 = COPY $rax
--    %2:gr64 = COPY %13
-+    %7:gr64 = COPY $rax
-     JMP_1 %bb.1
- 
--  bb.3:
-+  bb.4:
-     ADJCALLSTACKDOWN64 0, 0, 0, implicit-def dead $rsp, implicit-def dead $eflags, implicit-def dead $ssp, implicit $rsp, implicit $ssp
-     CALL64pcrel32 target-flags(x86-plt) @f2, csr_64, implicit $rsp, implicit $ssp, implicit-def $rsp, implicit-def $ssp, implicit-def $rax
-     ADJCALLSTACKUP64 0, 0, implicit-def dead $rsp, implicit-def dead $eflags, implicit-def dead $ssp, implicit $rsp, implicit $ssp
--    %12:gr64 = COPY $rax
--    %3:gr64 = COPY %12
-+    %6:gr64 = COPY $rax
-     JMP_1 %bb.1
- 
--  bb.4:
-+  bb.5:
-     ADJCALLSTACKDOWN64 0, 0, 0, implicit-def dead $rsp, implicit-def dead $eflags, implicit-def dead $ssp, implicit $rsp, implicit $ssp
-     CALL64pcrel32 target-flags(x86-plt) @f3, csr_64, implicit $rsp, implicit $ssp, implicit-def $rsp, implicit-def $ssp, implicit-def $rax
-     ADJCALLSTACKUP64 0, 0, implicit-def dead $rsp, implicit-def dead $eflags, implicit-def dead $ssp, implicit $rsp, implicit $ssp
--    %11:gr64 = COPY $rax
--    %4:gr64 = COPY %11
-+    %5:gr64 = COPY $rax
-     JMP_1 %bb.1
- 
--  bb.5:
-+  bb.6:
-     ADJCALLSTACKDOWN64 0, 0, 0, implicit-def dead $rsp, implicit-def dead $eflags, implicit-def dead $ssp, implicit $rsp, implicit $ssp
-     CALL64pcrel32 target-flags(x86-plt) @f4, csr_64, implicit $rsp, implicit $ssp, implicit-def $rsp, implicit-def $ssp, implicit-def $rax
-     ADJCALLSTACKUP64 0, 0, implicit-def dead $rsp, implicit-def dead $eflags, implicit-def dead $ssp, implicit $rsp, implicit $ssp
--    %10:gr64 = COPY $rax
--    %5:gr64 = COPY %10
-+    %4:gr64 = COPY $rax
-     JMP_1 %bb.1
- 
--  bb.6:
-+  bb.7:
-     ADJCALLSTACKDOWN64 0, 0, 0, implicit-def dead $rsp, implicit-def dead $eflags, implicit-def dead $ssp, implicit $rsp, implicit $ssp
-     CALL64pcrel32 target-flags(x86-plt) @f5, csr_64, implicit $rsp, implicit $ssp, implicit-def $rsp, implicit-def $ssp, implicit-def $rax
-     ADJCALLSTACKUP64 0, 0, implicit-def dead $rsp, implicit-def dead $eflags, implicit-def dead $ssp, implicit $rsp, implicit $ssp
--    %9:gr64 = COPY $rax
--    %6:gr64 = COPY %9
-+    %3:gr64 = COPY $rax
-+    JMP_1 %bb.1
-+
-+...
-+---
-+name:            jump_table_pic
-+tracksRegLiveness: true
-+jumpTable:
-+  kind:            block-address
-+  entries:
-+    - id:              0
-+      blocks:          [ '%bb.3', '%bb.4', '%bb.5', '%bb.6', '%bb.7' ]
-+body:             |
-+  ; CHECK-LABEL: name: jump_table_pic
-+  ; CHECK: bb.0:
-+  ; CHECK-NEXT:   successors: %bb.1(0x80000000)
-+  ; CHECK-NEXT: {{  $}}
-+  ; CHECK-NEXT:   ADJCALLSTACKDOWN64 0, 0, 0, implicit-def dead $rsp, implicit-def dead $eflags, implicit-def dead $ssp, implicit $rsp, implicit $ssp
-+  ; CHECK-NEXT:   CALL64pcrel32 target-flags(x86-plt) @f0, csr_64, implicit $rsp, implicit $ssp, implicit-def $rsp, implicit-def $ssp, implicit-def $rax
-+  ; CHECK-NEXT:   ADJCALLSTACKUP64 0, 0, implicit-def dead $rsp, implicit-def dead $eflags, implicit-def dead $ssp, implicit $rsp, implicit $ssp
-+  ; CHECK-NEXT:   [[COPY:%[0-9]+]]:gr64 = COPY $rax
-+  ; CHECK-NEXT: {{  $}}
-+  ; CHECK-NEXT: bb.1:
-+  ; CHECK-NEXT:   successors: %bb.3(0x1999999a), %bb.4(0x1999999a), %bb.5(0x1999999a), %bb.6(0x1999999a), %bb.7(0x1999999a)
-+  ; CHECK-NEXT: {{  $}}
-+  ; CHECK-NEXT:   [[PHI:%[0-9]+]]:gr64 = PHI [[COPY]], %bb.0, %2, %bb.7, %3, %bb.6, %4, %bb.5, %5, %bb.4, %6, %bb.3
-+  ; CHECK-NEXT:   [[DEC64r:%[0-9]+]]:gr64_nosp = DEC64r [[PHI]], implicit-def dead $eflags
-+  ; CHECK-NEXT:   [[LEA64r:%[0-9]+]]:gr64 = LEA64r $rip, 1, $noreg, %jump-table.0, $noreg
-+  ; CHECK-NEXT:   [[MOVSX64rm32_:%[0-9]+]]:gr64 = MOVSX64rm32 [[DEC64r]], 4, [[DEC64r]], 0, $noreg :: (load (s32) from jump-table)
-+  ; CHECK-NEXT:   [[ADD64rr:%[0-9]+]]:gr64 = ADD64rr [[LEA64r]], [[MOVSX64rm32_]], implicit-def dead $eflags
-+  ; CHECK-NEXT:   JMP64r [[ADD64rr]]
-+  ; CHECK-NEXT: {{  $}}
-+  ; CHECK-NEXT: bb.3:
-+  ; CHECK-NEXT:   successors: %bb.1(0x80000000)
-+  ; CHECK-NEXT: {{  $}}
-+  ; CHECK-NEXT:   ADJCALLSTACKDOWN64 0, 0, 0, implicit-def dead $rsp, implicit-def dead $eflags, implicit-def dead $ssp, implicit $rsp, implicit $ssp
-+  ; CHECK-NEXT:   CALL64pcrel32 target-flags(x86-plt) @f1, csr_64, implicit $rsp, implicit $ssp, implicit-def $rsp, implicit-def $ssp, implicit-def $rax
-+  ; CHECK-NEXT:   ADJCALLSTACKUP64 0, 0, implicit-def dead $rsp, implicit-def dead $eflags, implicit-def dead $ssp, implicit $rsp, implicit $ssp
-+  ; CHECK-NEXT:   [[COPY1:%[0-9]+]]:gr64 = COPY $rax
-+  ; CHECK-NEXT:   JMP_1 %bb.1
-+  ; CHECK-NEXT: {{  $}}
-+  ; CHECK-NEXT: bb.4:
-+  ; CHECK-NEXT:   successors: %bb.1(0x80000000)
-+  ; CHECK-NEXT: {{  $}}
-+  ; CHECK-NEXT:   ADJCALLSTACKDOWN64 0, 0, 0, implicit-def dead $rsp, implicit-def dead $eflags, implicit-def dead $ssp, implicit $rsp, implicit $ssp
-+  ; CHECK-NEXT:   CALL64pcrel32 target-flags(x86-plt) @f2, csr_64, implicit $rsp, implicit $ssp, implicit-def $rsp, implicit-def $ssp, implicit-def $rax
-+  ; CHECK-NEXT:   ADJCALLSTACKUP64 0, 0, implicit-def dead $rsp, implicit-def dead $eflags, implicit-def dead $ssp, implicit $rsp, implicit $ssp
-+  ; CHECK-NEXT:   [[COPY2:%[0-9]+]]:gr64 = COPY $rax
-+  ; CHECK-NEXT:   JMP_1 %bb.1
-+  ; CHECK-NEXT: {{  $}}
-+  ; CHECK-NEXT: bb.5:
-+  ; CHECK-NEXT:   successors: %bb.1(0x80000000)
-+  ; CHECK-NEXT: {{  $}}
-+  ; CHECK-NEXT:   ADJCALLSTACKDOWN64 0, 0, 0, implicit-def dead $rsp, implicit-def dead $eflags, implicit-def dead $ssp, implicit $rsp, implicit $ssp
-+  ; CHECK-NEXT:   CALL64pcrel32 target-flags(x86-plt) @f3, csr_64, implicit $rsp, implicit $ssp, implicit-def $rsp, implicit-def $ssp, implicit-def $rax
-+  ; CHECK-NEXT:   ADJCALLSTACKUP64 0, 0, implicit-def dead $rsp, implicit-def dead $eflags, implicit-def dead $ssp, implicit $rsp, implicit $ssp
-+  ; CHECK-NEXT:   [[COPY3:%[0-9]+]]:gr64 = COPY $rax
-+  ; CHECK-NEXT:   JMP_1 %bb.1
-+  ; CHECK-NEXT: {{  $}}
-+  ; CHECK-NEXT: bb.6:
-+  ; CHECK-NEXT:   successors: %bb.1(0x80000000)
-+  ; CHECK-NEXT: {{  $}}
-+  ; CHECK-NEXT:   ADJCALLSTACKDOWN64 0, 0, 0, implicit-def dead $rsp, implicit-def dead $eflags, implicit-def dead $ssp, implicit $rsp, implicit $ssp
-+  ; CHECK-NEXT:   CALL64pcrel32 target-flags(x86-plt) @f4, csr_64, implicit $rsp, implicit $ssp, implicit-def $rsp, implicit-def $ssp, implicit-def $rax
-+  ; CHECK-NEXT:   ADJCALLSTACKUP64 0, 0, implicit-def dead $rsp, implicit-def dead $eflags, implicit-def dead $ssp, implicit $rsp, implicit $ssp
-+  ; CHECK-NEXT:   [[COPY4:%[0-9]+]]:gr64 = COPY $rax
-+  ; CHECK-NEXT:   JMP_1 %bb.1
-+  ; CHECK-NEXT: {{  $}}
-+  ; CHECK-NEXT: bb.7:
-+  ; CHECK-NEXT:   successors: %bb.1(0x80000000)
-+  ; CHECK-NEXT: {{  $}}
-+  ; CHECK-NEXT:   ADJCALLSTACKDOWN64 0, 0, 0, implicit-def dead $rsp, implicit-def dead $eflags, implicit-def dead $ssp, implicit $rsp, implicit $ssp
-+  ; CHECK-NEXT:   CALL64pcrel32 target-flags(x86-plt) @f5, csr_64, implicit $rsp, implicit $ssp, implicit-def $rsp, implicit-def $ssp, implicit-def $rax
-+  ; CHECK-NEXT:   ADJCALLSTACKUP64 0, 0, implicit-def dead $rsp, implicit-def dead $eflags, implicit-def dead $ssp, implicit $rsp, implicit $ssp
-+  ; CHECK-NEXT:   [[COPY5:%[0-9]+]]:gr64 = COPY $rax
-+  ; CHECK-NEXT:   JMP_1 %bb.1
-+  bb.0:
-+    ADJCALLSTACKDOWN64 0, 0, 0, implicit-def dead $rsp, implicit-def dead $eflags, implicit-def dead $ssp, implicit $rsp, implicit $ssp
-+    CALL64pcrel32 target-flags(x86-plt) @f0, csr_64, implicit $rsp, implicit $ssp, implicit-def $rsp, implicit-def $ssp, implicit-def $rax
-+    ADJCALLSTACKUP64 0, 0, implicit-def dead $rsp, implicit-def dead $eflags, implicit-def dead $ssp, implicit $rsp, implicit $ssp
-+    %1:gr64 = COPY $rax
-+
-+  bb.1:
-+    %2:gr64 = PHI %1, %bb.0, %3, %bb.7, %4, %bb.6, %5, %bb.5, %6, %bb.4, %7, %bb.3
-+    %8:gr64_nosp = DEC64r %2, implicit-def dead $eflags
-+
-+  bb.2:
-+    successors: %bb.3(0x1999999a), %bb.4(0x1999999a), %bb.5(0x1999999a), %bb.6(0x1999999a), %bb.7(0x1999999a)
-+    %9:gr64 = LEA64r $rip, 1, $noreg, %jump-table.0, $noreg
-+    %10:gr64 = MOVSX64rm32 %8, 4, %8, 0, $noreg :: (load (s32) from jump-table)
-+    %11:gr64 = ADD64rr %9, %10, implicit-def dead $eflags
-+    JMP64r %11
-+
-+  bb.3:
-+    ADJCALLSTACKDOWN64 0, 0, 0, implicit-def dead $rsp, implicit-def dead $eflags, implicit-def dead $ssp, implicit $rsp, implicit $ssp
-+    CALL64pcrel32 target-flags(x86-plt) @f1, csr_64, implicit $rsp, implicit $ssp, implicit-def $rsp, implicit-def $ssp, implicit-def $rax
-+    ADJCALLSTACKUP64 0, 0, implicit-def dead $rsp, implicit-def dead $eflags, implicit-def dead $ssp, implicit $rsp, implicit $ssp
-+    %7:gr64 = COPY $rax
-+    JMP_1 %bb.1
-+
-+  bb.4:
-+    ADJCALLSTACKDOWN64 0, 0, 0, implicit-def dead $rsp, implicit-def dead $eflags, implicit-def dead $ssp, implicit $rsp, implicit $ssp
-+    CALL64pcrel32 target-flags(x86-plt) @f2, csr_64, implicit $rsp, implicit $ssp, implicit-def $rsp, implicit-def $ssp, implicit-def $rax
-+    ADJCALLSTACKUP64 0, 0, implicit-def dead $rsp, implicit-def dead $eflags, implicit-def dead $ssp, implicit $rsp, implicit $ssp
-+    %6:gr64 = COPY $rax
-+    JMP_1 %bb.1
-+
-+  bb.5:
-+    ADJCALLSTACKDOWN64 0, 0, 0, implicit-def dead $rsp, implicit-def dead $eflags, implicit-def dead $ssp, implicit $rsp, implicit $ssp
-+    CALL64pcrel32 target-flags(x86-plt) @f3, csr_64, implicit $rsp, implicit $ssp, implicit-def $rsp, implicit-def $ssp, implicit-def $rax
-+    ADJCALLSTACKUP64 0, 0, implicit-def dead $rsp, implicit-def dead $eflags, implicit-def dead $ssp, implicit $rsp, implicit $ssp
-+    %5:gr64 = COPY $rax
-+    JMP_1 %bb.1
+       SDValue Load =
+           DAG.getLoad(VT, SDLoc(N), LN0->getChain(), LN0->getBasePtr(),
+                       LN0->getMemOperand());
+diff -ruN --strip-trailing-cr a/llvm/test/CodeGen/X86/fold_bitcast_md_range.ll b/llvm/test/CodeGen/X86/fold_bitcast_md_range.ll
+--- a/llvm/test/CodeGen/X86/fold_bitcast_md_range.ll
++++ b/llvm/test/CodeGen/X86/fold_bitcast_md_range.ll
+@@ -0,0 +1,23 @@
++; NOTE: Assertions have been autogenerated by utils/update_llc_test_checks.py UTC_ARGS: --version 5
++; RUN: llc -mtriple=x86_64-apple-macosx10.12.0 < %s | FileCheck %s
++
++; Ensure that when a bitcast is folded into a load, range metadata is invalidated
++; if it does not match the new type.
++
++define i1 @fold_bitcast_range_metadata(ptr %valptr) {
++; CHECK-LABEL: fold_bitcast_range_metadata:
++; CHECK:       ## %bb.0: ## %start
++; CHECK-NEXT:    movdqa (%rdi), %xmm0
++; CHECK-NEXT:    pcmpeqb {{\.?LCPI[0-9]+_[0-9]+}}(%rip), %xmm0
++; CHECK-NEXT:    pmovmskb %xmm0, %eax
++; CHECK-NEXT:    cmpl $65535, %eax ## imm = 0xFFFF
++; CHECK-NEXT:    sete %al
++; CHECK-NEXT:    retq
++start:
++  %val = load i128, ptr %valptr, align 16, !range !0, !noundef !1
++  %bool = icmp eq i128 %val, 1
++  ret i1 %bool
++}
 +
-+  bb.6:
-+    ADJCALLSTACKDOWN64 0, 0, 0, implicit-def dead $rsp, implicit-def dead $eflags, implicit-def dead $ssp, implicit $rsp, implicit $ssp
-+    CALL64pcrel32 target-flags(x86-plt) @f4, csr_64, implicit $rsp, implicit $ssp, implicit-def $rsp, implicit-def $ssp, implicit-def $rax
-+    ADJCALLSTACKUP64 0, 0, implicit-def dead $rsp, implicit-def dead $eflags, implicit-def dead $ssp, implicit $rsp, implicit $ssp
-+    %4:gr64 = COPY $rax
-     JMP_1 %bb.1
- 
-   bb.7:
-+    ADJCALLSTACKDOWN64 0, 0, 0, implicit-def dead $rsp, implicit-def dead $eflags, implicit-def dead $ssp, implicit $rsp, implicit $ssp
-+    CALL64pcrel32 target-flags(x86-plt) @f5, csr_64, implicit $rsp, implicit $ssp, implicit-def $rsp, implicit-def $ssp, implicit-def $rax
-+    ADJCALLSTACKUP64 0, 0, implicit-def dead $rsp, implicit-def dead $eflags, implicit-def dead $ssp, implicit $rsp, implicit $ssp
-+    %3:gr64 = COPY $rax
-+    JMP_1 %bb.1
- 
- ...
-diff -ruN --strip-trailing-cr a/mlir/include/mlir/IR/MLIRContext.h b/mlir/include/mlir/IR/MLIRContext.h
---- a/mlir/include/mlir/IR/MLIRContext.h
-+++ b/mlir/include/mlir/IR/MLIRContext.h
-@@ -153,14 +153,6 @@
-     disableMultithreading(!enable);
-   }
- 
--  /// Set the flag specifying if thread-local storage should be used by storage
--  /// allocators in this context. Note that disabling mutlithreading implies
--  /// thread-local storage is also disabled.
--  void disableThreadLocalStorage(bool disable = true);
--  void enableThreadLocalStorage(bool enable = true) {
--    disableThreadLocalStorage(!enable);
--  }
--
-   /// Set a new thread pool to be used in this context. This method requires
-   /// that multithreading is disabled for this context prior to the call. This
-   /// allows to share a thread pool across multiple contexts, as well as
-diff -ruN --strip-trailing-cr a/mlir/lib/IR/AttributeDetail.h b/mlir/lib/IR/AttributeDetail.h
---- a/mlir/lib/IR/AttributeDetail.h
-+++ b/mlir/lib/IR/AttributeDetail.h
-@@ -24,7 +24,6 @@
- #include "llvm/ADT/APFloat.h"
- #include "llvm/ADT/PointerIntPair.h"
- #include "llvm/Support/TrailingObjects.h"
--#include <mutex>
- 
- namespace mlir {
- namespace detail {
-@@ -402,8 +401,7 @@
- /// is freed after the destruction of the distinct attribute allocator.
- class DistinctAttributeAllocator {
- public:
--  DistinctAttributeAllocator(bool threadingIsEnabled)
--      : threadingIsEnabled(threadingIsEnabled), useThreadLocalAllocator(true) {};
-+  DistinctAttributeAllocator() = default;
- 
-   DistinctAttributeAllocator(DistinctAttributeAllocator &&) = delete;
-   DistinctAttributeAllocator(const DistinctAttributeAllocator &) = delete;
-@@ -413,49 +411,12 @@
-   /// Allocates a distinct attribute storage using a thread local bump pointer
-   /// allocator to enable synchronization free parallel allocations.
-   DistinctAttrStorage *allocate(Attribute referencedAttr) {
--    if (!useThreadLocalAllocator && threadingIsEnabled) {
--      std::scoped_lock<std::mutex> lock(allocatorMutex);
--      return allocateImpl(referencedAttr);
--    }
--    return allocateImpl(referencedAttr);
--  }
--
--  /// Sets a flag that stores if multithreading is enabled. The flag is used to
--  /// decide if locking is needed when using a non thread-safe allocator.
--  void disableMultiThreading(bool disable = true) {
--    threadingIsEnabled = !disable;
--  }
--
--  /// Sets a flag to disable using thread local bump pointer allocators and use
--  /// a single thread-safe allocator. Use this to persist allocated storage
--  /// beyond the lifetime of a child thread calling this function while ensuring
--  /// thread-safe allocation.
--  void disableThreadLocalStorage(bool disable = true) {
--    useThreadLocalAllocator = !disable;
--  }
--
--private:
--  DistinctAttrStorage *allocateImpl(Attribute referencedAttr) {
--    return new (getAllocatorInUse().Allocate<DistinctAttrStorage>())
-+    return new (allocatorCache.get().Allocate<DistinctAttrStorage>())
-         DistinctAttrStorage(referencedAttr);
-   }
- 
--  /// If threading is disabled on the owning MLIR context, a normal non
--  /// thread-local, non-thread safe bump pointer allocator is used instead to
--  /// prevent use-after-free errors whenever attribute storage created on a
--  /// crash recover thread is accessed after the thread joins.
--  llvm::BumpPtrAllocator &getAllocatorInUse() {
--    if (useThreadLocalAllocator)
--      return allocatorCache.get();
--    return allocator;
--  }
--
-+private:
-   ThreadLocalCache<llvm::BumpPtrAllocator> allocatorCache;
--  llvm::BumpPtrAllocator allocator;
--  std::mutex allocatorMutex;
--
--  bool threadingIsEnabled : 1;
--  bool useThreadLocalAllocator : 1;
- };
- } // namespace detail
- } // namespace mlir
-diff -ruN --strip-trailing-cr a/mlir/lib/IR/MLIRContext.cpp b/mlir/lib/IR/MLIRContext.cpp
---- a/mlir/lib/IR/MLIRContext.cpp
-+++ b/mlir/lib/IR/MLIRContext.cpp
-@@ -268,8 +268,7 @@
- 
- public:
-   MLIRContextImpl(bool threadingIsEnabled)
--      : threadingIsEnabled(threadingIsEnabled),
--        distinctAttributeAllocator(threadingIsEnabled) {
-+      : threadingIsEnabled(threadingIsEnabled) {
-     if (threadingIsEnabled) {
-       ownedThreadPool = std::make_unique<llvm::DefaultThreadPool>();
-       threadPool = ownedThreadPool.get();
-@@ -597,7 +596,6 @@
-   // Update the threading mode for each of the uniquers.
-   impl->affineUniquer.disableMultithreading(disable);
-   impl->attributeUniquer.disableMultithreading(disable);
--  impl->distinctAttributeAllocator.disableMultiThreading(disable);
-   impl->typeUniquer.disableMultithreading(disable);
- 
-   // Destroy thread pool (stop all threads) if it is no longer needed, or create
-@@ -719,10 +717,6 @@
-   return RegisteredOperationName::lookup(name, this).has_value();
- }
- 
--void MLIRContext::disableThreadLocalStorage(bool disable) {
--  getImpl().distinctAttributeAllocator.disableThreadLocalStorage(disable);
--}
--
- void Dialect::addType(TypeID typeID, AbstractType &&typeInfo) {
-   auto &impl = context->getImpl();
-   assert(impl.multiThreadedExecutionContext == 0 &&
-diff -ruN --strip-trailing-cr a/mlir/lib/Pass/PassCrashRecovery.cpp b/mlir/lib/Pass/PassCrashRecovery.cpp
---- a/mlir/lib/Pass/PassCrashRecovery.cpp
-+++ b/mlir/lib/Pass/PassCrashRecovery.cpp
-@@ -414,15 +414,6 @@
- 
- LogicalResult PassManager::runWithCrashRecovery(Operation *op,
-                                                 AnalysisManager am) {
--  // Notify the context to disable the use of thread-local storage while the
--  // pass manager is running in a crash recovery context thread. Re-enable the
--  // thread local storage upon function exit. This is required to persist any
--  // attribute storage allocated during passes beyond the lifetime of the
--  // recovery context thread.
--  MLIRContext *ctx = getContext();
--  ctx->disableThreadLocalStorage();
--  auto guard =
--      llvm::make_scope_exit([ctx]() { ctx->enableThreadLocalStorage(); });
-   crashReproGenerator->initialize(getPasses(), op, verifyPasses);
- 
-   // Safely invoke the passes within a recovery context.
-diff -ruN --strip-trailing-cr a/mlir/test/Dialect/LLVMIR/add-debuginfo-func-scope-with-crash-reproduction.mlir b/mlir/test/Dialect/LLVMIR/add-debuginfo-func-scope-with-crash-reproduction.mlir
---- a/mlir/test/Dialect/LLVMIR/add-debuginfo-func-scope-with-crash-reproduction.mlir
-+++ b/mlir/test/Dialect/LLVMIR/add-debuginfo-func-scope-with-crash-reproduction.mlir
-@@ -1,22 +0,0 @@
--// Test that the enable-debug-info-scope-on-llvm-func pass can create its
--// distinct attributes when running in the crash reproducer thread.
--
--// RUN: mlir-opt --mlir-disable-threading --mlir-pass-pipeline-crash-reproducer=. \
--// RUN:          --pass-pipeline="builtin.module(ensure-debug-info-scope-on-llvm-func)" \
--// RUN:          --mlir-print-debuginfo %s | FileCheck %s
--
--// RUN: mlir-opt --mlir-pass-pipeline-crash-reproducer=. \
--// RUN:          --pass-pipeline="builtin.module(ensure-debug-info-scope-on-llvm-func)" \
--// RUN:          --mlir-print-debuginfo %s | FileCheck %s
--
--module {
--  llvm.func @func_no_debug() {
--    llvm.return loc(unknown)
--  } loc(unknown)
--} loc(unknown)
--
--// CHECK-LABEL: llvm.func @func_no_debug()
--// CHECK: llvm.return loc(#loc
--// CHECK: loc(#loc[[LOC:[0-9]+]])
--// CHECK: #di_compile_unit = #llvm.di_compile_unit<id = distinct[{{.*}}]<>,
--// CHECK: #di_subprogram = #llvm.di_subprogram<id = distinct[{{.*}}]<>
-diff -ruN --strip-trailing-cr a/mlir/test/IR/test-builtin-distinct-attrs-with-crash-reproduction.mlir b/mlir/test/IR/test-builtin-distinct-attrs-with-crash-reproduction.mlir
---- a/mlir/test/IR/test-builtin-distinct-attrs-with-crash-reproduction.mlir
-+++ b/mlir/test/IR/test-builtin-distinct-attrs-with-crash-reproduction.mlir
-@@ -1,18 +0,0 @@
--// This test verifies that when running with crash reproduction enabled, distinct
--// attribute storage is not allocated in thread-local storage. Since crash
--// reproduction runs the pass manager in a separate thread, using thread-local
--// storage for distinct attributes causes use-after-free errors once the thread
--// that runs the pass manager joins.
--
--// RUN: mlir-opt --mlir-disable-threading --mlir-pass-pipeline-crash-reproducer=. %s -test-distinct-attrs | FileCheck %s
--// RUN: mlir-opt --mlir-pass-pipeline-crash-reproducer=. %s -test-distinct-attrs | FileCheck %s
--
--// CHECK: #[[DIST0:.*]] = distinct[0]<42 : i32>
--// CHECK: #[[DIST1:.*]] = distinct[1]<42 : i32>
--#distinct = distinct[0]<42 : i32>
--
--// CHECK: @foo_1
--func.func @foo_1() {
--  // CHECK: "test.op"() {distinct.input = #[[DIST0]], distinct.output = #[[DIST1]]}
--  "test.op"() {distinct.input = #distinct} : () -> ()
--}
-diff -ruN --strip-trailing-cr a/utils/bazel/llvm-project-overlay/libc/test/src/math/smoke/BUILD.bazel b/utils/bazel/llvm-project-overlay/libc/test/src/math/smoke/BUILD.bazel
---- a/utils/bazel/llvm-project-overlay/libc/test/src/math/smoke/BUILD.bazel
-+++ b/utils/bazel/llvm-project-overlay/libc/test/src/math/smoke/BUILD.bazel
-@@ -204,20 +204,21 @@
-     hdrs = ["FmaTest.h"],
- )
- 
--math_test(
--    name = "f16fma",
--    hdrs = ["FmaTest.h"],
--)
--
--math_test(
--    name = "f16fmaf",
--    hdrs = ["FmaTest.h"],
--)
--
--math_test(
--    name = "f16fmal",
--    hdrs = ["FmaTest.h"],
--)
-+# TODO: Reenable these tests once they pass at Google.
-+# math_test(
-+#     name = "f16fma",
-+#     hdrs = ["FmaTest.h"],
-+# )
-+# 
-+# math_test(
-+#     name = "f16fmaf",
-+#     hdrs = ["FmaTest.h"],
-+# )
-+# 
-+# math_test(
-+#     name = "f16fmal",
-+#     hdrs = ["FmaTest.h"],
-+# )
- 
- math_test(
-     name = "dmull",
-@@ -476,10 +477,11 @@
- 
- # TODO: Add fma, fmaf, fmal, fmaf128 tests.
- 
--math_test(
--    name = "fmaf16",
--    hdrs = ["FmaTest.h"],
--)
-+# TODO: Reenable this test once it passes at Google.
-+# math_test(
-+#     name = "fmaf16",
-+#     hdrs = ["FmaTest.h"],
-+# )
- 
- math_test(
-     name = "fmax",
++!0 = !{i128 0, i128 3}
++!1 = !{}
diff --git a/third_party/llvm/workspace.bzl b/third_party/llvm/workspace.bzl
index d69e2a7..7346ba5 100644
--- a/third_party/llvm/workspace.bzl
+++ b/third_party/llvm/workspace.bzl
@@ -4,8 +4,8 @@ load("//third_party:repo.bzl", "tf_http_archive")
 
 def repo(name):
     """Imports LLVM."""
-    LLVM_COMMIT = "23bf98e4b5b763534ec568c792989e83de580b04"
-    LLVM_SHA256 = "df38223674c2e4cd5666eb964332304f7fc75f85c7f20aaa41c477ca290eff00"
+    LLVM_COMMIT = "64046e9d2628ce421682eea8465e41554b46c96d"
+    LLVM_SHA256 = "8720a7b2c0af291de7758e321f2f767055272b4c0369f7449522366d7e351424"
 
     tf_http_archive(
         name = name,
