--- a/third_party/amd/lib/TritonAMDGPUTransforms/AccelerateAMDMatmul.cpp
+++ b/third_party/amd/lib/TritonAMDGPUTransforms/AccelerateAMDMatmul.cpp
@@ -380,9 +380,17 @@ Value convertAndCastTensor(PatternRewriter &rewriter, Value value,
     else if (oldElemType.isF32() && newElemType.isF16())
       castedTensor =
           rewriter.create<arith::TruncFOp>(loc, castedType, convertedTensor);
-    else
-      castedTensor =
-          rewriter.create<tt::FpToFpOp>(loc, castedType, convertedTensor);
+    else {
+      if(oldElemType.getIntOrFloatBitWidth() > newElemType.getIntOrFloatBitWidth()) {
+        auto rmode =
+           RoundingModeAttr::get(rewriter.getContext(), RoundingMode::RTNE);
+        castedTensor =
+          rewriter.create<tt::FpToFpOp>(loc, castedType, convertedTensor, rmode);
+      } else {
+        castedTensor =
+            rewriter.create<tt::FpToFpOp>(loc, castedType, convertedTensor);
+      }
+    }
   }
   return castedTensor;
 }
 