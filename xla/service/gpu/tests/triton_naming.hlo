// RUN: hlo-opt %s --platform=gpu --stage=llvm-before-optimizations --xla_gpu_target_config_filename=%S/../../../backends/gpu/target_config/specs/%{GPU}.txtpb | FileCheck --check-prefixes=CHECK-%{PTX} %s

// CHECK-PTX: define ptx_kernel void @triton_gemm_r(
// CHECK-GCN: define amdgpu_kernel void @triton_gemm_r(

HloModule t, is_scheduled=true, entry_computation_layout={(f16[15,19],s8[19,17])->f16[15,17]}

dot_computation {
  p1 = f16[15,19] parameter(1)
  p0 = s8[19,17] parameter(0)
  convert = f16[19,17] convert(p0)
  ROOT dot = f16[15,17] dot(p1, convert), lhs_contracting_dims={1}, rhs_contracting_dims={0}, backend_config={"sizes":["64"]}
}

ENTRY e (p0: f16[15,19], p1: s8[19,17]) -> f16[15,17] {
  p1 = s8[19,17] parameter(1)
  p0 = f16[15,19] parameter(0)
  ROOT triton_gemm_r = f16[15,17] fusion(p1, p0),
    kind=kCustom, calls=dot_computation, backend_config={
      fusion_backend_config:{
        kind:"__triton_nested_gemm_fusion",
        block_level_fusion_config:{
          output_tiles:[{sizes:[64,32]}],
          num_stages:2,
          num_warps:8,
          num_ctas:1
        }
      }
    }
}
