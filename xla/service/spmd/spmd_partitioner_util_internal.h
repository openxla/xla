/* Copyright 2024 The OpenXLA Authors.

Licensed under the Apache License, Version 2.0 (the "License");
you may not use this file except in compliance with the License.
You may obtain a copy of the License at

    http://www.apache.org/licenses/LICENSE-2.0

Unless required by applicable law or agreed to in writing, software
distributed under the License is distributed on an "AS IS" BASIS,
WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
See the License for the specific language governing permissions and
limitations under the License.
==============================================================================*/

#ifndef XLA_SERVICE_SPMD_SPMD_PARTITIONER_UTIL_INTERNAL_H_
#define XLA_SERVICE_SPMD_SPMD_PARTITIONER_UTIL_INTERNAL_H_

#include <cstdint>
#include <optional>
#include <vector>

#include "absl/types/span.h"
#include "xla/hlo/ir/hlo_sharding.h"
#include "xla/hlo/ir/replica_group.h"

namespace xla {
namespace spmd {

// Generates partition groups (groups of devices that will communicate via a
// collective) from sharding and provided replication_dims.
// Callers should use GetPartitionGroupsForReplication instead of this function.
CollectiveDeviceList GetListOfListsPartitionGroupsForReplication(
    const HloSharding& sharding, absl::Span<const int64_t> replication_dims);

// Generates partition groups (groups of devices that will communicate via a
// collective) in iota format from sharding and provided replication_dims.
// NOTE: If provided sharding does not utilize all the partitions, we skip
// generating a compressed format. This is because this device ids
// (IotaReplicaGroupList) generated by this method are partition ids, but later
// they have to be expanded across replicas into global device ids (see
// ExpandPartitionGroupListAcrossReplicas) before they are inserted into a
// collective. The expansion to global device ids while retaining the compressed
// format is only possible if the device list generated covers all partitions.
// The generated device list can cover all partitions if the provided
// sharding covers all partitions.
// Callers should use GetPartitionGroupsForReplication instead of this function.
std::optional<IotaReplicaGroupList> GetIotaPartitionGroupsForReplication(
    const HloSharding& sharding, absl::Span<const int64_t> replication_dims);

// Generates mesh-based (V3) partition groups for replication across the axes
// corresponding to the provided replication dims.
// Callers should use GetPartitionGroupsForReplication instead of this function.
std::optional<MeshAxesReplicaGroupList>
GetMeshAxesPartitionGroupsForReplication(
    const HloSharding& sharding, absl::Span<const int64_t> replication_dims);

// Generates partition groups (groups of devices that will communicate via a
// collective) across provided target dims with provided group sizes in vector
// of vector format (legacy format).
CollectiveDeviceList GetListOfListsPartitionGroupsAcrossTargetDims(
    const HloSharding& sharding, absl::Span<const int64_t> target_dims,
    absl::Span<const int64_t> group_sizes);

// Generates partition groups (groups of devices that will communicate via a
// collective) across provided target dims with provided group sizes in iota
// format from sharding.
std::optional<IotaReplicaGroupList> GetIotaPartitionGroupsAcrossTargetDims(
    const HloSharding& sharding, absl::Span<const int64_t> target_dims,
    absl::Span<const int64_t> group_sizes);

// Generates mesh-based (V3) partition groups across the provided target dims
// with the provided group sizes. The group sizes must divide their
// corresponding target dims. Assuming that the hlo sharding has mesh axis
// sizes [d1,d2,...dn], the target dims are [a,b,...d] and the group sizes are
// [ga,gb,...gd] then ga must divide da, gb must divide db, etc. This is
// equivalent to replicating across the list of sub-axes
// [a:(da/ga)ga, b:(db/gb)gb, ... d:(dn/gd)gd].
std::optional<MeshAxesReplicaGroupList>
GetMeshAxesPartitionGroupsAcrossTargetDims(
    const HloSharding& sharding, absl::Span<const int64_t> target_dims,
    absl::Span<const int64_t> group_sizes);

}  // namespace spmd
}  // namespace xla

#endif  // XLA_SERVICE_SPMD_SPMD_PARTITIONER_UTIL_INTERNAL_H_
